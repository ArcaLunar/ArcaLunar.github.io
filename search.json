[{"title":"image-text-database","path":"/image-text-database/","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"软件工程：UML","path":"/swe-uml/","content":"Summary of “UML in Object-Oriented Analysis” 1. Purpose of UML in Analysis Modeling Goals: Understand the problem domain and provide a basis for design. Communicate design ideas efficiently among developers. Identify defects and omissions in specifications and designs before coding. Speed and Clarity: UML diagrams are faster to sketch than code and serve as a common language for developers. 2. UML Diagram Types Structure Diagrams: Class Diagrams: Model static structure (classes, attributes, relationships). Object Diagrams: Represent instances of classes at a specific point in time. Composite Structure Diagrams: Show internal structure of objects and collaborations. Behavior Diagrams: Activity Diagrams: Model workflows or business processes. State Machine Diagrams: Describe state transitions of objects. Interaction Diagrams: Sequence Diagrams: Depict object interactions over time. Communication Diagrams: Show message flows between objects. 3. Class Diagrams: Core of Domain Modeling Components: Classes: Named boxes with attributes (data) and operations (methods). Associations: Relationships between classes (e.g., Customer ↔ Order). Multiplicity: Defines cardinality (e.g., 1..* = “one or more”). Navigability: Direction of association (arrows). Domain Model: Represents problem-domain concepts (e.g., Product, Transaction, User). Focuses on conceptual classes (not implementation details). Steps to Build: Identify Classes: Use noun phrases from requirements and category lists (e.g., “Transaction,” “Record”). Define Attributes: Simple values (e.g., price, date). Avoid complex data as attributes (e.g., Address should be a class). Model Associations: Only meaningful relationships (e.g., Order contains OrderLineItems). 4. Best Practices for Class Diagrams Keep It Simple: Omit trivial associations to avoid clutter. Prioritize “need-to-know” relationships. Multiplicity Constraints: Use 1, 0..1, * (unbounded), or n (specific number) to define valid instances. Association Classes: Resolve many-to-many relationships by adding a class (e.g., Reservation between Customer and Flight). Example: SkillLevel between GameCharacter and Skill to track proficiency levels. 5. Domain Modeling Techniques Techniques for Identifying Classes: Noun/Phrase Extraction: Extract nouns from requirements (e.g., “Product Catalog” from “view products”). Category List: Use predefined categories (e.g., “Transaction,” “Container,” “Role”). Avoid Overcomplication: Do not model every relationship (e.g., ignore transient interactions like “Developer estimated PBI”). Focus on persistent relationships (e.g., PBI belongs to a Product Backlog). 6. Example: Domain Model for a POS System Key Classes: Customer, Cashier, Product, Sale, CashPayment. Associations: Sale contains SalesLineItems (multiplicity 1..*). Product is described by ProductDescription. Attributes: Sale has dateTime, total, and CashPayment (optional). 7. UML in Agile Development Iterative Approach: Build domain models incrementally, focusing on current user stories. Alignment with Implementation: Domain models inform REST API endpoints (e.g., shuttlebuses endpoint from ShuttleBus class). 8. Common Pitfalls Over-Simplification: Modeling complex data (e.g., Address) as attributes instead of classes. Over-Modeling: Including transient or unimportant relationships (e.g., Developer ↔ PBI for estimation). 9. Conclusion UML is a foundational tool for analyzing and designing software systems. Class diagrams are central to modeling problem domains and translating them into solutions. Proper use of UML reduces defects, clarifies requirements, and supports agile development practices. This summary captures the document’s focus on UML’s role in analysis, key diagrams, domain modeling techniques, and practical best practices."},{"title":"软件工程：Software Requirement Specification","path":"/swe-srs/","content":"Summary of “Software Requirements: Introduction” 1. Core Challenges in Requirements Engineering Key Issue: Understanding the problem the system must solve, often derived from customer/end-user needs. Challenges: Developers may misunderstand the business problem, leading to incorrect solutions. Customers/users may not clearly articulate their needs (especially problematic in predictive models like Waterfall). Developers must align software with end-users’ workflows to ensure practicality. 2. Drivers of Requirements Custom Software (Project-Based): Requirements driven by specific clients (e.g., government, enterprise tools). Contractual obligations dictate functionality and delivery timelines. Ownership transfers to the client post-delivery. Software Products: Requirements originate from the company’s vision/opportunity (e.g., apps, productivity tools). Developers prioritize features and constraints without a specific client’s contractual demands. Continuous evolution: Features can be added/removed post-release. 3. Types of Requirements Information Business Requirements: High-level organizational objectives (e.g., “Increase customer satisfaction”). Business Rules: Policies/constraints (e.g., pricing policies). Stored in a Business Rules Catalogue, not part of the SRS itself. User Requirements: Tasks users must perform or desired attributes (e.g., “Users want to check in online”). Functional Requirements: Specific behaviors the system must perform (e.g., “The system shall calculate fuel quantity”). Features: Bundles of related functional requirements (e.g., “User Authentication Feature”). System Requirements: Top-level/system-wide requirements (e.g., integration with hardware). Non-Functional Requirements: Properties like performance, security, usability (e.g., “Authorization must take ≤2 seconds”). External Interface Requirements: Connections to users, systems, or hardware (e.g., “JSON format for data exchange”). Constraints: Restrictions on development (e.g., “Use open-source libraries only”). 4. Business Rules Management Documentation: Rules are recorded in tables with: Rule ID, Rule Description, Volatility (how often they change), and Source (e.g., company policy). Example: Delivery pricing rules for an e-commerce system. Impact: Influence functional/non-functional requirements (e.g., permissions, UX design). 5. Software Requirements Specification (SRS) Purpose: Formal document outlining all functional and non-functional requirements. Structure: Introduction: Purpose, scope, conventions. Overall Description: Product context, user classes, constraints. System Features: Detailed functional requirements (e.g., “The system shall…”). Data Requirements: Logical models, reports, data retention policies. External Interfaces: User, software, hardware, and communication interfaces. Quality Attributes: Usability, performance, security, safety. Appendices: Glossary, analysis models. Formality: Varies by system criticality (e.g., strict for avionics vs. informal for web apps). Example: Flight Management System (FMS) requirements trace from system to low-level software specs (e.g., fuel quantity display in pounds/kilograms). 6. Requirements Traceability Critical in Safety-Critical Systems (e.g., aviation): Requirements must be bi-directionally traceable (e.g., from system to code). Example: FMS fuel quantity requirements linked to sensor polling intervals and data validity checks. DO-178C Compliance: Mandates traceability for airborne software. 7. Agile Requirements Management Alternatives to Traditional SRS: Vision and Scope Document: High-level goals and constraints. Product Backlog: Prioritized user stories/use cases with acceptance criteria. Dynamic Updates: Requirements evolve iteratively (e.g., user stories refined during sprints). Working Software: Focus on delivering increments over exhaustive documentation. Example: User stories for a flight check-in system (e.g., “As a passenger, I want to print boarding passes after check-in”). 8. Key Takeaways Requirement Types: Differentiate between business rules, user needs, functional/non-functional requirements. Documentation: Formal SRS for critical systems; agile backlogs for product development. Traceability: Essential for compliance and defect prevention in safety-critical domains. Agile Adaptation: Prioritize collaboration, iterative delivery, and flexibility over rigid planning. This summary captures the document’s focus on understanding requirements, their classification, documentation practices, and the shift toward agile methodologies for modern software development."},{"title":"软件工程：Software Process Model","path":"/swe-software-process-model/","content":"Summary of “Software Process and Activities: Process Models” 1. Introduction to Software Development Lifecycle (SDLC) SDLC: A structured sequence of development activities and tasks, organized into phases. Companies may adapt these models, but they generally fall into predictive or adaptive categories. Predictive Models: Plan all phases upfront (e.g., Waterfall). Emphasize control, documentation, and fixed requirements. Adaptive Models: Respond to change iteratively (e.g., Agile). Focus on flexibility, customer collaboration, and empirical process control. 2. Predictive Models: The Waterfall Model Structure: Linear, sequential phases: Requirements → 2. Design → 3. Implementation → 4. Testing → 5. Deployment → 6. Maintenance Key Features: Heavyweight Documentation: Formal plans and deliverables (e.g., requirements specs, design docs, test reports). Phase Dependency: A phase cannot start until the prior phase is completed and accepted. No re-entry once finalized. Milestones: Major deliverables reviewed at each phase to ensure completion. Advantages: Clear visibility, management control, and contractual clarity for mission-critical systems (e.g., aerospace, healthcare). Aligns with regulatory standards (e.g., DO-178C for airborne software). Disadvantages: Rigid: Cannot easily accommodate requirement changes or design flaws discovered late. Late Validation: Customers see a working product only at the end, risking undetected defects (cost to fix defects rises exponentially as development progresses). Inflexibility: Feedback loops require costly rework, often leading to frozen deliverables. 3. Adaptive Models: Agile and Empirical Process Control Core Principles: Transparency: Shared understanding of progress and goals. Inspection: Regular reviews of work and processes. Adaptation: Adjustments based on new knowledge. Iterative &amp; Incremental Development: Iterations (Sprints): Short, time-boxed cycles (e.g., 1–2 weeks in Scrum) delivering potentially releasable increments. Phases per Iteration: Each cycle includes planning, design, implementation, integration, testing, and review. Flexibility: Goals set at iteration start; requirements evolve over time. Benefits: Early and frequent customer feedback reduces late-stage defects. Handles uncertainty and complexity in innovative projects. Prioritizes working software over exhaustive documentation. Drawbacks: Overhead may outweigh benefits for simple, low-risk projects with stable requirements. 4. Product-Based vs. Project-Based Development Custom Software (Project-Based): Developed for specific clients (e.g., government systems, enterprise tools). Follows predictive models (e.g., Waterfall) for contractual clarity and stability. Ownership transfers to the client post-delivery. Software Products: Mass-market solutions (e.g., apps, productivity tools). Prioritizes time-to-market over rigid planning. Agile frameworks dominate due to rapid iteration and competition. Self-Managed Teams: No traditional project manager; roles like Product Owner (prioritizes backlog) and Scrum Master (facilitates process) are key. Continuous Development: Treated as ongoing processes, not discrete projects. 5. CHAOS Report Insights on Project Management Non-Agile Projects: Success rates vary with project manager skill, but bureaucracy and slow decision-making hinder outcomes. Agile Projects: Traditional project managers reduce success rates due to process overhead. Conclusion: Agile thrives without hierarchical project managers. Avoid tools like EPPM (Enterprise Project Portfolio Management) that introduce bureaucracy. Key Takeaway: “Software is infinite, while projects are finite.” Modern development should avoid artificial project boundaries and focus on continuous delivery. 6. When to Use Each Model Predictive Models (Waterfall): Appropriate for: Safety-critical systems, stable requirements, long-term contracts, and regulatory compliance. Risks: Fails in dynamic environments or when requirements are unclear. Adaptive Models (Agile): Appropriate for: Product development, innovative projects, evolving requirements, and complex problem-solving. Risks: Overhead for simple projects; requires disciplined team collaboration. 7. Conclusion Modern Trends: Shift toward product-based, Agile methodologies due to faster iteration, customer-centricity, and adaptability. Process Selection: Choose models based on project complexity, risk, and requirements stability. Predictive models remain viable for specific domains (e.g., aerospace), while Agile dominates in competitive, evolving markets. This summary encapsulates the document’s contrast between predictive and adaptive models, their strengths/weaknesses, and the industry’s move toward Agile for product development."},{"title":"multi-thread","path":"/multi-thread/","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"Linux 下用 HKU 账号使用 HK eduroam WiFi","path":"/connect-to-eduroam-hku/","content":"eduroam 我是 Linux Mint 系统，所以 Ubuntu/Mint 应该比较通用。 Option Value Security WPA &amp; WPA2 Enterprise Authentication Protected EAP (PEAP) Anonymous Identity 留空 Domain hku.hk CA Certificate 选 (None)，勾选 No CA Certificate is required PEAP version Automatic Inner Authentication MSCHAPv2 Username &lt;UID&gt;@hku.hk，&lt;UID&gt; 是邮箱 @ 前的部分，这里后缀必须是 @hku.hk Password Portal 的登录密码"},{"title":"Docker Introduction","path":"/docker-intro/","content":"Dockerfile Docker Image 编写完 Dockerfile 后，我们可以用命令创建一个 docker 镜像 1docker build -t [镜像名称] [Dockerfile 所在目录] 启动 container 还需要一个 container 才能运行起来 1docker run -p [映射到主机的哪个端口]:[容器内的哪个端口] -d [镜像名称] -p：指定端口 -d：后台运行。想要查看终端输出的话需要到 docker desktop 里查看 用 Volume 保存 container 的数据 利用 -v 参数，把本地文件夹 ~/A 挂载到 container 里的 .../B，这样在 container 里读写 .../B 其实等于读写 ~/A. 我们先创建一个数据卷 1docker volume create [数据卷位置] 然后在 docker run 的时候进行挂载 1docker run -v [数据卷在本地的位置]:[数据卷在容器里的位置] -d [镜像名称] Docker Compose 多个容器共同协作：例如数据库和前端分离。 在 docker-compose.yml 里用 services 进行定义 12345678910111213# docker-compose.ymlservices: # 定义前端和数据库 front-end: # 前端 build: . # 镜像——从文件夹构建 ports: # 端口映射 - &quot;80:5000&quot; database: # 数据库 image: &quot;mysql&quot; # 镜像——从其他地方拉取 environment: # 可以定义环境变量 OPENAI_API_KEY: &quot;...&quot; OPENAI_API_BASE: &quot;&quot; volumes: # 数据卷，等同于 -v 参数 - &quot;~/A:.../B&quot; 定义完毕后，使用 1docker compose up -d 来运行所有的 container 1docker compose down 来停止并删除所有的 container"},{"title":"本地部署 llama.cpp 大模型服务器并连接","path":"/local-deploy/","content":"llama.cpp 的安装、编译 alternative: llama-cpp-python 提供了 llama.cpp 的 Python 接口。通过 llama-cpp-python 也可以启动一个 LLM Server 启动一个 LLM server 直接在命令行里输入启动服务器 1llama-server -m [模型路径] --port 8080 模型要保证必须是 .gguf 格式，可以使用 llama.cpp 项目根目录下的 convert_hf_to_gguf.py 进行转换。 convert_hf_to_gguf&nbsp;食用方法 配置好虚拟环境后，命令行里输入 1python convert_hf_to_gguf.py [模型.bin文件所在的目录] 这个目录末尾应该是哈希码，例如 ~/.cache/huggingface/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/ad9f0ae0864d7fbcd1cd905e3c6c5b069cc8b562 连接 如果用 LangChain 进行连接，必须注意要输入 http://localhost:8080 的 http://（被坑了）"},{"title":"About Me","path":"/about/index.html","content":"About Me"},{"title":"强化学习：Markov Chain 与贝尔曼方程","path":"/wiki/rl/rl-bellman-equation.html","content":"我们定义： 机器人所处于的状态为 state s∈Ss \\in \\mathbb Ss∈S。S\\mathbb SS 表示机器人所有可能的状态 机器人采取的行动为 action a∈Aa \\in\\mathbb Aa∈A。A\\mathbb AA 表示机器人所有可能采取的行动 Markov Chain 给定当前状态，未来和过去互相独立，且采取的行动只和当前状态有关 st+1∈St+1∼Distribution(at,st)s_{t+1}\\in\\mathbb S_{t+1}\\sim\\text{Distribution}( a_t,s_t) st+1​∈St+1​∼Distribution(at​,st​) 状态空间中的每一个状态都有一定概率被转移到，因此我们用概率进行建模，即 T(s,a,s′)T(s,a,s&#x27;) T(s,a,s′) Markov Decision Process 因此进一步定义： 世界（环境）模型 T(s,a,s′)T(s,a,s&#x27;)T(s,a,s′)，表示++机器人在状态 sss 时，如果采取 aaa 行动，那么有 T(s,a,s′)T(s,a,s&#x27;)T(s,a,s′) 的概率进入状态 s′s&#x27;s′。++这个模型也就是机器人与环境交互的入口 奖励函数 R(s,a,s′)R(s,a,s&#x27;)R(s,a,s′)，表示如果机器人在状态 sss 时采取 aaa 行动并进入状态 s′s&#x27;s′，就能获得 R(s,a,s′)R(s,a,s&#x27;)R(s,a,s′) 的奖励。 我们希望，机器人在世界模型和奖励函数（这两个是事先给定的）中，学习到在某个环境下该采取何种行动这一个 objective，这样一个 objective 的数学本质是 π:S↦A\\pi:\\mathbb S\\mapsto\\mathbb Aπ:S↦A，即 π(s)=a\\pi(s)=aπ(s)=a，函数输入状态，输出该采取什么行动。我们把这个 π(s)\\pi(s)π(s) 称为 Policy How to Learn a Policy Evaluation 很显然，我们需要一个 criterion 才能评判一个 Policy 到底好不好。 当我们的机器人根据 πi()\\pi_i()πi​() 运行了一段时间后，会得到一连串的 Reward 和一个 Accumulative Reward，而由于世界模型是概率模型，因此同一个 πi()\\pi_i()πi​() 可能会产生不同的 Reward Sequence 和不同的 Accumulative Reward。 我们也要考虑步数的影响（不然机器人来回踱步刷分数），因此引入 Discount，在每一步的 Reward 上乘的衰减系数 γ\\gammaγ，表明 Reward 随着步数的增长而减少。 我们在此基础上定义，即为 Policy 的 Utility 为 Reward 的期望值。 State 的 Utility 为从这个 State sss 出发的 Expected Utility，即为 V(s)V(s)V(s)，用上标 ∗\\ast∗ 表示最优策略 MDP Search Tree MDP Search Tree Value of State 定义： Q-State 为机器人选择完行动后，但还没有执行（还没有转移到 s′s&#x27;s′）的中间状态。 根据这棵树的结构可以推导出 V∗(s)=max⁡aQ∗(s,a)Q∗(s,a)=∑s′T(s,a,s′)[R(s,a,s′)+γV∗(s′)]so we get…⟹V∗(s)=max⁡a∑s′T(s,a,s′)[R(s,a,s′)+γV∗(s′)]\\begin{aligned} V^\\ast(s)&amp;=\\max_a Q^\\ast(s,a)\\\\ Q^\\ast(s,a)&amp;=\\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V^\\ast(s&#x27;)\\Big]\\\\ &amp;\\textbf{so we get}\\dots\\\\ \\Longrightarrow V^\\ast(s)&amp;=\\max_a \\sum_{s&#x27;}T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V^\\ast(s&#x27;)\\Big] \\end{aligned} V∗(s)Q∗(s,a)⟹V∗(s)​=amax​Q∗(s,a)=s′∑​T(s,a,s′)[R(s,a,s′)+γV∗(s′)]so we get…=amax​s′∑​T(s,a,s′)[R(s,a,s′)+γV∗(s′)]​ 求解 Policy 从 V(s) 求解 policy 数值迭代算法 从 V0(s)=0V_0(s)=0V0​(s)=0 开始 用上一次的 Vt(s)V_t(s)Vt​(s) 更小当次的 Vt+1(s)V_{t+1}(s)Vt+1​(s) Vt+1(s)←max⁡a∑s′T(s,a,s′)[R(s,a,s′)+γVt(s′)]V_{t+1}(s)\\gets \\max_a\\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V_t(s&#x27;) \\Big] Vt+1​(s)←amax​s′∑​T(s,a,s′)[R(s,a,s′)+γVt​(s′)] 这里的 γ\\gammaγ 表示步数的 Discount 直到收敛 V∗(s)V^\\ast(s)V∗(s)，时间复杂度 O(S2A)O(S^2A)O(S2A) 从 V∗(s)V^\\ast(s)V∗(s) 提取 Policy π∗(s)=arg max⁡a∑s′T(s,a,s′)[R(s,a,s′)+γV∗(s′)]\\pi^\\ast(s)=\\argmax_a\\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V^\\ast(s&#x27;) \\Big] π∗(s)=aargmax​s′∑​T(s,a,s′)[R(s,a,s′)+γV∗(s′)] 为每一个 state 选择一个 action 策略迭代算法 当 Policy 固定为 πi()\\pi_i()πi​() 时，此时不用考虑最优策略，等同于不需要取 max⁡a\\max_amaxa​，因此从 state sss 出发的 expected utility 就只有单纯的求和了，为 Vπi(s)=∑s′T(s,πi(s),s′)[R(s,πi(s),s′)+γVπi(s′)]V^{\\pi_i}(s)=\\sum_{s&#x27;} T(s,\\pi_i(s),s&#x27;)\\Big[R(s,\\pi_i(s),s&#x27;)+\\gamma V^{\\pi_i}(s&#x27;)\\Big] Vπi​(s)=s′∑​T(s,πi​(s),s′)[R(s,πi​(s),s′)+γVπi​(s′)] Policy Evaluation. 为选定的 Policy 计算 Utility（非 Optimal Utility） Vt+1πi(s)←∑s′T(s,πi(s),s′)[R(s,πi(s),s′)+γVtπi(s′)]V_{t+1}^{\\pi_i}(s)\\gets \\sum_{s&#x27;}T(s,\\pi_i(s), s&#x27;)\\Big[R(s,\\pi_i(s),s&#x27;)+\\gamma V^{\\pi_i}_{t}(s&#x27;) \\Big] Vt+1πi​​(s)←s′∑​T(s,πi​(s),s′)[R(s,πi​(s),s′)+γVtπi​​(s′)] Policy Improvement. 优化 Policy πt+1(s)←arg max⁡a∑s′T(s,a,s′)[R(s,a,s′)+γVπi(s′)]\\pi_{t+1}(s)\\gets \\argmax_a \\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V^{\\pi_i}(s&#x27;) \\Big] πt+1​(s)←aargmax​s′∑​T(s,a,s′)[R(s,a,s′)+γVπi​(s′)] 直到 Policy 收敛 从 Q∗(s,a)Q^\\ast(s,a)Q∗(s,a) 提取 Policy π∗(s)=arg max⁡aQ∗(s,a)\\pi^\\ast(s)=\\argmax_a Q^\\ast(s,a) π∗(s)=aargmax​Q∗(s,a) 从 Q-State 求解 Policy Q∗(s,a)=∑s′T(s,a,s′)[R(s,a,s′)+γmax⁡a′Q∗(s′,a′)]Q^\\ast(s,a)=\\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma\\max_{a&#x27;}Q^\\ast(s&#x27;,a&#x27;) \\Big] Q∗(s,a)=s′∑​T(s,a,s′)[R(s,a,s′)+γa′max​Q∗(s′,a′)] 提取 Policy： π∗(s)=arg max⁡aQ∗(s,a)\\pi^\\ast(s)=\\argmax_a Q^\\ast(s,a) π∗(s)=aargmax​Q∗(s,a) Summary","categories":[null]},{"title":"Bonds","path":"/wiki/fina/bonds.html","content":"Bonds 债券 不拥有 Ownership 不能投票 无论是否盈利，盈利多少，企业都必须支付本息；否则视为破产 有法律义务支付本息 企业先支付本息，再支付分红 由于支付利息视作企业运营的开支，因此可以抵扣税款 Terms Maturity Date Face Value (Par Value) FFF Coupon Payment CCC Variations Zero-Coupon Bonds: 无利息 Bond Valuation NPV Approach Yield to Maturity (YTM) YTM 使得债券 NPV 为 000 时的 discount rate 假设一年付 mmm 次，那么每次付的比率是 YTMm\\frac{YTM}{m}mYTM​；假设 nnn 年 −P0+C×1−(1+YTM/m)−nmYTM/m+F×(1+YTM/m)−nm=0-P_0+C\\times\\frac{1-(1+YTM/m)^{-nm}}{YTM/m}+F\\times\\Big( 1+YTM/m \\Big)^{-nm}=0 −P0​+C×YTM/m1−(1+YTM/m)−nm​+F×(1+YTM/m)−nm=0 The investors are getting an annual rate of return equal to the return they require on the investment The YTM can be obtained ONLY IF we hold the bond until maturity Risk of Investment 债券投资的风险 利率风险：市场利率上升导致债券价格下跌。 信用风险：发行人违约可能性（如公司破产）。 流动性风险：债券难以快速变现。 通胀风险：通胀削弱固定收益的实际购买力。"},{"title":"Valuation of Stocks","path":"/wiki/fina/valuation-of-stocks.html","content":"Stock 股票 拥有对企业的所有权 Ownership 可以投票 以分红的形式分享利益 没有法律义务支付一定数额的分红 企业先付 bonds 产生的利息，再支付分红 支付的分红不能用于抵扣税款 Dividend Discount Model (DDM 模型) stock 会产生分红现金流， PV of Dividend Stream=∑i=1+∞Di(1+R)i\\text{PV of Dividend Stream}=\\sum_{i=1}^{+\\infin}\\frac{D_i}{(1+R)^i} PV of Dividend Stream=i=1∑+∞​(1+R)iDi​​ 也被称为 funcdamental value of stock. 在市场完全竞争的情况下，价格 P0=PV of Dividend StreamP_0=\\text{PV of Dividend Stream}P0​=PV of Dividend Stream. 这个模型被称为 Dividend Discount Model. Special Case 1: 恒常分红现金流 当 Di=DjD_i=D_jDi​=Dj​ 时，通过等比数列求和可以简便地计算 P0P_0P0​ P0=D1RP_0=\\frac{D_1}{R} P0​=RD1​​ Special Case 2: 现金流等比增长 也被称为 Gordon’s Growth Model，设分红以每年 ggg 的速度增长，即 Di=(1+g)Di−1D_i=(1+g)D_{i-1}Di​=(1+g)Di−1​，则有 P0=D1R−gP_0=\\frac{D_1}{R-g} P0​=R−gD1​​ 一些指标 Dividend Yield 计算产生的分红 Dividend Yield=D1P0\\text{Dividend Yield}=\\frac{D_1}{P_0} Dividend Yield=P0​D1​​ Capital Gains Yield 如果在 ttt 时刻卖出 stock，可以计算获得的资本 Capital Gains Yield=Pt−P0P0\\text{Capital Gains Yield}=\\frac{P_t-P_0}{P_0} Capital Gains Yield=P0​Pt​−P0​​ Common vs. Preferred Common stock 有投票权 Preferred stock 享有优先分红的权利 由于 Preferred stock 的期限是无穷的，我们可以直接按 Perpetual Bond 来看待。如果每年分红 DpD_pDp​，利率 RpR_pRp​，初始股价 P0P_0P0​，根据 DDM 模型，有 P0=DpRpP_0=\\frac{D_p}{R_p} P0​=Rp​Dp​​"},{"title":"Q Learning","path":"/wiki/rl/q-learning.html","content":"Q-Learning 我们的 Agent 每次从环境接收 transition=(s,a,r,s′)\\texttt{transition}=(s,a,r,s&#x27;)transition=(s,a,r,s′) 的反馈，以此进行学习。由于无法建模出转移概率 T(s,a,s′)T(s,a,s&#x27;)T(s,a,s′)，我们用采样的方式（蒙特卡洛）来训练 Qt+1(s,a)←(1−α)Qt(s,a)+α[R(s,a,s′)+γmax⁡a′Qt(s′,a′)]Q_{t+1}(s,a) \\gets (1-\\alpha)Q_{t}(s,a)+\\alpha\\Big[ R(s,a,s&#x27;)+\\gamma \\max_{a&#x27;} Q_t(s&#x27;,a&#x27;) \\Big] Qt+1​(s,a)←(1−α)Qt​(s,a)+α[R(s,a,s′)+γa′max​Qt​(s′,a′)] 这个式子也可以等价地写作 Qt+1(s,a)←Qt(s,a)+α[r+γmax⁡a′Qt(s′,a′)−Qt(s,a)]Q_{t+1}(s,a)\\gets Q_t(s,a)+\\alpha\\Big[ r+\\gamma \\max_{a&#x27;}Q_t(s&#x27;,a&#x27;)-Q_t(s,a) \\Big] Qt+1​(s,a)←Qt​(s,a)+α[r+γa′max​Qt​(s′,a′)−Qt​(s,a)] Approx Q-Learning 在 Approx Q-Learning 算法里，我们把 Q(s,a)Q(s,a)Q(s,a) 分解为多个关于 state sss 和行动 aaa 的 feature\\tt featurefeature 之线性组合（feature\\tt featurefeature 不一定需要和 s,as,as,a 成线性） Q(s,a)=∑iwi×fi(s,a)\\boxed {Q(s,a)=\\sum olimits_i w_i \\times f_i(s,a)} Q(s,a)=∑i​wi​×fi​(s,a)​ 令当次从环境的采样为 (s,a,s′,r)(s,a,s&#x27;,r)(s,a,s′,r)，表示从状态 sss 执行动作 aaa 转移到状态 s′s&#x27;s′ 得到奖励 rrr，定义 Sample Difference 为 Δ=r+γmax⁡a′Q(s′,a′)−Q(s,a)\\Delta=r+\\gamma\\max_{a&#x27;}Q(s&#x27;,a&#x27;)-Q(s,a) Δ=r+γa′max​Q(s′,a′)−Q(s,a) feature weights\\texttt{feature weights}feature weights 的更新则为 wi←wi+α×Δ×fi(s,a)w_i\\gets w_i+\\alpha\\times\\Delta\\times f_i(s,a) wi​←wi​+α×Δ×fi​(s,a) 推导 核心公式 GetAction()π(s)=arg max⁡aQ(s,a)UpdateWeights()wi←wi+α×[Δ]×fi(s,a)\\begin{array}{|r|cl|} \\hline \\text{GetAction()}&amp;\\pi(s)&amp;=\\argmax_{a}Q(s,a)\\\\ \\hline \\text{UpdateWeights()}&amp;w_i&amp;\\gets w_i+\\alpha\\times[\\Delta]\\times f_i(s,a)\\\\ \\hline \\end{array} GetAction()UpdateWeights()​π(s)wi​​=argmaxa​Q(s,a)←wi​+α×[Δ]×fi​(s,a)​​ 实现代码 12345678910111213141516171819class ApproxQLearningAgent(): def __init__(self): self.gamma = # reward discount rate self.alpha = # weight update factor self.epsilon = # learning rate self.weights = &#123; &quot;f1&quot;: 0.0, # correspond to w1*f1(s,a) &quot;f2&quot;: 0.0, # correspond to w2*f2(s,a) # ... &#125; def get_legal_actions(self): &#x27;&#x27;&#x27; 获取 &#x27;&#x27;&#x27; pass def"},{"title":"Cost Benefit Analysis","path":"/wiki/microecon/cost-benefit.html","content":"Rational Decision 对每一件事进行衡量，其付出为 C(x)C(x)C(x)，获得为 B(x)B(x)B(x)，那么定义 Economic Surplus ES(x)ES(x)ES(x) 为 ES(x)=B(x)−C(x)\\boxed{ES(x)=B(x)-C(x)} ES(x)=B(x)−C(x)​ Cost Benefit Principle当且仅当 ES(x)≥0ES(x)\\ge 0ES(x)≥0 时，才会做 xxx，此时收益大于付出；否则不做。"},{"title":"Tax and Subsidy","path":"/wiki/microecon/tax-subsidy.html","content":"本章最核心的理论是，无论税收或者补贴，假设为 TTT 元，那么当达到新的平衡点时，消费者支付价格与生产者成本价格之间的差值必为 TTT 元 Pd−Ps=T\\boxed{P^d-P^s=T} Pd−Ps=T​"},{"title":"PV, FV, NPV","path":"/wiki/fina/pv-fv-npv.html","content":"PV, NPV Present Value 一笔在未来会获得的钱在当下的价值 Future Value 一笔现在的钱在未来的价值 实际上 PV 和 FV 非常简单，主要就是考虑利滚利 (Compounding of Interest)，把指数算清楚即可。 某一笔钱的 PV/FV 钱的 PV 相当于说，如果某笔 TTT 年后的钱 QQQ，且利率 rrr 保持不变，那么现在要存 PVPVPV 块钱，这样经过 TTT 年的利滚利，这 PVPVPV 块钱就变成了 QQQ 块钱。 PV×(1+r)T=QPV\\times (1+r)^T=Q PV×(1+r)T=Q 反过来，Future Value 就是，现在存的 QQQ 块钱，在 TTT 年后会变成 FVFVFV 块钱。 FV=Q×(1+r)TFV=Q\\times(1+r)^T FV=Q×(1+r)T 现金流（多笔钱）的 PV/FV 本质就是多笔钱的 FV/PV 全部换算到当前的时间点， PVaggregate=∑PViFVaggregate=∑FViPV_{aggregate}=\\sum PV_{i}\\\\ FV_{aggregate}=\\sum FV_{i}\\\\ PVaggregate​=∑PVi​FVaggregate​=∑FVi​ 由于每笔钱的利滚利时间不同，因此右式的和式通常又可以写成有限项等比数列求和的形式 Annuity, Perpetuity Perpetuity 表示永久持续的恒定现金流，用 CCC 表示每年的现金流（且第一笔现金在一年后） 必须满足两个条件： The cash flows and the interest rates are constant over time, The first cash flow occurs one year from today. 那么所有这些钱的 PV 就是 PV=∑i=1∞C×(11+r)i=Cr\\begin{aligned} PV&amp;=\\sum_{i=1}^{\\infin} C\\times(\\frac{1}{1+r})^i\\\\ &amp;=\\frac{C}{r} \\end{aligned} PV​=i=1∑∞​C×(1+r1​)i=rC​​ Present Value of Annuity 与 Perpetuity 的区别在于 Annuity 有时限。假设经过 TTT 年，那么 Annuity 的 PV 就等于 PV=C(11+r)+C(11+r)2+⋯+C(11+r)T=C×1−(11+r)TrPV=C(\\frac{1}{1+r})+C(\\frac{1}{1+r})^2+\\dots+C(\\frac{1}{1+r})^T=C\\times\\frac{1-(\\frac{1}{1+r})^T}{r} PV=C(1+r1​)+C(1+r1​)2+⋯+C(1+r1​)T=C×r1−(1+r1​)T​ 在一笔现金的时候我们知道，(11+r)T(\\frac{1}{1+r})^T(1+r1​)T 就是 Present Value Factor，所以也可以直接代入写成 PV=1−Present Value Factor(T)rCPV=\\frac{1-\\text{Present Value Factor}(T)}{r}C PV=r1−Present Value Factor(T)​C Future Value of Annuity 如果以第 TTT 年的价值作为基准，把每一笔钱的 FV 都加起来，就能得到 FV=(1+r)T−1rC=Future Value Factor(T)−1rCFV=\\frac{(1+r)^T-1}{r}C=\\frac{\\text{Future Value Factor}(T)-1}{r}C FV=r(1+r)T−1​C=rFuture Value Factor(T)−1​C Effects of Inflation 由于通胀 (Inflation) 的存在，尽管手上的钞票数量变多了，但这并不意味着购买力 (Purchasing Power) 提升。 Purchasing Power the quantity of goods and services that we can buy with our money. … on Nominal/Real Interest Rate Fisher's&nbsp;Equation Nominal IR RRR: interest rate in terms of money Real IR rrr: interest rate in terms of purchasing power 我们用 hhh 表示物价的变化，即通胀率 (Inflation Rate)，则可以得出他们之间的关系 (Fisher Equation) (1+r)(1+h)=(1+R)(1+r)(1+h)=(1+R) (1+r)(1+h)=(1+R) 证明 考虑一开始的钱 QQQ，一开始的物价 PPP，则今年的购买力为 QP\\frac{Q}{P}PQ​，明年的购买力（即经过一年的通胀）为 Q(1+R)P(1+h)\\frac{Q(1+R)}{P(1+h)}P(1+h)Q(1+R)​ 根据 Real Interest Rate 的定义，我们有 Purchase Poweri+1−Purchase PoweriPurchase Poweri=Real IRQ(1+R)P(1+h)QP=1+r(1+r)(1+h)=1+R\\begin{aligned} \\frac{\\text{Purchase Power}_{i+1}-\\text{Purchase Power}_i}{\\text{Purchase Power}_i}&amp;=\\text{Real IR}\\\\ \\frac{\\frac{Q(1+R)}{P(1+h)}}{\\frac{Q}{P}}&amp;=1+r\\\\ (1+r)(1+h)&amp;=1+R \\end{aligned} Purchase Poweri​Purchase Poweri+1​−Purchase Poweri​​PQ​P(1+h)Q(1+R)​​(1+r)(1+h)​=Real IR=1+r=1+R​ 由于这些值都很小，所以我们通常直接近似为 r≊R−hr\\approxeq R-hr≊R−h … on PV &amp; NPV Inflation 并不影响 PV 和 NPV。但必须 discount nominal cash at a nominal rate 或者 discount real cash at a real rate 证明 考虑 inflation rate 为 hhh，nominal interest rate 为 RRR，考虑 nnn 年后的一笔钱 CCC (nominal)，那么用 Nominal Interest Rate 算的话 PVnominal=C(1+R)nPV_{nominal}=\\frac{C}{(1+R)^n} PVnominal​=(1+R)nC​ 用购买力计算的话，nnn 年后的购买力为 C(1+h)n\\frac{C}{(1+h)^n}(1+h)nC​，因此 discount at a real rate 的话，即为 PVreal=C(1+h)n(1+r)nPV_{real}=\\frac{\\frac{C}{(1+h)^n}}{(1+r)^n} PVreal​=(1+r)n(1+h)nC​​ 代入 Fisher’s Equation 1+R=(1+h)(1+r)1+R=(1+h)(1+r)1+R=(1+h)(1+r) 可得 PVreal=PVnominalPV_{real}=PV_{nominal} PVreal​=PVnominal​ 因此其实并不影响 Present Value。对于 Net PV，由于基准年的金额有 Nominal=RealNominal=RealNominal=Real，因此也不影响 NPV"},{"title":"IRR","path":"/wiki/fina/IRR.html","content":"Definition The IRR of the project is the single annual discount rate at which the NPV of the project is equal to zero. 公式 NPV=C0+∑i=1m(11+IRR)iCi=0NPV=C_0+\\sum_{i=1}^{m} \\Big(\\frac{1}{1+IRR}\\Big)^i C_i=0 NPV=C0​+i=1∑m​(1+IRR1​)iCi​=0 IRR Rule 定义 Minimum required return 计算 IRRIRRIRR，与 required return 进行比较 问题 还需要将 Interest Rate 纳入考量 解决办法 先算出两个 project 的 NPV 相等时的利率 RRR，然后根据现在的利率，判断选择那个 project. Amortization Schedule monthly: IRR12\\frac{IRR}{12}12IRR​"},{"title":"Investment Decision Rule","path":"/wiki/fina/invest-decision-rule.html","content":"Investment Decision Rule … based on Returns 就是看最后拿到的钱 RewardRewardReward 是不是初始投资 InvestInvestInvest 多就行， … based on NPV NPV定义​ 净现值（Net Present Value, NPV）是评估投资项目价值的核心指标，计算方式为项目所有现金流（含初始投资）按贴现率折算后的现值总和。公式为： NPV=C0​+∑i=1TCi(1+R)iNPV=C_0​+\\sum_{i=1}^T\\frac{C_i}{(1+R)^i}NPV=C0​​+∑i=1T​(1+R)iCi​​ CtC_tCt​​: 第 ttt 期的现金流（C0C_0C0​​ 为初始成本，通常为负值）。 RRR: 贴现率（通常为金融市场可获得的回报率）。 ​决策规则​ ​NPV &gt; 0：项目收益高于金融市场回报，应接受。 ​NPV &lt; 0：项目收益低于金融市场回报，应拒绝。 ​NPV = 0：项目收益与金融市场相当，决策无差异（可结合其他因素考虑）。 ​关键原则​ ​基准比较：以金融市场回报率为基准，衡量项目是否创造额外价值。 ​现金流方向： 现金流入（收入）为正值（Ct​&gt;0）。 现金流出（成本）为负值（Ct​&lt;0）。 沉没成本忽略：过去已发生且不可逆的成本（如前期调研费用）不计入NPV，仅考虑未来现金流。 ​注意事项​ ​时间价值：现金流的时点影响现值，需准确对应贴现期数。 ​零NPV的意义：项目回报率等于贴现率（金融市场回报率），而非无收益。 总结：NPV规则通过量化项目相对于金融市场的净收益，为投资决策提供清晰标准，强调未来现金流和沉没成本的正确处理。 … based on IRR 预设项目的最少回报 (Minimum Return Required)，然后判断项目的 IRR 是否高于预期。 Internal Rate of Return (IRR) 是将单笔资金拓展到多笔资金，IRRIRRIRR 是年利率 (Annual Rate of Return)，使得整个项目周期结束后的 NPV 为零 NPV=0=C0+∑i=1T(11+IRR)iCiNPV=0=C_0+\\sum_{i=1}^T \\Big(\\frac{1}{1+IRR}\\Big)^i C_i NPV=0=C0​+i=1∑T​(1+IRR1​)iCi​ NPV&nbsp;or&nbsp;IRR 实际上，IRR 和 NPV 大致成反比关系。 Notice the role of the return from the financial sector (e.g., interest rate on bank deposit) in the NPV rule and IRR rule: in the NPV rule, it is the discount rate in the IRR rule, it is the (minimum) required return of the real investment project under consideration. conventional: 初始投资都是 cash outflow，后续所有现金流都是入账 cash inflow non-conventional: 不符合 conventional 的现金流情况 IRR Rule 的问题 当同时考虑多个项目时，先计算 xxx，使得这几个项目在 Discount Rate 为 xxx 时的 NPV 相同。 Payback Rule 考虑多久可以回本（不考虑 discount） Discounted Payback Rule 先 discount cash flow，再应用 Payback Rule Profitability Index PI=PV of future cash flowsinitial costPI=\\frac{\\text{PV of future cash flows}}{\\text{initial cost}} PI=initial costPV of future cash flows​"},{"title":"Ascend C 介绍与 NPU 芯片","path":"/wiki/ascendc/intro.html","content":"d0144f89de14a1fc384914230d36d0ec0054caf00183a222885cc88f31848a18aab140cd588bb1a31357d2dfedf6c8adfb592b49da5961aaa495123a3ccb3fa9a9f6c36e1bc55e6ff161822b769668a2076f5cfab45f196e1c53f0376e4956630c8a0923bfd91ca220c8d6a51d78be71e5b15538793255c1fcf3fbc64b80ef22508f3168feccbdaffac7faff9ec41aa90bd14105244569a56fb953d126552fc91d226fb4aa73c720ffee5e27a6e6c44331325d651b1f74c98b14d272388278d75502dfd76dee11cf4ae7c17bae192f36d0fc6097e31014e778d3ce734f793cc91d6a0cd8deee525e0a2b5df1feb19690d6cb0ed574e528834c7497615774b37a7d6a622e4a391fda0f6d046ee84fabcc6866a2fa790d0da49f405d25262fe0b227284612f2bbedafb19c35fddce7dbee9ea231f1128845e2cb4d3acb14a798c9445debfe7149b4028652944b99b85e6edd553e3657d323986791286e06611026a0b53564e9d42cb8d5930b665780169dd1f70bcc60ea6a108e7508f6b4bb904766b050f2d77edb2d92da12da5e5c4e226216b6aebe1366030bb436121c7a9f88e091b50f1553e5c3fbf3e08989b7c17a3a39de4e90112e198843ee98d7250d6cd7aa6775e73d8e3f2c10e535f76a20fb37d456d87f6666f252b1711bb852ba8ebdb2569e786dc13560eadb4ae4c42e8b5d14abef39d4ba6c5316bef5bce30910aa0dbe3bd454a7fdf5dbd7c47c034aa4008e8976343eca32e87ba156dc597cb588f4606b79ed83933468023f298250221b45caa3fbc371929526c7172ba395c9ece27b8ece80706195af6c0e7022c6f17e2b0cdd6b68406ce32e43d5bd7bc28fba6d76fe865bc8d0418149ca493a51097a7de299e67e71170344738fcfd519ce277e2a286cff0c58e2a44ea50dddf92fa061b6360d6804ef591820ebe7ead7532e594b1b2328f6deb4d87aa44f3b2c206b04e743f4062a0f3e97c1b4864b8c6d7906763512c3f64396b213ab89caf45d38c0f50f1f5f93fd38816ec6bebbca3364766f2a26cda6379849f8a480114accbaeb749a9dd5b9f6cbee7c31fcb51ff6fcf80c879e9eaa5f05c522fbc29d55095152d5c8e5f7745956c602d18cc1637d57c82ea950aad8409b557346ad1245f228a4492cdfd9274376eadf8dc24f39ecd4594177677dd558ea8a857c7beb585e8d2d780bb29be3591827a4768e7f03b285aa795a4f294b5af5c6474303a17193a9be731f2d6453374ecc65ce9bbeb3cb7eccac9708994ea7be1632ecf6be3094 Password is needed."},{"title":"Google Gemini Robotics","path":"/wiki/agentai/google-gemini-robotics.html","content":"AI&nbsp;Summary Background • Core Problem: The paper addresses the challenge of bridging the gap between state‐of‐the‐art multimodal AI models and practical robotics. Although digital AI models have achieved impressive capabilities in processing text, images, and other modalities, these models traditionally lack the embodied reasoning (i.e., the ability to understand and physically interact with the real world) required for autonomous robot control. • Current Limitations and Challenges: Existing vision–language models excel at perception and symbolic tasks, yet they fall short when it comes to physical grounding. The authors point out that current research struggles with robust spatial understanding, dexterous manipulation, safe human–robot interactions, and adapting to novel object configurations and environments. Moreover, there is an absence of standardized benchmarks that cover the nuanced set of reasoning skills needed for embodied tasks. • Real-world Needs and Theoretical Gaps: The paper underscores the necessity for general-purpose robots capable of smooth, safe, and reactive movements. There is a critical need to extend digital reasoning to handle real-world cues such as 3D geometry, object affordances, and trajectory planning. The authors identify a theoretical gap in unifying multimodal understanding (visual and language) with physical action planning. Motivation • Driving Factors Behind the New Method: The motivation comes from the desire to leverage the advanced multimodal reasoning of models like Gemini 2.0 and extend these capabilities to control physical robots. The authors aim to overcome the limitations of existing systems which are typically confined to digital domains by integrating a comprehensive embodied reasoning framework into robotics. • Shortcomings of Existing Approaches: Current practices often suffer from poor generalization when faced with unseen object types, variable settings, and complex manipulation tasks. Many existing methods lack the ability to plan sequential actions under safety constraints and cannot efficiently adapt to new robot embodiments or environments. Issues such as limited computational efficiency in planning and a narrow focus on perception without actionable outputs further drive the need for an improved, unified approach. Methodology • Core Innovation: The paper introduces the Gemini Robotics family of models––a suite of vision–language–action (VLA) systems that fuse the powerful multimodal understanding of Gemini 2.0 with a dedicated robotics layer. Two principal variants are proposed: Gemini Robotics-ER (Embodied Reasoning): Enhances the base model’s spatial and temporal reasoning to perform tasks such as object detection, 2D pointing, trajectory prediction, and top-down grasp estimation. Gemini Robotics: Extends these capabilities by incorporating robot action data to achieve high-frequency, dexterous control over physical robots. • Technical Steps and Key Components: Multimodal Input Fusion: Integrates visual inputs (images) and textual instructions, using open‐vocabulary queries to detect and localize objects in both 2D and 3D (e.g., 3D bounding boxes and multi-view correspondence). Embodied Reasoning Pipeline: Employs a chain-of-thought (CoT) prompting technique, which encourages the model to generate intermediate reasoning steps, thereby ensuring precise spatial grounding and sequential planning. (Chain-of-thought prompting is a method where the model is instructed to “think out loud” through intermediate steps before giving the final answer.) Robot Control Integration: A dedicated pipeline converts high-level planning into low-level actuation commands via a robot API, managing safe and reactive motions while adhering to physical constraints. Specialization and Adaptation: An optional fine-tuning stage enables the system to adapt to long-horizon tasks, enhance dexterity (e.g., folding or playing cards), and adjust to variations in robot embodiments such as bi-arm platforms or humanoids. • Fundamental Differences from Baseline Approaches: Unlike conventional methods that may treat perception and control as separate tasks, the Gemini Robotics models offer an end-to-end, integrated solution. By combining embodied reasoning with action data, these models generalize better to novel tasks, improve adaptation with few demonstrations, and facilitate safe control in dynamic environments. Experiments &amp; Results • Experimental Setup: The models are evaluated on several benchmarks including the newly introduced Embodied Reasoning Question Answering (ERQA) benchmark, RealworldQA, and BLINK. The experimental design encompasses tasks ranging from simple object detection to complex, dexterous manipulation tasks in both simulated and real-world scenarios. Datasets include images sourced from in-house collections and publicly available datasets like OXE, UMI Data, and MECCANO. Baseline comparisons are made against existing vision–language and diffusion-based robotics models, using performance metrics such as accuracy, success rate, and continuous progress scores. • Key Findings: Gemini 2.0 variants (Flash and Pro Experimental) achieve state-of-the-art performance across multiple benchmark evaluations, often with notable improvements when chain-of-thought prompting is used. Quantitative results show improvements in tasks like 2D pointing accuracy (measured by how well predicted points fall within ground-truth regions) and successful grasp predictions in real-world robot control. In dexterous tasks such as folding an origami fox or playing a card game, Gemini Robotics outperforms baseline models in both binary success metrics and nuanced progress scores. • Ablation and Sensitivity Analyses: The paper reports ablation studies that highlight the benefits of each component—from embodied reasoning enhancements to fine-tuning stages. Sensitivity analyses reveal that prompts such as chain-of-thought can significantly affect overall performance, and that the integrated approach provides robust improvements even under distribution shifts (e.g., novel visual variations or rephrased instructions). Effectiveness Analysis • Underlying Reasons for Success: The method’s effectiveness stems from its dual focus on robust multimodal understanding and practical action integration. By augmenting a strong foundation model with specialized embodied reasoning and robot-specific training, the system manages to bridge the digital–physical divide. In particular, the use of multi-view spatial understanding and sequential reasoning ensures continuity between perception and physical manipulation. • Critical Success Factors: Model Architecture and Training: Leveraging Gemini 2.0’s large-scale, pre-trained capabilities provides a strong foundation for embodied reasoning. Effective Data Fusion: Integrating diverse data types—including images, text, and robot sensor readings—improves generalization and adaptability. Prompting Strategies: Techniques like chain-of-thought prompting contribute to clear intermediate reasoning, enhancing the decision-making process. Safety and Adaptability Protocols: The incorporation of robot API interfaces and safety guidelines enables smooth interaction in regulated physical environments. • Potential Limitations and Applicability Boundaries: While the proposed models demonstrate impressive performance, their success is tightly coupled with the quality and diversity of training data. The system may face constraints when encountering drastically different physical environments or unanticipated object configurations. Furthermore, the reliance on comprehensive safety protocols suggests that additional work is required to ensure deployment in less structured or more variable real-world settings. Contributions • Theoretical Contributions: The paper provides a unified framework that connects high-level multimodal reasoning directly with low-level robot control. It introduces new benchmark tasks (e.g., ERQA) to evaluate embodied reasoning, setting a new standard for measuring the full spectrum of capabilities required for physical interaction. • Practical Contributions: The development of the Gemini Robotics family offers an end-to-end solution for controlling robots with diverse manipulation tasks, from dexterous object handling to adaptive task execution. Detailed model cards and open-source evaluation protocols are provided, facilitating reproducibility and further research in embodied AI. The work also contributes guidelines and best practices for ensuring safety and responsible development in robotics applications. • Implications for Future Research: This research marks a significant step toward general-purpose embodied AI. Future work can build on these findings to further enhance generalization, reduce reliance on extensive fine-tuning, and tackle more complex physical interactions. The integration of multimodal reasoning with action control paves the way for robots that can adapt to diverse, unstructured real-world environments while ensuring safe and reliable operation."},{"title":"Pi 0, A Vision-Language-Action Flow Model for General Robot Control","path":"/wiki/agentai/pi-zero.html","content":"AI&nbsp;Summary Background The paper addresses the challenge of developing a unified robot foundation model that can handle a wide range of dexterous tasks across different robot platforms. Current robot learning approaches often suffer from limited generalization, data scarcity, and brittle performance when adapting to complex practical scenarios. Existing methods typically focus on narrow tasks or use discretized models that struggle with continuous, high-frequency control. The authors identify a real-world need for models that can integrate rich semantic understanding (gained from large-scale vision-language pre-training) with fine-grained physical control to perform intricate multi-stage tasks such as laundry folding or box assembly. Motivation The direct drive behind this work is the gap between the robust, versatile behavior seen in large language and vision-language models and the limitations of current robot control systems. Existing approaches fail to meet the demands of real-world robotic manipulation due to: Limited Generalization: Models are often trained on task-specific data and do not transfer well to diverse environments or novel tasks. Discrete Outputs: Many prior methods rely on autoregressive and token-based approaches, which are not well-suited for high-frequency continuous control. Data and Recovery Challenges: Training solely on curated, high-quality data results in brittle systems that cannot efficiently recover from errors or unexpected perturbations. This motivates the integration of internet-scale semantic pre-training with a continuous action generation method, thereby combining robust, flexible understanding with high-precision control. Methodology The core innovation is the design of a vision-language-action model (π0) that unifies pre-trained semantic knowledge with a novel mechanism for continuous action prediction. Key elements include: Pre-trained VLM Backbone: The model starts with a vision-language model (VLM) pre-trained on vast internet data (e.g., PaliGemma). This allows the system to inherit rich semantic representations and language understanding. Brief explanation: A VLM (Vision-Language Model) is trained on image-text pairs to extract visual and linguistic features simultaneously. Action Expert with Flow Matching: A separate module—termed the action expert—is added to predict continuous action sequences. Instead of relying on discrete token outputs, it uses conditional flow matching. Brief explanation: Flow matching is a variant of diffusion methods where a denoising vector field is learned to progressively transform noise into data, enabling precise continuous outputs. The model predicts action chunks (e.g., 50 future steps) at once, accommodating high-frequency control (up to 50 Hz). The design employs multi-stage training where the model is first exposed to diverse, lower-quality pre-training data and later fine-tuned on high-quality, task-specific data. Architectural Separation: The transformer backbone routes standard inputs (images and language) through the pre-trained VLM segment, while robot-specific proprioceptive inputs and continuous actions are handled by an additional expert. This mixture of experts approach allows leveraging pre-existing knowledge while adapting to robotics-specific demands. Two-Phase Training Recipe: Emphasizing the importance of both data diversity and quality, the training is split into a large-scale pre-training phase (covering 10,000 hours of data across 68 tasks and 7 robot configurations) and a post-training phase that refines the model for complex downstream tasks. Experiments &amp; Results The authors evaluate their model on a wide range of dexterous manipulation tasks spanning different robots and complexities: Experimental Setup: Tasks include shirt folding, table bussing (easy and hard versions), grocery bagging, removing toast from a toaster, laundry folding, box assembly, packing eggs, and more. Diverse robot configurations such as single-arm, dual-arm, and mobile manipulators are used to test cross-embodiment performance. Evaluation metrics involve task-specific score rubrics that measure progress and success (e.g., percentage of task completion or discrete scores per subtasks). Key Findings: The full π0 model, trained with both pre-training and fine-tuning, outperforms baseline approaches like OpenVLA and smaller models (π0-small) on both direct prompting (out-of-box performance) and after fine-tuning. Ablation studies show that incorporating continuous action generation via flow matching results in significant improvements in dexterity and robustness. The approach demonstrates the capability to perform complex, multi-stage tasks that were previously challenging or unsolvable using traditional methods. Effectiveness Analysis The method works due to several critical factors: Integration of Semantic and Physical Knowledge: The use of a pre-trained VLM imparts broad semantic understanding, enabling the model to interpret language commands effectively. This, when combined with flow matching, allows the system to translate high-level instructions into accurate continuous motions. Flow Matching for Continuous Control: By modeling the entire distribution of actions as a continuous process, the approach ensures high precision and the ability to recover from errors—a necessity in real-world dexterous tasks. Robust Training Recipe: The dual-phase training method (diverse pre-training followed by targeted fine-tuning) allows the model to learn both general competencies and task-specialized behaviors while mitigating issues of overfitting and brittleness. Critical Success Factors: The modular architecture separating vision-language and robotics-specific pathways facilitates efficient processing and speed. The ability to predict action chunks supports high-frequency control, crucial for tasks that require fine motor skills. Potential limitations include the reliance on massive amounts of pre-training data and the current lack of comprehensive understanding about optimal data composition. Moreover, while promising for robot manipulation, it remains to be seen how well the approach transfers to other domains such as autonomous driving or legged locomotion. Contributions The paper makes several novel contributions: Theoretical Contributions: It introduces a novel integration of a pre-trained vision-language model with flow matching to generate continuous action distributions—bridging the gap between discrete output methods and the requirements of dexterous robot control. The work advances our conceptual understanding of how multi-modal pre-training can be leveraged to build versatile and general-purpose robot foundation models. Practical Contributions: The π0 model is demonstrated across multiple robot embodiments and a wide array of tasks, showcasing its practicality and robustness in real-world settings. The proposed multi-stage training recipe—including cross-embodiment data integration and action chunking—sets a new benchmark for large-scale robot learning experiments (using approximately 10,000 hours of diverse data). The empirical results establish a state-of-the-art performance in complex, temporally extended tasks such as laundry folding and box assembly. Implications for Future Research: This work lays the groundwork for future exploration of universal robot foundation models that might extend beyond manipulation to domains like navigation and legged locomotion. The proposed framework encourages further studies on optimal data weighting, integration techniques, and extending these methods to even broader real-world scenarios. Background Large Scale Right Model Architecture Right Trainging Recipe"},{"title":"使用 Dify 的“节点”完成数据预处理","path":"/wiki/dify/custom-data-preprocess.html","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"安装与部署 Dify","path":"/wiki/dify/install-n-use.html","content":"下载 Dify 的 docker compose 文件 1git clone 启动 docker 确保 docker 可以共享文件夹 在 docker desktop -&gt; settings -&gt; resource share 里查看 folder 是否存在。 进入本地部署的 Dify 使用 ip a 查看 docker0 对应的 IP 地址（inet），然后用这个 IP 进入，而不是 localhost"},{"title":"Transformer 架构","path":"/wiki/llm/classic-transformer.html","content":"Before Transformer: RNN, Attention 在 RNN 里，我们用一个隐藏变量 hth_{t}ht​ 记录前 ttt 个 Input Token 所代表的 Context。如果要生成第 t+1t+1t+1 个 Output Token 的话，就利用输入的第 t+1t+1t+1 个 Input Token 和代表了前文信息的隐藏状态 hth_{t}ht​ 做 Attention Alignment 计算出一个向量，再转换成 Word. 这样一个 AutoRegressive 模型有两个显著的问题 由于是时序生成（必须一个一个 Token 地生成），无法并行 由于时序生成，如果要保存很久远的信息，隐藏状态 hth_tht​ 的大小就必须非常大，导致了 Computation &amp; Memory Overhead Model Arch Transformer 总体是 Encoder-Decoder 架构。Encoder 将 Input"},{"title":"LayerNorm","path":"/wiki/aitactics/layernorm.html","content":"LayerNorm 假设是在 CNN 的语境下，我们对一个 N×H×W×CN\\times H\\times W\\times CN×H×W×C 的 tensor 做 LayerNorm。 LayerNorm 做的事实际上是对于每一个 H×W×CH\\times W\\times CH×W×C 做 Normalization."},{"title":"ViT","path":"/wiki/multimodal/ViT.html","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"Decoder-Only Transformer","path":"/wiki/llm/decoder-only-transformer.html","content":"Decoder-only Transformers Decoder-only 架构通常用于生成任务，代表作包括 GPT，GPT-2 等。 什么是生成任务 简单来说，Decoder-only 解决的生成任务是指：给定前 nnn 个单词 x1,x2,…,xnx_1,x_2,\\dots,x_nx1​,x2​,…,xn​，要求输出第 n+1n+1n+1 个单词。可以看出，这类生成任务的本质是 AutoRegressive 的。 近年来，出现了使用 Diffusion 作为 Language Model 的生成，达到了极快的生成速度。"}]