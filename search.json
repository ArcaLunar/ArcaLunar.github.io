[{"title":"Matplotlib 快速入门指南","path":"/matplotlib-fast-tutorial/","content":"网格布局 plt.subplots() 例如，我想将 121212 张 MNIST 图片排列成 333 行 444 列的样子。 使用 fig, axes = plt.subplot() 新建图片，并划分成网格 可以搭配 axes = axes.flatten() 进一步方便处理（将二维网格拍成一维，方便循环处理） 代码 1234567fig, axes = plt.subplot(3, 4) # 可以额外指定 fig_size 指定图片大小axes = axes.flatten()for i in range(12): axes[i].imshow(......) axes[i].set_title(......) # 每一张小图像的标题 axes[i].axis(&quot;off&quot;) 如果想要给整张图添加总标题的话，是 plt.suptitle(&quot;......&quot;) 散点图 plt.scatter()"},{"title":"conda 与 pip 配置代理服务器","path":"/conda-pip-proxy/","content":"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 Password is needed."},{"title":"海康威视 (HikVision) 相机食用指南","path":"/hikvision-camera/","content":"打开相机、关闭相机的流程 首先要 MV_CC_Initialize() 初始化相机 SDK 需要实现 enum_device() 找到相机设备 通过 MV_CC_CreateHandle() 创建 handle MV_CC_OpenDevice() 打开相机"},{"title":"Python LangChain 将图像当作 URL 传递","path":"/raw-image-pass-as-url/","content":"Pass Image as if URL 一个小 trick 可以将本地图片 encode 成 byte string 之后，放在 URL 栏里传递给多模态大模型。 123import base64image_data = base64.b64encode()"},{"title":"使用 Python 和 Flask 库快速构建网页后端","path":"/python-flask-framework/","content":"启动一个后端 导入库后，用 app = Flask(__name__) 初始化一个 App。 一个 function 对应一个子网页的服务，用 @app.route() 指明，最后 app.run() 启动后端。 一个后端子网页 123@app.route(&quot;/upload&quot;, methods=[&quot;POST&quot;])def upload(): # ...... 启动后端 12if __name__ == &quot;__main__&quot;: app.run(debug=True, host=&quot;0.0.0.0&quot;, port=5000) 当 host 为 0.0.0.0 的话，Flask 会多设置一个 IP 地址，供本机的其他程序访问后端。"},{"title":"Django 快速开始","path":"/django-kickstart/","content":"Django 组织结构 Django 大体架构是一个 Project 管理若干个小 Application，每一个 Application 负责一个功能，跟 Application 平行的还有一个用于部署网站的 Config Folder（默认和 Project 同名）. 1234567891011121314151617181920212223242526272829UH├── CedarsCenter│ ├── admin.py│ ├── apps.py│ ├── __init__.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py├── manage.py├── StudentCenter│ ├── admin.py│ ├── apps.py│ ├── __init__.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py└── UH ├── asgi.py ├── __init__.py ├── __pycache__ │ ├── __init__.cpython-311.pyc │ └── settings.cpython-311.pyc ├── settings.py ├── urls.py └── wsgi.py 管理某一个 Project 的时候，通过 manage.py 运行相应的指令。例如在当前 Project 下新增一个 Application poll，则运行 1python manage.py startapp poll Django 中 Model 的作用 Model 的作用只是用来查询数据用的"},{"title":"Python 使用 C/C++ 接口","path":"/python-c-integration/","content":"Python 调用 C/C++ 代码 如何编写 C/C++ 代码？ 首先导入 Python.h 头文件，包含了必要的结构体、方法。（需要通过 sudo apt install python3-dev 提前安装好） 12#define PY_SSIZE_T_CLEAN#include &lt;python3.12/Python.h&gt; // 我这里需要额外指定一下路径 编译为动态库 1g++ -fPIC [file_name] -shared -o [module_name].so 在 Python 里使用 直接通过这个 Module 的名字导入 123import [module_name]# ......"},{"title":"MinerU Examples","path":"/MinerU-examples/","content":"uv 包管理器安装 MinerU 先用 uv 安装 setuptools wheel torch 1uv pip install setuptools wheel torch 然后再安装 detectron2 1uv pip install --no-build-isolation git+https://github.com/facebookresearch/detectron2.git 最后安装 magic-pdf[full] 1uv pip install &#x27;magic-pdf[full]&#x27; --extra-index-url https://wheels.myhloli.com --prerelease=allow 最后检查 magic-pdf 的版本 &gt;=0.7.0，而不是 0.6.1 如果像使用 GPU 进行 PaddlePaddle OCR 的推理，继续安装 paddlepaddle-gpu 1uv pip install paddlepaddle-gpu MinerU Command Line MinerU API 使用指南 MinerU 的使用流程基本上是 将 PDF 加载为 magic_pdf.data.dataset.Dataset 执行 OCR 和 Layout Inference 这里还想更详细地记录一下 API，感觉 Documentation 里写的不是很全，得从 demo.py 里找。"},{"title":"image-text-database","path":"/image-text-database/","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"软件工程：UML","path":"/swe-uml/","content":"Summary of “UML in Object-Oriented Analysis” 1. Purpose of UML in Analysis Modeling Goals: Understand the problem domain and provide a basis for design. Communicate design ideas efficiently among developers. Identify defects and omissions in specifications and designs before coding. Speed and Clarity: UML diagrams are faster to sketch than code and serve as a common language for developers. 2. UML Diagram Types Structure Diagrams: Class Diagrams: Model static structure (classes, attributes, relationships). Object Diagrams: Represent instances of classes at a specific point in time. Composite Structure Diagrams: Show internal structure of objects and collaborations. Behavior Diagrams: Activity Diagrams: Model workflows or business processes. State Machine Diagrams: Describe state transitions of objects. Interaction Diagrams: Sequence Diagrams: Depict object interactions over time. Communication Diagrams: Show message flows between objects. 3. Class Diagrams: Core of Domain Modeling Components: Classes: Named boxes with attributes (data) and operations (methods). Associations: Relationships between classes (e.g., Customer ↔ Order). Multiplicity: Defines cardinality (e.g., 1..* = “one or more”). Navigability: Direction of association (arrows). Domain Model: Represents problem-domain concepts (e.g., Product, Transaction, User). Focuses on conceptual classes (not implementation details). Steps to Build: Identify Classes: Use noun phrases from requirements and category lists (e.g., “Transaction,” “Record”). Define Attributes: Simple values (e.g., price, date). Avoid complex data as attributes (e.g., Address should be a class). Model Associations: Only meaningful relationships (e.g., Order contains OrderLineItems). 4. Best Practices for Class Diagrams Keep It Simple: Omit trivial associations to avoid clutter. Prioritize “need-to-know” relationships. Multiplicity Constraints: Use 1, 0..1, * (unbounded), or n (specific number) to define valid instances. Association Classes: Resolve many-to-many relationships by adding a class (e.g., Reservation between Customer and Flight). Example: SkillLevel between GameCharacter and Skill to track proficiency levels. 5. Domain Modeling Techniques Techniques for Identifying Classes: Noun/Phrase Extraction: Extract nouns from requirements (e.g., “Product Catalog” from “view products”). Category List: Use predefined categories (e.g., “Transaction,” “Container,” “Role”). Avoid Overcomplication: Do not model every relationship (e.g., ignore transient interactions like “Developer estimated PBI”). Focus on persistent relationships (e.g., PBI belongs to a Product Backlog). 6. Example: Domain Model for a POS System Key Classes: Customer, Cashier, Product, Sale, CashPayment. Associations: Sale contains SalesLineItems (multiplicity 1..*). Product is described by ProductDescription. Attributes: Sale has dateTime, total, and CashPayment (optional). 7. UML in Agile Development Iterative Approach: Build domain models incrementally, focusing on current user stories. Alignment with Implementation: Domain models inform REST API endpoints (e.g., shuttlebuses endpoint from ShuttleBus class). 8. Common Pitfalls Over-Simplification: Modeling complex data (e.g., Address) as attributes instead of classes. Over-Modeling: Including transient or unimportant relationships (e.g., Developer ↔ PBI for estimation). 9. Conclusion UML is a foundational tool for analyzing and designing software systems. Class diagrams are central to modeling problem domains and translating them into solutions. Proper use of UML reduces defects, clarifies requirements, and supports agile development practices. This summary captures the document’s focus on UML’s role in analysis, key diagrams, domain modeling techniques, and practical best practices."},{"title":"软件工程：Software Requirement Specification","path":"/swe-srs/","content":"Summary of “Software Requirements: Introduction” 1. Core Challenges in Requirements Engineering Key Issue: Understanding the problem the system must solve, often derived from customer/end-user needs. Challenges: Developers may misunderstand the business problem, leading to incorrect solutions. Customers/users may not clearly articulate their needs (especially problematic in predictive models like Waterfall). Developers must align software with end-users’ workflows to ensure practicality. 2. Drivers of Requirements Custom Software (Project-Based): Requirements driven by specific clients (e.g., government, enterprise tools). Contractual obligations dictate functionality and delivery timelines. Ownership transfers to the client post-delivery. Software Products: Requirements originate from the company’s vision/opportunity (e.g., apps, productivity tools). Developers prioritize features and constraints without a specific client’s contractual demands. Continuous evolution: Features can be added/removed post-release. 3. Types of Requirements Information Business Requirements: High-level organizational objectives (e.g., “Increase customer satisfaction”). Business Rules: Policies/constraints (e.g., pricing policies). Stored in a Business Rules Catalogue, not part of the SRS itself. User Requirements: Tasks users must perform or desired attributes (e.g., “Users want to check in online”). Functional Requirements: Specific behaviors the system must perform (e.g., “The system shall calculate fuel quantity”). Features: Bundles of related functional requirements (e.g., “User Authentication Feature”). System Requirements: Top-level/system-wide requirements (e.g., integration with hardware). Non-Functional Requirements: Properties like performance, security, usability (e.g., “Authorization must take ≤2 seconds”). External Interface Requirements: Connections to users, systems, or hardware (e.g., “JSON format for data exchange”). Constraints: Restrictions on development (e.g., “Use open-source libraries only”). 4. Business Rules Management Documentation: Rules are recorded in tables with: Rule ID, Rule Description, Volatility (how often they change), and Source (e.g., company policy). Example: Delivery pricing rules for an e-commerce system. Impact: Influence functional/non-functional requirements (e.g., permissions, UX design). 5. Software Requirements Specification (SRS) Purpose: Formal document outlining all functional and non-functional requirements. Structure: Introduction: Purpose, scope, conventions. Overall Description: Product context, user classes, constraints. System Features: Detailed functional requirements (e.g., “The system shall…”). Data Requirements: Logical models, reports, data retention policies. External Interfaces: User, software, hardware, and communication interfaces. Quality Attributes: Usability, performance, security, safety. Appendices: Glossary, analysis models. Formality: Varies by system criticality (e.g., strict for avionics vs. informal for web apps). Example: Flight Management System (FMS) requirements trace from system to low-level software specs (e.g., fuel quantity display in pounds/kilograms). 6. Requirements Traceability Critical in Safety-Critical Systems (e.g., aviation): Requirements must be bi-directionally traceable (e.g., from system to code). Example: FMS fuel quantity requirements linked to sensor polling intervals and data validity checks. DO-178C Compliance: Mandates traceability for airborne software. 7. Agile Requirements Management Alternatives to Traditional SRS: Vision and Scope Document: High-level goals and constraints. Product Backlog: Prioritized user stories/use cases with acceptance criteria. Dynamic Updates: Requirements evolve iteratively (e.g., user stories refined during sprints). Working Software: Focus on delivering increments over exhaustive documentation. Example: User stories for a flight check-in system (e.g., “As a passenger, I want to print boarding passes after check-in”). 8. Key Takeaways Requirement Types: Differentiate between business rules, user needs, functional/non-functional requirements. Documentation: Formal SRS for critical systems; agile backlogs for product development. Traceability: Essential for compliance and defect prevention in safety-critical domains. Agile Adaptation: Prioritize collaboration, iterative delivery, and flexibility over rigid planning. This summary captures the document’s focus on understanding requirements, their classification, documentation practices, and the shift toward agile methodologies for modern software development."},{"title":"软件工程：Software Process Model","path":"/swe-software-process-model/","content":"Summary of “Software Process and Activities: Process Models” 1. Introduction to Software Development Lifecycle (SDLC) SDLC: A structured sequence of development activities and tasks, organized into phases. Companies may adapt these models, but they generally fall into predictive or adaptive categories. Predictive Models: Plan all phases upfront (e.g., Waterfall). Emphasize control, documentation, and fixed requirements. Adaptive Models: Respond to change iteratively (e.g., Agile). Focus on flexibility, customer collaboration, and empirical process control. 2. Predictive Models: The Waterfall Model Structure: Linear, sequential phases: Requirements → 2. Design → 3. Implementation → 4. Testing → 5. Deployment → 6. Maintenance Key Features: Heavyweight Documentation: Formal plans and deliverables (e.g., requirements specs, design docs, test reports). Phase Dependency: A phase cannot start until the prior phase is completed and accepted. No re-entry once finalized. Milestones: Major deliverables reviewed at each phase to ensure completion. Advantages: Clear visibility, management control, and contractual clarity for mission-critical systems (e.g., aerospace, healthcare). Aligns with regulatory standards (e.g., DO-178C for airborne software). Disadvantages: Rigid: Cannot easily accommodate requirement changes or design flaws discovered late. Late Validation: Customers see a working product only at the end, risking undetected defects (cost to fix defects rises exponentially as development progresses). Inflexibility: Feedback loops require costly rework, often leading to frozen deliverables. 3. Adaptive Models: Agile and Empirical Process Control Core Principles: Transparency: Shared understanding of progress and goals. Inspection: Regular reviews of work and processes. Adaptation: Adjustments based on new knowledge. Iterative &amp; Incremental Development: Iterations (Sprints): Short, time-boxed cycles (e.g., 1–2 weeks in Scrum) delivering potentially releasable increments. Phases per Iteration: Each cycle includes planning, design, implementation, integration, testing, and review. Flexibility: Goals set at iteration start; requirements evolve over time. Benefits: Early and frequent customer feedback reduces late-stage defects. Handles uncertainty and complexity in innovative projects. Prioritizes working software over exhaustive documentation. Drawbacks: Overhead may outweigh benefits for simple, low-risk projects with stable requirements. 4. Product-Based vs. Project-Based Development Custom Software (Project-Based): Developed for specific clients (e.g., government systems, enterprise tools). Follows predictive models (e.g., Waterfall) for contractual clarity and stability. Ownership transfers to the client post-delivery. Software Products: Mass-market solutions (e.g., apps, productivity tools). Prioritizes time-to-market over rigid planning. Agile frameworks dominate due to rapid iteration and competition. Self-Managed Teams: No traditional project manager; roles like Product Owner (prioritizes backlog) and Scrum Master (facilitates process) are key. Continuous Development: Treated as ongoing processes, not discrete projects. 5. CHAOS Report Insights on Project Management Non-Agile Projects: Success rates vary with project manager skill, but bureaucracy and slow decision-making hinder outcomes. Agile Projects: Traditional project managers reduce success rates due to process overhead. Conclusion: Agile thrives without hierarchical project managers. Avoid tools like EPPM (Enterprise Project Portfolio Management) that introduce bureaucracy. Key Takeaway: “Software is infinite, while projects are finite.” Modern development should avoid artificial project boundaries and focus on continuous delivery. 6. When to Use Each Model Predictive Models (Waterfall): Appropriate for: Safety-critical systems, stable requirements, long-term contracts, and regulatory compliance. Risks: Fails in dynamic environments or when requirements are unclear. Adaptive Models (Agile): Appropriate for: Product development, innovative projects, evolving requirements, and complex problem-solving. Risks: Overhead for simple projects; requires disciplined team collaboration. 7. Conclusion Modern Trends: Shift toward product-based, Agile methodologies due to faster iteration, customer-centricity, and adaptability. Process Selection: Choose models based on project complexity, risk, and requirements stability. Predictive models remain viable for specific domains (e.g., aerospace), while Agile dominates in competitive, evolving markets. This summary encapsulates the document’s contrast between predictive and adaptive models, their strengths/weaknesses, and the industry’s move toward Agile for product development."},{"title":"multi-thread","path":"/multi-thread/","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"Linux 下用 HKU 账号使用 HK eduroam WiFi","path":"/connect-to-eduroam-hku/","content":"eduroam 我是 Linux Mint 系统，所以 Ubuntu/Mint 应该比较通用。 Option Value Security WPA &amp; WPA2 Enterprise Authentication Protected EAP (PEAP) Anonymous Identity 留空 Domain hku.hk CA Certificate 选 (None)，勾选 No CA Certificate is required PEAP version Automatic Inner Authentication MSCHAPv2 Username &lt;UID&gt;@hku.hk，&lt;UID&gt; 是邮箱 @ 前的部分，这里后缀必须是 @hku.hk Password Portal 的登录密码"},{"title":"Docker Introduction","path":"/docker-intro/","content":"Dockerfile Docker Image 编写完 Dockerfile 后，我们可以用命令创建一个 docker 镜像 1docker build -t [镜像名称] [Dockerfile 所在目录] 启动 container 还需要一个 container 才能运行起来 1docker run -p [映射到主机的哪个端口]:[容器内的哪个端口] -d [镜像名称] -p：指定端口 -d：后台运行。想要查看终端输出的话需要到 docker desktop 里查看 用 Volume 保存 container 的数据 利用 -v 参数，把本地文件夹 ~/A 挂载到 container 里的 .../B，这样在 container 里读写 .../B 其实等于读写 ~/A. 我们先创建一个数据卷 1docker volume create [数据卷位置] 然后在 docker run 的时候进行挂载 1docker run -v [数据卷在本地的位置]:[数据卷在容器里的位置] -d [镜像名称] Docker Compose 多个容器共同协作：例如数据库和前端分离。 在 docker-compose.yml 里用 services 进行定义 12345678910111213# docker-compose.ymlservices: # 定义前端和数据库 front-end: # 前端 build: . # 镜像——从文件夹构建 ports: # 端口映射 - &quot;80:5000&quot; database: # 数据库 image: &quot;mysql&quot; # 镜像——从其他地方拉取 environment: # 可以定义环境变量 OPENAI_API_KEY: &quot;...&quot; OPENAI_API_BASE: &quot;&quot; volumes: # 数据卷，等同于 -v 参数 - &quot;~/A:.../B&quot; 定义完毕后，使用 1docker compose up -d 来运行所有的 container 1docker compose down 来停止并删除所有的 container"},{"title":"本地部署 llama.cpp 大模型服务器并连接","path":"/local-deploy/","content":"llama.cpp 的安装、编译 alternative: llama-cpp-python 提供了 llama.cpp 的 Python 接口。通过 llama-cpp-python 也可以启动一个 LLM Server 启动一个 LLM server 直接在命令行里输入启动服务器 1llama-server -m [模型路径] --port 8080 模型要保证必须是 .gguf 格式，可以使用 llama.cpp 项目根目录下的 convert_hf_to_gguf.py 进行转换。 convert_hf_to_gguf&nbsp;食用方法 配置好虚拟环境后，命令行里输入 1python convert_hf_to_gguf.py [模型.bin文件所在的目录] 这个目录末尾应该是哈希码，例如 ~/.cache/huggingface/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/ad9f0ae0864d7fbcd1cd905e3c6c5b069cc8b562 连接 如果用 LangChain 进行连接，必须注意要输入 http://localhost:8080 的 http://（被坑了）"},{"title":"About Me","path":"/about/index.html","content":"About Me"},{"title":"OpenVLA 代码解析 (1)","path":"/wiki/agentai/OpenVLA-code-p1.html","content":"5d4944576327e6e1f59f35f07afdbc7917ffe61195e5ff6f7af12e15300ba733 Password is needed."},{"title":"Google Gemini Robotics","path":"/wiki/agentai/google-gemini-robotics.html","content":"AI&nbsp;Summary Background • Core Problem: The paper addresses the challenge of bridging the gap between state‐of‐the‐art multimodal AI models and practical robotics. Although digital AI models have achieved impressive capabilities in processing text, images, and other modalities, these models traditionally lack the embodied reasoning (i.e., the ability to understand and physically interact with the real world) required for autonomous robot control. • Current Limitations and Challenges: Existing vision–language models excel at perception and symbolic tasks, yet they fall short when it comes to physical grounding. The authors point out that current research struggles with robust spatial understanding, dexterous manipulation, safe human–robot interactions, and adapting to novel object configurations and environments. Moreover, there is an absence of standardized benchmarks that cover the nuanced set of reasoning skills needed for embodied tasks. • Real-world Needs and Theoretical Gaps: The paper underscores the necessity for general-purpose robots capable of smooth, safe, and reactive movements. There is a critical need to extend digital reasoning to handle real-world cues such as 3D geometry, object affordances, and trajectory planning. The authors identify a theoretical gap in unifying multimodal understanding (visual and language) with physical action planning. Motivation • Driving Factors Behind the New Method: The motivation comes from the desire to leverage the advanced multimodal reasoning of models like Gemini 2.0 and extend these capabilities to control physical robots. The authors aim to overcome the limitations of existing systems which are typically confined to digital domains by integrating a comprehensive embodied reasoning framework into robotics. • Shortcomings of Existing Approaches: Current practices often suffer from poor generalization when faced with unseen object types, variable settings, and complex manipulation tasks. Many existing methods lack the ability to plan sequential actions under safety constraints and cannot efficiently adapt to new robot embodiments or environments. Issues such as limited computational efficiency in planning and a narrow focus on perception without actionable outputs further drive the need for an improved, unified approach. Methodology • Core Innovation: The paper introduces the Gemini Robotics family of models––a suite of vision–language–action (VLA) systems that fuse the powerful multimodal understanding of Gemini 2.0 with a dedicated robotics layer. Two principal variants are proposed: Gemini Robotics-ER (Embodied Reasoning): Enhances the base model’s spatial and temporal reasoning to perform tasks such as object detection, 2D pointing, trajectory prediction, and top-down grasp estimation. Gemini Robotics: Extends these capabilities by incorporating robot action data to achieve high-frequency, dexterous control over physical robots. • Technical Steps and Key Components: Multimodal Input Fusion: Integrates visual inputs (images) and textual instructions, using open‐vocabulary queries to detect and localize objects in both 2D and 3D (e.g., 3D bounding boxes and multi-view correspondence). Embodied Reasoning Pipeline: Employs a chain-of-thought (CoT) prompting technique, which encourages the model to generate intermediate reasoning steps, thereby ensuring precise spatial grounding and sequential planning. (Chain-of-thought prompting is a method where the model is instructed to “think out loud” through intermediate steps before giving the final answer.) Robot Control Integration: A dedicated pipeline converts high-level planning into low-level actuation commands via a robot API, managing safe and reactive motions while adhering to physical constraints. Specialization and Adaptation: An optional fine-tuning stage enables the system to adapt to long-horizon tasks, enhance dexterity (e.g., folding or playing cards), and adjust to variations in robot embodiments such as bi-arm platforms or humanoids. • Fundamental Differences from Baseline Approaches: Unlike conventional methods that may treat perception and control as separate tasks, the Gemini Robotics models offer an end-to-end, integrated solution. By combining embodied reasoning with action data, these models generalize better to novel tasks, improve adaptation with few demonstrations, and facilitate safe control in dynamic environments. Experiments &amp; Results • Experimental Setup: The models are evaluated on several benchmarks including the newly introduced Embodied Reasoning Question Answering (ERQA) benchmark, RealworldQA, and BLINK. The experimental design encompasses tasks ranging from simple object detection to complex, dexterous manipulation tasks in both simulated and real-world scenarios. Datasets include images sourced from in-house collections and publicly available datasets like OXE, UMI Data, and MECCANO. Baseline comparisons are made against existing vision–language and diffusion-based robotics models, using performance metrics such as accuracy, success rate, and continuous progress scores. • Key Findings: Gemini 2.0 variants (Flash and Pro Experimental) achieve state-of-the-art performance across multiple benchmark evaluations, often with notable improvements when chain-of-thought prompting is used. Quantitative results show improvements in tasks like 2D pointing accuracy (measured by how well predicted points fall within ground-truth regions) and successful grasp predictions in real-world robot control. In dexterous tasks such as folding an origami fox or playing a card game, Gemini Robotics outperforms baseline models in both binary success metrics and nuanced progress scores. • Ablation and Sensitivity Analyses: The paper reports ablation studies that highlight the benefits of each component—from embodied reasoning enhancements to fine-tuning stages. Sensitivity analyses reveal that prompts such as chain-of-thought can significantly affect overall performance, and that the integrated approach provides robust improvements even under distribution shifts (e.g., novel visual variations or rephrased instructions). Effectiveness Analysis • Underlying Reasons for Success: The method’s effectiveness stems from its dual focus on robust multimodal understanding and practical action integration. By augmenting a strong foundation model with specialized embodied reasoning and robot-specific training, the system manages to bridge the digital–physical divide. In particular, the use of multi-view spatial understanding and sequential reasoning ensures continuity between perception and physical manipulation. • Critical Success Factors: Model Architecture and Training: Leveraging Gemini 2.0’s large-scale, pre-trained capabilities provides a strong foundation for embodied reasoning. Effective Data Fusion: Integrating diverse data types—including images, text, and robot sensor readings—improves generalization and adaptability. Prompting Strategies: Techniques like chain-of-thought prompting contribute to clear intermediate reasoning, enhancing the decision-making process. Safety and Adaptability Protocols: The incorporation of robot API interfaces and safety guidelines enables smooth interaction in regulated physical environments. • Potential Limitations and Applicability Boundaries: While the proposed models demonstrate impressive performance, their success is tightly coupled with the quality and diversity of training data. The system may face constraints when encountering drastically different physical environments or unanticipated object configurations. Furthermore, the reliance on comprehensive safety protocols suggests that additional work is required to ensure deployment in less structured or more variable real-world settings. Contributions • Theoretical Contributions: The paper provides a unified framework that connects high-level multimodal reasoning directly with low-level robot control. It introduces new benchmark tasks (e.g., ERQA) to evaluate embodied reasoning, setting a new standard for measuring the full spectrum of capabilities required for physical interaction. • Practical Contributions: The development of the Gemini Robotics family offers an end-to-end solution for controlling robots with diverse manipulation tasks, from dexterous object handling to adaptive task execution. Detailed model cards and open-source evaluation protocols are provided, facilitating reproducibility and further research in embodied AI. The work also contributes guidelines and best practices for ensuring safety and responsible development in robotics applications. • Implications for Future Research: This research marks a significant step toward general-purpose embodied AI. Future work can build on these findings to further enhance generalization, reduce reliance on extensive fine-tuning, and tackle more complex physical interactions. The integration of multimodal reasoning with action control paves the way for robots that can adapt to diverse, unstructured real-world environments while ensuring safe and reliable operation."},{"title":"OpenVLA 论文","path":"/wiki/agentai/OpenVLA.html","content":"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 Password is needed."},{"title":"Pi 0, A Vision-Language-Action Flow Model for General Robot Control","path":"/wiki/agentai/pi-zero.html","content":"AI&nbsp;Summary Background The paper addresses the challenge of developing a unified robot foundation model that can handle a wide range of dexterous tasks across different robot platforms. Current robot learning approaches often suffer from limited generalization, data scarcity, and brittle performance when adapting to complex practical scenarios. Existing methods typically focus on narrow tasks or use discretized models that struggle with continuous, high-frequency control. The authors identify a real-world need for models that can integrate rich semantic understanding (gained from large-scale vision-language pre-training) with fine-grained physical control to perform intricate multi-stage tasks such as laundry folding or box assembly. Motivation The direct drive behind this work is the gap between the robust, versatile behavior seen in large language and vision-language models and the limitations of current robot control systems. Existing approaches fail to meet the demands of real-world robotic manipulation due to: Limited Generalization: Models are often trained on task-specific data and do not transfer well to diverse environments or novel tasks. Discrete Outputs: Many prior methods rely on autoregressive and token-based approaches, which are not well-suited for high-frequency continuous control. Data and Recovery Challenges: Training solely on curated, high-quality data results in brittle systems that cannot efficiently recover from errors or unexpected perturbations. This motivates the integration of internet-scale semantic pre-training with a continuous action generation method, thereby combining robust, flexible understanding with high-precision control. Methodology The core innovation is the design of a vision-language-action model (π0) that unifies pre-trained semantic knowledge with a novel mechanism for continuous action prediction. Key elements include: Pre-trained VLM Backbone: The model starts with a vision-language model (VLM) pre-trained on vast internet data (e.g., PaliGemma). This allows the system to inherit rich semantic representations and language understanding. Brief explanation: A VLM (Vision-Language Model) is trained on image-text pairs to extract visual and linguistic features simultaneously. Action Expert with Flow Matching: A separate module—termed the action expert—is added to predict continuous action sequences. Instead of relying on discrete token outputs, it uses conditional flow matching. Brief explanation: Flow matching is a variant of diffusion methods where a denoising vector field is learned to progressively transform noise into data, enabling precise continuous outputs. The model predicts action chunks (e.g., 50 future steps) at once, accommodating high-frequency control (up to 50 Hz). The design employs multi-stage training where the model is first exposed to diverse, lower-quality pre-training data and later fine-tuned on high-quality, task-specific data. Architectural Separation: The transformer backbone routes standard inputs (images and language) through the pre-trained VLM segment, while robot-specific proprioceptive inputs and continuous actions are handled by an additional expert. This mixture of experts approach allows leveraging pre-existing knowledge while adapting to robotics-specific demands. Two-Phase Training Recipe: Emphasizing the importance of both data diversity and quality, the training is split into a large-scale pre-training phase (covering 10,000 hours of data across 68 tasks and 7 robot configurations) and a post-training phase that refines the model for complex downstream tasks. Experiments &amp; Results The authors evaluate their model on a wide range of dexterous manipulation tasks spanning different robots and complexities: Experimental Setup: Tasks include shirt folding, table bussing (easy and hard versions), grocery bagging, removing toast from a toaster, laundry folding, box assembly, packing eggs, and more. Diverse robot configurations such as single-arm, dual-arm, and mobile manipulators are used to test cross-embodiment performance. Evaluation metrics involve task-specific score rubrics that measure progress and success (e.g., percentage of task completion or discrete scores per subtasks). Key Findings: The full π0 model, trained with both pre-training and fine-tuning, outperforms baseline approaches like OpenVLA and smaller models (π0-small) on both direct prompting (out-of-box performance) and after fine-tuning. Ablation studies show that incorporating continuous action generation via flow matching results in significant improvements in dexterity and robustness. The approach demonstrates the capability to perform complex, multi-stage tasks that were previously challenging or unsolvable using traditional methods. Effectiveness Analysis The method works due to several critical factors: Integration of Semantic and Physical Knowledge: The use of a pre-trained VLM imparts broad semantic understanding, enabling the model to interpret language commands effectively. This, when combined with flow matching, allows the system to translate high-level instructions into accurate continuous motions. Flow Matching for Continuous Control: By modeling the entire distribution of actions as a continuous process, the approach ensures high precision and the ability to recover from errors—a necessity in real-world dexterous tasks. Robust Training Recipe: The dual-phase training method (diverse pre-training followed by targeted fine-tuning) allows the model to learn both general competencies and task-specialized behaviors while mitigating issues of overfitting and brittleness. Critical Success Factors: The modular architecture separating vision-language and robotics-specific pathways facilitates efficient processing and speed. The ability to predict action chunks supports high-frequency control, crucial for tasks that require fine motor skills. Potential limitations include the reliance on massive amounts of pre-training data and the current lack of comprehensive understanding about optimal data composition. Moreover, while promising for robot manipulation, it remains to be seen how well the approach transfers to other domains such as autonomous driving or legged locomotion. Contributions The paper makes several novel contributions: Theoretical Contributions: It introduces a novel integration of a pre-trained vision-language model with flow matching to generate continuous action distributions—bridging the gap between discrete output methods and the requirements of dexterous robot control. The work advances our conceptual understanding of how multi-modal pre-training can be leveraged to build versatile and general-purpose robot foundation models. Practical Contributions: The π0 model is demonstrated across multiple robot embodiments and a wide array of tasks, showcasing its practicality and robustness in real-world settings. The proposed multi-stage training recipe—including cross-embodiment data integration and action chunking—sets a new benchmark for large-scale robot learning experiments (using approximately 10,000 hours of diverse data). The empirical results establish a state-of-the-art performance in complex, temporally extended tasks such as laundry folding and box assembly. Implications for Future Research: This work lays the groundwork for future exploration of universal robot foundation models that might extend beyond manipulation to domains like navigation and legged locomotion. The proposed framework encourages further studies on optimal data weighting, integration techniques, and extending these methods to even broader real-world scenarios. Background Large Scale Right Model Architecture Right Trainging Recipe"},{"title":"Triton Introduction","path":"/wiki/ai-infra/triton-intro.html","content":"PyTorch 关键组件 TorchDynamo 将所有复杂算子简化到 PrimTorch 中的 250 个算子 移除未使用的算子 确实需要存储、写入内存的中间算子，以及可融合的算子，从而减少开销 PrimTorch 定义了两个算子集合：Aten ops 和 Prim ops 将 PyTorch 程序的各种计算用这些算子集里的算子表示 简化后端需要编写的算子数量 AOTAutograd 提前获取反向传播 基于完整的 forward/backward 根据算子的依赖关系进行算子调度，对算子和层进行融合 TorchInductor 进行算子融合 自动生成低级 GPU 上的 Triton 代码（或者 CPU 上的 C++/OpenMP） 编译流程 我们用下面的例子介绍一下大致的编译流程，在运行时加入调试参数 TORCH_LOGS=&quot;...&quot; python example.py 查看中间的日志输出 12345678910import torch@torch.compiledef toy_example(x: torch.Tensor) -&gt; torch.Tensor: y = x.sin() z = y.cos() return zif __name__ == &quot;__main__&quot;: x = torch.randn(1000, device=&quot;cuda&quot;, requires_grad=True) # 开启反向传播 Step 1. TorchDynamo 运行 TORCH_LOGS=&quot;dynamo&quot; uv run example.py，我们先来看第一步 TorchDynamo 的输出。 日志输出12345678910111213141516171819202122232425262728293031323334[torch/_dynamo/symbolic_convert.py:2706] [0/0] Step 1: torchdynamo start tracing toy_example [很长的路径]/example.py:5[torch/_dynamo/symbolic_convert.py:3028] [0/0] Step 1: torchdynamo done tracing toy_example[torch/_dynamo/output_graph.py:1458] [0/0] Step 2: calling compiler function inductor[torch/_dynamo/output_graph.py:1463] [0/0] Step 2: done compiler function inductor[torch/fx/experimental/symbolic_shapes.py:4547] [0/0] produce_guards[torch/_dynamo/pgo.py:636] [0/0] put_code_state: no cache key, skipping[torch/_dynamo/eval_frame.py:398] TorchDynamo attempted to trace the following frames [ toy_example [很长的路径]/example.py:5 ][torch/_dynamo/utils.py:446] TorchDynamo compilation metrics: Function Runtimes (s) ------------------------------------ -------------- _compile.compile_inner 0.5482 OutputGraph.call_user_compiler 0.4845 _recursive_pre_grad_passes 0.0018 create_aot_dispatcher_function 0.4817 _recursive_joint_graph_passes 0.0684 compile_fx.&lt;locals&gt;.fw_compiler_base 0.3442 compile_fx_inner 0.3437 inductor_codecache_torch_key 0.0523 TritonBundler.read_and_emit 0.0002 PyCodeCache.load_by_key_path 0.0122 async_compile.precompile 0.007 async_compile.wait 0.0001 从日志中可以看到，TorchDynamo 的框架流程就是 对要编译的模型进行追踪，然后编译并生成中间表示 (FX Graph IR) 调用 compiler.inductor 对模型进行化简 1.1 Dynamo 图捕获 Dynamo 首先进行图捕获。这里，__graph_code 将原始代码的 Dataflow 进行捕获，并输出捕获的 DAG，即 FX Graph IR. FX Graph IR1234567891011121314151617181920212223# [torch/fx/passes/runtime_assert.py:118] [0/0] [__graph_code] def forward(self, L_x_: &quot;f32[1000]&quot;): l_x_ = L_x_ # File: example.py:7 in toy_example, code: y = x.sin() y: &quot;f32[1000]&quot; = l_x_.sin(); l_x_ = None # File: example.py:8 in toy_example, code: z = y.cos() z: &quot;f32[1000]&quot; = y.cos(); y = None return (z,)[torch/_dynamo/output_graph.py:1353] [0/0] [__graph_code] def forward(self, L_x_: &quot;f32[1000][1]cuda:0&quot;): l_x_ = L_x_ # File: example.py:7 in toy_example, code: y = x.sin() y: &quot;f32[1000][1]cuda:0&quot; = l_x_.sin(); l_x_ = None # File: example.py:8 in toy_example, code: z = y.cos() z: &quot;f32[1000][1]cuda:0&quot; = y.cos(); y = None return (z,) 1.2 AOTAutograd Dynamo 的 AOTAutograd 阶段 生成正向传播图和反向传播图（也是表示为 FX Graph IR 的形式） 会将 FX Graph IR 中的算子替换为 ATen 算子库里的算子 基于完整的正向、反向传播图的视角，根据依赖关系，进行算子调度、对算子和层进行融合 将复杂的算子根据字典进一步分解为更底层的 Core ATen IR 算子或者 Prim IR 算子 AOTAutograd IR 生成的正向图与反向图12345678910111213141516171819202122232425262728293031# 这个是正向图# ===== Forward graph 0 =====# torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, primals_1: &quot;f32[1000][1]cuda:0&quot;): ## File: example.py:7 in toy_example, code: y = x.sin() sin: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.sin.default(primals_1) ## File: example.py:8 in toy_example, code: z = y.cos() cos: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.cos.default(sin); sin = None return (cos, primals_1)# 这个是反向图# [torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:603]# [0/0] [__aot_graphs]# # TRACED GRAPH# ===== Backward graph 0 =====&lt;eval_with_key&gt;.1 class GraphModule(torch.nn.Module): def forward(self, primals_1: &quot;f32[1000][1]cuda:0&quot;, tangents_1: &quot;f32[1000][1]cuda:0&quot;): # File: example.py:7 in toy_example, code: y = x.sin() sin: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.sin.default(primals_1) # File: example.py:8 in toy_example, code: z = y.cos() sin_1: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.sin.default(sin); sin = None neg: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.neg.default(sin_1); sin_1 = None mul: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.mul.Tensor(tangents_1, neg); tangents_1 = neg = None # File: example.py:7 in toy_example, code: y = x.sin() cos_1: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.cos.default(primals_1); primals_1 = None mul_1: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.mul.Tensor(mul, cos_1); mul = cos_1 = None return (mul_1,) 2. Inductor Triton 的核心： compile() model fullgraph dynamic"},{"title":"RMSNorm","path":"/wiki/aitactics/RMSNorm.html","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"LayerNorm","path":"/wiki/aitactics/layernorm.html","content":"LayerNorm 假设是在 CNN 的语境下，我们对一个 N×H×W×CN\\times H\\times W\\times CN×H×W×C 的 tensor 做 LayerNorm。 LayerNorm 做的事实际上是对于每一个 H×W×CH\\times W\\times CH×W×C 做 Normalization."},{"title":"2024 ICPC 区域赛：香港","path":"/wiki/algo/2024-icpc-regional-hk.html","content":"E. Concave Hull 算法流程 先算一次凹包，把所有的点分成“在凸包上”和“不在凸包上”的点 SSS。 枚举 SSS 中的每一个点作为凹点 p0p_0p0​，然后对其他所有点 pip_ipi​ 计算出向量 vi=pip0→v_i=\\overrightarrow{p_ip_0}vi​=pi​p0​​ 并按极角排序。 极角排序完了之后，向量必定是 on, /, /, /, on, /, /, on, on, /, /, on ...... 这样排列（两个在凸包上的点 c1,c2c_1,c_2c1​,c2​ 中间夹着一些不在凸包上的点 djd_jdj​，记这些点的集合为 F={F0=c1,F1=d1,d2,…,Fm=dm,Fm+1=c2}F=\\{F_0=c_1,F_1=d_1,d_2,\\dots,F_m=d_m,F_{m+1}=c_2\\}F={F0​=c1​,F1​=d1​,d2​,…,Fm​=dm​,Fm+1​=c2​}）。我们尝试计算以 p0p_0p0​ 作为凹点，Fi,Fi+1F_i,F_{i+1}Fi​,Fi+1​ 作为优角的两边的凹包面积。 这里的话，如果跑暴力算法，时间复杂度会来到 O(n3)O(n^3)O(n3)。考虑到这个凹包的面积其实是凸包面积去掉一部分面积，我们可以利用这一点加速计算。 我们把凹包凹进去的部分分成左右两半凸壳，做两次 Andrew 凸包扫描算法（从左往右或者从右往左）。例如 Andrew 算法从左往右扫描，只要扫描算法扫描经过这些点 FFF，那么我们就能算出 c1→Fic_1\\to F_ic1​→Fi​ 左半凸壳的面积。同理也可以计算出右半凸壳的面积。因此以 p0p_0p0​ 为凹点、Fi,Fi+1F_i,F_{i+1}Fi​,Fi+1​ 为优角的凹包面积也就可以算出来了（大凸包面积，减掉这一个凹角对应的凸包上三角形的面积，再加上左右两个凸壳的面积） 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177#include &lt;algorithm&gt;#include &lt;cassert&gt;#include &lt;cmath&gt;#include &lt;iostream&gt;#include &lt;ranges&gt;#include &lt;utility&gt;#include &lt;set&gt;#include &lt;vector&gt;using i64 = long long;constexpr i64 M = 1e9 + 7;struct pvec &#123; int x, y; friend std::istream &amp;operator&gt;&gt;(std::istream &amp;is, pvec &amp;a) &#123; return is &gt;&gt; a.x &gt;&gt; a.y; &#125; friend std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const pvec &amp;a) &#123; return os &lt;&lt; a.x &lt;&lt; &#x27; &#x27; &lt;&lt; a.y; &#125; bool operator==(const pvec &amp;a) const &#123; return x == a.x &amp;&amp; y == a.y; &#125; pvec operator-(const pvec &amp;a) const &#123; return &#123;x - a.x, y - a.y&#125;; &#125; bool operator&lt;(const pvec &amp;a) const &#123; return x == a.x ? y &lt; a.y : x &lt; a.x; &#125;&#125;;int sign(i64 val) &#123; return val &lt; 0 ? -1 : (val &gt; 0 ? 1 : 0); &#125;i64 cross(const pvec &amp;a, const pvec &amp;b) &#123; return 1ll * a.x * b.y - 1ll * a.y * b.x; &#125;i64 cross(const pvec &amp;a, const pvec &amp;b, const pvec &amp;c) &#123; return cross(b - a, c - a); &#125;i64 dot(const pvec &amp;a, const pvec &amp;b) &#123; return 1ll * a.x * b.x + 1ll * a.y * b.y; &#125;int scross(const pvec &amp;a, const pvec &amp;b, const pvec &amp;c) &#123; return sign(cross(a, b, c)); &#125;i64 sqrlen(const pvec &amp;a) &#123; return dot(a, a); &#125;auto convex_hull(const std::vector&lt;pvec&gt; &amp;x) &#123; std::vector&lt;pvec&gt; v(x); std::vector&lt;pvec&gt; used, unused; std::sort(v.begin(), v.end()); int m = v.size(), tp = -1; for (int i = 0; i &lt; m; i++) &#123; while (tp &gt; 0 &amp;&amp; cross(used[tp-1], used[tp], v[i]) &lt;= 0) tp--, used.pop_back(); used.push_back(v[i]), tp++; &#125; int t = tp; for (int i = m - 1; i &gt;= 0; i--) &#123; while (tp &gt; t &amp;&amp; cross(used[tp-1], used[tp], v[i]) &lt;= 0) &#123; tp--; used.pop_back(); &#125; used.push_back(v[i]), tp++; &#125; used.pop_back(); std::set&lt;pvec&gt; s; for(auto d: used) s.insert(d); for(auto d: v) if (!s.contains(d)) unused.push_back(d); return std::pair&#123;used, unused&#125;;&#125;bool comp(const pvec &amp;a, const pvec &amp;b) &#123; bool upA = a.y &gt; 0 || (a.y == 0 &amp;&amp; a.x &gt;= 0); bool upB = b.y &gt; 0 || (b.y == 0 &amp;&amp; b.x &gt;= 0); if (upA != upB) return upA; auto val = cross(a, b); return val &gt; 0;&#125;i64 area(const std::vector&lt;pvec&gt; &amp;p) &#123; i64 res = 0; for (int i = 0, m = p.size(); i &lt; m; i++) res += cross(p[i], p[(i + 1) % m]); return res;&#125;void run() &#123; int n; std::cin &gt;&gt; n; std::vector&lt;pvec&gt; p(n); for (auto &amp;x : p) std::cin &gt;&gt; x; auto [used, un] = convex_hull(p); int sz = used.size(); i64 ans = 0; for (const auto &amp;x : un) &#123; // enum concave point. std::vector&lt;std::pair&lt;pvec, int&gt;&gt; al; std::vector&lt;pvec&gt; cur(sz); std::vector&lt;i64&gt; val(sz, 0); // area of triangle formed by on-convex points i64 sum = 0; for (const auto &amp;y : un) &#123; // compute vectors if (y == x) continue; al.push_back(&#123;y - x, -1&#125;); &#125; for (int i = 0; i &lt; sz; i++) &#123; cur[i] = used[i] - x; al.push_back(&#123;cur[i], i&#125;); &#125; // sort by angle std::sort(al.begin(), al.end(), [&amp;](const auto &amp;a, const auto &amp;b) &#123; return comp(a.first, b.first); &#125;); // rotate to satisfy pattern: // [on-convex, not, not, ..., not, on-convex, not, not .... , not, on-convex] for (int i = 0; i &lt; al.size(); i++) &#123; if (al[i].second == -1) continue; std::rotate(al.begin(), al.begin() + i, al.end()); break; &#125; // compute convex area for (int i = 0; i &lt; sz; i++) &#123; val[i] = cross(cur[i], cur[(i + 1) % sz]); sum += val[i]; &#125; // enum all points between 2 on-convex points for (int l = 0, r = 0, al_size = al.size(); l &lt; al_size; l = r) &#123; r = l + 1; while (r &lt; al_size &amp;&amp; al[r].second == -1) r++; // (l, r) is the range of not-on-convex points // l, r are on-convex points int pos = al[l].second; std::vector&lt;i64&gt; T(r - l, 0); assert((pos + 1) % sz == al[r % al_size].second); // left convex [&amp;al, &amp;T, &amp;l, &amp;r] &#123; std::vector&lt;pvec&gt; pts; int top = -1; i64 ssum = 0; for (int fix = l; fix &lt; r; fix++) &#123; const auto &amp;q = al[fix].first; while (top &gt;= 1 &amp;&amp; cross(q - pts[top - 1], pts[top] - pts[top - 1]) &gt;= 0) &#123; ssum -= cross(pts[top - 1], pts[top]); top--, pts.pop_back(); &#125; pts.push_back(q), top++; if (top &gt;= 1) ssum += cross(pts[top - 1], pts[top]); T[fix - l] += ssum; &#125; &#125;(); // right convex [&amp;al, &amp;T, &amp;l, &amp;r, &amp;al_size] &#123; std::vector&lt;pvec&gt; pts; int top = -1; i64 ssum = 0; for (int fix = r; fix &gt; l; fix--) &#123; const auto &amp;q = al[fix % al_size].first; while (top &gt;= 1 &amp;&amp; cross(pts[top - 1], pts[top], q) &gt;= 0) &#123; ssum -= cross(pts[top], pts[top - 1]); top--, pts.pop_back(); &#125; pts.push_back(q); top++; if (top &gt;= 1) ssum += cross(pts[top], pts[top - 1]); T[fix - l - 1] += ssum; &#125; &#125;(); for (int i = 0; i &lt; r - l; i++) &#123; i64 st = sum - val[pos] + T[i]; (ans += std::abs(st)) %= M; &#125; &#125; &#125; std::cout &lt;&lt; ans &lt;&lt; &#x27; &#x27;;&#125;int main() &#123; // std::ios::sync_with_stdio(false); // std::cin.tie(nullptr); // std::cout.tie(nullptr); int T = 1; // std::cin &gt;&gt; T; while (T--) run(); return 0;&#125;"},{"title":"2023 ICPC World Final Luxor","path":"/wiki/algo/2023-icpc-wf-luxor.html","content":"A. D. Carl’s Vacation 可以联想到将军饮马模型。我们把三维的金字塔侧面展平到二维上，那么答案的最短路径就可以表达为 tip1→foot1→foot2→top2tip_1\\to foot_1\\to foot_2\\to top_2 tip1​→foot1​→foot2​→top2​ 于是，我们可以枚举每个金字塔的四个侧面，共 4×4=164\\times 4=164×4=16 种情况，在每种情况里求最短路径即可。 接下来考虑如何求这个最短路径。我们肯定需要找到两个 footfootfoot 的坐标。考虑用向量的模长表示线段长度，以及将两个 footfootfoot 的定比分点作为变量的话，那么路径长度 f(k1,k2)f(k_1,k_2)f(k1​,k2​) 分别关于 k1,k2k_1,k_2k1​,k2​ 是单峰函数，所以可以三分套三分。 小细节：浮点数三分或者二分的话，可以指定二分次数，而非 l,rl,rl,r 相差 eps\\texttt{eps}eps，后者容易出现浮点误差。 Code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &quot;headers/geometry.hpp&quot;#include &lt;iostream&gt;using namespace Geo2D;using namespace std;Point p1[4], p2[4], tip1, tip2;Decimal h1, h2, d1, d2, len1, len2;Decimal phi = 0.618, cphi = -phi + 1;int main() &#123; cin &gt;&gt; p1[0] &gt;&gt; p1[1] &gt;&gt; h1; cin &gt;&gt; p2[0] &gt;&gt; p2[1] &gt;&gt; h2; for (int i = 2; i &lt; 4; i++) &#123; p1[i] = p1[i - 1] + (p1[i - 1] - p1[i - 2]).Perp(); p2[i] = p2[i - 1] + (p2[i - 1] - p2[i - 2]).Perp(); &#125; tip1 = (p1[0] + p1[2]) / 2; tip2 = (p2[0] + p2[2]) / 2; len1 = p1[0].Distance(p1[1]); len2 = p2[0].Distance(p2[1]); d1 = (len1.sqr() / 4 + h1.sqr()).sqrt(); d2 = (len2.sqr() / 4 + h2.sqr()).sqrt(); Decimal ans = 2e18; for (int i = 0; i &lt; 4; i++) &#123; Vector v1 = p1[(i + 1) % 4] - p1[i]; Point midp1 = (p1[i] + p1[(i + 1) % 4]) / 2; Point pt1 = midp1 + v1.Normal() * d1; for (int j = 0; j &lt; 4; j++) &#123; Vector v2 = p2[(j + 1) % 4] - p2[j]; Point midp2 = (p2[j] + p2[(j + 1) % 4]) / 2; Point pt2 = midp2 + v2.Normal() * d2; Decimal precent_l1 = 0; Decimal precent_r1 = 1; auto findfoot1 = [&amp;](Decimal precent_mid1) -&gt; Decimal &#123; Point foot1 = p1[i] + v1 * precent_mid1; Decimal precent_l2 = 0; Decimal precent_r2 = 1; auto findfoot2 = [&amp;](Decimal precent_mid2) -&gt; Decimal &#123; Point foot2 = p2[j] + v2 * precent_mid2; return foot1.Distance(foot2) + foot1.Distance(pt1) + foot2.Distance(pt2); &#125;; for (int __ = 1; __ &lt;= 100; __++) &#123; Decimal l2 = precent_l2 * phi + precent_r2 * cphi; Decimal r2 = precent_l2 * cphi + precent_r2 * phi; if (findfoot2(l2) &gt; findfoot2(r2)) precent_l2 = l2; else precent_r2 = r2; &#125; return findfoot2(precent_l2); &#125;; for (int _ = 1; _ &lt;= 100; _++) &#123; Decimal l1 = precent_l1 * phi + precent_r1 * cphi; Decimal r1 = precent_l1 * cphi + precent_r1 * phi; if (findfoot1(l1) &gt; findfoot1(r1)) precent_l1 = l1; else precent_r1 = r1; &#125; ans = min(ans, findfoot1(precent_l1)); &#125; &#125; std::cout &lt;&lt; ans &lt;&lt; &#x27; &#x27;;&#125;"},{"title":"计算几何：凸包","path":"/wiki/algo/convex-hull.html","content":"求解凸包"},{"title":"贪心算法","path":"/wiki/algo/greedy.html","content":"如何证明贪心算法的正确性？ 证明最佳的 solution 可以通过贪心算法在不增加 cost 的情况下求出来 证明每一步选择时，贪心算法的答案都不劣于其他算法 贪心模型 任务规划"},{"title":"Ascend C 介绍与 NPU 芯片","path":"/wiki/ascendc/intro.html","content":"d0144f89de14a1fc384914230d36d0ec0054caf00183a222885cc88f31848a18aab140cd588bb1a31357d2dfedf6c8adfb592b49da5961aaa495123a3ccb3fa9a9f6c36e1bc55e6ff161822b769668a2076f5cfab45f196e1c53f0376e4956630c8a0923bfd91ca220c8d6a51d78be71e5b15538793255c1fcf3fbc64b80ef22508f3168feccbdaffac7faff9ec41aa90bd14105244569a56fb953d126552fc91d226fb4aa73c720ffee5e27a6e6c44331325d651b1f74c98b14d272388278d75502dfd76dee11cf4ae7c17bae192f36d0fc6097e31014e778d3ce734f793cc91d6a0cd8deee525e0a2b5df1feb19690d6cb0ed574e528834c7497615774b37a7d6a622e4a391fda0f6d046ee84fabcc6866a2fa790d0da49f405d25262fe0b227284612f2bbedafb19c35fddce7dbee9ea231f1128845e2cb4d3acb14a798c9445debfe7149b4028652944b99b85e6edd553e3657d323986791286e06611026a0b53564e9d42cb8d5930b665780169dd1f70bcc60ea6a108e7508f6b4bb904766b050f2d77edb2d92da12da5e5c4e226216b6aebe1366030bb436121c7a9f88e091b50f1553e5c3fbf3e08989b7c17a3a39de4e90112e198843ee98d7250d6cd7aa6775e73d8e3f2c10e535f76a20fb37d456d87f6666f252b1711bb852ba8ebdb2569e786dc13560eadb4ae4c42e8b5d14abef39d4ba6c5316bef5bce30910aa0dbe3bd454a7fdf5dbd7c47c034aa4008e8976343eca32e87ba156dc597cb588f4606b79ed83933468023f298250221b45caa3fbc371929526c7172ba395c9ece27b8ece80706195af6c0e7022c6f17e2b0cdd6b68406ce32e43d5bd7bc28fba6d76fe865bc8d0418149ca493a51097a7de299e67e71170344738fcfd519ce277e2a286cff0c58e2a44ea50dddf92fa061b6360d6804ef591820ebe7ead7532e594b1b2328f6deb4d87aa44f3b2c206b04e743f4062a0f3e97c1b4864b8c6d7906763512c3f64396b213ab89caf45d38c0f50f1f5f93fd38816ec6bebbca3364766f2a26cda6379849f8a480114accbaeb749a9dd5b9f6cbee7c31fcb51ff6fcf80c879e9eaa5f05c522fbc29d55095152d5c8e5f7745956c602d18cc1637d57c82ea950aad8409b557346ad1245f228a4492cdfd9274376eadf8dc24f39ecd4594177677dd558ea8a857c7beb585e8d2d780bb29be3591827a4768e7f03b285aa795a4f294b5af5c6474303a17193a9be731f2d6453374ecc65ce9bbeb3cb7eccac9708994ea7be1632ecf6be3094 Password is needed."},{"title":"安装与部署 Dify","path":"/wiki/dify/install-n-use.html","content":"下载 Dify 的 docker compose 文件 1git clone 启动 docker 确保 docker 可以共享文件夹 在 docker desktop -&gt; settings -&gt; resource share 里查看 folder 是否存在。 进入本地部署的 Dify 使用 ip a 查看 docker0 对应的 IP 地址（inet），然后用这个 IP 进入，而不是 localhost"},{"title":"使用 Dify 的“节点”完成数据预处理","path":"/wiki/dify/custom-data-preprocess.html","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"IRR","path":"/wiki/fina/IRR.html","content":"Definition The IRR of the project is the single annual discount rate at which the NPV of the project is equal to zero. 公式 NPV=C0+∑i=1m(11+IRR)iCi=0NPV=C_0+\\sum_{i=1}^{m} \\Big(\\frac{1}{1+IRR}\\Big)^i C_i=0 NPV=C0​+i=1∑m​(1+IRR1​)iCi​=0 IRR Rule 定义 Minimum required return 计算 IRRIRRIRR，与 required return 进行比较 问题 还需要将 Interest Rate 纳入考量 解决办法 先算出两个 project 的 NPV 相等时的利率 RRR，然后根据现在的利率，判断选择那个 project. Amortization Schedule monthly: IRR12\\frac{IRR}{12}12IRR​"},{"title":"Bonds","path":"/wiki/fina/bonds.html","content":"Bonds 债券 不拥有 Ownership 不能投票 无论是否盈利，盈利多少，企业都必须支付本息；否则视为破产 有法律义务支付本息 企业先支付本息，再支付分红 由于支付利息视作企业运营的开支，因此可以抵扣税款 Terms Maturity Date Face Value (Par Value) FFF Coupon Payment CCC Variations Zero-Coupon Bonds: 无利息 Bond Valuation NPV Approach Yield to Maturity (YTM) YTM 使得债券 NPV 为 000 时的 discount rate 假设一年付 mmm 次，那么每次付的比率是 YTMm\\frac{YTM}{m}mYTM​；假设 nnn 年 −P0+C×1−(1+YTM/m)−nmYTM/m+F×(1+YTM/m)−nm=0-P_0+C\\times\\frac{1-(1+YTM/m)^{-nm}}{YTM/m}+F\\times\\Big( 1+YTM/m \\Big)^{-nm}=0 −P0​+C×YTM/m1−(1+YTM/m)−nm​+F×(1+YTM/m)−nm=0 The investors are getting an annual rate of return equal to the return they require on the investment The YTM can be obtained ONLY IF we hold the bond until maturity Risk of Investment 债券投资的风险 利率风险：市场利率上升导致债券价格下跌。 信用风险：发行人违约可能性（如公司破产）。 流动性风险：债券难以快速变现。 通胀风险：通胀削弱固定收益的实际购买力。"},{"title":"Investment Decision Rule","path":"/wiki/fina/invest-decision-rule.html","content":"Investment Decision Rule … based on Returns 就是看最后拿到的钱 RewardRewardReward 是不是初始投资 InvestInvestInvest 多就行， … based on NPV NPV定义​ 净现值（Net Present Value, NPV）是评估投资项目价值的核心指标，计算方式为项目所有现金流（含初始投资）按贴现率折算后的现值总和。公式为： NPV=C0​+∑i=1TCi(1+R)iNPV=C_0​+\\sum_{i=1}^T\\frac{C_i}{(1+R)^i}NPV=C0​​+∑i=1T​(1+R)iCi​​ CtC_tCt​​: 第 ttt 期的现金流（C0C_0C0​​ 为初始成本，通常为负值）。 RRR: 贴现率（通常为金融市场可获得的回报率）。 ​决策规则​ ​NPV &gt; 0：项目收益高于金融市场回报，应接受。 ​NPV &lt; 0：项目收益低于金融市场回报，应拒绝。 ​NPV = 0：项目收益与金融市场相当，决策无差异（可结合其他因素考虑）。 ​关键原则​ ​基准比较：以金融市场回报率为基准，衡量项目是否创造额外价值。 ​现金流方向： 现金流入（收入）为正值（Ct​&gt;0）。 现金流出（成本）为负值（Ct​&lt;0）。 沉没成本忽略：过去已发生且不可逆的成本（如前期调研费用）不计入NPV，仅考虑未来现金流。 ​注意事项​ ​时间价值：现金流的时点影响现值，需准确对应贴现期数。 ​零NPV的意义：项目回报率等于贴现率（金融市场回报率），而非无收益。 总结：NPV规则通过量化项目相对于金融市场的净收益，为投资决策提供清晰标准，强调未来现金流和沉没成本的正确处理。 … based on IRR 预设项目的最少回报 (Minimum Return Required)，然后判断项目的 IRR 是否高于预期。 Internal Rate of Return (IRR) 是将单笔资金拓展到多笔资金，IRRIRRIRR 是年利率 (Annual Rate of Return)，使得整个项目周期结束后的 NPV 为零 NPV=0=C0+∑i=1T(11+IRR)iCiNPV=0=C_0+\\sum_{i=1}^T \\Big(\\frac{1}{1+IRR}\\Big)^i C_i NPV=0=C0​+i=1∑T​(1+IRR1​)iCi​ NPV&nbsp;or&nbsp;IRR 实际上，IRR 和 NPV 大致成反比关系。 Notice the role of the return from the financial sector (e.g., interest rate on bank deposit) in the NPV rule and IRR rule: in the NPV rule, it is the discount rate in the IRR rule, it is the (minimum) required return of the real investment project under consideration. conventional: 初始投资都是 cash outflow，后续所有现金流都是入账 cash inflow non-conventional: 不符合 conventional 的现金流情况 IRR Rule 的问题 当同时考虑多个项目时，先计算 xxx，使得这几个项目在 Discount Rate 为 xxx 时的 NPV 相同。 Payback Rule 考虑多久可以回本（不考虑 discount） Discounted Payback Rule 先 discount cash flow，再应用 Payback Rule Profitability Index PI=PV of future cash flowsinitial costPI=\\frac{\\text{PV of future cash flows}}{\\text{initial cost}} PI=initial costPV of future cash flows​"},{"title":"PV, FV, NPV","path":"/wiki/fina/pv-fv-npv.html","content":"PV, NPV Present Value 一笔在未来会获得的钱在当下的价值 Future Value 一笔现在的钱在未来的价值 实际上 PV 和 FV 非常简单，主要就是考虑利滚利 (Compounding of Interest)，把指数算清楚即可。 某一笔钱的 PV/FV 钱的 PV 相当于说，如果某笔 TTT 年后的钱 QQQ，且利率 rrr 保持不变，那么现在要存 PVPVPV 块钱，这样经过 TTT 年的利滚利，这 PVPVPV 块钱就变成了 QQQ 块钱。 PV×(1+r)T=QPV\\times (1+r)^T=Q PV×(1+r)T=Q 反过来，Future Value 就是，现在存的 QQQ 块钱，在 TTT 年后会变成 FVFVFV 块钱。 FV=Q×(1+r)TFV=Q\\times(1+r)^T FV=Q×(1+r)T 现金流（多笔钱）的 PV/FV 本质就是多笔钱的 FV/PV 全部换算到当前的时间点， PVaggregate=∑PViFVaggregate=∑FViPV_{aggregate}=\\sum PV_{i}\\\\ FV_{aggregate}=\\sum FV_{i}\\\\ PVaggregate​=∑PVi​FVaggregate​=∑FVi​ 由于每笔钱的利滚利时间不同，因此右式的和式通常又可以写成有限项等比数列求和的形式 Annuity, Perpetuity Perpetuity 表示永久持续的恒定现金流，用 CCC 表示每年的现金流（且第一笔现金在一年后） 必须满足两个条件： The cash flows and the interest rates are constant over time, The first cash flow occurs one year from today. 那么所有这些钱的 PV 就是 PV=∑i=1∞C×(11+r)i=Cr\\begin{aligned} PV&amp;=\\sum_{i=1}^{\\infin} C\\times(\\frac{1}{1+r})^i\\\\ &amp;=\\frac{C}{r} \\end{aligned} PV​=i=1∑∞​C×(1+r1​)i=rC​​ Present Value of Annuity 与 Perpetuity 的区别在于 Annuity 有时限。假设经过 TTT 年，那么 Annuity 的 PV 就等于 PV=C(11+r)+C(11+r)2+⋯+C(11+r)T=C×1−(11+r)TrPV=C(\\frac{1}{1+r})+C(\\frac{1}{1+r})^2+\\dots+C(\\frac{1}{1+r})^T=C\\times\\frac{1-(\\frac{1}{1+r})^T}{r} PV=C(1+r1​)+C(1+r1​)2+⋯+C(1+r1​)T=C×r1−(1+r1​)T​ 在一笔现金的时候我们知道，(11+r)T(\\frac{1}{1+r})^T(1+r1​)T 就是 Present Value Factor，所以也可以直接代入写成 PV=1−Present Value Factor(T)rCPV=\\frac{1-\\text{Present Value Factor}(T)}{r}C PV=r1−Present Value Factor(T)​C Future Value of Annuity 如果以第 TTT 年的价值作为基准，把每一笔钱的 FV 都加起来，就能得到 FV=(1+r)T−1rC=Future Value Factor(T)−1rCFV=\\frac{(1+r)^T-1}{r}C=\\frac{\\text{Future Value Factor}(T)-1}{r}C FV=r(1+r)T−1​C=rFuture Value Factor(T)−1​C Effects of Inflation 由于通胀 (Inflation) 的存在，尽管手上的钞票数量变多了，但这并不意味着购买力 (Purchasing Power) 提升。 Purchasing Power the quantity of goods and services that we can buy with our money. … on Nominal/Real Interest Rate Fisher's&nbsp;Equation Nominal IR RRR: interest rate in terms of money Real IR rrr: interest rate in terms of purchasing power 我们用 hhh 表示物价的变化，即通胀率 (Inflation Rate)，则可以得出他们之间的关系 (Fisher Equation) (1+r)(1+h)=(1+R)(1+r)(1+h)=(1+R) (1+r)(1+h)=(1+R) 证明 考虑一开始的钱 QQQ，一开始的物价 PPP，则今年的购买力为 QP\\frac{Q}{P}PQ​，明年的购买力（即经过一年的通胀）为 Q(1+R)P(1+h)\\frac{Q(1+R)}{P(1+h)}P(1+h)Q(1+R)​ 根据 Real Interest Rate 的定义，我们有 Purchase Poweri+1−Purchase PoweriPurchase Poweri=Real IRQ(1+R)P(1+h)QP=1+r(1+r)(1+h)=1+R\\begin{aligned} \\frac{\\text{Purchase Power}_{i+1}-\\text{Purchase Power}_i}{\\text{Purchase Power}_i}&amp;=\\text{Real IR}\\\\ \\frac{\\frac{Q(1+R)}{P(1+h)}}{\\frac{Q}{P}}&amp;=1+r\\\\ (1+r)(1+h)&amp;=1+R \\end{aligned} Purchase Poweri​Purchase Poweri+1​−Purchase Poweri​​PQ​P(1+h)Q(1+R)​​(1+r)(1+h)​=Real IR=1+r=1+R​ 由于这些值都很小，所以我们通常直接近似为 r≊R−hr\\approxeq R-hr≊R−h … on PV &amp; NPV Inflation 并不影响 PV 和 NPV。但必须 discount nominal cash at a nominal rate 或者 discount real cash at a real rate 证明 考虑 inflation rate 为 hhh，nominal interest rate 为 RRR，考虑 nnn 年后的一笔钱 CCC (nominal)，那么用 Nominal Interest Rate 算的话 PVnominal=C(1+R)nPV_{nominal}=\\frac{C}{(1+R)^n} PVnominal​=(1+R)nC​ 用购买力计算的话，nnn 年后的购买力为 C(1+h)n\\frac{C}{(1+h)^n}(1+h)nC​，因此 discount at a real rate 的话，即为 PVreal=C(1+h)n(1+r)nPV_{real}=\\frac{\\frac{C}{(1+h)^n}}{(1+r)^n} PVreal​=(1+r)n(1+h)nC​​ 代入 Fisher’s Equation 1+R=(1+h)(1+r)1+R=(1+h)(1+r)1+R=(1+h)(1+r) 可得 PVreal=PVnominalPV_{real}=PV_{nominal} PVreal​=PVnominal​ 因此其实并不影响 Present Value。对于 Net PV，由于基准年的金额有 Nominal=RealNominal=RealNominal=Real，因此也不影响 NPV"},{"title":"Valuation of Stocks","path":"/wiki/fina/valuation-of-stocks.html","content":"Stock 股票 拥有对企业的所有权 Ownership 可以投票 以分红的形式分享利益 没有法律义务支付一定数额的分红 企业先付 bonds 产生的利息，再支付分红 支付的分红不能用于抵扣税款 Dividend Discount Model (DDM 模型) stock 会产生分红现金流， PV of Dividend Stream=∑i=1+∞Di(1+R)i\\text{PV of Dividend Stream}=\\sum_{i=1}^{+\\infin}\\frac{D_i}{(1+R)^i} PV of Dividend Stream=i=1∑+∞​(1+R)iDi​​ 也被称为 funcdamental value of stock. 在市场完全竞争的情况下，价格 P0=PV of Dividend StreamP_0=\\text{PV of Dividend Stream}P0​=PV of Dividend Stream. 这个模型被称为 Dividend Discount Model. Special Case 1: 恒常分红现金流 当 Di=DjD_i=D_jDi​=Dj​ 时，通过等比数列求和可以简便地计算 P0P_0P0​ P0=D1RP_0=\\frac{D_1}{R} P0​=RD1​​ Special Case 2: 现金流等比增长 也被称为 Gordon’s Growth Model，设分红以每年 ggg 的速度增长，即 Di=(1+g)Di−1D_i=(1+g)D_{i-1}Di​=(1+g)Di−1​，则有 P0=D1R−gP_0=\\frac{D_1}{R-g} P0​=R−gD1​​ 一些指标 Dividend Yield 计算产生的分红 Dividend Yield=D1P0\\text{Dividend Yield}=\\frac{D_1}{P_0} Dividend Yield=P0​D1​​ Capital Gains Yield 如果在 ttt 时刻卖出 stock，可以计算获得的资本 Capital Gains Yield=Pt−P0P0\\text{Capital Gains Yield}=\\frac{P_t-P_0}{P_0} Capital Gains Yield=P0​Pt​−P0​​ Common vs. Preferred Common stock 有投票权 Preferred stock 享有优先分红的权利 由于 Preferred stock 的期限是无穷的，我们可以直接按 Perpetual Bond 来看待。如果每年分红 DpD_pDp​，利率 RpR_pRp​，初始股价 P0P_0P0​，根据 DDM 模型，有 P0=DpRpP_0=\\frac{D_p}{R_p} P0​=Rp​Dp​​"},{"title":"Decoder-Only Transformer","path":"/wiki/llm/decoder-only-transformer.html","content":"Decoder-only Transformers Decoder-only 架构通常用于生成任务，代表作包括 GPT，GPT-2 等。 什么是生成任务 简单来说，Decoder-only 解决的生成任务是指：给定前 nnn 个单词 x1,x2,…,xnx_1,x_2,\\dots,x_nx1​,x2​,…,xn​，要求输出第 n+1n+1n+1 个单词。可以看出，这类生成任务的本质是 AutoRegressive 的。 近年来，出现了使用 Diffusion 作为 Language Model 的生成，达到了极快的生成速度。"},{"title":"Transformer 架构","path":"/wiki/llm/classic-transformer.html","content":"Before Transformer: RNN, Attention 在 RNN 里，我们用一个隐藏变量 hth_{t}ht​ 记录前 ttt 个 Input Token 所代表的 Context。如果要生成第 t+1t+1t+1 个 Output Token 的话，就利用输入的第 t+1t+1t+1 个 Input Token 和代表了前文信息的隐藏状态 hth_{t}ht​ 做 Attention Alignment 计算出一个向量，再转换成 Word. 这样一个 AutoRegressive 模型有两个显著的问题 由于是时序生成（必须一个一个 Token 地生成），无法并行 由于时序生成，如果要保存很久远的信息，隐藏状态 hth_tht​ 的大小就必须非常大，导致了 Computation &amp; Memory Overhead Model Arch Transformer 总体是 Encoder-Decoder 架构。Encoder 将 Input"},{"title":"minimind","path":"/wiki/llm/minimind.html","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"Tokenizer 分词器","path":"/wiki/llm/tokenizer.html","content":"Tokenizer Tokenizer 在 LLM（大型语言模型）的上下文中指的是负责将输入文本分解成称为 tokens 的更小单元的组件。这些 tokens 是模型处理的基本元素（例如单词、子词或字符）。Tokenizer 将原始文本转换为模型可以处理的数字表示，并且在处理之后，还能将 tokens 转换回人类可读的文本。 Hugging Face Tokenizer: tokenizer.json"},{"title":"Comparative Statics","path":"/wiki/microecon/comparative-statics.html","content":"Change of Demand Curve 令 xxx 表示商品，那么其 Demand Curve 可以表示为 Qxd=a+bPxd+…Q^d_x=a+bP^d_x+\\dots Qxd​=a+bPxd​+… Increase in Demand 直线向右上移动，可以是向上平移，也可以是向右平移 Movement 影响因素：Income Normal Good Income↑ ⟹ Qxd↑\\text{Income}\\uparrow \\implies Q^d_x\\uparrowIncome↑⟹Qxd​↑ Inferior Good Income↑ ⟹ Qxd↓\\text{Income}\\uparrow \\implies Q^d_x\\downarrowIncome↑⟹Qxd​↓ 影响因素：Population 影响因素：Price&nbsp;of&nbsp;Substitutes Psubstitute↑ ⟹ Qxd↑P_{\\text{substitute}}\\uparrow \\implies Q^d_x\\uparrow Psubstitute​↑⟹Qxd​↑ 当其他平替的价格上涨，消费者自然而然会转向价格更低的 xxx 影响因素：Price&nbsp;of&nbsp;Complement Pcomplement↑ ⟹ Qxd↓P_{\\text{complement}}\\uparrow \\implies Q^d_x\\downarrow Pcomplement​↑⟹Qxd​↓ 影响因素：Expectation The expectation of a higher (lower) price for a good in the future increases (decreases) current demand for the good. 影响因素：Tastes Supply Movement of Supply Curve Increase in Supply Technology Entry implies more sellers in the market increasing supply. Exit implies fewer sellers in the market decreasing supply. Sellers will supply less of a good if the price of an alternate good using the same inputs rises (and vice versa). (-)"},{"title":"Cost Benefit Analysis","path":"/wiki/microecon/cost-benefit.html","content":"Rational Decision 对每一件事进行衡量，其付出为 C(x)C(x)C(x)，获得为 B(x)B(x)B(x)，那么定义 Economic Surplus ES(x)ES(x)ES(x) 为 ES(x)=B(x)−C(x)\\boxed{ES(x)=B(x)-C(x)} ES(x)=B(x)−C(x)​ Cost Benefit Principle当且仅当 ES(x)≥0ES(x)\\ge 0ES(x)≥0 时，才会做 xxx，此时收益大于付出；否则不做。 Cost/Benefit 只包含会影响被决策的 Cost 和 Benefit Sunk Cost Marginal(Additional) Cost/Benefit Only if Marginal Benefit≥Marginal Cost\\text{Marginal Benefit}\\ge\\text{Marginal Cost} Marginal Benefit≥Marginal Cost Allocation of Resources 优先分配给 Marginal Benefit 多的 Opportunity Cost 所有不选的选项里，Economic Surplus(不选的选项的 Cost = Benefit，没有这部分的开销了) 最大的那个"},{"title":"Elasticity 弹性","path":"/wiki/microecon/elasticity.html","content":"弹性 量化某个变量随着另一个变量的变化而变化的程度 弹性大：因变量对自变量的变化很敏感 弹性小：因变量对自变量的变化不怎么敏感 Price Elasticity of Demand 量化 PED=percentage change in Quantity demandedpercentage change in Price=%ΔQd%ΔPPED=\\frac{\\textbf{percentage}\\text{ change in Quantity demanded}} {\\textbf{percentage}\\text{ change in Price}}=\\boxed{\\frac{\\%\\Delta Q^d}{\\%\\Delta P}} PED=percentage change in Pricepercentage change in Quantity demanded​=%ΔP%ΔQd​​ 两点&nbsp;PED&nbsp;计算公式 我们用中点代为计算 Percentage Change Percentage=New−Old(New+Old)/2\\text{Percentage}=\\frac{\\text{New}-\\text{Old}}{(\\text{New+Old})/2} Percentage=(New+Old)/2New−Old​ 那么 PEDPEDPED 的计算公式可以改写成 PED=Qnewd−QolddPnew−Pold×Pnew+PoldQnewd+Qoldd\\boxed{ PED=\\frac{Q^d_{new}-Q^d_{old}}{P_{new}-P_{old}}\\times \\frac{P_{new}+P_{old}}{Q^d_{new}+Q^d_{old}} } PED=Pnew​−Pold​Qnewd​−Qoldd​​×Qnewd​+Qoldd​Pnew​+Pold​​​ 当某个点 oldoldold 已经被固定了的时候，考虑其差值 ΔQ→0\\Delta Q\\to 0ΔQ→0，就有 PED=ΔQdΔP×2Pold+ΔP2Qoldd+ΔQd→ΔQdΔP×PoldQoldd→PQd×1slope\\begin{aligned} PED&amp;=\\frac{\\Delta Q^d}{\\Delta P}\\times \\frac{2P_{old}+\\Delta P}{2Q^d_{old}+\\Delta Q^d}\\\\ &amp;\\to \\frac{\\Delta Q^d}{\\Delta P}\\times\\frac{P_{old}}{Q^d_{old}}\\\\ &amp;\\to \\boxed{\\frac{P}{Q^d}\\times \\frac{1}{\\text{slope}}} \\end{aligned} PED​=ΔPΔQd​×2Qoldd​+ΔQd2Pold​+ΔP​→ΔPΔQd​×Qoldd​Pold​​→QdP​×slope1​​​ Observation Price Elasticity 随着点在 Quantity of Demand 曲线上的移动而变化；并且在中点处为 −1-1−1，往上 &lt;−1\\lt -1&lt;−1，往下 &gt;−1\\gt -1&gt;−1 如果两条 QdQ^dQd 曲线有交点，那么更加平缓的那条直线在这个点上的弹性更大。 Elasticity 与 Revenue 收入基本公式 Revenue=Quantity×Price\\text{Revenue}=\\text{Quantity}\\times\\text{Price} Revenue=Quantity×Price 因此考虑 Elasticity 的话，Revenue 是关于 Price 的二次函数，并且在 PED=−1PED=-1PED=−1 的时候，取到最大值 弹性需求（∣η∣&gt;1∣\\eta∣&gt;1∣η∣&gt;1）：降价增加总收益（需求量增幅 &gt;&gt;&gt; 价格降幅）。 非弹性需求（∣η∣&lt;1∣\\eta∣&lt;1∣η∣&lt;1）：降价减少总收益（需求量增幅 &lt;&lt;&lt; 价格降幅）。 单位弹性（∣η∣=1∣\\eta∣=1∣η∣=1）：总收益最大。 也可以在 QdQ^dQd 直线上直观地进行比较：找到点变化前后对应的矩形变化面积。更一般的，如果点在中点上方，则总收益一定增加；在下方则总收益减少。 Constant Elasticity 如果一条曲线在每一个点的 PPP Elasticity of QQQ 都相等为 −k-k−k，那么其曲线可以表示为 f(P,Q):PkQ=Cf(P,Q):\\boxed{P^{\\textcolor{red}{k}}Q=C} f(P,Q):PkQ=C​ 证明（不考） 考虑 Q-P 曲线 fff 在这一个点的 Elasticity，用点斜式即为 Elasticity=−k=PQ×dQdP\\text{Elasticity}=-k=\\frac{P}{Q}\\times\\frac{dQ}{dP} Elasticity=−k=QP​×dPdQ​ 把 xdxx\\mathop{dx}xdx 放到一起： −kPdP=1QdQ-\\frac{k}{P}\\mathop{dP}=\\frac{1}{Q}\\mathop{dQ} −Pk​dP=Q1​dQ 两边积分 −kln⁡P+CP=ln⁡Q+CQln⁡Q+kln⁡P=cPkQ=C\\begin{aligned} -k\\ln{P}+C_P&amp;=\\ln{Q}+C_Q\\\\ \\ln Q+k\\ln P&amp;=c\\\\ P^kQ&amp;=C \\end{aligned} −klnP+CP​lnQ+klnPPkQ​=lnQ+CQ​=c=C​ 左右取对数，曲线方程也可以写作 ln⁡Q=−kln⁡P+c\\boxed{ \\ln Q=\\textcolor{red}{-k} \\ln P+c } lnQ=−klnP+c​ 影响 Price Elasticity of Demand 的因素 Availability of Substitutes Time Horizon 产品有效期 Category of product (specific or broad) Necessities vs. Luxuries Purchase Size Substitutes Fewer substitutes makes it harder for consumers to adjust QQQ when PPP changes… so demand is more inelastic. Many substitutes? Switching brands when prices change is easy, so demand is more elastic. Time Horizon Category 另外两种 Elasticity Cross-Elasticity Exy=%ΔQd of X%ΔP of Y=PyQxd×ΔQxΔPy\\begin{aligned} E_{xy}&amp;=\\frac{\\%\\Delta Q^d \\text{ of X}}{\\%\\Delta P \\text{ of Y}}\\\\ &amp;=\\boxed{\\frac{P_y}{Q^d_x}\\times\\frac{\\Delta Q_x}{\\Delta P_y}} \\end{aligned} Exy​​=%ΔP of Y%ΔQd of X​=Qxd​Py​​×ΔPy​ΔQx​​​​ Exy&gt;0E_{xy}&gt;0Exy​&gt;0 说明是 Substitute ；反之，说明是 complement Income Elasticity EI=%ΔQd%ΔIncome=IQx×ΔQxΔI\\begin{aligned} E_I&amp;=\\frac{\\%\\Delta Q^d}{\\%\\Delta \\text{Income}}\\\\ &amp;=\\boxed{\\frac{I}{Q_x}\\times\\frac{\\Delta Q_x}{\\Delta I}} \\end{aligned} EI​​=%ΔIncome%ΔQd​=Qx​I​×ΔIΔQx​​​​ EI&gt;1E_I\\gt 1EI​&gt;1 说明是 Luxury EI&gt;0E_I\\gt 0EI​&gt;0 说明是 Normal Goods EI&lt;0E_I\\lt 0EI​&lt;0 为 Inferior Goods Price Elasticity of Supply 类似的，也有中点公式和点斜公式 性质 PES&gt;0PES\\gt 0PES&gt;0 若截距 &gt;0\\gt 0&gt;0，那么随着 QsQ^sQs 增加，PESPESPES 降低，但永远 &gt;1\\gt 1&gt;1 若过原点，则 PES≡1PES\\equiv 1PES≡1 影响因素 Change in Per-Unit Costs with Increased Production Time Horizon Share of Market for Inputs Geographic Scope Elasticity and Quick Predictions 把基准点放在 Equilibrium Point，记 ηs\\eta_sηs​ 为 Price Elasticity of Supply，ηd\\eta_dηd​ 为 Price Elasticity of Demand，则有 % change in Price from a shift in Demand ΔQd=% change in Demand ΔQdηs+∣ηd∣% change in Price from a shift in Supply ΔQs=−% change in Supply ΔQsηs+∣ηd∣\\begin{array}{rll} \\text{\\% change in \\textbf{Price} from a shift in \\textbf{Demand} }\\Delta Q^d\\\\ =\\frac{\\text{\\% change in \\textbf{Demand} }\\Delta Q^d}{\\eta_s+|\\eta_d|}\\\\ \\text{\\% change in \\textbf{Price} from a shift in \\textbf{Supply} }\\Delta Q^s \\\\ =\\textcolor{red}{-}\\frac{\\text{\\% change in \\textbf{Supply} }\\Delta Q^s}{\\eta_s+|\\eta_d|} \\end{array} % change in Price from a shift in Demand ΔQd=ηs​+∣ηd​∣% change in Demand ΔQd​% change in Price from a shift in Supply ΔQs=−ηs​+∣ηd​∣% change in Supply ΔQs​​"},{"title":"Tax and Subsidy","path":"/wiki/microecon/tax-subsidy.html","content":"本章最核心的理论是，无论税收或者补贴，假设为 TTT 元，那么当达到新的平衡点时，消费者支付价格与生产者成本价格之间的差值必为 TTT 元 Pd−Ps=T\\boxed{P^d-P^s=T} Pd−Ps=T​ Tax Subsidy"},{"title":"Supply Demand","path":"/wiki/microecon/supply-demand.html","content":"Demand Curve Normal good: When we have more income, we choose to buy more of the good. Inferior good: When we have more income, we choose to buy less of the good. Combination of Demand Curves Qtotald=Q1d+Q2dQ^d_{total}=Q^d_{1}+Q^d_2 Qtotald​=Q1d​+Q2d​ Supply Curve Horizontally: How many suppliers are willing and able to sell at a certain price. Vertically: The minimum price for which suppliers are willing to sell a certain quantity. Combination of Supply Curves Qtotals=Q1s+Q2sQ^s_{total}=Q^s_{1}+Q^s_2 Qtotals​=Q1s​+Q2s​ 计算 Equilibrium: Supply Curve 与 Demand Curve 的交点 Economic Surplus 这个 Surplus 可以这样理解：如果我预期 100100100 元买下，而我实际只花了 606060，那么其实我会觉得我赚了 100−60=40100-60=40100−60=40。 而在 Equilibrium 的情况下，交易价为 Equi Price，在 Demand Curve 上不同预期价（Price，纵坐标）有对应的人数（Quantity，横坐标，实际上应该是 ΔQ\\Delta QΔQ），因此对于这个预期价而言，他们获得的“赚了”感是 P×ΔQP\\times \\Delta QP×ΔQ 因此在下图的公式里，所有的 Surplus 是一个三角形 Total Economic Surplus=Consumer Surplus+Producer Surplus\\text{Total Economic Surplus}=\\text{Consumer Surplus}+\\text{Producer Surplus} Total Economic Surplus=Consumer Surplus+Producer Surplus 如果 Economic Surplus &lt;0\\lt 0&lt;0 那么交易就不会发生 红色部分就是 Total Economic Surplus 分别计算 Consumer 和 Producer 的 Surplus"},{"title":"Trading 交易与分工","path":"/wiki/microecon/trading.html","content":"Unit Requirement Table 与 Unit Productivity Table Requirement 和 Productivity Table 最重要的区别就是：前者给出生产一个物品需要的资源，后者给出在限定资源的情况下能生产多少物品。 有一个简单的转化： 1Requirement=Productivity\\frac{1}{\\text{Requirement}}=\\text{Productivity} Requirement1​=Productivity Opportunity Cost Opportunity Cost Copp()C_{opp}()Copp​() 描述某个人在生产某件物品的时候，能够生产多少的其他物品；直观理解就是这个人生产这件物品有多 efficient 重要公式Copp(A)=Time of ATime of B=Productivity of BProductivity of AC_{opp}(A)=\\frac{\\text{Time of }A}{\\text{Time of }B}=\\frac{\\text{Productivity of }B}{\\text{Productivity of }A}Copp​(A)=Time of BTime of A​=Productivity of AProductivity of B​ 这里的 Quantity 是在一段长度确定的时间内的。并且可以注意到 Copp(A)=1Copp(B)C_{opp}(A)=\\frac{1}{C_{opp}(B)}Copp​(A)=Copp​(B)1​ 如果对于两个人 X,YX,YX,Y，如果 Copp,X(A)&lt;Copp,Y(A)C_{opp,X}(A)\\lt C_{opp,Y}(A)Copp,X​(A)&lt;Copp,Y​(A)，即 XXX 在 AAA 上的 Opportunity Cost 更小，我们称 XXX 在 AAA 上有 Comparative Advantage. Specialization 分工 一个经济体里肯定会有分工，理性经济体里的分工由 Opportunity Cost 的大小来决定：让 Copp(A)C_{opp}(A)Copp​(A) 最小的人来负责这件 AAA （总是让最高效的人来处理这件事） 分工的存在，也可以让经济体达到 1+1&gt;21+1\\gt 21+1&gt;2 的效果。 Term of Trade (TOT) TOTTOTTOT 描述交易时的换算比例（例如 1.11.11.1 Tea/Cake 说明 111 个蛋糕能交易 1.11.11.1 包茶） 因为交易的双方都需要从交易中获利（否则根本不会进行交易），此时 Term of Trade 叫需要满足一些条件，使得双方都能获利。这里的获利的意思是，我从你这里买东西比我自己生产这个东西要好（你更加熟练，需要的资源更少）。 一个重要的公式就是，对于交易的双方，TOTAperBTOT_{A\\mathop{per}B}TOTAperB​（表示 1 unit B=TOT unit A\\text{\\(1\\) unit \\(B=TOT\\) unit \\(A\\)}1 unit B=TOT unit A）应该满足 Copp,X(A)≤TOTAperB≤Copp,Y(A)C_{opp,X}(A)\\le TOT_{A\\mathop{per}B}\\le C_{opp,Y}(A) Copp,X​(A)≤TOTAperB​≤Copp,Y​(A) 证明 我们假设经济体只生产 A,BA,BA,B 两件物品，且生产 AAA 的 XXX 与生产 BBB 的 YYY 进行交易。那么我们首先知道，根据分工，有 Copp,X(A)&lt;Copp,Y(A)Copp,X(B)&gt;Copp,Y(B)C_{opp,X}(A)\\lt C_{opp,Y}(A)\\\\ C_{opp,X}(B)\\gt C_{opp,Y}(B) Copp,X​(A)&lt;Copp,Y​(A)Copp,X​(B)&gt;Copp,Y​(B) 交易双方判断能否获利的准则是： （Requirement）生产相同数量时，相比自己生产，能否获得资源上的节约？ （Quantity）拥有相同数量资源时，相比自己生产，能否获得产品数量上的提升？ 现在假设 TOT 的计算是 111 个单位 BBB 能交易 TOTTOTTOT 单位的 AAA（那么其单位就是 A/BA/BA/B），用资源的节省量推导。 那么，对 XXX 而言，他生产的是 AAA，购买的是 BBB，那么他生产的 111 个单位的 AAA 能换来 1TOT\\frac{1}{TOT}TOT1​ 的 BBB，理论应该节约 RX(B)−1TOTRX(A)≥0 ⟺ TOT≥RX(A)RX(B)=Copp,X(A)\\begin{aligned} &amp;R_{X}(B)-\\frac{1}{TOT}R_X(A)\\ge 0\\\\ \\iff &amp;TOT\\ge \\frac{R_X(A)}{R_X(B)}=C_{opp,X}(A) \\end{aligned} ⟺​RX​(B)−TOT1​RX​(A)≥0TOT≥RX​(B)RX​(A)​=Copp,X​(A)​ 同理，对 YYY 而言，他生产的每单位 BBB 能换 TOTTOTTOT 单位的 AAA，理论上，生产 AAA 可以节约 RY(A)−TOT×RY(B)≥0 ⟺ TOT≤RY(A)RY(B)=Copp,Y(A)\\begin{aligned} &amp;R_Y(A)-TOT\\times R_Y(B)\\ge 0\\\\ \\iff&amp;TOT\\le\\frac{ R_Y(A)}{R_Y(B)}=C_{opp,Y}(A) \\end{aligned} ⟺​RY​(A)−TOT×RY​(B)≥0TOT≤RY​(B)RY​(A)​=Copp,Y​(A)​ 所以，对于交易的双方，TOTAperBTOT_{A\\mathop{per}B}TOTAperB​（表示 1 unit B=TOT unit A\\text{\\(1\\) unit \\(B=TOT\\) unit \\(A\\)}1 unit B=TOT unit A）应该满足 Copp,X(A)≤TOTAperB≤Copp,Y(A)C_{opp,X}(A)\\le TOT_{A\\mathop{per}B}\\le C_{opp,Y}(A) Copp,X​(A)≤TOTAperB​≤Copp,Y​(A) (PPC) Production Possibility Curve PPC 上的一条直线 我们假设纵轴表示 AAA 的生产，横轴表示 BBB 的生产，那么截距表示全力生产某一样物品的情况下，该物品的产量。 我们来考察这条直线的斜率 kkk，则有 k=−Productivity of AProductivity of B=−Copp(B)=−1Copp(A)\\begin{aligned} k&amp;=-\\frac{\\text{Productivity of }A}{\\text{Productivity of }B}\\\\ &amp;=-C_{opp}(B)\\\\ &amp;=-\\frac{1}{C_{opp}(A)} \\end{aligned} k​=−Productivity of BProductivity of A​=−Copp​(B)=−Copp​(A)1​​ 我们更关心 ∣k∣|k|∣k∣，这个绝对值的意义更加鲜明：多生产 111 个单位的 BBB 的 Opportunity Cost 为 ∣k∣|k|∣k∣ 的单位的 AAA.，而 ∣k∣=Copp(B)|k|=C_{opp}(B)∣k∣=Copp​(B) 多条直线：分工 Low-Hanging-Fruit&nbsp;Principle 这个原理描述一个经济体内多人合作分工时，若要扩大生产，一定先让 Lowest Opportunity Cost 的人去做（因为最高效） 如果扩大的是 BBB 的生产（横轴），那么从左向右斜率的绝对值越来越大，越来越陡峭；图像呈现向上凸。 如果扩大的是 AAA 的生产（纵轴），那么从下往上直线的斜率的绝对值越来越小，越来越平缓（因为 Copp(A)C_{opp}(A)Copp​(A) 与 Copp(B)C_{opp}(B)Copp​(B) 成反比）；不过图像仍是上凸的。 直线的相交位置：(Bi−1,Ai)(B_{i-1},A_i)(Bi−1​,Ai​) 影响 PPC 的因素 资源增多 科技进步 总结 通常来说，如果交易双方的 Copp()C_{opp}()Copp​() 差距越大，那么双方交易带来的资源节省和产能提升也会越大。 (CPC) Consumption Probalitity Curve Closed Economy: 无开放贸易 在无开放贸易的情况下，一个经济体的 CPC 和 PPC 是重合的。因为除了这几个人没有人需要生产的物品，因此这些人生产出来的东西只能被自己消耗。 有浪费会趋于减产，有不够会趋于增产，最终都会回归到 PPC 上，因此 CPC 与 PPC 重合。 Open Economy and Open Trade 我们可以从几个角度来看 Open Trade 对 Production 和 Consumption 的影响，然后来看一看相关的计算。 以下假设假设贸易市场上 AAA 的价格为 aaa，BBB 的价格为 bbb，假设 TOTTOTTOT 用 AperBA\\mathop{per} BAperB 计算，此时对于贸易市场来说，TOT=TOTAperB=abTOT=TOT_{A\\mathop{per}B}=\\frac{a}{b}TOT=TOTAperB​=ba​ 例子：如何生产使得收益最大化 贸易市场的价格可以用一根斜率确定、截距不定的直线在 PPC 图像（纵轴为 AAA，横轴为 BBB）上表示出来，这条直线的斜率就是 −TOT-TOT−TOT 为了让利益最大化，我们平移这条直线，让他和 PPC 产生交点，对于每一个交点计算收益，取最大值即可。 从交点倒推&nbsp;TOT&nbsp;和市场价格 一个很 tricky 的点是，图像上 PPC 的斜率是 −Copp(B)-C_{opp}(B)−Copp​(B)，但市场的直线的斜率是 −TOTAperB-TOT_{A\\mathop{per}B}−TOTAperB​。记得取倒数。 最大化组合消费 通常会问，若消费 nnn 单位的 AAA，那么最多能消费多少 BBB？ 我们把这个过程转化为，X,YX,YX,Y 两人先生产，通过贸易市场换成钱，再用钱在市场上买所需的物品。这里不考虑成“生产后的东西先拿出一部分满足消费”，是因为这两个思路是等价的 计算：在这个市场下，通过交易最多能赚多少钱 通过计算 TOTTOTTOT，判断出每一个应该生产什么（贸易市场的 TOTAperBTOT_{A\\mathbb{per}B}TOTAperB​ 更大，则生产 AAA；否则生产 BBB） 把生产出来的东西卖成钱 先购买需要消费的东西 然后就能计算最多能买多少了"},{"title":"（隐）马尔可夫模型","path":"/wiki/ml/markov-model.html","content":"Markov Property 第 ttt 时刻的 State 只依赖于 t−1t-1t−1 时刻的 StateP(Xt∣Xt−1)P(X_t|X_{t-1}) P(Xt​∣Xt−1​) Mini-Forward Algorithm P(X1)is knownP(Xt∣Xt−1)is knownP(Xt)=∑xt−1P(Xt∣Xt−1)⋅P(Xt−1)\\begin{array}{r|l} P(X_1)&amp;\\text{is known}\\\\ P(X_t|X_{t-1})&amp;\\text{is known}\\\\ \\hline P(X_t)&amp;=\\sum_{x_{t-1}} P(X_t|X_{t-1})\\cdot P(X_{t-1}) \\end{array} P(X1​)P(Xt​∣Xt−1​)P(Xt​)​is knownis known=∑xt−1​​P(Xt​∣Xt−1​)⋅P(Xt−1​)​​ Markov Model Hidden Markov Model HMM Inference: Passage of Time (Prediction) Passage of Time 推理中，我们关心的是，给定前 ttt 时刻的观测 e1:te_{1: t}e1:t​，求解第 t+1t+1t+1 时刻隐变量的分布。 P(xt+1∣e1:t)P(x_{t+1}|e_{1: t}) P(xt+1​∣e1:t​) 这个本质上是在求解 12graph LRx1((&quot;x[t]&quot;)) --&gt; x2((&quot;x[t+1]&quot;)) 推导 将条件概率表示为联合概率 P(xt+1∣e1:t)=P(xt+1,e1:t)P(e1:t)P(x_{t+1}|e_{1: t})=\\frac{P(x_{t+1},e_{1: t})}{P(e_{1: t})} P(xt+1​∣e1:t​)=P(e1:t​)P(xt+1​,e1:t​)​ 考虑 xtx_txt​ 这个隐变量，分子就变为对 P(…,xt,… )P(\\dots, x_t,\\dots)P(…,xt​,…) 进行 sum up =∑xtP(xt+1,xt,e1:t)P(e1:t)=\\frac{\\sum_{x_t}P(x_{t+1},x_t,e_{1: t})}{P(e_{1: t})} =P(e1:t​)∑xt​​P(xt+1​,xt​,e1:t​)​ 再将分子用三元贝叶斯定理展开 =∑xtP(xt+1∣xt,e1:t)⋅P(xt∣e1:t)⋅P(e1:t)P(e1:t)=∑xtP(xt+1∣xt,e1:t)⋅P(xt∣e1:t)\\begin{aligned} &amp;=\\frac{\\sum_{x_t}P(x_{t+1}|x_t,e_{1: t})\\cdot P(x_t|e_{1: t})\\cdot \\cancel{P(e_{1: t})}}{\\cancel{P(e_{1: t})}}\\\\ &amp;=\\sum_{x_t}P(x_{t+1}|x_t,e_{1: t})\\cdot P(x_t|e_{1: t}) \\end{aligned} ​=P(e1:t​)​∑xt​​P(xt+1​∣xt​,e1:t​)⋅P(xt​∣e1:t​)⋅P(e1:t​)​​=xt​∑​P(xt+1​∣xt​,e1:t​)⋅P(xt​∣e1:t​)​ 根据马尔可夫假设和独立性假设，xt+1x_{t+1}xt+1​ 只受 xtx_txt​ 直接影响，因此 P(xt+1∣xt,e1:t)=P(xt+1∣xt)P(x_{t+1}|x_t,e_{1: t})=P(x_{t+1}|x_t)P(xt+1​∣xt​,e1:t​)=P(xt+1​∣xt​) =∑xtP(xt+1∣xt)⋅P(xt∣e1:t)=\\boxed{\\sum_{x_t}P(x_{t+1}|x_t)\\cdot P(x_t|e_{1: t})} =xt​∑​P(xt+1​∣xt​)⋅P(xt​∣e1:t​)​ Inference: Observation (Filtering) 给定前 ttt 时刻的观测 e1:te_{1: t}e1:t​，求解当前的隐变量的分布 P(xt∣e1:t)P(x_t|e_{1: t}) P(xt​∣e1:t​) 推导 依然先转化为联合概率 =P(xt,et,e1:t−1)P(e1:t)=\\frac{P(x_t,e_t,e_{1: t-1})}{P(e_{1: t})} =P(e1:t​)P(xt​,et​,e1:t−1​)​ 用三元贝叶斯定理展开 =P(et∣xt,e1:t−1)⋅P(xt∣e1:t−1)⋅P(e1:t−1)P(et∣e1:t−1)⋅P(e1:t−1)=\\frac{P(e_t|x_t,e_{1: t-1})\\cdot P(x_t|e_{1: t-1})\\cdot \\cancel{P(e_{1: t-1})}}{P(e_t|e_{1: t-1})\\cdot \\cancel{P(e_{1: t-1})}} =P(et​∣e1:t−1​)⋅P(e1:t−1​)​P(et​∣xt​,e1:t−1​)⋅P(xt​∣e1:t−1​)⋅P(e1:t−1​)​​ 根据独立性假设，ete_tet​ 只于当前时刻的 xtx_txt​ 有关，因此可以化简为 =P(et∣xt)⋅P(xt∣e1:t−1)P(et∣e1:t−1)=\\boxed{\\frac{P(e_t|x_t)\\cdot \\color{red}{P(x_t|e_{1: t-1})}}{P(e_t|e_{1: t-1})}} =P(et​∣e1:t−1​)P(et​∣xt​)⋅P(xt​∣e1:t−1​)​​ x 注意到红色部分就是 Inference: Passage of Time 部分的结果"},{"title":"Particle Filter 粒子滤波","path":"/wiki/ml/particle-filter.html","content":"Particle Filter: Overview 现实世界里，xxx 的维度太大，会涉及很多变量 对 xxx 的一些 Samples 进行运算，而非所有 xxx Sampling x′=sample(distribution(X′∣x))x&#x27;=\\text{sample}\\Big( \\text{distribution}(X&#x27;|x) \\Big) x′=sample(distribution(X′∣x))"},{"title":"ViT","path":"/wiki/multimodal/ViT.html","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"Q Learning","path":"/wiki/rl/q-learning.html","content":"Q-Learning 我们的 Agent 每次从环境接收 transition=(s,a,r,s′)\\texttt{transition}=(s,a,r,s&#x27;)transition=(s,a,r,s′) 的反馈，以此进行学习。由于无法建模出转移概率 T(s,a,s′)T(s,a,s&#x27;)T(s,a,s′)，我们用采样的方式（蒙特卡洛）来训练 Qt+1(s,a)←(1−α)Qt(s,a)+α[R(s,a,s′)+γmax⁡a′Qt(s′,a′)]Q_{t+1}(s,a) \\gets (1-\\alpha)Q_{t}(s,a)+\\alpha\\Big[ R(s,a,s&#x27;)+\\gamma \\max_{a&#x27;} Q_t(s&#x27;,a&#x27;) \\Big] Qt+1​(s,a)←(1−α)Qt​(s,a)+α[R(s,a,s′)+γa′max​Qt​(s′,a′)] 这个式子也可以等价地写作 Qt+1(s,a)←Qt(s,a)+α[r+γmax⁡a′Qt(s′,a′)−Qt(s,a)]Q_{t+1}(s,a)\\gets Q_t(s,a)+\\alpha\\Big[ r+\\gamma \\max_{a&#x27;}Q_t(s&#x27;,a&#x27;)-Q_t(s,a) \\Big] Qt+1​(s,a)←Qt​(s,a)+α[r+γa′max​Qt​(s′,a′)−Qt​(s,a)] Approx Q-Learning 在 Approx Q-Learning 算法里，我们把 Q(s,a)Q(s,a)Q(s,a) 分解为多个关于 state sss 和行动 aaa 的 feature\\tt featurefeature 之线性组合（feature\\tt featurefeature 不一定需要和 s,as,as,a 成线性） Q(s,a)=∑iwi×fi(s,a)\\boxed {Q(s,a)=\\sum olimits_i w_i \\times f_i(s,a)} Q(s,a)=∑i​wi​×fi​(s,a)​ 令当次从环境的采样为 (s,a,s′,r)(s,a,s&#x27;,r)(s,a,s′,r)，表示从状态 sss 执行动作 aaa 转移到状态 s′s&#x27;s′ 得到奖励 rrr，定义 Sample Difference 为 Δ=r+γmax⁡a′Q(s′,a′)−Q(s,a)\\Delta=r+\\gamma\\max_{a&#x27;}Q(s&#x27;,a&#x27;)-Q(s,a) Δ=r+γa′max​Q(s′,a′)−Q(s,a) feature weights\\texttt{feature weights}feature weights 的更新则为 wi←wi+α×Δ×fi(s,a)w_i\\gets w_i+\\alpha\\times\\Delta\\times f_i(s,a) wi​←wi​+α×Δ×fi​(s,a) 推导 核心公式 GetAction()π(s)=arg max⁡aQ(s,a)UpdateWeights()wi←wi+α×[Δ]×fi(s,a)\\begin{array}{|r|cl|} \\hline \\text{GetAction()}&amp;\\pi(s)&amp;=\\argmax_{a}Q(s,a)\\\\ \\hline \\text{UpdateWeights()}&amp;w_i&amp;\\gets w_i+\\alpha\\times[\\Delta]\\times f_i(s,a)\\\\ \\hline \\end{array} GetAction()UpdateWeights()​π(s)wi​​=argmaxa​Q(s,a)←wi​+α×[Δ]×fi​(s,a)​​ 实现代码 12345678910111213141516171819class ApproxQLearningAgent(): def __init__(self): self.gamma = # reward discount rate self.alpha = # weight update factor self.epsilon = # learning rate self.weights = &#123; &quot;f1&quot;: 0.0, # correspond to w1*f1(s,a) &quot;f2&quot;: 0.0, # correspond to w2*f2(s,a) # ... &#125; def get_legal_actions(self): &#x27;&#x27;&#x27; 获取 &#x27;&#x27;&#x27; pass def"},{"title":"强化学习：Markov Chain 与贝尔曼方程","path":"/wiki/rl/rl-bellman-equation.html","content":"我们定义： 机器人所处于的状态为 state s∈Ss \\in \\mathbb Ss∈S。S\\mathbb SS 表示机器人所有可能的状态 机器人采取的行动为 action a∈Aa \\in\\mathbb Aa∈A。A\\mathbb AA 表示机器人所有可能采取的行动 Markov Chain 给定当前状态，未来和过去互相独立，且采取的行动只和当前状态有关 st+1∈St+1∼Distribution(at,st)s_{t+1}\\in\\mathbb S_{t+1}\\sim\\text{Distribution}( a_t,s_t) st+1​∈St+1​∼Distribution(at​,st​) 状态空间中的每一个状态都有一定概率被转移到，因此我们用概率进行建模，即 T(s,a,s′)T(s,a,s&#x27;) T(s,a,s′) Markov Decision Process 因此进一步定义： 世界（环境）模型 T(s,a,s′)T(s,a,s&#x27;)T(s,a,s′)，表示++机器人在状态 sss 时，如果采取 aaa 行动，那么有 T(s,a,s′)T(s,a,s&#x27;)T(s,a,s′) 的概率进入状态 s′s&#x27;s′。++这个模型也就是机器人与环境交互的入口 奖励函数 R(s,a,s′)R(s,a,s&#x27;)R(s,a,s′)，表示如果机器人在状态 sss 时采取 aaa 行动并进入状态 s′s&#x27;s′，就能获得 R(s,a,s′)R(s,a,s&#x27;)R(s,a,s′) 的奖励。 我们希望，机器人在世界模型和奖励函数（这两个是事先给定的）中，学习到在某个环境下该采取何种行动这一个 objective，这样一个 objective 的数学本质是 π:S↦A\\pi:\\mathbb S\\mapsto\\mathbb Aπ:S↦A，即 π(s)=a\\pi(s)=aπ(s)=a，函数输入状态，输出该采取什么行动。我们把这个 π(s)\\pi(s)π(s) 称为 Policy How to Learn a Policy Evaluation 很显然，我们需要一个 criterion 才能评判一个 Policy 到底好不好。 当我们的机器人根据 πi()\\pi_i()πi​() 运行了一段时间后，会得到一连串的 Reward 和一个 Accumulative Reward，而由于世界模型是概率模型，因此同一个 πi()\\pi_i()πi​() 可能会产生不同的 Reward Sequence 和不同的 Accumulative Reward。 我们也要考虑步数的影响（不然机器人来回踱步刷分数），因此引入 Discount，在每一步的 Reward 上乘的衰减系数 γ\\gammaγ，表明 Reward 随着步数的增长而减少。 我们在此基础上定义，即为 Policy 的 Utility 为 Reward 的期望值。 State 的 Utility 为从这个 State sss 出发的 Expected Utility，即为 V(s)V(s)V(s)，用上标 ∗\\ast∗ 表示最优策略 MDP Search Tree MDP Search Tree Value of State 定义： Q-State 为机器人选择完行动后，但还没有执行（还没有转移到 s′s&#x27;s′）的中间状态。 根据这棵树的结构可以推导出 V∗(s)=max⁡aQ∗(s,a)Q∗(s,a)=∑s′T(s,a,s′)[R(s,a,s′)+γV∗(s′)]so we get…⟹V∗(s)=max⁡a∑s′T(s,a,s′)[R(s,a,s′)+γV∗(s′)]\\begin{aligned} V^\\ast(s)&amp;=\\max_a Q^\\ast(s,a)\\\\ Q^\\ast(s,a)&amp;=\\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V^\\ast(s&#x27;)\\Big]\\\\ &amp;\\textbf{so we get}\\dots\\\\ \\Longrightarrow V^\\ast(s)&amp;=\\max_a \\sum_{s&#x27;}T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V^\\ast(s&#x27;)\\Big] \\end{aligned} V∗(s)Q∗(s,a)⟹V∗(s)​=amax​Q∗(s,a)=s′∑​T(s,a,s′)[R(s,a,s′)+γV∗(s′)]so we get…=amax​s′∑​T(s,a,s′)[R(s,a,s′)+γV∗(s′)]​ 求解 Policy 从 V(s) 求解 policy 数值迭代算法 从 V0(s)=0V_0(s)=0V0​(s)=0 开始 用上一次的 Vt(s)V_t(s)Vt​(s) 更小当次的 Vt+1(s)V_{t+1}(s)Vt+1​(s) Vt+1(s)←max⁡a∑s′T(s,a,s′)[R(s,a,s′)+γVt(s′)]V_{t+1}(s)\\gets \\max_a\\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V_t(s&#x27;) \\Big] Vt+1​(s)←amax​s′∑​T(s,a,s′)[R(s,a,s′)+γVt​(s′)] 这里的 γ\\gammaγ 表示步数的 Discount 直到收敛 V∗(s)V^\\ast(s)V∗(s)，时间复杂度 O(S2A)O(S^2A)O(S2A) 从 V∗(s)V^\\ast(s)V∗(s) 提取 Policy π∗(s)=arg max⁡a∑s′T(s,a,s′)[R(s,a,s′)+γV∗(s′)]\\pi^\\ast(s)=\\argmax_a\\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V^\\ast(s&#x27;) \\Big] π∗(s)=aargmax​s′∑​T(s,a,s′)[R(s,a,s′)+γV∗(s′)] 为每一个 state 选择一个 action 策略迭代算法 当 Policy 固定为 πi()\\pi_i()πi​() 时，此时不用考虑最优策略，等同于不需要取 max⁡a\\max_amaxa​，因此从 state sss 出发的 expected utility 就只有单纯的求和了，为 Vπi(s)=∑s′T(s,πi(s),s′)[R(s,πi(s),s′)+γVπi(s′)]V^{\\pi_i}(s)=\\sum_{s&#x27;} T(s,\\pi_i(s),s&#x27;)\\Big[R(s,\\pi_i(s),s&#x27;)+\\gamma V^{\\pi_i}(s&#x27;)\\Big] Vπi​(s)=s′∑​T(s,πi​(s),s′)[R(s,πi​(s),s′)+γVπi​(s′)] Policy Evaluation. 为选定的 Policy 计算 Utility（非 Optimal Utility） Vt+1πi(s)←∑s′T(s,πi(s),s′)[R(s,πi(s),s′)+γVtπi(s′)]V_{t+1}^{\\pi_i}(s)\\gets \\sum_{s&#x27;}T(s,\\pi_i(s), s&#x27;)\\Big[R(s,\\pi_i(s),s&#x27;)+\\gamma V^{\\pi_i}_{t}(s&#x27;) \\Big] Vt+1πi​​(s)←s′∑​T(s,πi​(s),s′)[R(s,πi​(s),s′)+γVtπi​​(s′)] Policy Improvement. 优化 Policy πt+1(s)←arg max⁡a∑s′T(s,a,s′)[R(s,a,s′)+γVπi(s′)]\\pi_{t+1}(s)\\gets \\argmax_a \\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V^{\\pi_i}(s&#x27;) \\Big] πt+1​(s)←aargmax​s′∑​T(s,a,s′)[R(s,a,s′)+γVπi​(s′)] 直到 Policy 收敛 从 Q∗(s,a)Q^\\ast(s,a)Q∗(s,a) 提取 Policy π∗(s)=arg max⁡aQ∗(s,a)\\pi^\\ast(s)=\\argmax_a Q^\\ast(s,a) π∗(s)=aargmax​Q∗(s,a) 从 Q-State 求解 Policy Q∗(s,a)=∑s′T(s,a,s′)[R(s,a,s′)+γmax⁡a′Q∗(s′,a′)]Q^\\ast(s,a)=\\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma\\max_{a&#x27;}Q^\\ast(s&#x27;,a&#x27;) \\Big] Q∗(s,a)=s′∑​T(s,a,s′)[R(s,a,s′)+γa′max​Q∗(s′,a′)] 提取 Policy： π∗(s)=arg max⁡aQ∗(s,a)\\pi^\\ast(s)=\\argmax_a Q^\\ast(s,a) π∗(s)=aargmax​Q∗(s,a) Summary","categories":[null]},{"title":"Isaac Lab(Sim) 简介","path":"/wiki/simulation/isaac-lab-brief.html","content":"Assets Isaac Sim Has more built-in scenes and robots available Classic: Cartpole, Humanoid, Ant Fixed-Arm and Hands: UR10, Franka, Allegro, Shadow Hand Quadrupeds: Anybotics Anymal-B, Anymal-C, Anymal-D, Unitree A1, Unitree Go1, Unitree Go2, Boston Dynamics Spot Humanoids: Unitree H1, Unitree G1 Quadcopter: Crazyflie Procedure Isaac Lab: Manager Method: More specified control Direct Method: Similar to Maniskill. Example of Direct Method: 1234567891011121314151617181920212223242526272829303132333435def _get_rewards(self) -&gt; torch.Tensor: total_reward = compute_rewards( self.cfg.rew_scale_alive, self.cfg.rew_scale_terminated, self.cfg.rew_scale_pole_pos, self.cfg.rew_scale_cart_vel, self.cfg.rew_scale_pole_vel, self.joint_pos[:, self._pole_dof_idx[0]], self.joint_vel[:, self._pole_dof_idx[0]], self.joint_pos[:, self._cart_dof_idx[0]], self.joint_vel[:, self._cart_dof_idx[0]], self.reset_terminated, ) return total_reward@torch.jit.scriptdef compute_rewards( rew_scale_alive: float, rew_scale_terminated: float, rew_scale_pole_pos: float, rew_scale_cart_vel: float, rew_scale_pole_vel: float, pole_pos: torch.Tensor, pole_vel: torch.Tensor, cart_pos: torch.Tensor, cart_vel: torch.Tensor, reset_terminated: torch.Tensor,): rew_alive = rew_scale_alive * (1.0 - reset_terminated.float()) rew_termination = rew_scale_terminated * reset_terminated.float() rew_pole_pos = rew_scale_pole_pos * torch.sum(torch.square(pole_pos).unsqueeze(dim=1), dim=-1) rew_cart_vel = rew_scale_cart_vel * torch.sum(torch.abs(cart_vel).unsqueeze(dim=1), dim=-1) rew_pole_vel = rew_scale_pole_vel * torch.sum(torch.abs(pole_vel).unsqueeze(dim=1), dim=-1) total_reward = rew_alive + rew_termination + rew_pole_pos + rew_cart_vel + rew_pole_vel return total_reward Tasks"},{"title":"ManiSkill 物理仿真：编写 Tasks for RL","path":"/wiki/simulation/maniskill-testcase.html","content":"Task Components 较为繁琐的说法 Setting up the Task Class Loading (Robots, Assets, Sensors, etc.) (run once) Episode initialization / Randomization (run every env.reset) Success/Failure Condition (run every env.step) Extra Observations (run every env.step) (Optional) Dense Reward Function (run every env.step) (Optional) Setting up cameras/sensors for observations and rendering/recording (run once) 最简工作流示例 env init env.step 负责根据 Action，然后在物理仿真，模拟无理式解的变化，并计算 Reward。 env.step 简单来说，一个类包含这些元素： @register_env() 方便外部调用 class CustomEnv(BaseEnv) 使用继承，快速开发新 Testcase （成员变量）SUPPORTED_ROBOTS = [] 定义该 Testcase 里使用的 Robot （成员变量）agent: Union[...] Robot，也即 Agent Environment Class 首先，我们定义一个类继承 BaseEnv，这个类是我们初始化 Environment 的入口。同时需要调用 mani_skill.utils.registeration.register_env() 函数进行“注册”（主要是定义名称和限定最大迭代步数） 12@register_env(&quot;CustomEnv-v1&quot;, max_episode_steps=200)class CustomEnv(BaseEnv): 然后我们在这个环境里定义我们需要的 Agent 定义物体 位置与朝向 建议在 _load_scene() 的时候就设置一次位置与朝向，然后在 _initialize_episode() 中"},{"title":"Tokenizer, BPE 算法","path":"/wiki/llm/tokenizer-bpe.html","content":"Byte-Pair Encoding 算法 Byte-Pair Encoding（BPE）算法是一种常用于分词器（Tokenizer）中的无监督分词方法，其主要思想是将文本中最常见的字符对（或子词对）不断合并，从而构建出一个词汇表。由于进行多轮 （假设 kkk 轮）合并，而每一次合并都会基于统计频率将一对 Token 合并为一个新 Token，因此在 kkk 轮迭代后，BPE 算法可以将长度为 kkk 的单词合并为一个 Token 将输入的文本转化为 UTF-8 Encoding 统计 Byte-Pair 的频率 计算频率最高的 Byte-Pair，合并为一个新的 Token 用新的 Token 替换旧 Byte-Pair 出现的位置 回到第 222 步，重新统计 Byte-Pair (Token-Pair) 频率 直到词汇表大小达到预设值 BPE 算法通过这种逐步合并的方式，不仅能有效地表示常见词汇，还能灵活处理低频词和新词，对于大型语言模型的分词和词表构建有很大的优势。 BPE 代码实现"},{"title":"Support Vector Machine","path":"/wiki/ml/svm.html","content":"Linear SVM Kernel SVM 通过映射函数 ϕ()\\phi()ϕ()，将低维的特征向量 feature vector xxx 映射到高维空间中 vxv_xvx​，以期望在低维空间不可线性分割的 feature vector 在高维空间可以被线性分割。 但是当映射到高维空间之后，高维向量之间的点乘运算比较耗时，因此利用核函数 Kernel Function K(v1,v2)\\mathcal{K}(v_1,v_2)K(v1​,v2​) 替换点乘运算。例如常见的做法是 K(x(i),x(j))=exp⁡(−γ∥x(i)−x(j)∥2)\\mathcal{K}(x^{(i)},x^{(j)})=\\exp\\Big( -\\gamma\\|x^{(i)}-x^{(j)} \\|^2 \\Big) K(x(i),x(j))=exp(−γ∥x(i)−x(j)∥2) 当 γ=12σ2\\gamma=\\frac{1}{2\\sigma^2}γ=2σ21​ 时，就是高斯核函数。"},{"title":"Django 模板","path":"/wiki/web_fullstack/django-template.html","content":"Django 模板 Django 模板的作用是，可以根据数据动态地展示网页。例如，可以根据用户的权限，选择向用户展示 dashboard 或者登录界面。 与 views.py 交互"},{"title":"django 表单","path":"/wiki/web_fullstack/django-forms.html","content":"django.forms.Form 类 在 Form 里定义需要填写的栏目，这样就可以直接在 template 里渲染了"},{"title":"SVD","path":"/wiki/linear-algebra/SVD.html","content":"SVD 分解"},{"title":"PCA","path":"/wiki/ml/PCA.html","content":"PCA 主成分分析 算法流程 代码实现 SciKit&nbsp;Learn 我们使用 sklearn 库实现（这个库可以通过 pip install scikit-learn 进行安装） 先导入 PCA 库，这是 scikit-learn 封装好的 PCA 类，后续可以直接调用 .fit_transform() 对数据进行 Projection. 以及，由于 PCA 对数据量级敏感，我们需要先 standardization，将数据点放缩到正态分布 N(0,1)N(0,1)N(0,1)，即 X′=X−μσX&#x27;=\\frac{X-\\mu}{\\sigma}X′=σX−μ​。这一步操作 scikit-learn 里也有封装好的类 sklearn.preprocessing.StandardScaler 使用 standardization 而非 normalization 的原因是，PCA 需要计算 Data point 矩阵的协方差矩阵，而 normalization 无法保留数据点的协方差信息，只有 standardization 可以。 12from sklearn.decomposition import PCAfrom sklearn.preprocessing import StandardScaler 我们可以指定 PCA 将 Dimension 减少到多少个，例如减少到 505050 个 1pca = PCA(n_components=50)"},{"title":"friends","path":"/friends/index.html","content":"Friends XXZ’s blog"},{"title":"内核性能分析工具","path":"/wiki/ai-infra/performance-analysis-tools.html","content":"内核优化的常见步骤 分析 Kernel 的执行时间 统计、查看各个 Kernel 的执行时间 定位性能瓶颈，确定需要优化的 Kernel 检查 GPU 的利用率等信息 例如检查是否占用过多的寄存器 （更细粒度）确定 Kernel 的性能瓶颈 优化 Kernel 性能 通过各种技术手段（软硬件、调度、内存优化）优化 Kernel"},{"title":"Plurality Majority Voting","path":"/wiki/ml/plurality-majority.html","content":"Majority Voting 多个模型分别输出预测结果，然后取投票最多的那个标签作为最后的输出。"},{"title":"Price Ceiling/Floor","path":"/wiki/microecon/price-ceiling-floor.html","content":"Price Ceiling 价格上限在 P−QP-QP−Q 图像上表示为一条水平线 Ceiling Line 黑色实线为坐标轴，纵轴 PPP，横轴为 QQQ 橙色线表示 P=F(Qs)P=F(Q^s)P=F(Qs) 黄色线表示 P=F(Qd)P=F(Q^d)P=F(Qd) 蓝色线表示 Price Ceiling， 注意！ 只有当蓝色低于 Equilibrium 点的时候才需要额外分析，如果价格上限高于市场价，那么对于市场完全没有影响 于是此时我们可以看到，需求量远远大于"}]