[{"title":"HKU COMP3270 目录","path":"/comp3270-menu/","content":"课程笔记兼目录 Minimax Alpha-beta 剪枝"},{"title":"Agentic 系统","path":"/what-is-agentic/","content":"Agentic System"},{"title":"LightRAG 论文","path":"/lightrag-paper/","content":"RAG 任务概述 我们可以把 RAG 任务用一个统一的框架来描述： M=(G,R=(I,S))M(q;D)=G(q,S(q;D^))D^=I(D) \\begin{aligned} M&amp;=(G, R=(I, S))\\\\ M(q;D)&amp;=G(q, S(q; \\hat D))\\\\ \\hat D&amp;=I(D) \\end{aligned} MM(q;D)D^​=(G,R=(I,S))=G(q,S(q;D^))=I(D)​这里的字母变量都是什么意思呢？有必要搞这么复杂的数学描述吗……原论文甚至还用上了希腊字母和花体字…… MMM 是整个 RAG 框架。 M(q;D)M(q;D)M(q;D) 代表一次查询：给定问题 qqq 和知识库 DDD 让模型给出回答。 这里的 GGG 是 Generation Module，即模型生成。 R=(I,S)R=(I,S)R=(I,S) 是 RAG 里的 Retrieval-Augment 部分 其中 III 用于处理知识库 DDD，将原始文档 DDD 转化为特定的数据结构 D^\\hat DD^，以期更好质量的 retrieval SSS 是 Search，其实更像 Augment 的过程，从处理好的数据库 D^\\hat DD^ 里获取相关的信息，传递给 Generation 模块 GGG 让模型进行输出。"},{"title":"另一种视角下的网络流体系","path":"/networkflow-another-view/","content":"DFS/BFS 如何证明路径不存在？"},{"title":"ManiSkill Task Definition Snippet","path":"/maniskill-snippets/","content":"转动容器，移动小球以插入柱子"},{"title":"RecursiveCharacterTextSplitter 具体实现","path":"/langchain-RecursiveCharacterTextSplitter/","content":"RecursiveCharacterTextSplitter split 首先是调用了 Python 的 re.split(sep, text) 做了一次基本的分割，同时用 [s for s in re.split(sep, text) if s != &quot;&quot;] 做基础的过滤，过滤掉那些为空的字符串。 merge 然后针对切割出来的块进行 merge"},{"title":"自然语言处理（NLP）的发展与关键技术：从词义到大模型","path":"/nlp-development/","content":"词义表示的进化：从规则到分布式语义 WordNet 近义词表示 早期的NLP系统依赖人工构建的规则和词典，如 WordNet。这类工具通过同义词集合和上下位关系 (Hyponymy) 描述词义，例如将“proficient”标记为“good”的同义词。然而，这种方法存在明显局限： 静态性：无法捕捉新兴含义（如“wicked”在俚语中的“酷”意）；一些单词仅在特定情况下意义相近 主观性：词语意义需要人工界定 实时性：依赖人工标注，更新缓慢； 缺乏相似性计算 ：无法量化“hotel”和“motel”的语义相似度。 Localist: One-Hot 编码与词袋模型 2013 年前，NLP 普遍采用 One-Hot 编码 表示词汇，即用高维稀疏向量（如长度为 101010 万的向量中仅一个位置为 111）表示单词。这种“局部表示”导致： 维度灾难 ：101010 万词汇需 101010 万维空间； 零相似性 ：正交向量无法反映词义关联（如“hotel”与“motel”）。 Distributed Semantics 与 Word2Vec Word2Vec 是一种通过无监督学习生成词向量的工具，其核心思想是基于词的上下文共现规律，将词映射到低维稠密向量空间中，使得语义相似的词在向量空间中距离较近。主要有两种模型：一种是根据上下文推理中心词的 CBOW 模型，另一种是根据中心词推理上下文的 Skip-Gram 模型。 这里的 Word Vector 也被称为 Word Embedding 或者 Word Representations Skip Gram 给定上下文长度为 mmm，对于样本数据中心词为 wtw_twt​，其上下文为 wt−m,…,wt+mw_{t-m},\\dots,w_{t+m}wt−m​,…,wt+m​，Skip Gram 训练的目标就是最大化上下文词的条件概率 ∏j=−mmP(wt+j∣wt) \\prod_{j=-m}^m P(w_{t+j}|w_t) j=−m∏m​P(wt+j​∣wt​)对于全部语料库，那么就要最大化每一个这样的中心词和上下文的条件概率，把他们乘起来（假设 Skip Gram 的参数为 θ\\thetaθ） 这里的 θ\\thetaθ 其实是一个矩阵。假设我们把词汇编码为 ddd 维稠密向量，词汇表大小为 VVV，则 θ\\thetaθ 的大小应该为 R2dV\\mathbb R^{2dV}R2dV，我们这里直接把 θ\\thetaθ 当作词汇表来看。 其本质是一个将词汇映射到 embedding 空间的函数 f:{0,1}V↦Rdf:\\mathbb \\{0,1\\}^V\\mapsto R^{d}f:{0,1}V↦Rd。要取出 viv_ivi​ 向量，可以通过矩阵乘法，设置每一行为 111、其余全部置 000 来取出这一行的词向量，相当于 θ\\thetaθ 乘上了一个常数。 即 vw=θTCv(w)v_w=\\theta^TC_v(w)vw​=θTCv​(w)，uw=θTCu(w)u_w=\\theta^TC_u(w)uw​=θTCu​(w)，这里的 Cv,CuC_v,C_uCv​,Cu​ 可以是 www 的 One-Hot Vector. θ=arg max⁡θ∏t=1T∏−m≤j≤mj≠0Pθ(wt+j∣wt) \\theta=\\argmax_\\theta \\prod_{t=1}^T \\prod_{-m \\le j\\le m}^{j e 0} P_\\theta(w_{t+j}|w_t) θ=θargmax​t=1∏T​−m≤j≤m∏j=0​Pθ​(wt+j​∣wt​)这也等同于最小化其负对数 θ=arg min⁡θJ(θ)=arg min⁡θ−1T∑t=1T∑−m≤j≤mj≠0log⁡Pθ(wt+j∣wt) \\theta=\\argmin_\\theta J(\\theta)=\\argmin_\\theta -\\frac{1}{T}\\sum_{t=1}^T \\sum_{-m \\le j\\le m}^{j e 0} \\log P_\\theta(w_{t+j}|w_t) θ=θargmin​J(θ)=θargmin​−T1​t=1∑T​−m≤j≤m∑j=0​logPθ​(wt+j​∣wt​)这里概率的计算就是老套路 softmax 了，我们把整个词汇库的 context vector 和当前词的中心词向量点乘起来，做 softmax（这里用 ooo 表示上下文词，uwu_wuw​ 表示单词 www 作为上下文时的向量，vwv_wvw​ 表示 www 作为中心词时的向量） P(o∣c)=exp⁡(uoTvc)∑w∈Vexp⁡(uwTvc) P(o|c)=\\frac{\\exp(u_{o}^T v_c)}{\\sum_{w\\in \\mathbb V} \\exp(u_w^T v_c)} P(o∣c)=∑w∈V​exp(uwT​vc​)exp(uoT​vc​)​于是损失函数 J(θ)J(\\theta)J(θ) 变成了 J(θ)=−1T∑t=1T∑−m≤j≤mj≠0(uoTvc−log⁡∑w∈Vexp⁡(uwTvc)) J(\\theta)=-\\frac{1}{T}\\sum_{t=1}^{T} \\sum_{-m \\le j\\le m}^{j e 0} \\Big(u_o^Tv_c-\\log\\sum_{w\\in\\mathbb V}\\exp(u_w^Tv_c)\\Big) J(θ)=−T1​t=1∑T​−m≤j≤m∑j=0​(uoT​vc​−logw∈V∑​exp(uwT​vc​))"},{"title":"Intro to AI: Searching","path":"/ai-and-searching/","content":"Searching Searching Problem 的组成部分 state space successor function (包含 action 和 cost/reward，例如路径) start state 和 goal state 搜索问题的解决方法：a sequence of action which transforms start state into goal state 于是可以表示为图论问题 节点：代表 state 有向边：代表 state transformation 目标：从一个节点走到另一个节点 这张图是全局的，包含所有 state 的信息和转移。如果我们只关注从某一个 state (例如 start state) 出发的可能性（即局部的），则得到搜索树 ……但是子树结构大量重复 ……可能有环，导致树高无限高 解决方案：只保留正在考虑的部分子树，其余的全部扔掉 DFS 令一个状态可以拓展到 bbb 个状态，最多 mmm 层，则 树中节点数量：O(bm)O(b^m)O(bm) 原图无环时，DFS 搜索树是有穷的 不一定 Optimal，因为只往 leftmost 方向走 BFS 到达一个状态，所探明的节点数量为 O(bs)O(b^s)O(bs)，sss 为当前所处在的深度 必然是 complete 的 不一定 optimal，除非 cost 均为 111"},{"title":"LightRAG: query 处理查询的深入探究","path":"/lightrag-query-method/","content":"LightRAG.query() 支持四类查询： Local: 只注重局部信息 Global: 只注重全局信息 Hybrid Naive: 当作最传统的 RAG 来使用 Bypass: 不使用额外的知识库 Mix: Naive + Hybrid 下面，我们主要来看 GraphRAG 相关的 Hybrid 查询（其实就是一个 kg_query() 的 router） 启动异步查询"},{"title":"HKU GPU Farm 指北","path":"/hku-gpu-farm/","content":"进入 GPU Farm 用 ssh 链接 gpugate1.cs.hku.hk 然后输入密码即可。 1ssh [your_username]@gpugate1.cs.hku.hk 进入 GPU 模式 注意 安装任何软件、仓库都必须先进 GPU Mode. 1gpu-interactive"},{"title":"LightRAG: 构建索引 insert() 方法深入探究","path":"/lightrag-insert-method/","content":"LightRAG LightRAG 是针对 GraphRAG 构建索引速度慢、消耗 Token 量大而诞生的解决方案，更多详细的方法论请移步 wiki，这一篇主要聚焦与代码层面的实现。 注意事项 由于 Python 的异步模块 asyncio 不支持嵌套，.insert() 方法在执行的时候会报错：This event loop has already been running。我们需要用 nest_asyncio 打个补丁 先安装 nest_asyncio 包 1pip install nest-asyncio 再导入，并 patch 一下 12import nest_asyncionest_asyncio.apply() 然后就 ok 了 启动异步索引构建 .insert() 这个函数是插入文档的入口，是一个同步函数（然而 readme 里写成了异步函数，well）。它的工作实际上就是调用了异步函数进行插入文档 .insert() 123456789101112131415161718192021222324252627282930def insert( self, input: str | list[str], split_by_character: str | None = None, split_by_character_only: bool = False, ids: str | list[str] | None = None, file_paths: str | list[str] | None = None,) -&gt; None: &quot;&quot;&quot; Sync Insert documents with checkpoint support Args: input: 文档字符串，或者包含很多字符串的列表。用于插入的文档 split_by_character: 是否按字符（而非 token）进行切割，如果把一个 token 切开了，把 token 放进来 split_by_character_only: 只以字符切割，忽略 token ids: 文档的标识符（应该不同），不提供则用 hash 计算 file_paths: 文档的路径，只用于 citation 目的 &quot;&quot;&quot; loop = always_get_an_event_loop() loop.run_until_complete( self.ainsert( input, split_by_character, split_by_character_only, ids, file_paths ) ) 异步进行插入 .ainsert() 将处理分为两个主要阶段，真是太有异步了（ 将文档加入队列 (.apipeline_enqueue_documents()) 处理队列中的文档 (.apipeline_process_enqueue_documents()) 完整代码 其实好像没必要开一个 Heading 4 ( .ainsert() 123456789101112131415161718192021222324252627async def ainsert( self, input: str | list[str], split_by_character: str | None = None, split_by_character_only: bool = False, ids: str | list[str] | None = None, file_paths: str | list[str] | None = None,) -&gt; None: &quot;&quot;&quot; Async Insert documents with checkpoint support Args: （基本同上） input: 文档字符串，或者包含很多字符串的列表。用于插入的文档 split_by_character: 是否按字符（而非 token）进行切割，如果把一个 token 切开了，把 token 放进来 split_by_character_only: 只以字符切割，忽略 token ids: 文档的标识符（应该不同），不提供则用 hash 计算 file_paths: 文档的路径，只用于 citation 目的 &quot;&quot;&quot; await self.apipeline_enqueue_documents(input, ids, file_paths) await self.apipeline_process_enqueue_documents( split_by_character, split_by_character_only ) 对文档进行预处理 docstring 比较明晰地写明了 .apipeline_enqueue_documents() 这个函数在干什么。这里截取出代码详细解释一遍。 首先是预检查：把单个 str 放进列表方便后续统一的操作。然后检查 file_path 的数量是不是和 str 的数量对得上，毕竟file_path 的作用是引用 Pre-check 123456789101112131415if isinstance(input, str): input = [input]if isinstance(ids, str): ids = [ids]if isinstance(file_paths, str): file_paths = [file_paths]# If file_paths is provided, ensure it matches the number of documentsif file_paths is not None: if isinstance(file_paths, str): file_paths = [file_paths] if len(file_paths) != len(input): raise ValueError( &quot;Number of file paths must match the number of documents&quot; ) 检查文档的 ID。 如果提供了 ID，则 检查数量是否与文档的数量一致 检查 ID 是否重复 否则就生成 MD5 作为 ID 这个阶段还把 file_path 作为引用和文档内容打包在一起，形成 id: &#123; content: , file_path: &#125; 的 Object 格式 pack up information 1234567891011121314151617181920212223242526272829303132333435# 1. Validate ids if provided or generate MD5 hash IDsif ids is not None: # Check if the number of IDs matches the number of documents if len(ids) != len(input): raise ValueError(&quot;Number of IDs must match the number of documents&quot;) # Check if IDs are unique if len(ids) != len(set(ids)): raise ValueError(&quot;IDs must be unique&quot;) # Generate contents dict of IDs provided by user and documents contents = &#123; id_: &#123;&quot;content&quot;: doc, &quot;file_path&quot;: path&#125; for id_, doc, path in zip(ids, input, file_paths) &#125;else: # Clean input text and remove duplicates cleaned_input = [ (clean_text(doc), path) for doc, path in zip(input, file_paths) ] unique_content_with_paths = &#123;&#125; # Keep track of unique content and their paths for content, path in cleaned_input: if content not in unique_content_with_paths: unique_content_with_paths[content] = path # Generate contents dict of MD5 hash IDs and documents with paths contents = &#123; compute_mdhash_id(content, prefix=&quot;doc-&quot;): &#123; &quot;content&quot;: content, &quot;file_path&quot;: path, &#125; for content, path in unique_content_with_paths.items() &#125; 紧接着在输入的文档内部进行去重，意思是说，去除输入里的重复文档 Code 12345678910111213# 2. Remove duplicate contentsunique_contents = &#123;&#125;for id_, content_data in contents.items(): content = content_data[&quot;content&quot;] file_path = content_data[&quot;file_path&quot;] if content not in unique_contents: unique_contents[content] = (id_, file_path)# Reconstruct contents with unique contentcontents = &#123; id_: &#123;&quot;content&quot;: content, &quot;file_path&quot;: file_path&#125; for content, (id_, file_path) in unique_contents.items()&#125; 为每一份文档建立一个状态，方便追踪（包括更新时间） 这里的 content_summary 并非 LLM 的总结，仅仅只是做了截取。 Code 123456789101112131415# 3. Generate document initial statusnew_docs: dict[str, Any] = &#123; id_: &#123; &quot;status&quot;: DocStatus.PENDING, &quot;content&quot;: content_data[&quot;content&quot;], &quot;content_summary&quot;: get_content_summary(content_data[&quot;content&quot;]), &quot;content_length&quot;: len(content_data[&quot;content&quot;]), &quot;created_at&quot;: datetime.now().isoformat(), &quot;updated_at&quot;: datetime.now().isoformat(), &quot;file_path&quot;: content_data[ &quot;file_path&quot; ], # Store file path in document status &#125; for id_, content_data in contents.items()&#125; 12345678910111213141516def get_content_summary(content: str, max_length: int = 250) -&gt; str: &quot;&quot;&quot;Get summary of document content Args: content: Original document content max_length: Maximum length of summary Returns: Truncated content with ellipsis if needed &quot;&quot;&quot; content = content.strip() if len(content) &lt;= max_length: return content return content[:max_length] + &quot;...&quot; 紧接着是根据已有的数据库过滤掉已经添加过的文档。 Code 123456789101112131415161718192021222324252627# 4. Filter out already processed documents# Get docs idsall_new_doc_ids = set(new_docs.keys())# Exclude IDs of documents that are already in progressunique_new_doc_ids = await self.doc_status.filter_keys(all_new_doc_ids)# Log ignored document IDsignored_ids = [ doc_id for doc_id in unique_new_doc_ids if doc_id not in new_docs]if ignored_ids: logger.warning( f&quot;Ignoring &#123;len(ignored_ids)&#125; document IDs not found in new_docs&quot; ) for doc_id in ignored_ids: logger.warning(f&quot;Ignored document ID: &#123;doc_id&#125;&quot;)# Filter new_docs to only include documents with unique IDsnew_docs = &#123; doc_id: new_docs[doc_id] for doc_id in unique_new_doc_ids if doc_id in new_docs&#125;if not new_docs: logger.info(&quot;No new unique documents were found.&quot;) return 最后把过滤出来的文档插入文档数据库终于！（笑 Code 123# 5. Store status documentawait self.doc_status.upsert(new_docs)logger.info(f&quot;Stored &#123;len(new_docs)&#125; new unique documents&quot;) 正式处理文档 .apipeline_process_enqueue_documents() 大体的结构分成 async with 部分和 try ... finally 部分，分别对应“获取所有待处理文档”和“处理文档”的逻辑。 获取待处理文档的逻辑比较直观：获取数据库的锁之后，把数据库里的要处理的文档拿出来。但是写的比较奇怪，先不去深挖细节了（挖个坑先 Code 12345678910111213141516171819202122232425262728293031323334353637383940async with pipeline_status_lock:# Ensure only one worker is processing documentsif not pipeline_status.get(&quot;busy&quot;, False): processing_docs, failed_docs, pending_docs = await asyncio.gather( self.doc_status.get_docs_by_status(DocStatus.PROCESSING), self.doc_status.get_docs_by_status(DocStatus.FAILED), self.doc_status.get_docs_by_status(DocStatus.PENDING), ) to_process_docs: dict[str, DocProcessingStatus] = &#123;&#125; to_process_docs.update(processing_docs) to_process_docs.update(failed_docs) to_process_docs.update(pending_docs) if not to_process_docs: logger.info(&quot;No documents to process&quot;) return pipeline_status.update( &#123; &quot;busy&quot;: True, &quot;job_name&quot;: &quot;Default Job&quot;, &quot;job_start&quot;: datetime.now().isoformat(), &quot;docs&quot;: 0, &quot;batchs&quot;: 0, # Total number of files to be processed &quot;cur_batch&quot;: 0, # Number of files already processed &quot;request_pending&quot;: False, # Clear any previous request &quot;latest_message&quot;: &quot;&quot;, &#125; ) # Cleaning history_messages without breaking it as a shared list object del pipeline_status[&quot;history_messages&quot;][:]else: # Another process is busy, just set request flag and return pipeline_status[&quot;request_pending&quot;] = True logger.info( &quot;Another process is already processing the document queue. Request queued.&quot; ) return 注意 以下是 LightRAG 的核心部分，针对单篇文档提取 entity 和 relation，因此忽略了其他的一些操作，例如往 chunk database 里插入 chunks，插入 full doc 等等。包括错误处理、异步同步处理等等在内的很多细节也一并选择没有展开 那么肯定要考虑多篇文档的同时处理的。项目的处理也比较容易想到，也还是用 asyncio.create_task() 后用 asyncio.gather() 并行执行 把文档和 prompt 输入大模型 这一部分由 _process_single_content() 完成。首先 patch Prompt 输入，然后调用 use_llm_func_with_cache() 获得 LLM 输出并缓存下来。 接着开始解析输出，for ... in range(entity_extract_max_gleaning) 表示如果最多尝试提取关系 entity_extract_max_gleaning 次。 注意 以下的两个步骤是针对一块 chunk 做的。也就是说，如果文档太长而被切分成很多 chunk，那么以下两个步骤也会运行多次。 那么批量处理是如何进行的呢？ 项目源码这里采用多线程的方式批量处理 chunk. 具体做法是定义了一个 semaphore，然后将所有任务都用 asyncio.create_task() 包装后，由 asyncio.wait() 统一执行并阻塞直到任务全部完成。 这里我们先忽略错误处理，先关注后面的流程。 收集完 chunk_results 后，直接用 list 的 extend() 方法合并到 all_nodes, all_edges 里面 合并 chunk 12345678910111213# Collect all nodes and edges from all chunksall_nodes = defaultdict(list)all_edges = defaultdict(list)for maybe_nodes, maybe_edges in chunk_results: # Collect nodes for entity_name, entities in maybe_nodes.items(): all_nodes[entity_name].extend(entities) # Collect edges with sorted keys for undirected graph for edge_key, edges in maybe_edges.items(): sorted_edge_key = tuple(sorted(edge_key)) all_edges[sorted_edge_key].extend(edges) 合并完这篇文档内的 entity 和 relation 之后，就要进入 graph insert 阶段了。我们把这部分放到后面再说。 解析大模型的输出 _process_extraction_result() 是 extract_entities() 中定义的一个内部辅助函数，主要负责处理来自大语言模型 (LLM) 的提取结果，将非结构化的文本响应转换为结构化的实体和关系数据 首先将 LLM 返回的结果依照配置好的分隔符切开为 Record/Completion，每一条 Record/Completion 可能包含实体或者关系。 1234567async def _process_extraction_result( result: str, # 从 LLM 获取的提取结果文本字符串 chunk_key: str, # 文本块的唯一标识符，用于源跟踪 file_path: str = &quot;unknown_source&quot;, # 文件路径，用于引用来源（默认为&quot;unknown_source&quot;）):# 返回一个元组 (maybe_nodes, maybe_edges)，包含提取出的实体和关系 紧接着处理每一条记录（通过正则的匹配字符串可以发现每一条 Record 都包裹在一对圆括号内），在每一条 record 的内部，再使用 tuple delimiter 分割出 Entity 与 Attribute 12345678for record in records: record = re.search(r&quot;\\((.*)\\)&quot;, record) if record is None: continue record = record.group(1) record_attributes = split_string_by_multi_markers( record, [context_base[&quot;tuple_delimiter&quot;]] ) 接着分别尝试将这条 record 解析为 Entity 或者 Relation. 根据 prompt.py 里记录的 prompt，可以看到我们要求大模型输出的格式为用 tuple delimiter 分割的元组。 1Format each entity as (&quot;entity&quot;&#123;tuple_delimiter&#125;&lt;entity_name&gt;&#123;tuple_delimiter&#125;&lt;entity_type&gt;&#123;tuple_delimiter&#125;&lt;entity_description&gt;) 1234567# 提取为实体if_entities = await _handle_single_entity_extraction( record_attributes, chunk_key, file_path)if if_entities is not None: maybe_nodes[if_entities[&quot;entity_name&quot;]].append(if_entities) continue 12345678# 提取为关系if_relation = await _handle_single_relationship_extraction( record_attributes, chunk_key, file_path)if if_relation is not None: maybe_edges[(if_relation[&quot;src_id&quot;], if_relation[&quot;tgt_id&quot;])].append( if_relation ) 合并实体节点和关系边 这一块就是简单地用提取的实体名称和关系名称做合并 Code 12345678910111213141516# Process gleaning result separately with file pathglean_nodes, glean_edges = await _process_extraction_result( glean_result, chunk_key, file_path)# Merge results - only add entities and edges with new namesfor entity_name, entities in glean_nodes.items(): if ( entity_name not in maybe_nodes ): # Only accetp entities with new name in gleaning stage maybe_nodes[entity_name].extend(entities)for edge_key, edges in glean_edges.items(): if ( edge_key not in maybe_edges ): # Only accetp edges with new name in gleaning stage maybe_edges[edge_key].extend(edges) 为了避免 LLM 遗漏 Entity，我们再额外用 LLM 判断是否有遗漏，用 prompt.py 里的 if_loop_prompt 作为输入，直到没有遗漏了就退出循环。 最后返回从这个 chunk 提取出来的 nodes 和 edges Code 12345678910if_loop_result: str = await use_llm_func_with_cache( if_loop_prompt, use_llm_func, llm_response_cache=llm_response_cache, history_messages=history, cache_type=&quot;extract&quot;,)if_loop_result = if_loop_result.strip().strip(&#x27;&quot;&#x27;).strip(&quot;&#x27;&quot;).lower()if if_loop_result != &quot;yes&quot;: break 更新知识图谱 由于是异步执行，我们需要先获取锁确保数据的完整性 1async with graph_db_lock: 接着是根据已有的图谱过滤掉已经添加过的点和边，这一部分比较偏工程实现，这里不做展开 根据已有知识库进行过滤 123456789101112131415161718192021222324252627282930313233# Centralized processing of all nodes and edgesentities_data = []relationships_data = []# Use graph database lock to ensure atomic merges and updatesasync with graph_db_lock: # Process and update all entities at once for entity_name, entities in all_nodes.items(): entity_data = await _merge_nodes_then_upsert( entity_name, entities, knowledge_graph_inst, global_config, pipeline_status, pipeline_status_lock, llm_response_cache, ) entities_data.append(entity_data) # Process and update all relationships at once for edge_key, edges in all_edges.items(): edge_data = await _merge_edges_then_upsert( edge_key[0], edge_key[1], edges, knowledge_graph_inst, global_config, pipeline_status, pipeline_status_lock, llm_response_cache, ) if edge_data is not None: relationships_data.append(edge_data) 然后是更新节点数据库 更新节点数据库 12345678910111213# Update vector databases with all collected dataif entity_vdb is not None and entities_data: data_for_vdb = &#123; compute_mdhash_id(dp[&quot;entity_name&quot;], prefix=&quot;ent-&quot;): &#123; &quot;entity_name&quot;: dp[&quot;entity_name&quot;], &quot;entity_type&quot;: dp[&quot;entity_type&quot;], &quot;content&quot;: f&quot;&#123;dp[&#x27;entity_name&#x27;]&#125; &#123;dp[&#x27;description&#x27;]&#125;&quot;, &quot;source_id&quot;: dp[&quot;source_id&quot;], &quot;file_path&quot;: dp.get(&quot;file_path&quot;, &quot;unknown_source&quot;), &#125; for dp in entities_data &#125; await entity_vdb.upsert(data_for_vdb) ……和关系数据库 更新关系数据库 12345678910111213if relationships_vdb is not None and relationships_data: data_for_vdb = &#123; compute_mdhash_id(dp[&quot;src_id&quot;] + dp[&quot;tgt_id&quot;], prefix=&quot;rel-&quot;): &#123; &quot;src_id&quot;: dp[&quot;src_id&quot;], &quot;tgt_id&quot;: dp[&quot;tgt_id&quot;], &quot;keywords&quot;: dp[&quot;keywords&quot;], &quot;content&quot;: f&quot;&#123;dp[&#x27;src_id&#x27;]&#125;\\t&#123;dp[&#x27;tgt_id&#x27;]&#125; &#123;dp[&#x27;keywords&#x27;]&#125; &#123;dp[&#x27;description&#x27;]&#125;&quot;, &quot;source_id&quot;: dp[&quot;source_id&quot;], &quot;file_path&quot;: dp.get(&quot;file_path&quot;, &quot;unknown_source&quot;), &#125; for dp in relationships_data &#125; await relationships_vdb.upsert(data_for_vdb)"},{"title":"Django REST API 框架","path":"/swe-django-rest-framework/","content":"REST 的六大设计约束 客户端-服务器架构 分离职责：客户端与服务器完全解耦，各自独立演化。 优势：提升可扩展性，简化服务器端复杂度，允许客户端灵活更新。 无状态性 定义：服务器不保存客户端会话状态，每次请求必须包含完整上下文。 实现：通过请求参数、Cookie 或 Token 传递必要信息。 优势：提高可靠性、可伸缩性，避免单点故障。 缓存 要求：响应必须明确标注是否可缓存（如 Cache-Control 头）。 优势：减少网络流量，提升性能，优化用户体验。 统一接口 核心要素： 资源标识：每个资源通过唯一 URI（如 /products/123）访问。 操作方式：使用标准 HTTP 方法（GET/POST/PUT/PATCH/DELETE）操作资源。 表示交换：通过 JSON/XML 等格式传输资源状态（Representational State Transfer）。 自描述消息：响应包含元数据（如 Content-Type），无需额外文档即可解析。 HATEOAS：超文本驱动应用状态，响应中嵌入链接引导下一步操作（如 &#123;&quot;next&quot;: &quot;/products?page=2&quot;&#125;）。 分层系统 定义：支持中间层（如代理、缓存服务器），隐藏底层实现细节。 优势：增强可扩展性，简化部署，隔离客户端与服务器直接交互。 按需代码（可选） 功能：允许服务器动态下载代码到客户端（如 JavaScript 扩展功能）。 场景：适用于需要动态行为调整的场景（如 Web 应用热更新）。 REST 的本质目标 解耦系统组件：通过标准化接口降低依赖，支持独立开发与维护。 高效通信：利用 HTTP 协议特性（如缓存、状态码）优化性能。 可进化性：允许服务端迭代升级，只要保持接口兼容。 关键实践建议 资源设计：以名词命名资源（如 /orders），而非动词（如 /get-orders）。 层级结构：通过 URL 层级体现资源关系（如 /managers/23/orders）。 HATEOAS 实现：在响应中提供导航链接，减少客户端硬编码路径依赖。"},{"title":"异步编程","path":"/async-programming/","content":"Python: asyncio 与异步编程"},{"title":"大模型实战：预训练","path":"/llm-pretrain-cookbook/","content":"Pretraining"},{"title":"llama.cpp server 端的 API","path":"/llama-cpp-server-api/","content":"llama-server 参数"},{"title":"OpenAI 流式传输与 StreamLit","path":"/openai-stream-mode-w-streamlit/","content":"流式传输 大模型的 API 通常都支持流式传输。所谓流式传输，就是指将大模型生成的文字拆分成一小块一小块发送过来，比如说每隔 555 秒就发送一次生成的文字，而不是等文字全部生成完毕才一次性全部发送。 这样做的好处在于 langchain langchain 的 ChatOpenAI 已经包装的十分完善了。"},{"title":"Python 并行库 joblib","path":"/python-joblib/","content":"joblib joblib 提供两个最核心的功能：caching 和 parallel computing. 使用 joblib.Parallel 进行并行计算 joblib.Parallel 的基础用法是通过 n_jobs 指定进程数（指定 n_jobs=-1 则表示能用多少用多少），初始化类后，用 joblib.delayed(&lt;function&gt;)(args) 指定每一个进程的工作 并行读取图片，保存为 NumPy Array 123456789101112131415import matplotlib.pyplot as plt # 读取图片from joblib import Parallel, delayed # 并行计算from rich.progress import track # 可视化进度条def read_img(path): return plt.imread(path)imgs = Parallel(n_jobs=-1)( delayed(read_img)(path) for path in track(csv[&quot;im_name&quot;], description=&quot;Loading images ... &quot;, transient=True) # transient=True 指定进度条在完成后隐藏) # parallel() 结束之后，imgs 是 List[np.ndarray]imgs = np.asarray(imgs) # 转化为 np.ndarray"},{"title":"使用 Socat 创建虚拟串口并指定名称","path":"/socat-usage/","content":"Preface 起因主要是社团……没有车的时候调试个 serial port 十分费劲，甚至根本调试不了写的对不对 所以只能用 socat 开虚拟串口模拟通讯了 socat 安装 安装比较容易，可以直接通过 apt 包管理器安装 1sudo apt install socat socat 指定串口名称 指定名称时，用 link= 表示指定的串口位置，pty,raw,echo=0 表示串口的配置参数 1sudo socat -d -d pty,raw,echo=0,link=/dev/ttyACM0 pty,raw,echo=0,link=/dev/ttyACM1 然后还需要给 /dev/ttyACM0, /dev/ttyACM1 这两个串口权限，方便起见，这里直接全部设为 rwx 12sudo chmod 777 /dev/ttyACM0sudo chmod 777 /dev/ttyACM1"},{"title":"roboverse","path":"/roboverse/","content":"Robotics Dataset Scene Concerns real world complex, uncontrollable synthesis quality, diversity, standardization"},{"title":"使用 llama.cpp 在本地部署大模型","path":"/llama-cpp-locally-deploy/","content":"安装 llama.cpp 可以通过 brew 安装，一条命令行搞定，省心省力。 1brew install llama.cpp"},{"title":"Python 通过 URL 获取 Embedding","path":"/python-get-embedding-through-urls/","content":"requests 需求类似于不希望内部数据上传到其他网页，于是希望在本地同时部署 Embedding Model 和 LLM. 于是，我用 llama-server 同时 serve 了 BGE-m3 和 Deepseek-R1-Distill-Llama-8B，前者作为 Embedding 模型暴露在 http://localhost:8081，后者作为 LLM 暴露在 http://localhost:8080 然后就遇到了一个小问题，怎么通过 Python 去获取 Embedding 呢？我这里的解决方案是直接用 requests 库发送请求了。好在 llama.cpp 提供的 llama-server 能够兼容 OpenAI 的 API 接口。 12345678910111213141516171819202122import requestsembedding_url = &quot;http://localhost:8081/v1/embeddings&quot;# OpenAI compatible embeddingapi_key = &quot;not_used&quot;# 因为是本地部署，所有干脆没有设置 API Keydata = &#123; &quot;input&quot;: &quot;要嵌入的文字&quot;, &quot;model&quot;: &quot;BGE-m3&quot;, # 这里就填本地部署的模型名称&#125;headers = &#123; &quot;Authorization&quot;: f&quot;Bearer &#123;api_key&#125;&quot;, &quot;content-type&quot;: &quot;application/json&quot;,&#125;result = requests.post( embedding_url, data=str(data), # 这里必须将字典以字符串的格式传入 headers=headers, # 这个 headers 其实也可以不用)embedding = result.json()[&quot;data&quot;][0][&quot;embedding&quot;]"},{"title":"Linux Mint 22.1 升级 6.11 内核和升级英伟达 560 驱动","path":"/upgrade-to-linux-kernel611-and-nvidia/","content":"升级到 Linux Kernel 6.11.0-21.21 事情的原委很简单，Update Manager 疯狂地提醒我该升级 Kernel 了，正巧想玩玩 CUDA 升级一下 nvcc，于是想顺便升级一下 nvidia-driver. 但是很快就初见端倪，升级 Kernel 提示 1installed linux-image-6.11.0-21-generic package post-installation script subprocess returned error exit status 11 啊？报错了？又往前翻了翻，发现 1nvidia-fs/2.22.3 autoinstall failed due to missing dependencies: nvidia OK 破案了，原来又是英伟达驱动搞的鬼，那么先处理 nvidia-drvier 吧[1] nvidia-driver-560 我现在已经在用 nvidia-driver-550 了，但是为什么会报错缺少 nvidia 呢？这里没有多想，就顺着上面的帖子，重装驱动了。 我是直接在 Driver Manager 里的 GUI 操作，但是报错安装失败。 man! 怎么个事？重启一下系统，虽然可以开机，但是默认切换到 Intel 核显了，并且 nvidia-smi 也提示无法链接 GPU. 值得一提的是，系统居然是 6.11 内核的……我还以为没安装成功呢 hhhh 那看来只能进 recovery-mode 了 Recovery Mode 进入 Recovery Mode 后，尝试用命令行删除驱动，再重新安装驱动。先移动到 network 打开网络，然后移动到 root 回车进入命令行。先删除所有英伟达的驱动 1apt purge ~nnvidia 删除倒是挺简单的，然后安装驱动，我直接选择了 nvidia-driver-560-open（这个版本是英伟达官方推荐 Ubuntu 24.04 系统使用的驱动版本，而我使用的 Linux Mint 也是基于 Ubuntu 24.04 制作的） 1apt install nvidia-driver-560-open 回车等待结果，然而，在 Building for Linux-kernel-6.11.0-21.21-generic 的时候，却出现了报错 12nvidia-dkms-560 configuration failed# 大致差不多长这样，其实就是提示你有两个组件构建失败 不过在构建失败后，也给出了一个日志文件让我们去查看，日志目录是 /var/lib/dkms/nvidia/&lt;版本号&gt;/build/make.log，我们用 vim 进行查看 12cc: unrecognized command line option &#x27;-ftrivial-auto-var-init=zero&#x27;# 大致是这么个意思 然后又检查一下 cc -v 版本信息，发现是 11.4.0，而 nvidia-driver-560-open 是用 gcc-13 构建的 所以问题很明晰了，nvidia-driver-560-open 用 gcc-13 进行构建，但是由于编译时，可执行文件用的是 cc，而在我的机器上，我的 cc 版本为 gcc-11，所以不支持这个命令行参数（即 ftrivial-auto-var-init=zero），因此构建失败，也导致了后续一系列的问题。 好消息是，我本机已经安装过 gcc-13，因此，我先删除了 gcc-11, g++-11, gcc-11-base 等包，然后用 symlink 将 cc 直接映射为 gcc-13 1ln -s /usr/bin/gcc-13 /usr/bin/cc 再次安装 nvidia-driver-560-open，成功！安装 Linux Kernel 6.11，也是成功！ 还好没有心急让电脑 remake TAT https://answers.launchpad.net/ubuntu/+question/820141 ↩︎"},{"title":"Matplotlib 快速入门指南","path":"/matplotlib-fast-tutorial/","content":"网格布局 plt.subplots() 例如，我想将 121212 张 MNIST 图片排列成 333 行 444 列的样子。 使用 fig, axes = plt.subplot() 新建图片，并划分成网格 可以搭配 axes = axes.flatten() 进一步方便处理（将二维网格拍成一维，方便循环处理） 代码 1234567fig, axes = plt.subplot(3, 4) # 可以额外指定 fig_size 指定图片大小axes = axes.flatten()for i in range(12): axes[i].imshow(......) axes[i].set_title(......) # 每一张小图像的标题 axes[i].axis(&quot;off&quot;) 如果想要给整张图添加总标题的话，是 plt.suptitle(&quot;......&quot;) 散点图 plt.scatter()"},{"title":"conda 与 pip 配置代理服务器","path":"/conda-pip-proxy/","content":"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 Password is needed."},{"title":"海康威视相机食用指北","path":"/海康威视相机食用指北/","content":"打开相机、关闭相机的流程 首先要 MV_CC_Initialize() 初始化相机 SDK 需要实现 enum_device() 找到相机设备 通过 MV_CC_CreateHandle() 创建 handle MV_CC_OpenDevice() 打开相机"},{"title":"Python LangChain 将图像当作 URL 传递","path":"/raw-image-pass-as-url/","content":"Pass Image as if URL 一个小 trick 可以将本地图片 encode 成 byte string 之后，放在 URL 栏里传递给多模态大模型。 123456789import base64with open(&quot;path/to/image.png&quot;, &quot;rb&quot;) as image_file: b64_image = base64.b64encode(image_file.read()).decode(&quot;utf-8&quot;)def encode(path): with open(path, &quot;rb&quot;) as image_file: code = base64.b64encode(image_file.read()).decode(&quot;utf-8&quot;) return f&quot;data:image;base64,&#123;code&#125;&quot; 然后就可以正常放在 URL 栏里了。"},{"title":"使用 Python 和 Flask 库快速构建网页后端","path":"/python-flask-framework/","content":"启动一个后端 导入库后，用 app = Flask(__name__) 初始化一个 App。 一个 function 对应一个子网页的服务，用 @app.route() 指明，最后 app.run() 启动后端。 一个后端子网页 123@app.route(&quot;/upload&quot;, methods=[&quot;POST&quot;])def upload(): # ...... 启动后端 12if __name__ == &quot;__main__&quot;: app.run(debug=True, host=&quot;0.0.0.0&quot;, port=5000) 当 host 为 0.0.0.0 的话，Flask 会多设置一个 IP 地址，供本机的其他程序访问后端。"},{"title":"Django 快速开始","path":"/django-kickstart/","content":"Django 组织结构 Django 大体架构是一个 Project 管理若干个小 Application，每一个 Application 负责一个功能，跟 Application 平行的还有一个用于部署网站的 Config Folder（默认和 Project 同名）. 1234567891011121314151617181920212223242526272829UH├── CedarsCenter│ ├── admin.py│ ├── apps.py│ ├── __init__.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py├── manage.py├── StudentCenter│ ├── admin.py│ ├── apps.py│ ├── __init__.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py└── UH ├── asgi.py ├── __init__.py ├── __pycache__ │ ├── __init__.cpython-311.pyc │ └── settings.cpython-311.pyc ├── settings.py ├── urls.py └── wsgi.py 管理某一个 Project 的时候，通过 manage.py 运行相应的指令。例如在当前 Project 下新增一个 Application poll，则运行 1python manage.py startapp poll Django 中 Model 的作用 Model 的作用只是用来查询数据用的"},{"title":"Python 使用 C/C++ 接口","path":"/python-c-integration/","content":"Python 调用 C/C++ 代码 如何编写 C/C++ 代码？ 首先导入 Python.h 头文件，包含了必要的结构体、方法。（需要通过 sudo apt install python3-dev 提前安装好） 12#define PY_SSIZE_T_CLEAN#include &lt;python3.12/Python.h&gt; // 我这里需要额外指定一下路径 编译为动态库 1g++ -fPIC [file_name] -shared -o [module_name].so 在 Python 里使用 直接通过这个 Module 的名字导入 123import [module_name]# ......"},{"title":"MinerU Examples","path":"/MinerU-examples/","content":"uv 包管理器安装 MinerU 先用 uv 安装 setuptools wheel torch 1uv pip install setuptools wheel torch 然后再安装 detectron2 1uv pip install --no-build-isolation git+https://github.com/facebookresearch/detectron2.git 最后安装 magic-pdf[full] 1uv pip install &#x27;magic-pdf[full]&#x27; --extra-index-url https://wheels.myhloli.com --prerelease=allow 最后检查 magic-pdf 的版本 &gt;=0.7.0，而不是 0.6.1 如果像使用 GPU 进行 PaddlePaddle OCR 的推理，继续安装 paddlepaddle-gpu 1uv pip install paddlepaddle-gpu MinerU Command Line MinerU API 使用指南 MinerU 的使用流程基本上是 将 PDF 加载为 magic_pdf.data.dataset.Dataset 执行 OCR 和 Layout Inference 这里还想更详细地记录一下 API，感觉 Documentation 里写的不是很全，得从 demo.py 里找。"},{"title":"image-text-database","path":"/image-text-database/","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"软件工程：UML","path":"/swe-uml/","content":"Summary of “UML in Object-Oriented Analysis” 1. Purpose of UML in Analysis Modeling Goals: Understand the problem domain and provide a basis for design. Communicate design ideas efficiently among developers. Identify defects and omissions in specifications and designs before coding. Speed and Clarity: UML diagrams are faster to sketch than code and serve as a common language for developers. 2. UML Diagram Types Structure Diagrams: Class Diagrams: Model static structure (classes, attributes, relationships). Object Diagrams: Represent instances of classes at a specific point in time. Composite Structure Diagrams: Show internal structure of objects and collaborations. Behavior Diagrams: Activity Diagrams: Model workflows or business processes. State Machine Diagrams: Describe state transitions of objects. Interaction Diagrams: Sequence Diagrams: Depict object interactions over time. Communication Diagrams: Show message flows between objects. 3. Class Diagrams: Core of Domain Modeling Components: Classes: Named boxes with attributes (data) and operations (methods). Associations: Relationships between classes (e.g., Customer ↔ Order). Multiplicity: Defines cardinality (e.g., 1..* = “one or more”). Navigability: Direction of association (arrows). Domain Model: Represents problem-domain concepts (e.g., Product, Transaction, User). Focuses on conceptual classes (not implementation details). Steps to Build: Identify Classes: Use noun phrases from requirements and category lists (e.g., “Transaction,” “Record”). Define Attributes: Simple values (e.g., price, date). Avoid complex data as attributes (e.g., Address should be a class). Model Associations: Only meaningful relationships (e.g., Order contains OrderLineItems). 4. Best Practices for Class Diagrams Keep It Simple: Omit trivial associations to avoid clutter. Prioritize “need-to-know” relationships. Multiplicity Constraints: Use 1, 0..1, * (unbounded), or n (specific number) to define valid instances. Association Classes: Resolve many-to-many relationships by adding a class (e.g., Reservation between Customer and Flight). Example: SkillLevel between GameCharacter and Skill to track proficiency levels. 5. Domain Modeling Techniques Techniques for Identifying Classes: Noun/Phrase Extraction: Extract nouns from requirements (e.g., “Product Catalog” from “view products”). Category List: Use predefined categories (e.g., “Transaction,” “Container,” “Role”). Avoid Overcomplication: Do not model every relationship (e.g., ignore transient interactions like “Developer estimated PBI”). Focus on persistent relationships (e.g., PBI belongs to a Product Backlog). 6. Example: Domain Model for a POS System Key Classes: Customer, Cashier, Product, Sale, CashPayment. Associations: Sale contains SalesLineItems (multiplicity 1..*). Product is described by ProductDescription. Attributes: Sale has dateTime, total, and CashPayment (optional). 7. UML in Agile Development Iterative Approach: Build domain models incrementally, focusing on current user stories. Alignment with Implementation: Domain models inform REST API endpoints (e.g., shuttlebuses endpoint from ShuttleBus class). 8. Common Pitfalls Over-Simplification: Modeling complex data (e.g., Address) as attributes instead of classes. Over-Modeling: Including transient or unimportant relationships (e.g., Developer ↔ PBI for estimation). 9. Conclusion UML is a foundational tool for analyzing and designing software systems. Class diagrams are central to modeling problem domains and translating them into solutions. Proper use of UML reduces defects, clarifies requirements, and supports agile development practices. This summary captures the document’s focus on UML’s role in analysis, key diagrams, domain modeling techniques, and practical best practices."},{"title":"软件工程：Software Requirement Specification","path":"/swe-srs/","content":"Summary of “Software Requirements: Introduction” 1. Core Challenges in Requirements Engineering Key Issue: Understanding the problem the system must solve, often derived from customer/end-user needs. Challenges: Developers may misunderstand the business problem, leading to incorrect solutions. Customers/users may not clearly articulate their needs (especially problematic in predictive models like Waterfall). Developers must align software with end-users’ workflows to ensure practicality. 2. Drivers of Requirements Custom Software (Project-Based): Requirements driven by specific clients (e.g., government, enterprise tools). Contractual obligations dictate functionality and delivery timelines. Ownership transfers to the client post-delivery. Software Products: Requirements originate from the company’s vision/opportunity (e.g., apps, productivity tools). Developers prioritize features and constraints without a specific client’s contractual demands. Continuous evolution: Features can be added/removed post-release. 3. Types of Requirements Information Business Requirements: High-level organizational objectives (e.g., “Increase customer satisfaction”). Business Rules: Policies/constraints (e.g., pricing policies). Stored in a Business Rules Catalogue, not part of the SRS itself. User Requirements: Tasks users must perform or desired attributes (e.g., “Users want to check in online”). Functional Requirements: Specific behaviors the system must perform (e.g., “The system shall calculate fuel quantity”). Features: Bundles of related functional requirements (e.g., “User Authentication Feature”). System Requirements: Top-level/system-wide requirements (e.g., integration with hardware). Non-Functional Requirements: Properties like performance, security, usability (e.g., “Authorization must take ≤2 seconds”). External Interface Requirements: Connections to users, systems, or hardware (e.g., “JSON format for data exchange”). Constraints: Restrictions on development (e.g., “Use open-source libraries only”). 4. Business Rules Management Documentation: Rules are recorded in tables with: Rule ID, Rule Description, Volatility (how often they change), and Source (e.g., company policy). Example: Delivery pricing rules for an e-commerce system. Impact: Influence functional/non-functional requirements (e.g., permissions, UX design). 5. Software Requirements Specification (SRS) Purpose: Formal document outlining all functional and non-functional requirements. Structure: Introduction: Purpose, scope, conventions. Overall Description: Product context, user classes, constraints. System Features: Detailed functional requirements (e.g., “The system shall…”). Data Requirements: Logical models, reports, data retention policies. External Interfaces: User, software, hardware, and communication interfaces. Quality Attributes: Usability, performance, security, safety. Appendices: Glossary, analysis models. Formality: Varies by system criticality (e.g., strict for avionics vs. informal for web apps). Example: Flight Management System (FMS) requirements trace from system to low-level software specs (e.g., fuel quantity display in pounds/kilograms). 6. Requirements Traceability Critical in Safety-Critical Systems (e.g., aviation): Requirements must be bi-directionally traceable (e.g., from system to code). Example: FMS fuel quantity requirements linked to sensor polling intervals and data validity checks. DO-178C Compliance: Mandates traceability for airborne software. 7. Agile Requirements Management Alternatives to Traditional SRS: Vision and Scope Document: High-level goals and constraints. Product Backlog: Prioritized user stories/use cases with acceptance criteria. Dynamic Updates: Requirements evolve iteratively (e.g., user stories refined during sprints). Working Software: Focus on delivering increments over exhaustive documentation. Example: User stories for a flight check-in system (e.g., “As a passenger, I want to print boarding passes after check-in”). 8. Key Takeaways Requirement Types: Differentiate between business rules, user needs, functional/non-functional requirements. Documentation: Formal SRS for critical systems; agile backlogs for product development. Traceability: Essential for compliance and defect prevention in safety-critical domains. Agile Adaptation: Prioritize collaboration, iterative delivery, and flexibility over rigid planning. This summary captures the document’s focus on understanding requirements, their classification, documentation practices, and the shift toward agile methodologies for modern software development."},{"title":"软件工程：Software Process Model","path":"/swe-software-process-model/","content":"Summary of “Software Process and Activities: Process Models” 1. Introduction to Software Development Lifecycle (SDLC) SDLC: A structured sequence of development activities and tasks, organized into phases. Companies may adapt these models, but they generally fall into predictive or adaptive categories. Predictive Models: Plan all phases upfront (e.g., Waterfall). Emphasize control, documentation, and fixed requirements. Adaptive Models: Respond to change iteratively (e.g., Agile). Focus on flexibility, customer collaboration, and empirical process control. 2. Predictive Models: The Waterfall Model Structure: Linear, sequential phases: Requirements → 2. Design → 3. Implementation → 4. Testing → 5. Deployment → 6. Maintenance Key Features: Heavyweight Documentation: Formal plans and deliverables (e.g., requirements specs, design docs, test reports). Phase Dependency: A phase cannot start until the prior phase is completed and accepted. No re-entry once finalized. Milestones: Major deliverables reviewed at each phase to ensure completion. Advantages: Clear visibility, management control, and contractual clarity for mission-critical systems (e.g., aerospace, healthcare). Aligns with regulatory standards (e.g., DO-178C for airborne software). Disadvantages: Rigid: Cannot easily accommodate requirement changes or design flaws discovered late. Late Validation: Customers see a working product only at the end, risking undetected defects (cost to fix defects rises exponentially as development progresses). Inflexibility: Feedback loops require costly rework, often leading to frozen deliverables. 3. Adaptive Models: Agile and Empirical Process Control Core Principles: Transparency: Shared understanding of progress and goals. Inspection: Regular reviews of work and processes. Adaptation: Adjustments based on new knowledge. Iterative &amp; Incremental Development: Iterations (Sprints): Short, time-boxed cycles (e.g., 1–2 weeks in Scrum) delivering potentially releasable increments. Phases per Iteration: Each cycle includes planning, design, implementation, integration, testing, and review. Flexibility: Goals set at iteration start; requirements evolve over time. Benefits: Early and frequent customer feedback reduces late-stage defects. Handles uncertainty and complexity in innovative projects. Prioritizes working software over exhaustive documentation. Drawbacks: Overhead may outweigh benefits for simple, low-risk projects with stable requirements. 4. Product-Based vs. Project-Based Development Custom Software (Project-Based): Developed for specific clients (e.g., government systems, enterprise tools). Follows predictive models (e.g., Waterfall) for contractual clarity and stability. Ownership transfers to the client post-delivery. Software Products: Mass-market solutions (e.g., apps, productivity tools). Prioritizes time-to-market over rigid planning. Agile frameworks dominate due to rapid iteration and competition. Self-Managed Teams: No traditional project manager; roles like Product Owner (prioritizes backlog) and Scrum Master (facilitates process) are key. Continuous Development: Treated as ongoing processes, not discrete projects. 5. CHAOS Report Insights on Project Management Non-Agile Projects: Success rates vary with project manager skill, but bureaucracy and slow decision-making hinder outcomes. Agile Projects: Traditional project managers reduce success rates due to process overhead. Conclusion: Agile thrives without hierarchical project managers. Avoid tools like EPPM (Enterprise Project Portfolio Management) that introduce bureaucracy. Key Takeaway: “Software is infinite, while projects are finite.” Modern development should avoid artificial project boundaries and focus on continuous delivery. 6. When to Use Each Model Predictive Models (Waterfall): Appropriate for: Safety-critical systems, stable requirements, long-term contracts, and regulatory compliance. Risks: Fails in dynamic environments or when requirements are unclear. Adaptive Models (Agile): Appropriate for: Product development, innovative projects, evolving requirements, and complex problem-solving. Risks: Overhead for simple projects; requires disciplined team collaboration. 7. Conclusion Modern Trends: Shift toward product-based, Agile methodologies due to faster iteration, customer-centricity, and adaptability. Process Selection: Choose models based on project complexity, risk, and requirements stability. Predictive models remain viable for specific domains (e.g., aerospace), while Agile dominates in competitive, evolving markets. This summary encapsulates the document’s contrast between predictive and adaptive models, their strengths/weaknesses, and the industry’s move toward Agile for product development."},{"title":"multi-thread","path":"/multi-thread/","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"大模型权重文件 .gguf 分析以及转换","path":"/gguf/","content":".gguf .gguf 是 Hugging Face 自己开发的大模型权重格式，适合快速载入模型以及推理。最初在 llama.cpp 项目里使用。 GGUF"},{"title":"Linux 下用 HKU 账号使用 HK eduroam WiFi","path":"/connect-to-eduroam-hku/","content":"eduroam 我是 Linux Mint 系统，所以 Ubuntu/Mint 应该比较通用。 Option Value Security WPA &amp; WPA2 Enterprise Authentication Protected EAP (PEAP) Anonymous Identity 留空 Domain hku.hk CA Certificate 选 (None)，勾选 No CA Certificate is required PEAP version Automatic Inner Authentication MSCHAPv2 Username &lt;UID&gt;@hku.hk，&lt;UID&gt; 是邮箱 @ 前的部分，这里后缀必须是 @hku.hk Password Portal 的登录密码"},{"title":"Docker Introduction","path":"/docker-intro/","content":"Dockerfile Docker Image 编写完 Dockerfile 后，我们可以用命令创建一个 docker 镜像 1docker build -t [镜像名称] [Dockerfile 所在目录] 启动 container 还需要一个 container 才能运行起来 1docker run -p [映射到主机的哪个端口]:[容器内的哪个端口] -d [镜像名称] -p：指定端口 -d：后台运行。想要查看终端输出的话需要到 docker desktop 里查看 用 Volume 保存 container 的数据 利用 -v 参数，把本地文件夹 ~/A 挂载到 container 里的 .../B，这样在 container 里读写 .../B 其实等于读写 ~/A. 我们先创建一个数据卷 1docker volume create [数据卷位置] 然后在 docker run 的时候进行挂载 1docker run -v [数据卷在本地的位置]:[数据卷在容器里的位置] -d [镜像名称] Docker Compose 多个容器共同协作：例如数据库和前端分离。 在 docker-compose.yml 里用 services 进行定义 12345678910111213# docker-compose.ymlservices: # 定义前端和数据库 front-end: # 前端 build: . # 镜像——从文件夹构建 ports: # 端口映射 - &quot;80:5000&quot; database: # 数据库 image: &quot;mysql&quot; # 镜像——从其他地方拉取 environment: # 可以定义环境变量 OPENAI_API_KEY: &quot;...&quot; OPENAI_API_BASE: &quot;&quot; volumes: # 数据卷，等同于 -v 参数 - &quot;~/A:.../B&quot; 定义完毕后，使用 1docker compose up -d 来运行所有的 container 1docker compose down 来停止并删除所有的 container"},{"title":"本地部署 llama.cpp 大模型服务器并连接","path":"/local-deploy/","content":"llama.cpp 的安装、编译 alternative: llama-cpp-python 提供了 llama.cpp 的 Python 接口。通过 llama-cpp-python 也可以启动一个 LLM Server 启动一个 LLM server 直接在命令行里输入启动服务器 1llama-server -m [模型路径] --port 8080 模型要保证必须是 .gguf 格式，可以使用 llama.cpp 项目根目录下的 convert_hf_to_gguf.py 进行转换。 convert_hf_to_gguf 食用方法 配置好虚拟环境后，命令行里输入 1python convert_hf_to_gguf.py [模型.bin文件所在的目录] 这个目录末尾应该是哈希码，例如 ~/.cache/huggingface/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/ad9f0ae0864d7fbcd1cd905e3c6c5b069cc8b562 连接 如果用 LangChain 进行连接，必须注意要输入 http://localhost:8080 的 http://（被坑了）"},{"title":"friends","path":"/friends/index.html","content":"Friends XXZ’s blog"},{"title":"OpenVLA 代码解析 (1)","path":"/wiki/agentai/OpenVLA-code-p1.html","content":"5d4944576327e6e1f59f35f07afdbc7917ffe61195e5ff6f7af12e15300ba733 Password is needed."},{"title":"About Me","path":"/about/index.html","content":"About Me I want to … Wallpaper engine on Linux! RM Simulator! Archive.yazi (compress and extract)"},{"title":"OpenVLA-dataproc-pipeline","path":"/wiki/agentai/OpenVLA-dataproc-pipeline.html","content":"OpenVLA 数据处理过程 normalization diff embodyment 在环境下评测 model, performance, accuracy"},{"title":"OpenVLA 论文","path":"/wiki/agentai/OpenVLA.html","content":"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 Password is needed."},{"title":"Google Gemini Robotics","path":"/wiki/agentai/google-gemini-robotics.html","content":"AI Summary Background • Core Problem: The paper addresses the challenge of bridging the gap between state‐of‐the‐art multimodal AI models and practical robotics. Although digital AI models have achieved impressive capabilities in processing text, images, and other modalities, these models traditionally lack the embodied reasoning (i.e., the ability to understand and physically interact with the real world) required for autonomous robot control. • Current Limitations and Challenges: Existing vision–language models excel at perception and symbolic tasks, yet they fall short when it comes to physical grounding. The authors point out that current research struggles with robust spatial understanding, dexterous manipulation, safe human–robot interactions, and adapting to novel object configurations and environments. Moreover, there is an absence of standardized benchmarks that cover the nuanced set of reasoning skills needed for embodied tasks. • Real-world Needs and Theoretical Gaps: The paper underscores the necessity for general-purpose robots capable of smooth, safe, and reactive movements. There is a critical need to extend digital reasoning to handle real-world cues such as 3D geometry, object affordances, and trajectory planning. The authors identify a theoretical gap in unifying multimodal understanding (visual and language) with physical action planning. Motivation • Driving Factors Behind the New Method: The motivation comes from the desire to leverage the advanced multimodal reasoning of models like Gemini 2.0 and extend these capabilities to control physical robots. The authors aim to overcome the limitations of existing systems which are typically confined to digital domains by integrating a comprehensive embodied reasoning framework into robotics. • Shortcomings of Existing Approaches: Current practices often suffer from poor generalization when faced with unseen object types, variable settings, and complex manipulation tasks. Many existing methods lack the ability to plan sequential actions under safety constraints and cannot efficiently adapt to new robot embodiments or environments. Issues such as limited computational efficiency in planning and a narrow focus on perception without actionable outputs further drive the need for an improved, unified approach. Methodology • Core Innovation: The paper introduces the Gemini Robotics family of models––a suite of vision–language–action (VLA) systems that fuse the powerful multimodal understanding of Gemini 2.0 with a dedicated robotics layer. Two principal variants are proposed: Gemini Robotics-ER (Embodied Reasoning): Enhances the base model’s spatial and temporal reasoning to perform tasks such as object detection, 2D pointing, trajectory prediction, and top-down grasp estimation. Gemini Robotics: Extends these capabilities by incorporating robot action data to achieve high-frequency, dexterous control over physical robots. • Technical Steps and Key Components: Multimodal Input Fusion: Integrates visual inputs (images) and textual instructions, using open‐vocabulary queries to detect and localize objects in both 2D and 3D (e.g., 3D bounding boxes and multi-view correspondence). Embodied Reasoning Pipeline: Employs a chain-of-thought (CoT) prompting technique, which encourages the model to generate intermediate reasoning steps, thereby ensuring precise spatial grounding and sequential planning. (Chain-of-thought prompting is a method where the model is instructed to “think out loud” through intermediate steps before giving the final answer.) Robot Control Integration: A dedicated pipeline converts high-level planning into low-level actuation commands via a robot API, managing safe and reactive motions while adhering to physical constraints. Specialization and Adaptation: An optional fine-tuning stage enables the system to adapt to long-horizon tasks, enhance dexterity (e.g., folding or playing cards), and adjust to variations in robot embodiments such as bi-arm platforms or humanoids. • Fundamental Differences from Baseline Approaches: Unlike conventional methods that may treat perception and control as separate tasks, the Gemini Robotics models offer an end-to-end, integrated solution. By combining embodied reasoning with action data, these models generalize better to novel tasks, improve adaptation with few demonstrations, and facilitate safe control in dynamic environments. Experiments &amp; Results • Experimental Setup: The models are evaluated on several benchmarks including the newly introduced Embodied Reasoning Question Answering (ERQA) benchmark, RealworldQA, and BLINK. The experimental design encompasses tasks ranging from simple object detection to complex, dexterous manipulation tasks in both simulated and real-world scenarios. Datasets include images sourced from in-house collections and publicly available datasets like OXE, UMI Data, and MECCANO. Baseline comparisons are made against existing vision–language and diffusion-based robotics models, using performance metrics such as accuracy, success rate, and continuous progress scores. • Key Findings: Gemini 2.0 variants (Flash and Pro Experimental) achieve state-of-the-art performance across multiple benchmark evaluations, often with notable improvements when chain-of-thought prompting is used. Quantitative results show improvements in tasks like 2D pointing accuracy (measured by how well predicted points fall within ground-truth regions) and successful grasp predictions in real-world robot control. In dexterous tasks such as folding an origami fox or playing a card game, Gemini Robotics outperforms baseline models in both binary success metrics and nuanced progress scores. • Ablation and Sensitivity Analyses: The paper reports ablation studies that highlight the benefits of each component—from embodied reasoning enhancements to fine-tuning stages. Sensitivity analyses reveal that prompts such as chain-of-thought can significantly affect overall performance, and that the integrated approach provides robust improvements even under distribution shifts (e.g., novel visual variations or rephrased instructions). Effectiveness Analysis • Underlying Reasons for Success: The method’s effectiveness stems from its dual focus on robust multimodal understanding and practical action integration. By augmenting a strong foundation model with specialized embodied reasoning and robot-specific training, the system manages to bridge the digital–physical divide. In particular, the use of multi-view spatial understanding and sequential reasoning ensures continuity between perception and physical manipulation. • Critical Success Factors: Model Architecture and Training: Leveraging Gemini 2.0’s large-scale, pre-trained capabilities provides a strong foundation for embodied reasoning. Effective Data Fusion: Integrating diverse data types—including images, text, and robot sensor readings—improves generalization and adaptability. Prompting Strategies: Techniques like chain-of-thought prompting contribute to clear intermediate reasoning, enhancing the decision-making process. Safety and Adaptability Protocols: The incorporation of robot API interfaces and safety guidelines enables smooth interaction in regulated physical environments. • Potential Limitations and Applicability Boundaries: While the proposed models demonstrate impressive performance, their success is tightly coupled with the quality and diversity of training data. The system may face constraints when encountering drastically different physical environments or unanticipated object configurations. Furthermore, the reliance on comprehensive safety protocols suggests that additional work is required to ensure deployment in less structured or more variable real-world settings. Contributions • Theoretical Contributions: The paper provides a unified framework that connects high-level multimodal reasoning directly with low-level robot control. It introduces new benchmark tasks (e.g., ERQA) to evaluate embodied reasoning, setting a new standard for measuring the full spectrum of capabilities required for physical interaction. • Practical Contributions: The development of the Gemini Robotics family offers an end-to-end solution for controlling robots with diverse manipulation tasks, from dexterous object handling to adaptive task execution. Detailed model cards and open-source evaluation protocols are provided, facilitating reproducibility and further research in embodied AI. The work also contributes guidelines and best practices for ensuring safety and responsible development in robotics applications. • Implications for Future Research: This research marks a significant step toward general-purpose embodied AI. Future work can build on these findings to further enhance generalization, reduce reliance on extensive fine-tuning, and tackle more complex physical interactions. The integration of multimodal reasoning with action control paves the way for robots that can adapt to diverse, unstructured real-world environments while ensuring safe and reliable operation."},{"title":"Pi 0, A Vision-Language-Action Flow Model for General Robot Control","path":"/wiki/agentai/pi-zero.html","content":"AI Summary Background The paper addresses the challenge of developing a unified robot foundation model that can handle a wide range of dexterous tasks across different robot platforms. Current robot learning approaches often suffer from limited generalization, data scarcity, and brittle performance when adapting to complex practical scenarios. Existing methods typically focus on narrow tasks or use discretized models that struggle with continuous, high-frequency control. The authors identify a real-world need for models that can integrate rich semantic understanding (gained from large-scale vision-language pre-training) with fine-grained physical control to perform intricate multi-stage tasks such as laundry folding or box assembly. Motivation The direct drive behind this work is the gap between the robust, versatile behavior seen in large language and vision-language models and the limitations of current robot control systems. Existing approaches fail to meet the demands of real-world robotic manipulation due to: Limited Generalization: Models are often trained on task-specific data and do not transfer well to diverse environments or novel tasks. Discrete Outputs: Many prior methods rely on autoregressive and token-based approaches, which are not well-suited for high-frequency continuous control. Data and Recovery Challenges: Training solely on curated, high-quality data results in brittle systems that cannot efficiently recover from errors or unexpected perturbations. This motivates the integration of internet-scale semantic pre-training with a continuous action generation method, thereby combining robust, flexible understanding with high-precision control. Methodology The core innovation is the design of a vision-language-action model (π0) that unifies pre-trained semantic knowledge with a novel mechanism for continuous action prediction. Key elements include: Pre-trained VLM Backbone: The model starts with a vision-language model (VLM) pre-trained on vast internet data (e.g., PaliGemma). This allows the system to inherit rich semantic representations and language understanding. Brief explanation: A VLM (Vision-Language Model) is trained on image-text pairs to extract visual and linguistic features simultaneously. Action Expert with Flow Matching: A separate module—termed the action expert—is added to predict continuous action sequences. Instead of relying on discrete token outputs, it uses conditional flow matching. Brief explanation: Flow matching is a variant of diffusion methods where a denoising vector field is learned to progressively transform noise into data, enabling precise continuous outputs. The model predicts action chunks (e.g., 50 future steps) at once, accommodating high-frequency control (up to 50 Hz). The design employs multi-stage training where the model is first exposed to diverse, lower-quality pre-training data and later fine-tuned on high-quality, task-specific data. Architectural Separation: The transformer backbone routes standard inputs (images and language) through the pre-trained VLM segment, while robot-specific proprioceptive inputs and continuous actions are handled by an additional expert. This mixture of experts approach allows leveraging pre-existing knowledge while adapting to robotics-specific demands. Two-Phase Training Recipe: Emphasizing the importance of both data diversity and quality, the training is split into a large-scale pre-training phase (covering 10,000 hours of data across 68 tasks and 7 robot configurations) and a post-training phase that refines the model for complex downstream tasks. Experiments &amp; Results The authors evaluate their model on a wide range of dexterous manipulation tasks spanning different robots and complexities: Experimental Setup: Tasks include shirt folding, table bussing (easy and hard versions), grocery bagging, removing toast from a toaster, laundry folding, box assembly, packing eggs, and more. Diverse robot configurations such as single-arm, dual-arm, and mobile manipulators are used to test cross-embodiment performance. Evaluation metrics involve task-specific score rubrics that measure progress and success (e.g., percentage of task completion or discrete scores per subtasks). Key Findings: The full π0 model, trained with both pre-training and fine-tuning, outperforms baseline approaches like OpenVLA and smaller models (π0-small) on both direct prompting (out-of-box performance) and after fine-tuning. Ablation studies show that incorporating continuous action generation via flow matching results in significant improvements in dexterity and robustness. The approach demonstrates the capability to perform complex, multi-stage tasks that were previously challenging or unsolvable using traditional methods. Effectiveness Analysis The method works due to several critical factors: Integration of Semantic and Physical Knowledge: The use of a pre-trained VLM imparts broad semantic understanding, enabling the model to interpret language commands effectively. This, when combined with flow matching, allows the system to translate high-level instructions into accurate continuous motions. Flow Matching for Continuous Control: By modeling the entire distribution of actions as a continuous process, the approach ensures high precision and the ability to recover from errors—a necessity in real-world dexterous tasks. Robust Training Recipe: The dual-phase training method (diverse pre-training followed by targeted fine-tuning) allows the model to learn both general competencies and task-specialized behaviors while mitigating issues of overfitting and brittleness. Critical Success Factors: The modular architecture separating vision-language and robotics-specific pathways facilitates efficient processing and speed. The ability to predict action chunks supports high-frequency control, crucial for tasks that require fine motor skills. Potential limitations include the reliance on massive amounts of pre-training data and the current lack of comprehensive understanding about optimal data composition. Moreover, while promising for robot manipulation, it remains to be seen how well the approach transfers to other domains such as autonomous driving or legged locomotion. Contributions The paper makes several novel contributions: Theoretical Contributions: It introduces a novel integration of a pre-trained vision-language model with flow matching to generate continuous action distributions—bridging the gap between discrete output methods and the requirements of dexterous robot control. The work advances our conceptual understanding of how multi-modal pre-training can be leveraged to build versatile and general-purpose robot foundation models. Practical Contributions: The π0 model is demonstrated across multiple robot embodiments and a wide array of tasks, showcasing its practicality and robustness in real-world settings. The proposed multi-stage training recipe—including cross-embodiment data integration and action chunking—sets a new benchmark for large-scale robot learning experiments (using approximately 10,000 hours of diverse data). The empirical results establish a state-of-the-art performance in complex, temporally extended tasks such as laundry folding and box assembly. Implications for Future Research: This work lays the groundwork for future exploration of universal robot foundation models that might extend beyond manipulation to domains like navigation and legged locomotion. The proposed framework encourages further studies on optimal data weighting, integration techniques, and extending these methods to even broader real-world scenarios. Background Large Scale Right Model Architecture Right Trainging Recipe"},{"title":"内核性能分析工具","path":"/wiki/ai-infra/performance-analysis-tools.html","content":"内核优化的常见步骤 分析 Kernel 的执行时间 统计、查看各个 Kernel 的执行时间 定位性能瓶颈，确定需要优化的 Kernel 检查 GPU 的利用率等信息 例如检查是否占用过多的寄存器 （更细粒度）确定 Kernel 的性能瓶颈 优化 Kernel 性能 通过各种技术手段（软硬件、调度、内存优化）优化 Kernel PyTorch 内置 torch.profiler TensorBoard Holistic Trace Analysis NVIDIA Nsight 工具 Nsight System Nsight Compute Triton Proton"},{"title":"Triton Introduction","path":"/wiki/ai-infra/triton-intro.html","content":"PyTorch 关键组件 TorchDynamo 将所有复杂算子简化到 PrimTorch 中的 250 个算子 移除未使用的算子 确实需要存储、写入内存的中间算子，以及可融合的算子，从而减少开销 PrimTorch 定义了两个算子集合：Aten ops 和 Prim ops 将 PyTorch 程序的各种计算用这些算子集里的算子表示 简化后端需要编写的算子数量 AOTAutograd 提前获取反向传播 基于完整的 forward/backward 根据算子的依赖关系进行算子调度，对算子和层进行融合 TorchInductor 进行算子融合 自动生成低级 GPU 上的 Triton 代码（或者 CPU 上的 C++/OpenMP） 编译流程 我们用下面的例子介绍一下大致的编译流程，在运行时加入调试参数 TORCH_LOGS=&quot;...&quot; python example.py 查看中间的日志输出 12345678910import torch@torch.compiledef toy_example(x: torch.Tensor) -&gt; torch.Tensor: y = x.sin() z = y.cos() return zif __name__ == &quot;__main__&quot;: x = torch.randn(1000, device=&quot;cuda&quot;, requires_grad=True) # 开启反向传播 Step 1. TorchDynamo 运行 TORCH_LOGS=&quot;dynamo&quot; uv run example.py，我们先来看第一步 TorchDynamo 的输出。 日志输出12345678910111213141516171819202122232425262728293031323334[torch/_dynamo/symbolic_convert.py:2706] [0/0] Step 1: torchdynamo start tracing toy_example [很长的路径]/example.py:5[torch/_dynamo/symbolic_convert.py:3028] [0/0] Step 1: torchdynamo done tracing toy_example[torch/_dynamo/output_graph.py:1458] [0/0] Step 2: calling compiler function inductor[torch/_dynamo/output_graph.py:1463] [0/0] Step 2: done compiler function inductor[torch/fx/experimental/symbolic_shapes.py:4547] [0/0] produce_guards[torch/_dynamo/pgo.py:636] [0/0] put_code_state: no cache key, skipping[torch/_dynamo/eval_frame.py:398] TorchDynamo attempted to trace the following frames [ toy_example [很长的路径]/example.py:5 ][torch/_dynamo/utils.py:446] TorchDynamo compilation metrics: Function Runtimes (s) ------------------------------------ -------------- _compile.compile_inner 0.5482 OutputGraph.call_user_compiler 0.4845 _recursive_pre_grad_passes 0.0018 create_aot_dispatcher_function 0.4817 _recursive_joint_graph_passes 0.0684 compile_fx.&lt;locals&gt;.fw_compiler_base 0.3442 compile_fx_inner 0.3437 inductor_codecache_torch_key 0.0523 TritonBundler.read_and_emit 0.0002 PyCodeCache.load_by_key_path 0.0122 async_compile.precompile 0.007 async_compile.wait 0.0001 从日志中可以看到，TorchDynamo 的框架流程就是 对要编译的模型进行追踪，然后编译并生成中间表示 (FX Graph IR) 调用 compiler.inductor 对模型进行化简 1.1 Dynamo 图捕获 Dynamo 首先进行图捕获。这里，__graph_code 将原始代码的 Dataflow 进行捕获，并输出捕获的 DAG，即 FX Graph IR. FX Graph IR1234567891011121314151617181920212223# [torch/fx/passes/runtime_assert.py:118] [0/0] [__graph_code] def forward(self, L_x_: &quot;f32[1000]&quot;): l_x_ = L_x_ # File: example.py:7 in toy_example, code: y = x.sin() y: &quot;f32[1000]&quot; = l_x_.sin(); l_x_ = None # File: example.py:8 in toy_example, code: z = y.cos() z: &quot;f32[1000]&quot; = y.cos(); y = None return (z,)[torch/_dynamo/output_graph.py:1353] [0/0] [__graph_code] def forward(self, L_x_: &quot;f32[1000][1]cuda:0&quot;): l_x_ = L_x_ # File: example.py:7 in toy_example, code: y = x.sin() y: &quot;f32[1000][1]cuda:0&quot; = l_x_.sin(); l_x_ = None # File: example.py:8 in toy_example, code: z = y.cos() z: &quot;f32[1000][1]cuda:0&quot; = y.cos(); y = None return (z,) 1.2 AOTAutograd Dynamo 的 AOTAutograd 阶段 生成正向传播图和反向传播图（也是表示为 FX Graph IR 的形式） 会将 FX Graph IR 中的算子替换为 ATen 算子库里的算子 基于完整的正向、反向传播图的视角，根据依赖关系，进行算子调度、对算子和层进行融合 将复杂的算子根据字典进一步分解为更底层的 Core ATen IR 算子或者 Prim IR 算子 AOTAutograd IR 生成的正向图与反向图12345678910111213141516171819202122232425262728293031# 这个是正向图# ===== Forward graph 0 =====# torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, primals_1: &quot;f32[1000][1]cuda:0&quot;): ## File: example.py:7 in toy_example, code: y = x.sin() sin: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.sin.default(primals_1) ## File: example.py:8 in toy_example, code: z = y.cos() cos: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.cos.default(sin); sin = None return (cos, primals_1)# 这个是反向图# [torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:603]# [0/0] [__aot_graphs]# # TRACED GRAPH# ===== Backward graph 0 =====&lt;eval_with_key&gt;.1 class GraphModule(torch.nn.Module): def forward(self, primals_1: &quot;f32[1000][1]cuda:0&quot;, tangents_1: &quot;f32[1000][1]cuda:0&quot;): # File: example.py:7 in toy_example, code: y = x.sin() sin: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.sin.default(primals_1) # File: example.py:8 in toy_example, code: z = y.cos() sin_1: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.sin.default(sin); sin = None neg: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.neg.default(sin_1); sin_1 = None mul: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.mul.Tensor(tangents_1, neg); tangents_1 = neg = None # File: example.py:7 in toy_example, code: y = x.sin() cos_1: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.cos.default(primals_1); primals_1 = None mul_1: &quot;f32[1000][1]cuda:0&quot; = torch.ops.aten.mul.Tensor(mul, cos_1); mul = cos_1 = None return (mul_1,) 2. Inductor Triton 的核心： compile() model fullgraph dynamic"},{"title":"RMSNorm","path":"/wiki/aitactics/RMSNorm.html","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"LayerNorm","path":"/wiki/aitactics/layernorm.html","content":"LayerNorm 假设是在 CNN 的语境下，我们对一个 N×H×W×CN\\times H\\times W\\times CN×H×W×C 的 tensor 做 LayerNorm。 LayerNorm 做的事实际上是对于每一个 H×W×CH\\times W\\times CH×W×C 做 Normalization."},{"title":"Ascend C 介绍与 NPU 芯片","path":"/wiki/ascendc/intro.html","content":"d0144f89de14a1fc384914230d36d0ec0054caf00183a222885cc88f31848a18aab140cd588bb1a31357d2dfedf6c8adfb592b49da5961aaa495123a3ccb3fa9a9f6c36e1bc55e6ff161822b769668a2076f5cfab45f196e1c53f0376e4956630c8a0923bfd91ca220c8d6a51d78be71e5b15538793255c1fcf3fbc64b80ef22508f3168feccbdaffac7faff9ec41aa90bd14105244569a56fb953d126552fc91d226fb4aa73c720ffee5e27a6e6c44331325d651b1f74c98b14d272388278d75502dfd76dee11cf4ae7c17bae192f36d0fc6097e31014e778d3ce734f793cc91d6a0cd8deee525e0a2b5df1feb19690d6cb0ed574e528834c7497615774b37a7d6a622e4a391fda0f6d046ee84fabcc6866a2fa790d0da49f405d25262fe0b227284612f2bbedafb19c35fddce7dbee9ea231f1128845e2cb4d3acb14a798c9445debfe7149b4028652944b99b85e6edd553e3657d323986791286e06611026a0b53564e9d42cb8d5930b665780169dd1f70bcc60ea6a108e7508f6b4bb904766b050f2d77edb2d92da12da5e5c4e226216b6aebe1366030bb436121c7a9f88e091b50f1553e5c3fbf3e08989b7c17a3a39de4e90112e198843ee98d7250d6cd7aa6775e73d8e3f2c10e535f76a20fb37d456d87f6666f252b1711bb852ba8ebdb2569e786dc13560eadb4ae4c42e8b5d14abef39d4ba6c5316bef5bce30910aa0dbe3bd454a7fdf5dbd7c47c034aa4008e8976343eca32e87ba156dc597cb588f4606b79ed83933468023f298250221b45caa3fbc371929526c7172ba395c9ece27b8ece80706195af6c0e7022c6f17e2b0cdd6b68406ce32e43d5bd7bc28fba6d76fe865bc8d0418149ca493a51097a7de299e67e71170344738fcfd519ce277e2a286cff0c58e2a44ea50dddf92fa061b6360d6804ef591820ebe7ead7532e594b1b2328f6deb4d87aa44f3b2c206b04e743f4062a0f3e97c1b4864b8c6d7906763512c3f64396b213ab89caf45d38c0f50f1f5f93fd38816ec6bebbca3364766f2a26cda6379849f8a480114accbaeb749a9dd5b9f6cbee7c31fcb51ff6fcf80c879e9eaa5f05c522fbc29d55095152d5c8e5f7745956c602d18cc1637d57c82ea950aad8409b557346ad1245f228a4492cdfd9274376eadf8dc24f39ecd4594177677dd558ea8a857c7beb585e8d2d780bb29be3591827a4768e7f03b285aa795a4f294b5af5c6474303a17193a9be731f2d6453374ecc65ce9bbeb3cb7eccac9708994ea7be1632ecf6be3094 Password is needed."},{"title":"博弈论：Minimax 与 Alpha-Beta 剪枝","path":"/wiki/algo/alpha-beta-minimax.html","content":"Minimax 博弈游戏可以简化成这样的局面：第 iii 轮我方行动，目的是最大化得分；下一轮对手行动，目的是最小化我方得分；再下一轮又是我方行动，目的是最大化得分……如此往复。 Minimax 搜索优化：Alpha-Beta 剪枝 记节点分数为 xxx，我们给每一个节点维护两个值 α,β\\alpha,\\betaα,β 满足 α≤x≤β\\alpha\\le x\\le\\betaα≤x≤β. 算法流程大致如下： 如果是我方行动"},{"title":"NP 理论：近似算法","path":"/wiki/algo/approx-algo.html","content":"近似算法 近似算法的目的在于：对 NP 难问题设计多项式时间算法，保证解的质量在一定比例内（近似比）"},{"title":"Boruvka 算法：特殊限制下的最小生成树算法","path":"/wiki/algo/boruvka.html","content":"Boruvka 最小生成树算法 Boruvka 在思想上算是 Kruskal 和 Prim 算法的结合，在 某个点出发的边的边权可以放在一起考虑 边权具有特殊性质 时具有较大优势。 算法流程 和 Kruskal 一样，我们维护若干个连通块。我们定义，连通块 cic_ici​ 的最小边表示这个连通块和其他连通块之间的边里最小的边，即 min⁡w(e){e:e=(u,v);u∈ci∧v∈cj∧i≠j}\\min_{w(e)}\\{ e:e=(u,v);u\\in c_i\\land v\\in c_j\\land i e j \\}minw(e)​{e:e=(u,v);u∈ci​∧v∈cj​∧i=j} 初始时，每一个点 vvv 都分配一个连通块 cvc_vcv​。 计算每一个点属于哪一个连通块，把这个连通块的最小边设为 None 遍历每一条边 e=(u,v)e=(u,v)e=(u,v)，如果 u,vu,vu,v 不在同一个连通块内，用 w(e)w(e)w(e) 更新这两个连通块 cu,cvc_u,c_vcu​,cv​ 的最小边 如果所有连通块的最小边都是 None，则结束；否则，将每个连通块的最小边加入答案，继续从 111 循环"},{"title":"无/有源汇 上下界 可行/最大/最小流","path":"/wiki/algo/bounded-flow.html","content":"无源汇 上下界可行流 每条边都存在下界 b(u,v),c(u,v)b(u,v),c(u,v)b(u,v),c(u,v) 分别表示这条边的流量至少、至多为多少。 我们先直接假设每条边已经流了 b(u,v)b(u,v)b(u,v) 的流量，设为初始流量 然后构造新图 HHH，其中的每一条边 eH(u,v)e_H(u,v)eH​(u,v) 满足其容量为 c(u,v)−b(u,v)c(u,v)-b(u,v)c(u,v)−b(u,v) 然后对 HHH 中的节点 iii 进行调整，假设 HHH 中两个额外的点 S,TS,TS,T 分别作为 HHH 中的源汇点 如果初始流量中 iii 的收支平衡，则不用添加边 如果 iii 的入流多于出流，差值为 ddd，则 SSS 向 iii 连边，容量为 ddd 如果 iii 的出流多于入流，差值为 ddd，则 iii 向 TTT 连边，容量为 ddd 然后以 SSS 为源点，TTT 为汇点跑最大流。 如果 SSS 出发的边都满流，则存在可行流；否则不存在 正确性证明 有源汇 上下界可行流 设源点为 SSS，汇点为 TTT，则我们连 T→ST\\to ST→S 的边，其下界为 000，上界为 ∞\\infin∞。于是问题转化为无源汇上下界可行流。 此时若有解，S→TS\\to TS→T 的可行流的流量就等于 T→ST\\to ST→S 的附加边的流量。 上下界最大流 上下界最小流"},{"title":"计算几何：凸包","path":"/wiki/algo/convex-hull.html","content":"求解凸包"},{"title":"算法设计：计数模型","path":"/wiki/algo/counting-techniques.html","content":"计数模型 算法竞赛里的计数问题通常有几种类别： 给定区间，求这个区间里合法元素的个数"},{"title":"动态规划例题 (1)","path":"/wiki/algo/dp-design.html","content":"动态规划例题 不能很清晰地分类……就全丢到这里了…… Codeforces 2107 F1TP LinkSubmission我们考虑 apa_pap​，我们可以这样做：花费 i−pi-pi−p 把 apa_pap​ 换到自己前面花费 apa_pap​ 超车再花费 111 把 apa_pap​ 换到自己面前再花费 apa_pap​ 超车……于是我们可以利用 apa_pap​ 超车一个区间 ([l,r],l≤p≤r[l,r],l\\le p\\le r[l,r],l≤p≤r) 的车手，花费为（假设当前正在 rrr 的身后）(r−l+1)⋅ap超车费用+r−l把 ap 从身后换到身前+r−p把 ap 从原来的位置换到自己身前\\begin{array}{rlll}(r-l+1)\\cdot a_p &amp;超车费用\\\\+r-l &amp;把\\ a_p\\ 从身后换到身前\\\\+r-p &amp;把\\ a_p\\ 从原来的位置换到自己身前\\end{array}(r−l+1)⋅ap​+r−l+r−p​超车费用把 ap​ 从身后换到身前把 ap​ 从原来的位置换到自己身前​当我们从 rrr 向 lll 扫描的时候，此时我们枚举的 ppp 递减，因此 r−pr-pr−p 递增，要使这个式子最小，apa_pap​ 必须为 [l,r][l,r][l,r] 内最小值（且最靠右），才有可能最小化这个式子。解决完这个区间之后，我们发现，整个 [1,n][1,n][1,n] 可以切分成多个这样的子结构（每个小区间里选出自己的 apa_pap​）。差不多就类似于走进另一个区间发现在另一个区间用另一个数当 apa_pap​ 更划算。现在我们来定义状态。设 dp[i]dp[i]dp[i] 表示从第 nnn 个人后面走到第 iii 个人后面、第 i+1i+1i+1 个人前面时所需要的最小费用。那么 dp[0]dp[0]dp[0] 就是我们需要的答案，初始化 dp[n]=0dp[n]=0dp[n]=0.随后，我们从后向前枚举 iii（现在在第 iii 个人后面），并且枚举 jjj，表明我们要从 iii 走到 jjj 位置，即 dp[i]→dp[j]dp[i]\\to dp[j]dp[i]→dp[j].根据上文的分析，我们需要知道 a[j…i]a[j\\dots i]a[j…i] 的最小值 a[p]a[p]a[p]（有多个的话取最右的，这个可以在枚举 jjj 时一起维护）dp[j−1]←min⁡dp[i]+a[p]×(i−j+1)⏟超车费用+i−p⏟第一次换到身前+i−j⏟换到身前(j≤p≤i)dp[j-1]\\underset{\\min}{\\gets} dp[i]+\\underbrace{a[p]\\times(i-j+1)}_{超车费用}+\\underbrace{i-p}_{第一次换到身前}+\\underbrace{i-j}_{换到身前} (j\\le p\\le i)dp[j−1]min←​dp[i]+超车费用a[p]×(i−j+1)​​+第一次换到身前i−p​​+换到身前i−j​​(j≤p≤i)因为 a[p]a[p]a[p] 考虑了 a[j]a[j]a[j]，所以 jjj 位置也会被超车，因此更新的是 dp[j−1]dp[j-1]dp[j−1]"},{"title":"网络流：EK 算法","path":"/wiki/algo/edmonds-karp.html","content":"EK 算法 EK 算法在 Residual Graph 里找增广路的时候，使用 BFS 算法求解出的增广路一定是 shortest (in terms of fewest edges). 算法证明 Distance Lemma 令 EF 算法第 iii 次在 GfG_fGf​ 上找到的增广路为 fif_ifi​，并且这些 fif_ifi​ 是最短的（经过最少的边）。记 GiG_{i}Gi​ 为 fif_ifi​ 对应的 residual graph，di(u,v)d_i(u,v)di​(u,v) 为 GiG_{i}Gi​ 上两点之间的最短距离（最小边数），那么有 di+1(s,v)≥di(s,v) \\boxed{d_{i+1}(s,v)\\ge d_i(s,v)} di+1​(s,v)≥di​(s,v)​ 证明 令 s,vs,vs,v 最短路径上的点按 distance 递增排列。我们用数学归纳法证明。 当 di+1(s,v)=0d_{i+1}(s,v)=0di+1​(s,v)=0 时，说明 s=vs=vs=v 两者是同一个点，因此在 fif_ifi​ 对应的图里，di(s,v)=0≤di+1(s,v)d_i(s,v)=0\\le d_{i+1}(s,v)di​(s,v)=0≤di+1​(s,v). 考虑任意长度 L&gt;0L\\gt 0L&gt;0，假设引理对 ∀v,di+1(s,v)&lt;L\\forall v, d_{i+1}(s,v)\\lt L∀v,di+1​(s,v)&lt;L 成立，考察 ∀v,di+1(s,v)=L\\forall v,d_{i+1}(s,v)=L∀v,di+1​(s,v)=L： 在 residual graph Gi+1G_{i+1}Gi+1​ 上找到 s,vs,vs,v 的最短路，令 xxx 为 vvv 的上一个节点，那么有 di+1(s,x)=L−1d_{i+1}(s,x)=L-1di+1​(s,x)=L−1 所以根据假设 di(s,x)≤L−1d_{i}(s,x)\\le L-1di​(s,x)≤L−1，我们再根据这个信息，推理 di(s,v)d_i(s,v)di​(s,v)。在 GiG_iGi​ 上有两种情况 GiG_iGi​ 中存在 (x,v)(x,v)(x,v) 这条边 这种情况下，我们只需要走 s→x→vs\\to x\\to vs→x→v，就一定可以保证 di(s,v)≤Ld_i(s,v)\\le Ldi​(s,v)≤L，所以 di(s,v)≤di+1(s,v)d_i(s,v)\\le d_{i+1}(s,v)di​(s,v)≤di+1​(s,v) GiG_iGi​ 中不存在 (x,v)(x,v)(x,v) 这条边 如果 GiG_iGi​ 不存在这条边，但 Gi+1G_{i+1}Gi+1​ 存在这条边，这就说明 (v,x)∈Gi(v,x)\\in G_i(v,x)∈Gi​ EK 算法找到了一条增广路，s→v→x→ts\\to v\\to x\\to ts→v→x→t 此时，由于 EF 算法找到的总是最短路，而 di(s,x)≤L−1d_i(s,x)\\le L-1di​(s,x)≤L−1 且经过 (v,x)(v,x)(v,x)，因此我们可以推导出 di(s,v)=di(s,x)−1≤L−2 d_i(s,v)=d_i(s,x)-1\\le L-2 di​(s,v)=di​(s,x)−1≤L−2所以 di(s,v)≤di+1(s,v)d_i(s,v)\\le d_{i+1}(s,v)di​(s,v)≤di+1​(s,v) 便自动成立了 Critical Edge Lemma"},{"title":"网络流：Ford-Fulkerson 增广路算法","path":"/wiki/algo/ford-fulkerson.html","content":"Ford Fulkerson 算法 对于边 (u,v)(u,v)(u,v)，我们定义 Residual Capacity cf(u,v)=c(u,v)−f(u,v)c_f(u,v)=c(u,v)-f(u,v)cf​(u,v)=c(u,v)−f(u,v)。把所有剩余容量 &gt;0\\gt 0&gt;0 的边构成的子图定义为 Residual Graph GfG_fGf​。 Residual Graph 能够 work 的核心在于对 Backward Edge 的理解。Forward Edge 上的增广和 Backward Edge 上的增广可以抵消。 退流 Ford-Fulkerson 增广算法的时间复杂度是 O(nmf)O(nmf)O(nmf) 的，受容量最大的边的影响。 正确性证明"},{"title":"图论、网络流：最小割树 (Gomory-Hu Tree)","path":"/wiki/algo/gomory-hu-tree.html","content":"Gomory-Hu Tree 以下分析约定： 符号 含义 valSval_SvalS​ 令 SSS 是边集，那么 c(S)c(S)c(S) 就是其边权和 cutu,v={U,V−U}cut_{u,v}=\\{U,V-U\\}cutu,v​={U,V−U} 分割 u,vu,vu,v 的最小割，其中 u∈U,v∈V−Uu\\in U, v\\in V-Uu∈U,v∈V−U edgeUedge_UedgeU​ 对于一个割 U,V−UU,V-UU,V−U，其为割下的所有边，即 {(u,v):u∈U,v∈V−U}\\{(u,v):u\\in U,v\\in V-U\\}{(u,v):u∈U,v∈V−U} mincutu,vmincut_{u,v}mincutu,v​ (u,v)(u,v)(u,v) 的最小割（权值最小） minvalu,vminval_{u,v}minvalu,v​ =val(mincut(u,v))=val(mincut(u,v))=val(mincut(u,v)) 最小割树 T=(V,ET)T=(V,E_T)T=(V,ET​) 是这样一种树，对于所有的边 (s,t)∈ET(s,t)\\in E_T(s,t)∈ET​，从树上去掉这两条边之后剩下的两个连通块 S,TS,TS,T，恰好就是 s,ts,ts,t 的最小割 mincuts,tmincut_{s,t}mincuts,t​ 代码实现 Code 1// pass 例题"},{"title":"贪心算法","path":"/wiki/algo/greedy.html","content":"如何证明贪心算法的正确性？ 证明最佳的 solution 可以通过贪心算法在不增加 cost 的情况下求出来 证明每一步选择时，贪心算法的答案都不劣于其他算法，或者都是最优的 贪心模型 任务规划"},{"title":"区间 DP","path":"/wiki/algo/interval-dp.html","content":"区间 DP 常见建模技巧 将区间左右端点显式表现在 dp 状态定义里 例如说 dp[l][r]dp[l][r]dp[l][r] 表示区间 [l,r][l,r][l,r] 内的某某状态，且通常需要小区间拼接成大区间。为了保证正确性，这种转移通常先枚举区间长度，然后再枚举左右端点。 dp[l,r]←F( [l,a1],[a1,a2],…[am,r] ),l≤a1≤a2⋯≤am≤r dp[l,r]\\gets F\\Big(\\ [l,a_1],[a_1,a_2],\\dots[a_m,r] \\ \\Big),l\\le a_1\\le a_2\\dots\\le a_m\\le r dp[l,r]←F( [l,a1​],[a1​,a2​],…[am​,r] ),l≤a1​≤a2​⋯≤am​≤r有的时候，也会省略掉一个端点，只保留 lll (or rrr)。这种形式的 DP 通常是区间的特例，即 dp[i]dp[i]dp[i] 代表 [i,n][i,n][i,n] 后缀或者 [1,i][1,i][1,i] 前缀。状态转移差不多就是 dp[i]←dp[j]+f( [i,j) ) dp[i]\\gets dp[j]+f\\Big(\\ [i,j)\\ \\Big) dp[i]←dp[j]+f( [i,j) )"},{"title":"Manacher","path":"/wiki/algo/manacher.html","content":"Manacher 算法 Manacher 推广 如果我们的 pattern 拥有如下的一些性质，那么我们就可以利用 Manacher 进行加速： 具有类似回文的对称性。如果维护的回文 Box 为 [l,r][l,r][l,r]，那么这种对称性使得 R[i]R[i]R[i] 至少 ≥R[l+r−i]\\ge R[l+r-i]≥R[l+r−i]. 外推性：如果 s[l…r]s[l\\dots r]s[l…r] 满足性质，那么 s[l+1…r−1]s[l+1\\dots r-1]s[l+1…r−1] 也应该满足性质 例题 P3501 [POI 2010] ANT-Antisymmetry 题目所描述的 pattern 符合外推性：一个合法的 pattern 必须有 s[0]≠s[−1]s[0] e s[-1]s[0]=s[−1], 去掉之后的子串也必然满足&quot;反对称&quot;. 而且也具有对称性。于是可以使用 Manacher 算法，而且反对称的串长必为偶数，我们在数字中间 pad #，这样就可以向 Manacher 那样了。时间复杂度 O(n)O(n)O(n) Code 12345678910111213141516171819202122232425262728293031323334353637383940414243#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;vector&gt;int main() &#123; int n; std::cin &gt;&gt; n; std::string s; std::cin &gt;&gt; s; std::string T = &quot;.&quot;; for (auto c : s) T += c, T += &quot;.&quot;; int L = T.length(); std::vector&lt;int&gt; R(L + 1, 0); auto check = [&amp;](int p1, int p2) &#123; if (T[p1] == &#x27;.&#x27; &amp;&amp; T[p2] == &#x27;.&#x27;) return true; else if (T[p1] == &#x27;1&#x27; &amp;&amp; T[p2] == &#x27;0&#x27;) return true; else if (T[p1] == &#x27;0&#x27; &amp;&amp; T[p2] == &#x27;1&#x27;) return true; else return false; &#125;; int C = 0, r = 0; long long ans = 0; for (int i = 0; i &lt; L; i += 2) &#123; int reflect = 2 * C - i; int k; if (i &lt;= C + r) k = std::min(R[reflect], C + r - i); else k = 0; while (i - k &gt;= 0 &amp;&amp; i + k &lt; L &amp;&amp; check(i - k, i + k)) k++; R[i] = k - 1; if (i + R[i] &gt; C + r) &#123; C = i; r = R[i]; &#125; ans += R[i] / 2; &#125; std::cout &lt;&lt; ans &lt;&lt; std::endl;&#125; .typst-text { pointer-events: bounding-box; } .tsel span, .tsel { left: 0; position: fixed; text-align: justify; white-space: nowrap; width: 100%; height: 100%; text-align-last: justify; color: transparent; white-space: pre; } .tsel span::-moz-selection, .tsel::-moz-selection { color: transparent; background: #7db9dea0; } .tsel span::selection, .tsel::selection { color: transparent; background: #7db9dea0; } .pseudo-link { fill: transparent; cursor: pointer; pointer-events: all; } svg { fill: none; } .outline_glyph path, path.outline_glyph { fill: var(--glyph_fill); stroke: var(--glyph_stroke); } .outline_glyph path, path.outline_glyph { transition: 0.2s fill stroke; } .hover .typst-text { --glyph_fill: #66bab7; --glyph_stroke: #66bab7; } .typst-jump-ripple, .typst-debug-react-ripple { width: 0; height: 0; background-color: transparent; position: absolute; border-radius: 50%; } .typst-jump-ripple { border: 1px solid #66bab7; } .typst-debug-react-ripple { border: 1px solid #cb1b45; } @keyframes typst-jump-ripple-effect { to { width: 10vw; height: 10vw; opacity: 0.01; margin: -5vw; } } @keyframes typst-debug-react-ripple-effect { to { width: 3vw; height: 3vw; opacity: 0.01; margin: -1.5vw; } } Let 𝑎, 𝑏, and 𝑐 be the side lengths of right-angled triangle. Then, we know that:𝑎2+𝑏2=𝑐2Prove by induction:∑𝑛𝑘=1𝑘=𝑛(𝑛+1)2 Man! What can I say."},{"title":"网络流模型","path":"/wiki/algo/network-flow-models.html","content":"二分图匹配模型"},{"title":"网络流：最大流、最小割","path":"/wiki/algo/network-flow.html","content":"Flow Network 网络流图 G=(V,E,c)G=(V,E,c)G=(V,E,c) 是一张有向图，其中每一条有向边 e=(u,v)e=(u,v)e=(u,v) 有容量 (capacity) c(u,v)≥0c(u,v)\\ge 0c(u,v)≥0. 除此之外，GGG 中还有两个特殊节点 source sss 和 sink ttt. Flow 在此基础上，我们定义流 (Flow). GGG 上的流 fff 给每一条边 e=(u,v)e=(u,v)e=(u,v) 都赋上一个实数 f(u,v)f(u,v)f(u,v) 且满足： 每一条边的流量都不会超过其容量 capacity.f(u,v)≤c(u,v)f(u,v)\\le c(u,v)f(u,v)≤c(u,v) 除了源点与汇点，其余每一点都满足：流入的流量和流出的流量相等。∀v∈V−{s,t},∑(x,v)∈Ef(x,v)=∑(v,y)∈Ef(v,y)\\forall v\\in V-\\{s,t\\}, \\sum_{(x,v)\\in E} f(x,v)=\\sum_{(v,y)\\in E} f(v,y)∀v∈V−{s,t},(x,v)∈E∑​f(x,v)=(v,y)∈E∑​f(v,y) 最大流求解算法 Ford-Fulkerson 算法 Cut 什么是割？ 图的一个“割” (Cut) 是指将图分成两个点集 A,BA,BA,B 且源点 s∈As\\in As∈A，汇点 t∈Bt\\in Bt∈B. 定义 Capacity of Cut cap(A,B)=∑e out of Ac(e)cap(A,B)=\\sum_{e\\text{ out of }A}c(e)cap(A,B)=∑e out of A​c(e) Flow Value Lemma 令 fff 为 GGG 上任意的流，(A,B)(A,B)(A,B) 为 GGG 上任意的割（s∈A,t∈Bs\\in A,t\\in Bs∈A,t∈B），则必有 value(f)=∑e out of Af(e)−∑e into Af(e) \\text{value}(f)=\\sum_{e \\text{ out of }A}f(e)-\\sum_{e\\text{ into }A} f(e) value(f)=e out of A∑​f(e)−e into A∑​f(e) 证明 考虑 AAA 中的每一个节点，除了源点 sss 以外，其余所有点都满足 outflow(v)=inflow(v)\\text{outflow}(v)=\\text{inflow}(v)outflow(v)=inflow(v)，而 sss 的 inflow(s)=0\\text{inflow}(s)=0inflow(s)=0，所以 value(f)=∑outflow(s)=∑v∈Aoutflow(v)−inflow(v) \\mathrm{value}(f)=\\sum \\mathrm{outflow}(s)=\\sum_{v\\in A} \\mathrm{outflow}(v)-\\mathrm{inflow}(v) value(f)=∑outflow(s)=v∈A∑​outflow(v)−inflow(v)我们再来考察 ∑v∈Aoutflow(v)\\sum_{v\\in A}\\mathrm{outflow}(v)∑v∈A​outflow(v)，检查所有边，可得 ∑v∈Aoutflow(v)=∑e inside Af(e)+∑e out of Af(e) \\sum_{v\\in A}\\mathrm{outflow}(v)=\\sum_{e\\text{ inside }A}f(e)+\\sum_{e\\text{ out of }A}f(e) v∈A∑​outflow(v)=e inside A∑​f(e)+e out of A∑​f(e)同理对 inflow 有 ∑v∈Ainflow(v)=∑e inside Af(e)+∑e into Af(e) \\sum_{v\\in A}\\mathrm{inflow}(v)=\\sum_{e\\text{ inside }A}f(e)+\\sum_{e\\text{ into }A}f(e) v∈A∑​inflow(v)=e inside A∑​f(e)+e into A∑​f(e)两式相减可得 value(f)=∑e out of Af(e)−∑e into Af(e) \\mathrm{value}(f)=\\sum_{e\\text{ out of }A}f(e)-\\sum_{e\\text{ into }A}f(e) value(f)=e out of A∑​f(e)−e into A∑​f(e) 由此也可以推得几个推论 Corollary 1 value(f)≤cap(A,B) \\mathrm{value}(f)\\le \\mathrm{cap}(A,B) value(f)≤cap(A,B) 证明 value(f)=∑e out of Af(e)−∑e into Af(e)≤∑e out of Af(e)≤∑e out of Acap(e)=cap(A,B) \\begin{aligned} \\mathrm{value}(f)&amp;=\\sum_{e\\text{ out of }A} f(e)-\\sum_{e\\text{ into }A} f(e)\\\\ &amp;\\le \\sum_{e\\text{ out of }A} f(e)\\\\ &amp;\\le\\sum_{e\\text{ out of }A} \\mathrm{cap}(e)\\\\ &amp;=\\mathrm{cap}(A,B) \\end{aligned} value(f)​=e out of A∑​f(e)−e into A∑​f(e)≤e out of A∑​f(e)≤e out of A∑​cap(e)=cap(A,B)​ Theorem 3 令 fff 为图上的流且使得 GfG_fGf​ 不存在增广路，那么存在一种 cut (A,B)(A,B)(A,B) 使得 value(f)=cap(A,B)\\mathrm{value}(f)=cap(A,B)value(f)=cap(A,B). 证明 既然 GfG_fGf​ 上已经不存在增广路，那么 GfG_fGf​ 天然的可以被划分为两个集合 A,BA,BA,B，其中 A={ v:s→v },B=V−AA=\\set{v:s\\to v},B=V-AA={v:s→v},B=V−A 这也就是说，原图 GGG 中，AAA 到 BBB 的有向边的 residual capacity 均为 000，根据 Flow Value Lemma，cut(A,B)\\mathrm{cut}(A,B)cut(A,B) 就是一种符合条件的割。 最大流最小割定理 Max Flow=Min Cut \\text{Max Flow}=\\text{Min Cut} Max Flow=Min Cut"},{"title":"【博弈论】Nim 游戏","path":"/wiki/algo/nim-game.html","content":"有向图游戏（博弈图） 博弈图是一张有向图，每一个节点表示游戏的状态（例如每个堆里石子的个数），有向边表示行动（取石子导致了状态的变化）。根据定义，博弈图是有向无环图 Nim Game Graph Nim 定理"},{"title":"NP 理论初探","path":"/wiki/algo/np-complete.html","content":"P 与 NP P: 存在多项式算法，可以解出一个 solution NP: 存在多项式算法，给定 solution 可以判定输入是否合法 NP-Complete: 所有 NP 问题都可以归约到 AAA，且 AAA 是 NP 问题，则 AAA 是 NP-Complete 问题 NP-Hard Polynomial-Time Reduce B≤pAB \\le_p AB≤p​A 或者 B→AB\\to AB→A，表示存在一个多项式算法 fff： 将 BBB 问题的输入 xxx 转化为 AAA 问题的输入 f(x)f(x)f(x)； xxx 是 BBB 问题的一组合法解，当且仅当 f(x)f(x)f(x) 是 AAA 问题的一组合法解。 NP 问题判定定理 111 若 B→AB\\to AB→A，且 AAA 是 P 问题，则 BBB 也是 P 问题。 【证明】 因为 AAA 问题内多项式时间 O(f(x))O(f(x))O(f(x)) 内可解，而又存在多项式算法 O(g(x))O(g(x))O(g(x)) 可以转化输入，则可以在 O(f(x)+g(x))O(f(x)+g(x))O(f(x)+g(x)) 的时间内解决 BBB. □\\square□ NP-Hard 优化问题 (Optimization Problem) NP Problem 是在寻找可行解，而其对应的优化问题则是在找最优解。 如果某个优化问题对应的判定问题是 NP Complete 的，则这个优化问题为 NP Hard 的。 考虑判定问题 XXX 和对应的优化问题 YYY，如果 XXX 是 NP Complete 问题 我们可以在多项式时间内解决 YYY 则我们可以在多项式时间内解决 XXX，从而 P=NPP=NPP=NP，那么 YYY 就是 NP-Hard 的。"},{"title":"经典 NP-Complete 问题与证明","path":"/wiki/algo/npc-problems.html","content":"SAT 形式：AND of OR clauses, Conjunctive Normal Form. 一个 SAT 是多个 clause 取 AND 的结果，每一个 clause 是多个变量取 OR 的结果。 (x1∨¬x2)∧(¬x1∨x3∨x4)∧(x2∨¬x3​) (x_1\\lor \\lnot x_2)\\land (\\lnot x_1\\lor x_3\\lor x_4)\\land (x_2\\lor \\lnot x_3​) (x1​∨¬x2​)∧(¬x1​∨x3​∨x4​)∧(x2​∨¬x3​​) from SAT to 3SAT 3SAT: 在 SAT 的基础上，满足每一个 clause 只包含三个变量。 Clique 团 Clique Problem 是指: 给定一张图 $G=(V,E)$ 和一个整数 $k$，检查是否存在 $|V'|=k$ 的 clique. 证明 首先，clique problem 是 NP 问题。这个比较好证明。 其次，我们尝试把 3SAT 归约到 Clique. 对于每一个 clause ci=x1∨x2∨x3c_i=x_1\\lor x_2\\lor x_3ci​=x1​∨x2​∨x3​，建立三个节点 ni,1,ni,2,ni,3n_{i,1},n_{i,2},n_{i,3}ni,1​,ni,2​,ni,3​. 对于图中不属于同一个 clause 的两个节点 xi,xjx_i, x_jxi​,xj​，只要 xi≠¬xjx_i e \\lnot x_jxi​=¬xj​，就建立一条边。 我们令 k=mk=mk=m，检查图里是否存在大小为 kkk 的 clique. Subset Sum 给定 nnn 个元素 {a1,a2,…an}\\{ a_1,a_2,\\dots a_n \\}{a1​,a2​,…an​} 和一个数 TTT，是否存在能从这 nnn 个元素里找到一个子集，使得其和为 TTT？ 证明 我们证明 3SAT∝pSubset Sum\\text{3SAT} \\propto_p \\text{Subset Sum}3SAT∝p​Subset Sum 考虑 3SAT 有 nnn 个变量和 mmm 个 clause，对于每一个 3SAT 变量 xix_ixi​，在 subset sum 里创建两个变量 ti,fit_i,f_iti​,fi​ 我们令 set 里的变量均有 n+mn+mn+m 位，前 nnn 位记为变量部分，后 mmm 位记为子句部分。 tit_iti​ 变量部分第 iii 位设置为 111，子句部分若 clausej\\text{clause}_jclausej​ 包含 xix_ixi​ 则子句部分的第 jjj 位设置为 111 fif_ifi​ 变量部分第 iii 位设置为 111，子句部分若 clausej\\text{clause}_jclausej​ 包含 ¬xi\\lnot x_i¬xi​ 则子句部分的第 jjj 位设置为 111 同时，对每一个子句 clausei\\text{clause}_iclausei​，创建变量 cic_ici​，其变量部分为全 000，子句部分仅第 iii 位为 111. 考虑如何构造 TTT，令 TTT 的变量部分的每一位都是 111，子句部分的每一位都是 333. 3SAT ⟹ \\implies⟹ Subset Sum 如果 3SAT 存在一种合法的方案 SSS，对于 xi∈Sx_i\\in Sxi​∈S，如果 xi=truex_i=\\texttt{true}xi​=true，则往 subset 里添加 tit_iti​，否则添加 fif_ifi​. 又因为对每一个子句而言，至少有一个 xix_ixi​ 或者 ¬xi\\lnot x_i¬xi​ 为真，因此最多选两个 cjc_jcj​ 一定可以让 TTT 子句部分的第 jjj 位为 333. 3SAT ⟸ \\impliedby⟸ Subset Sum 考虑某个子集的元素： 如果包含 tit_iti​，则令 xi=truex_i=\\texttt{true}xi​=true 如果包含 fif_ifi​，则令 xi=falsex_i=\\texttt{false}xi​=false 因此对于每一个 clausej\\text{clause}_jclausej​ 而言，因为 cjc_jcj​ 最多被选 222 次，而 TTT 对应位置为 333，所有至少有一个 xi∈clausej=truex_i\\in \\text{clause}_j=\\texttt{true}xi​∈clausej​=true，即 clause 为真，从而 3SAT 满足。 Equal Sum Partition 给定数集 {a1,a2,…,an}\\{a_1,a_2,\\dots,a_n\\}{a1​,a2​,…,an​}，能否选出子集，使得子集的和恰好为总和的一半？ 证明 我们证明 Subset Sum∝pEqual Sum Partition\\text{Subset Sum}\\propto_p \\text{Equal Sum Partition}Subset Sum∝p​Equal Sum Partition 令 s=∑ais=\\sum a_is=∑ai​， 如果 t=s2t=\\frac s2t=2s​，那么问题不变 如果 t&gt;s2t\\gt \\frac s2t&gt;2s​，那么添加一个数 an+1=2t−sa_{n+1}=2t-san+1​=2t−s 否则 t&lt;s2t\\lt \\frac s2t&lt;2s​，那么添加一个数 an+1=s−2ta_{n+1}=s-2tan+1​=s−2t General Knapsack 背包问题 存在 nnn 个物品，每一个都有重量 wiw_iwi​ 和价值 viv_ivi​。给出重量限制 WWW 和价值目标 VVV，能否选出一些物品 SSS，使得 ∑i∈Swi≤W\\sum_{i\\in S} w_i\\le W∑i∈S​wi​≤W 并且 ∑i∈Svi≥V\\sum_{i\\in S} v_i\\ge V∑i∈S​vi​≥V. 证明 思路：我们证明 Subset Sum∝pKnapsack\\text{Subset Sum}\\propto_p \\text{Knapsack}Subset Sum∝p​Knapsack 【归约】令物品 wi=vi=aiw_i=v_i=a_iwi​=vi​=ai​，且 W=V=TW=V=TW=V=T. Hamiltonian Path 哈密顿路径 有向图下的哈密顿路径 证明 我们证明 3SAT∝pH-Cycle\\text{3SAT}\\propto_p \\text{H-Cycle}3SAT∝p​H-Cycle 【归约】 令 3SAT 有 nnn 个变量和 mmm 个子句。对于一个变量 xix_ixi​： 让其对应一行节点 rowirow_irowi​，包含 3m+33m+33m+3 个节点，这一行的相邻节点之间连双向边 在这一行节点中，从第二个节点开始，每三个节点代表一个 clause cjc_jcj​，颜色顺序为黄、绿、绿 额外有一个黄色节点，分别指向这一行的开头结尾两个节点 规定 xi=truex_i=\\texttt{true}xi​=true 则往左走，否则往右走 一行的开头结尾两个节点又分别指向 xi+1x_{i+1}xi+1​ 的额外黄色节点 对应 $x_i$ 对于每一个子句 cjc_jcj​，找到其所包含的三个变量的行 rowirow_irowi​ 中，对应 cjc_jcj​ 的两个绿色节点 rowi,1,rowi,2row_{i,1},row_{i,2}rowi,1​,rowi,2​，分别连不同方向的有向边。 如果是 xix_ixi​，则连边方向为：靠左的绿色节点 对应 $c_j$ 3SAT ⟹ \\implies⟹ H-Path 如果一个合法的 3SAT 方案存在 最长路径 旅行商问题"},{"title":"网络流：预流推进算法","path":"/wiki/algo/push-relabel.html","content":"代码参考 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138template &lt;typename T&gt;class FlowGraph &#123; public: struct Edge &#123; std::size_t to; T cap; // flow, capacity &#125;; std::vector&lt;int&gt; dist; std::vector&lt;std::size_t&gt; cur; std::vector&lt;std::vector&lt;std::size_t&gt;&gt; adj; std::vector&lt;Edge&gt; edges; std::size_t s, t; std::size_t vtot, etot; // ! ===== functionality ===== FlowGraph() : vtot(0), etot(0) &#123;&#125; void init(std::size_t s, std::size_t t, std::size_t vtot) &#123; this-&gt;s = s, this-&gt;t = t, this-&gt;vtot = vtot; adj.resize(vtot), dist.resize(vtot), cur.resize(vtot); &#125; void add(std::size_t u, std::size_t v, T f) &#123; adj.at(u).push_back(edges.size()); edges.emplace_back(v, f); adj.at(v).push_back(edges.size()); edges.emplace_back(u, 0); &#125;&#125;;template &lt;typename T&gt;class PushRelabel : public FlowGraph&lt;T&gt; &#123; public: std::vector&lt;T&gt; height; std::vector&lt;T&gt; excess; std::vector&lt;std::size_t&gt; gap; std::vector&lt;std::vector&lt;std::size_t&gt;&gt; bucket; T level&#123;0&#125;; static constexpr T inf = std::numeric_limits&lt;T&gt;::max(); bool push(std::size_t u) &#123; bool init = u == this-&gt;s; for (auto e : this-&gt;adj.at(u)) &#123; auto [v, cap] = this-&gt;edges.at(e); if (cap == 0 or this-&gt;height.at(v) == inf) continue; if (!init and this-&gt;height.at(u) != this-&gt;height.at(v) + 1) continue; T k = init ? cap : std::min(cap, this-&gt;excess.at(u)); if (v != this-&gt;s and v != this-&gt;t and this-&gt;excess.at(v) == 0) &#123; this-&gt;bucket.at(this-&gt;height.at(v)).push_back(v); this-&gt;level = std::max(this-&gt;level, this-&gt;height.at(v)); &#125; // push this-&gt;excess.at(u) -= k; this-&gt;excess.at(v) += k; this-&gt;edges.at(e).cap -= k; this-&gt;edges.at(e ^ 1).cap += k; if (this-&gt;excess.at(u) == 0) return false; // finish pushing &#125; return true; &#125; void relabel(std::size_t u) &#123; this-&gt;height.at(u) = inf; for (auto e : this-&gt;adj.at(u)) &#123; auto [v, cap] = this-&gt;edges.at(e); if (cap &gt; 0) this-&gt;height.at(u) = std::min(this-&gt;height.at(u), this-&gt;height.at(v)); &#125; this-&gt;height.at(u)++; if (this-&gt;height.at(u) &lt; static_cast&lt;T&gt;(this-&gt;vtot)) &#123; this-&gt;bucket.at(this-&gt;height.at(u)).push_back(u); level = std::max(level, this-&gt;height.at(u)); ++this-&gt;gap.at(this-&gt;height.at(u)); &#125; &#125; bool bfs_init() &#123; this-&gt;height.assign(this-&gt;vtot, inf); std::queue&lt;std::size_t&gt; q; q.push(this-&gt;t); this-&gt;height.at(this-&gt;t) = 0; while (!q.empty()) &#123; auto u = q.front(); q.pop(); for (auto e : this-&gt;adj.at(u)) &#123; auto [v, cap] = this-&gt;edges.at(e); auto [rv, rcap] = this-&gt;edges.at(e ^ 1); if (rcap &gt; 0 and this-&gt;height.at(v) &gt; this-&gt;height.at(u) + 1) &#123; this-&gt;height.at(v) = this-&gt;height.at(u) + 1; q.push(v); &#125; &#125; &#125; return this-&gt;height.at(this-&gt;s) != inf; &#125; std::size_t select() &#123; while (this-&gt;level &gt; -1 and this-&gt;bucket.at(this-&gt;level).size() == 0) this-&gt;level--; return this-&gt;level == -1 ? 114514 : this-&gt;bucket.at(this-&gt;level).back(); &#125; public: void init(std::size_t s, std::size_t t, std::size_t n) &#123; FlowGraph&lt;T&gt;::init(s, t, n); this-&gt;height.assign(n, inf); this-&gt;excess.assign(n, 0); this-&gt;gap.assign(n + 1, 0); this-&gt;bucket.assign(n + 1, &#123;&#125;); this-&gt;level = 0; &#125; T max_flow() &#123; if (not this-&gt;bfs_init()) return 0; this-&gt;gap.assign(this-&gt;vtot, 0); for (std::size_t i = 0; i &lt; this-&gt;vtot; i++) if (this-&gt;height.at(i) != inf) this-&gt;gap.at(this-&gt;height.at(i))++; this-&gt;height.at(this-&gt;s) = this-&gt;vtot; this-&gt;push(this-&gt;s); for (std::size_t u = select(); u != 114514; u = select()) &#123; this-&gt;bucket.at(this-&gt;level).pop_back(); if (this-&gt;push(u)) &#123; if (not --this-&gt;gap.at(this-&gt;height.at(u))) &#123; for (std::size_t i = 0; i &lt; this-&gt;vtot; i++) &#123; if (i == this-&gt;s) continue; if (this-&gt;height.at(i) &gt;= static_cast&lt;T&gt;(this-&gt;vtot + 1)) continue; if (this-&gt;height.at(i) &lt;= this-&gt;height.at(u)) continue; this-&gt;height.at(i) = static_cast&lt;T&gt;(this-&gt;vtot + 1); &#125; &#125; this-&gt;relabel(u); &#125; &#125; return this-&gt;excess.at(this-&gt;t); &#125;&#125;;"},{"title":"线段树分治","path":"/wiki/algo/segtree-decomp.html","content":"线段树分治"},{"title":"2023 ICPC World Final Luxor","path":"/wiki/algo_contests/2023-icpc-wf-luxor.html","content":"A. D. Carl’s Vacation 可以联想到将军饮马模型。我们把三维的金字塔侧面展平到二维上，那么答案的最短路径就可以表达为 tip1→foot1→foot2→top2 tip_1\\to foot_1\\to foot_2\\to top_2 tip1​→foot1​→foot2​→top2​于是，我们可以枚举每个金字塔的四个侧面，共 4×4=164\\times 4=164×4=16 种情况，在每种情况里求最短路径即可。 接下来考虑如何求这个最短路径。我们肯定需要找到两个 footfootfoot 的坐标。考虑用向量的模长表示线段长度，以及将两个 footfootfoot 的定比分点作为变量的话，那么路径长度 f(k1,k2)f(k_1,k_2)f(k1​,k2​) 分别关于 k1,k2k_1,k_2k1​,k2​ 是单峰函数，所以可以三分套三分。 小细节：浮点数三分或者二分的话，可以指定二分次数，而非 l,rl,rl,r 相差 eps\\texttt{eps}eps，后者容易出现浮点误差。 Code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &quot;headers/geometry.hpp&quot;#include &lt;iostream&gt;using namespace Geo2D;using namespace std;Point p1[4], p2[4], tip1, tip2;Decimal h1, h2, d1, d2, len1, len2;Decimal phi = 0.618, cphi = -phi + 1;int main() &#123; cin &gt;&gt; p1[0] &gt;&gt; p1[1] &gt;&gt; h1; cin &gt;&gt; p2[0] &gt;&gt; p2[1] &gt;&gt; h2; for (int i = 2; i &lt; 4; i++) &#123; p1[i] = p1[i - 1] + (p1[i - 1] - p1[i - 2]).Perp(); p2[i] = p2[i - 1] + (p2[i - 1] - p2[i - 2]).Perp(); &#125; tip1 = (p1[0] + p1[2]) / 2; tip2 = (p2[0] + p2[2]) / 2; len1 = p1[0].Distance(p1[1]); len2 = p2[0].Distance(p2[1]); d1 = (len1.sqr() / 4 + h1.sqr()).sqrt(); d2 = (len2.sqr() / 4 + h2.sqr()).sqrt(); Decimal ans = 2e18; for (int i = 0; i &lt; 4; i++) &#123; Vector v1 = p1[(i + 1) % 4] - p1[i]; Point midp1 = (p1[i] + p1[(i + 1) % 4]) / 2; Point pt1 = midp1 + v1.Normal() * d1; for (int j = 0; j &lt; 4; j++) &#123; Vector v2 = p2[(j + 1) % 4] - p2[j]; Point midp2 = (p2[j] + p2[(j + 1) % 4]) / 2; Point pt2 = midp2 + v2.Normal() * d2; Decimal precent_l1 = 0; Decimal precent_r1 = 1; auto findfoot1 = [&amp;](Decimal precent_mid1) -&gt; Decimal &#123; Point foot1 = p1[i] + v1 * precent_mid1; Decimal precent_l2 = 0; Decimal precent_r2 = 1; auto findfoot2 = [&amp;](Decimal precent_mid2) -&gt; Decimal &#123; Point foot2 = p2[j] + v2 * precent_mid2; return foot1.Distance(foot2) + foot1.Distance(pt1) + foot2.Distance(pt2); &#125;; for (int __ = 1; __ &lt;= 100; __++) &#123; Decimal l2 = precent_l2 * phi + precent_r2 * cphi; Decimal r2 = precent_l2 * cphi + precent_r2 * phi; if (findfoot2(l2) &gt; findfoot2(r2)) precent_l2 = l2; else precent_r2 = r2; &#125; return findfoot2(precent_l2); &#125;; for (int _ = 1; _ &lt;= 100; _++) &#123; Decimal l1 = precent_l1 * phi + precent_r1 * cphi; Decimal r1 = precent_l1 * cphi + precent_r1 * phi; if (findfoot1(l1) &gt; findfoot1(r1)) precent_l1 = l1; else precent_r1 = r1; &#125; ans = min(ans, findfoot1(precent_l1)); &#125; &#125; std::cout &lt;&lt; ans &lt;&lt; &#x27; &#x27;;&#125;"},{"title":"2024 ICPC EC 第二场网络预选赛","path":"/wiki/algo_contests/2024-icpc-ec-online-2.html","content":"这一场其实是队友带飞的，但是还是来补一下题。 A. Gambling on Choosing Regionals 最核心的点就是，对于某只队伍 tit_iti​ 最坏情况下其他学校都派最强的队伍来和这支队伍竞争，那么可想而知，如果学校越多，那么很有可能其他学校的强队全都来了，那么自己的机会就越来越小了，所以核心的点就是一定选择最小的赛站。 因为 tit_iti​ 总是有优先权，因此对于 tit_iti​ 来说，在他之上的队伍由两部分组成（假设最小的赛站，每个学校可以出 ccc 支队伍） 其他学校的所有强队，数量 ≤c\\le c≤c 本学校的强队，数量 ≤c−1\\le c-1≤c−1。因为包含 tit_iti​ 因此，我们直接对每只队伍的实力排序，先每个学校取前 ccc 个，然后如果某个队伍不在其学校的前 ccc 名，那么踢掉最后一名，把这支队伍换上来。总时间复杂度 O(nlog⁡n)O(n\\log n)O(nlogn). G. Game 首先我们要看出来平局其实没有用（因为不会产生任何影响）。我们直接令 p1=a0a0+a1,p2=a1a0+a1p_1=\\frac{a_0}{a_0+a_1},p_2=\\frac{a_1}{a_0+a_1}p1​=a0​+a1​a0​​,p2​=a0​+a1​a1​​. 然后分别考虑两人的筹码数和获胜条件，设 Alice 有 aaa 个筹码，Bob 有 bbb 个 如果 a&gt;=ba&gt;=ba&gt;=b，令 a=kb+r,r∈[0,b)a=kb+r,r\\in[0,b)a=kb+r,r∈[0,b) 此时，Alice 只要在这 kkk 次里赢一次，游戏就结束了。 这里的分布是“有 p1p_1p1​ 概率获胜， continue until first win”，其获胜概率为 ∑i=0kp1p2i=1−p2k1−p2×p1\\sum_{i=0}^k p_1 p_2^i=\\frac{1-p_2^k}{1-p_2}\\times p_1∑i=0k​p1​p2i​=1−p2​1−p2k​​×p1​ 然而，如果全输了，那么 r&lt;br\\lt br&lt;b 会进入 2) 分支。综合一下，即为 win(a,b)=1−p2k1−p2p1+p2k×win(r,b)win(a,b)=\\frac{1-p_2^k}{1-p_2}p_1+p_2^k\\times win(r, b)win(a,b)=1−p2​1−p2k​​p1​+p2k​×win(r,b) 如果 a&lt;ba&lt;ba&lt;b，令 b=ka+r,r∈[0,a)b=ka+r,r\\in[0, a)b=ka+r,r∈[0,a) 此时局面刚好反过来，Alice 要想获胜，必须保证这 kkk 次不能输（否则游戏结束） 当这 kkk 全赢了之后，局面回到 1)。因此 win(a,b)=p1k×win(a,r)win(a,b)=p_1^k\\times win(a, r)win(a,b)=p1k​×win(a,r) 而回顾 win(x,y)win(x,y)win(x,y) 的参数变化，这不就是辗转相除法吗！因此整体时间复杂度为 O(log⁡n)O(\\log n)O(logn)，考虑到逆元、快速幂的计算（p1,p2,kp_1,p_2,kp1​,p2​,k 与 nnn 差不多量级），其实差不多是 O(log⁡2n)O(\\log^2n)O(log2n) Code 注意最好用 int 做逆元相关的题，速度会比 uint64_t 之类的快很多。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950#include &lt;iostream&gt;constexpr int M = 998244353;inline int smul(int a, int b) &#123; return (1ll * a * b &lt; M ? a * b : 1ll * a * b % M); &#125;inline int sadd(int a, int b) &#123; return (a + b &gt;= M ? a + b - M : a + b); &#125;int fpow(int base, int power = M - 2) &#123; int res = 1; for (; power; power &gt;&gt;= 1) &#123; if (power &amp; 1) res = smul(res, base); base = smul(base, base); &#125; return res;&#125;int answer(int a, int b, int win, int lose) &#123; if (a == 0 || b == 0) return a != 0; if (a &gt;= b) &#123; int k = a / b, r = a % b; int c = fpow(lose, k); int numerator = sadd(1, M - fpow(lose, k)); // 1 - lose^k (mod M) int denominator = sadd(1, M - lose); // 1 - lose (mod M) int tmp = smul(win, smul(numerator, fpow(denominator))); // Using modular inverse return sadd(smul(c, answer(r, b, win, lose)), tmp); &#125; else &#123; int k = b / a, r = b % a; int c = fpow(win, k); return smul(c, answer(a, r, win, lose)); &#125;&#125;void run() &#123; int a, b; int p1, p2, P; std::cin &gt;&gt; a &gt;&gt; b &gt;&gt; p1 &gt;&gt; p2 &gt;&gt; P; P = p1 + p2; p1 = smul(p1, fpow(P)), p2 = smul(p2, fpow(P)); std::cout &lt;&lt; answer(a, b, p1, p2) &lt;&lt; &#x27; &#x27;;&#125;int main() &#123; std::cin.tie(0)-&gt;sync_with_stdio(0); int T; std::cin &gt;&gt; T; while (T--) run();&#125; L. 502 Bad Gateway 当当前时刻为 1,2,3,…1,2,3,\\dots1,2,3,… 的时候，按按钮重置时间反而得不偿失；相反，如果当前时刻比较大，那么重置时间更有可能缩短用时。 于是基于这一个观察，我们可以猜测：存在一个阈值 ccc，当时刻 &lt;c\\lt c&lt;c 我们就慢慢等；反之我们就一直按按钮，直到 &lt;c\\lt c&lt;c 为止。 根据我们的猜测，每摁一次按钮，重置到 &lt;c\\lt c&lt;c 的概率为 p=ctp=\\frac{c}{t}p=tc​. “不断按成功概率为 ppp 的按钮，直到第一次成功停止”，诶，这不就是几何分布吗？"},{"title":"2024 ICPC 区域赛（西欧北欧 NWERC）","path":"/wiki/algo_contests/2024-icpc-nwerc.html","content":"A. Alphabetical Aristocrats very ez."},{"title":"2025 杭电多校春季赛 4","path":"/wiki/algo_contests/2025-hdu-spring-04.html","content":"战斗爽 根据题意我们可以直接模拟： 我们用 priority_queue 维护所有敌人的攻击力 atk 以及尚且存活的敌人的血量 alive，用数组 dead 记录敌人是否活着 直接在 while 循环里模拟每一轮： 从 alive 里根据规则取出一个敌人，结算伤害，更新其存活状态 接下来结算收到的伤害。从 atk 堆顶取出攻击力最大的，如果堆顶的敌人已经死亡，则弹出取下一个元素，直到堆顶的敌人是存活的。 Code 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;algorithm&gt;#include &lt;iostream&gt;#include &lt;queue&gt;#include &lt;tuple&gt;#include &lt;vector&gt;using i64 = long long;using M = std::tuple&lt;int, int, int, int&gt;; // hp, atk, id, timesusing N = std::tuple&lt;int, int&gt;; // atk, idvoid run() &#123; int n, u, k, hq; std::cin &gt;&gt; n &gt;&gt; u &gt;&gt; k &gt;&gt; hq; std::priority_queue&lt;M, std::vector&lt;M&gt;, std::greater&lt;M&gt;&gt; pq; std::priority_queue&lt;N&gt; atks; i64 atk = 0; for (i64 i = 0, a, b; i &lt; n; i++) &#123; std::cin &gt;&gt; a &gt;&gt; b; pq.push(&#123;b, a, i, 0&#125;); atks.push(&#123;a, i&#125;); atk = std::max(atk, a); &#125; int cnt = 0; std::vector&lt;int&gt; dead(n, false); while (!pq.empty() and hq &gt;= 0) &#123; auto [hp, a, id, t] = pq.top(); pq.pop(); // attack it if (t &lt; k) &#123; if (t == 0) hp -= u; else hp -= u / 2; t++; if (hp &lt;= 0) cnt++, dead.at(id) = true; else pq.push(&#123;hp, a, id, t&#125;); &#125; while (!atks.empty()) &#123; if (dead.at(std::get&lt;1&gt;(atks.top()))) atks.pop(); else break; &#125; atk = std::get&lt;0&gt;(atks.top()); hq -= atk; &#125; std::cout &lt;&lt; cnt &lt;&lt; &#x27; &#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int T = 1; std::cin &gt;&gt; T; while (T--) run(); return 0;&#125; 持家 考虑打 aaa 折，减 bbb 元，原价 PPP 元，则有 (P−b)×a=Pa−ba&lt;Pa−b (P-b)\\times a=Pa-ba \\lt Pa-b (P−b)×a=Pa−ba&lt;Pa−b所以我们应该总是先用打折券，再用减价券。时间复杂度为排序的 O(nlog⁡n)O(n\\log n)O(nlogn) Code 123456789101112131415161718192021222324252627282930313233343536373839404142#include &lt;algorithm&gt;#include &lt;iomanip&gt;#include &lt;iostream&gt;#include &lt;vector&gt;using i64 = long long;void run() &#123; int P, n, k; std::cin &gt;&gt; P &gt;&gt; n &gt;&gt; k; std::vector&lt;double&gt; a, b; for (int i = 0, c, t; i &lt; n; i++) &#123; std::cin &gt;&gt; t &gt;&gt; c; if (t == 0) a.push_back(c * 1.0 / 10); else b.push_back(c); &#125; std::sort(a.begin(), a.end()), a.insert(a.begin(), 1); std::sort(b.begin(), b.end(), std::greater()), b.insert(b.begin(), 0); for (int i = 1; i &lt; a.size(); i++) a[i] *= a[i - 1]; for (int i = 1; i &lt; b.size(); i++) b[i] += b[i - 1]; double ans = P; for (int i = 0; i &lt;= k; i++) if (i &lt; a.size()) ans = std::min(ans, a[i] * P - b[std::min(k - i, int(b.size()) - 1)]); std::cout &lt;&lt; std::fixed &lt;&lt; std::setprecision(2) &lt;&lt; std::max(ans, 0.0) &lt;&lt; &#x27; &#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int T = 1; std::cin &gt;&gt; T; while (T--) run(); return 0;&#125;"},{"title":"2024 ICPC 区域赛：香港","path":"/wiki/algo_contests/2024-icpc-regional-hk.html","content":"E. Concave Hull 算法流程 先算一次凹包，把所有的点分成“在凸包上”和“不在凸包上”的点 SSS。 枚举 SSS 中的每一个点作为凹点 p0p_0p0​，然后对其他所有点 pip_ipi​ 计算出向量 vi=pip0→v_i=\\overrightarrow{p_ip_0}vi​=pi​p0​​ 并按极角排序。 极角排序完了之后，向量必定是 on, /, /, /, on, /, /, on, on, /, /, on ...... 这样排列（两个在凸包上的点 c1,c2c_1,c_2c1​,c2​ 中间夹着一些不在凸包上的点 djd_jdj​，记这些点的集合为 F={F0=c1,F1=d1,d2,…,Fm=dm,Fm+1=c2}F=\\{F_0=c_1,F_1=d_1,d_2,\\dots,F_m=d_m,F_{m+1}=c_2\\}F={F0​=c1​,F1​=d1​,d2​,…,Fm​=dm​,Fm+1​=c2​}）。我们尝试计算以 p0p_0p0​ 作为凹点，Fi,Fi+1F_i,F_{i+1}Fi​,Fi+1​ 作为优角的两边的凹包面积。 这里的话，如果跑暴力算法，时间复杂度会来到 O(n3)O(n^3)O(n3)。考虑到这个凹包的面积其实是凸包面积去掉一部分面积，我们可以利用这一点加速计算。 两个三角形 我们把凹包凹进去的部分分成左右两半凸壳（图中黄色和绿色部分），做两次 Andrew 凸包扫描算法（从左往右，然后从右往左）。例如 Andrew 算法从左往右扫描，只要扫描算法扫描经过这些点 FFF，那么我们就能算出由 c1→Fic_1\\to F_ic1​→Fi​ 这些点构成（且包括了 FiF_iFi​ 的）的左半凸壳的面积。同理也可以计算出右半凸壳的面积。因此以 p0p_0p0​ 为凹点、Fi,Fi+1F_i,F_{i+1}Fi​,Fi+1​ 为优角的凹包面积也就可以算出来了（大凸包面积，减掉这一个凹角对应的凸包上三角形的面积 ΔADG\\Delta ADGΔADG，再加上左右两个凸壳的面积） Code Code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177#include &lt;algorithm&gt;#include &lt;cassert&gt;#include &lt;cmath&gt;#include &lt;iostream&gt;#include &lt;ranges&gt;#include &lt;utility&gt;#include &lt;set&gt;#include &lt;vector&gt;using i64 = long long;constexpr i64 M = 1e9 + 7;struct pvec &#123; int x, y; friend std::istream &amp;operator&gt;&gt;(std::istream &amp;is, pvec &amp;a) &#123; return is &gt;&gt; a.x &gt;&gt; a.y; &#125; friend std::ostream &amp;operator&lt;&lt;(std::ostream &amp;os, const pvec &amp;a) &#123; return os &lt;&lt; a.x &lt;&lt; &#x27; &#x27; &lt;&lt; a.y; &#125; bool operator==(const pvec &amp;a) const &#123; return x == a.x &amp;&amp; y == a.y; &#125; pvec operator-(const pvec &amp;a) const &#123; return &#123;x - a.x, y - a.y&#125;; &#125; bool operator&lt;(const pvec &amp;a) const &#123; return x == a.x ? y &lt; a.y : x &lt; a.x; &#125;&#125;;int sign(i64 val) &#123; return val &lt; 0 ? -1 : (val &gt; 0 ? 1 : 0); &#125;i64 cross(const pvec &amp;a, const pvec &amp;b) &#123; return 1ll * a.x * b.y - 1ll * a.y * b.x; &#125;i64 cross(const pvec &amp;a, const pvec &amp;b, const pvec &amp;c) &#123; return cross(b - a, c - a); &#125;i64 dot(const pvec &amp;a, const pvec &amp;b) &#123; return 1ll * a.x * b.x + 1ll * a.y * b.y; &#125;int scross(const pvec &amp;a, const pvec &amp;b, const pvec &amp;c) &#123; return sign(cross(a, b, c)); &#125;i64 sqrlen(const pvec &amp;a) &#123; return dot(a, a); &#125;auto convex_hull(const std::vector&lt;pvec&gt; &amp;x) &#123; std::vector&lt;pvec&gt; v(x); std::vector&lt;pvec&gt; used, unused; std::sort(v.begin(), v.end()); int m = v.size(), tp = -1; for (int i = 0; i &lt; m; i++) &#123; while (tp &gt; 0 &amp;&amp; cross(used[tp-1], used[tp], v[i]) &lt;= 0) tp--, used.pop_back(); used.push_back(v[i]), tp++; &#125; int t = tp; for (int i = m - 1; i &gt;= 0; i--) &#123; while (tp &gt; t &amp;&amp; cross(used[tp-1], used[tp], v[i]) &lt;= 0) &#123; tp--; used.pop_back(); &#125; used.push_back(v[i]), tp++; &#125; used.pop_back(); std::set&lt;pvec&gt; s; for(auto d: used) s.insert(d); for(auto d: v) if (!s.contains(d)) unused.push_back(d); return std::pair&#123;used, unused&#125;;&#125;bool comp(const pvec &amp;a, const pvec &amp;b) &#123; bool upA = a.y &gt; 0 || (a.y == 0 &amp;&amp; a.x &gt;= 0); bool upB = b.y &gt; 0 || (b.y == 0 &amp;&amp; b.x &gt;= 0); if (upA != upB) return upA; auto val = cross(a, b); return val &gt; 0;&#125;i64 area(const std::vector&lt;pvec&gt; &amp;p) &#123; i64 res = 0; for (int i = 0, m = p.size(); i &lt; m; i++) res += cross(p[i], p[(i + 1) % m]); return res;&#125;void run() &#123; int n; std::cin &gt;&gt; n; std::vector&lt;pvec&gt; p(n); for (auto &amp;x : p) std::cin &gt;&gt; x; auto [used, un] = convex_hull(p); int sz = used.size(); i64 ans = 0; for (const auto &amp;x : un) &#123; // enum concave point. std::vector&lt;std::pair&lt;pvec, int&gt;&gt; al; std::vector&lt;pvec&gt; cur(sz); std::vector&lt;i64&gt; val(sz, 0); // area of triangle formed by on-convex points i64 sum = 0; for (const auto &amp;y : un) &#123; // compute vectors if (y == x) continue; al.push_back(&#123;y - x, -1&#125;); &#125; for (int i = 0; i &lt; sz; i++) &#123; cur[i] = used[i] - x; al.push_back(&#123;cur[i], i&#125;); &#125; // sort by angle std::sort(al.begin(), al.end(), [&amp;](const auto &amp;a, const auto &amp;b) &#123; return comp(a.first, b.first); &#125;); // rotate to satisfy pattern: // [on-convex, not, not, ..., not, on-convex, not, not .... , not, on-convex] for (int i = 0; i &lt; al.size(); i++) &#123; if (al[i].second == -1) continue; std::rotate(al.begin(), al.begin() + i, al.end()); break; &#125; // compute convex area for (int i = 0; i &lt; sz; i++) &#123; val[i] = cross(cur[i], cur[(i + 1) % sz]); sum += val[i]; &#125; // enum all points between 2 on-convex points for (int l = 0, r = 0, al_size = al.size(); l &lt; al_size; l = r) &#123; r = l + 1; while (r &lt; al_size &amp;&amp; al[r].second == -1) r++; // (l, r) is the range of not-on-convex points // l, r are on-convex points int pos = al[l].second; std::vector&lt;i64&gt; T(r - l, 0); assert((pos + 1) % sz == al[r % al_size].second); // left convex [&amp;al, &amp;T, &amp;l, &amp;r] &#123; std::vector&lt;pvec&gt; pts; int top = -1; i64 ssum = 0; for (int fix = l; fix &lt; r; fix++) &#123; const auto &amp;q = al[fix].first; while (top &gt;= 1 &amp;&amp; cross(q - pts[top - 1], pts[top] - pts[top - 1]) &gt;= 0) &#123; ssum -= cross(pts[top - 1], pts[top]); top--, pts.pop_back(); &#125; pts.push_back(q), top++; if (top &gt;= 1) ssum += cross(pts[top - 1], pts[top]); T[fix - l] += ssum; &#125; &#125;(); // right convex [&amp;al, &amp;T, &amp;l, &amp;r, &amp;al_size] &#123; std::vector&lt;pvec&gt; pts; int top = -1; i64 ssum = 0; for (int fix = r; fix &gt; l; fix--) &#123; const auto &amp;q = al[fix % al_size].first; while (top &gt;= 1 &amp;&amp; cross(pts[top - 1], pts[top], q) &gt;= 0) &#123; ssum -= cross(pts[top], pts[top - 1]); top--, pts.pop_back(); &#125; pts.push_back(q); top++; if (top &gt;= 1) ssum += cross(pts[top], pts[top - 1]); T[fix - l - 1] += ssum; &#125; &#125;(); for (int i = 0; i &lt; r - l; i++) &#123; i64 st = sum - val[pos] + T[i]; (ans += std::abs(st)) %= M; &#125; &#125; &#125; std::cout &lt;&lt; ans &lt;&lt; &#x27; &#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int T = 1; // std::cin &gt;&gt; T; while (T--) run(); return 0;&#125; H. Mah-Jong 算法流程 我们先预处理出所有可能的顺子的情况 SSS，每个顺子最多出现 222 次（否则可以视为 333 个碰），最少出现 000 次，因此最多 729729729 种情况。 于是每一个合法的区间都可以视为，SSS 中的某一个顺子搭配 sss 加上 若干个碰，因此对于区间 [l,r][l, r][l,r] 而言，令这个区间有 did_idi​ 个数字为 iii 的麻将牌，而顺子组合 sss 要求 bib_ibi​ 个数字为 iii 的牌，那么区间合法这个条件等同于 di≡bi(mod3)di≥bi \\begin{aligned} d_i&amp;\\equiv b_i \\pmod 3\\\\ d_i&amp;\\ge b_i \\end{aligned} di​di​​≡bi​(mod3)≥bi​​ 考虑如何维护 di≥bid_i\\ge b_idi​≥bi​ 这个条件： 如果我们固定右端点 rrr，那么我们只需要让 l:r→1l:r\\to 1l:r→1 扫描，直到 [l,r][l,r][l,r] 的 did_idi​ 开始满足 di≥bid_i\\ge b_idi​≥bi​，那么对于所有 p&lt;lp\\lt lp&lt;l，都一定会有 [p,r]:di≥bi[p,r]:d_i\\ge b_i[p,r]:di​≥bi​（因为 p&lt;lp\\lt lp&lt;l，因此只会往这个区间里添加新的数，因此 did_idi​ 不可能变小） 考虑如何维护同余 di≡bi(mod3)d_i\\equiv b_i\\pmod {3}di​≡bi​(mod3) 用桶维护即可。可以开 888 维数组或者用三进制表示 时间复杂度 O(36n)O(3^6n)O(36n) Code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475#include &lt;iostream&gt;#include &lt;ranges&gt;#include &lt;vector&gt;using i64 = long long;void run() &#123; int n; std::cin &gt;&gt; n; std::vector cnt(n + 1, std::vector&lt;int&gt;(8, 0)); std::vector&lt;int&gt; mask(n + 1, 0); std::vector&lt;int&gt; a(n + 1, 0); auto encode = [&amp;](int d) &#123; int s = 0; for (auto i : std::views::iota(0, 8)) s = s * 3 + cnt.at(d).at(i) % 3; return s; &#125;; auto decode_chow = [&amp;](int pat) &#123; std::vector&lt;int&gt; p(8, 0); for (int i : std::views::iota(0, 6)) &#123; int u = pat % 3; pat /= 3; p.at(i) += u, p.at(i + 1) += u, p.at(i + 2) += u; &#125; return p; &#125;; for (int i = 1; i &lt;= n; i++) &#123; std::cin &gt;&gt; a.at(i); a.at(i)--; cnt.at(i) = cnt.at(i - 1); cnt.at(i).at(a.at(i))++; mask.at(i) = encode(i); &#125; i64 ans = 0; std::vector&lt;int&gt; bucket(8000, 0); for (auto pattern : std::views::iota(0, 729)) &#123; auto pat = decode_chow(pattern); for (int i = 0; i &lt;= n; i++) bucket.at(mask.at(i))++; int r = 0; for (int l = 1; l &lt;= n; l++) &#123; for (; r &lt;= l; r++) bucket.at(mask.at(r))--; // 先去除不合法的区间（即 右端点小于左端点的区间） int target = 0; for (int t : std::views::iota(0, 8)) &#123; // 用双指针去除不满足偏序关系的 while (r &lt;= n &amp;&amp; cnt.at(r).at(t) &lt; cnt.at(l - 1).at(t) + pat.at(t)) &#123; bucket.at(mask.at(r))--; r++; &#125; target = target * 3 + (cnt.at(l - 1).at(t) + pat.at(t)) % 3; &#125; if (r &gt; n) break; ans += bucket[target]; // 加上满足同余的区间的贡献 &#125; &#125; std::cout &lt;&lt; ans &lt;&lt; &#x27; &#x27;;&#125;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int T = 1; std::cin &gt;&gt; T; while (T--) run(); return 0;&#125;"},{"title":"香港中文大学（深圳）2025 校赛暨粤港澳国际编程比赛","path":"/wiki/algo_contests/20250419-CUHKSZ-contest.html","content":"A. Milky Loong 大致题意：给你一个字符串，提取一部分文字出来和另一部分拼一起。 实际也非常简单，用 Python 随便水一水就可以了。毕竟是照顾初学者的签到题 B. 约瑟夫问题 大致题意： 有 n≤105n\\le 10^5n≤105 个人围成一个圆，给定一个 2≤k≤92\\le k\\le 92≤k≤9，每个人轮流报数： 如果这个数是 kkk 的倍数、或者其十进制表示带有 kkk 这个数字，那么这个人就被杀死 报数的时候会跳过已经死掉的人 问最后活下来的是谁。 也毕竟简单。考虑到最多每 kkk 个数字就会干掉一个人，因此最多 nknknk 轮就会结束。 C. F. 试飞 大致题意： nnn 个人里面有 mmm 个人具有飞行经验，你的目标是选出两个有飞行经验的人试飞。 你每次可以选择任意 222 个人让其试飞，如果这两个人都具有飞行经验，则任务立刻结束；否则试飞失败。 你只能用至多 ⌊n2m⌋\\lfloor \\frac{n^2}{m}\\rfloor⌊mn2​⌋ 次试飞完成目标。 非常有意思的一道题目。考察鸽巢原理。具体做法是，把这 nnn 个人平分到 m−1m-1m−1 个组里，那么根据鸽巢原理，必然有一个组里有 222 个人具有飞行经验。 于是，我们直接对每一个组暴力枚举 pair. 由于是平分，每个组差不多 nm−1\\frac{n}{m-1}m−1n​ 人，因此一个组内的枚举次数为 12×(nm−1−1)×nm−1\\frac{1}{2}\\times(\\frac{n}{m-1}-1)\\times\\frac{n}{m-1}21​×(m−1n​−1)×m−1n​，而有 m−1m-1m−1 组，因此总枚举次数为 (m−1)×12×(nm−1−1)×nm−1=n22(m−1)−n≤n2m \\begin{aligned} &amp;(m-1)\\times\\frac{1}{2}\\times(\\frac{n}{m-1}-1)\\times\\frac{n}{m-1}\\\\ =&amp;\\frac{n^2}{2(m-1)}-n\\\\ \\le &amp;\\frac{n^2}{m} \\end{aligned} =≤​(m−1)×21​×(m−1n​−1)×m−1n​2(m−1)n2​−nmn2​​"},{"title":"北京大学 2024 年《数据结构与算法A（实验班）》期末考试","path":"/wiki/algo_contests/pku-2024-ds-and-algo-A-final.html","content":"D. MST 算法流程 先对 “(边权, ID)” 进行排序（从小到大） 初始化…… 并查集，两颗线段树（一棵维护从左向右的字符串哈希值，另一棵维护从右向左的字符串哈希值） 给并查集上的每一个连通块分配一个随机数（nnn 个，初始时并查集都不连通） 初始化 vector，记录一下每一个连通块内的所有点 遍历排序过的边…… (w,id)(w,id)(w,id) 首先，计算一下 ididid 对应的边集，(1,id−1),(2,id−2),…,(id−12,id−id−12)(1,id-1), (2,id-2), \\dots, (\\frac{id-1}{2}, id-\\frac{id-1}{2})(1,id−1),(2,id−2),…,(2id−1​,id−2id−1​) 从 l=id−12,r=id−id−12l=\\frac{id-1}{2},r=id-\\frac{id-1}{2}l=2id−1​,r=id−2id−1​ 开始向外二分查找下一条要连接的边 (l−M,r+M)(l-M, r+M)(l−M,r+M) 在并查集上连接这一条边对应的两个点 l−M,r+Ml-M,r+Ml−M,r+M， 同时维护 vector（更新同一个连通块内的点，这里需要用启发式合并）。 维护 vector 的同时，在线段树上同步修改对应点的值（修改成新连通块的值），即同步维护字符串的哈希值。 每合并两个点，就把边权加入答案 最后输出答案 正确性证明 考虑根据 Kruskal 算法的思路，我们总是尝试从边权最小的边 e=(u,v)e=(u,v)e=(u,v) 开始尝试加入 MST，如果 (u,v)(u,v)(u,v) 在并查集里不连通，那么就说明这条边可以加入 MST. 现在的话，边都是以 ai+ja_{i+j}ai+j​ 的形式给出，例如对于 aka_kak​，它所代表的边为 (1,k−1),(2,k−2),…(1,k-1),(2,k-2),\\dots(1,k−1),(2,k−2),…。 如果我们给并查集里的每一个连通块分配一个字母，那么考虑并查集里的两个点 i,ji,ji,j 且我们正在考虑 aka_kak​ 满足 k=i+jk=i+jk=i+j：那么我们可以发现的一点是，如果 i,ji,ji,j 已经连通，那么他们的字母应该是相同的，否则就不相同。如果字母相同，我们就不需要在 (i,j)(i,j)(i,j) 之间连边，因为他们已经在同一个连通块里（根据 Kruskal 算法，加入 (i,j)(i,j)(i,j) 这条边会产生一个环）；否则我们就可以加入这条边，在并查集里把他们连起来。 然后我们就可以发现一件事：如果对每一条 aka_kak​ 对应的边 (i,j)(i,j)(i,j) 来说，都不需要向 MST 里添加这条边，这意味着 i,ji,ji,j 对应的值相等；而 i+j=ki+j=ki+j=k，因此总是有 val[i]=val[k−i]val[i]=val[k-i]val[i]=val[k−i]，也就是说 aka_kak​ 所对应的点 1…k−11\\dots k-11…k−1 是回文串！ 这意味着我们可以通过不断判断某一段前后缀是否回文，来看这一段前后缀是不是已经在并查集（也即 MST）上连接完毕。我们可以用二分快速进行查找和判断。 时间复杂度分析 根据 MST 的性质，MST 是一棵树，最多 n−1n-1n−1 条边，而因为每一次二分必将连接一条边，因此“二分枚举待连接的边”这个操作最多进行 n−1n-1n−1 次，即 O(n)O(n)O(n) 次。每一次二分最多在包含 nnn 条边的集合内搜索，因此二分次数是 O(nlog⁡n)O(n\\log n)O(nlogn) 的。每一次二分都需要在线段树上进行区间查询，而单次区间查询是 O(log⁡n)O(\\log n)O(logn) 的，所有二分部分的时间复杂度是 O(nlog⁡2n)O(n\\log^2 n)O(nlog2n) 接着考虑启发式合并部分的复杂度。由于每一次都将小的集合添加到大的集合里，因此每一次合并，被添加的元素所在的集合大小都会翻倍，由于最多有 nnn 个点，因此最坏情况下一个元素会被添加 log⁡n\\log nlogn 次，因此启发式合并一共会产生 O(nlog⁡n)O(n\\log n)O(nlogn) 次添加元素操作。 但是在每次添加元素的时候，我们还要维护线段树，对单点修改、区间查询线段树而言，修改一次的复杂度是 O(log⁡n)O(\\log n)O(logn)，因此启发式合并以及维护线段树的总体复杂度就是 O(nlog⁡2n)O(n\\log^2 n)O(nlog2n) 因此总体时间复杂度为 O(nlog⁡2n)O(n\\log^2n)O(nlog2n) Code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136#include &lt;algorithm&gt;#include &lt;cassert&gt;#include &lt;functional&gt;#include &lt;iostream&gt;#include &lt;numeric&gt;#include &lt;random&gt;#include &lt;utility&gt;#include &lt;vector&gt;using u64 = unsigned long long;constexpr u64 P = 4816069;std::mt19937_64 rng(std::random_device&#123;&#125;());std::vector&lt;u64&gt; base, rd;struct ModTree &#123; struct Node &#123; int l, r; u64 fhash, bhash; &#125;; std::vector&lt;Node&gt; tree; int n; Node update(Node l, Node r) &#123; Node res; res.l = l.l, res.r = r.r; res.fhash = l.fhash * base[r.r - r.l + 1] + r.fhash; res.bhash = r.bhash * base[l.r - l.l + 1] + l.bhash; return res; &#125; void init(int n) &#123; tree.assign(n * 4, Node()); this-&gt;n = n; &#125; void build(std::vector&lt;u64&gt; &amp;vec, int p, int l, int r) &#123; tree[p].l = l, tree[p].r = r; if (l == r) &#123; tree[p].fhash = tree[p].bhash = vec[l]; return; &#125; int mid = (l + r) &gt;&gt; 1; build(vec, p &lt;&lt; 1, l, mid); build(vec, p &lt;&lt; 1 | 1, mid + 1, r); tree[p] = update(tree[p &lt;&lt; 1], tree[p &lt;&lt; 1 | 1]); &#125; void modify(int p, int pos, u64 val) &#123; if (tree[p].l == tree[p].r) &#123; tree[p].fhash = tree[p].bhash = val; return; &#125; int mid = (tree[p].l + tree[p].r) &gt;&gt; 1; if (pos &lt;= mid) modify(p &lt;&lt; 1, pos, val); else modify(p &lt;&lt; 1 | 1, pos, val); tree[p] = update(tree[p &lt;&lt; 1], tree[p &lt;&lt; 1 | 1]); &#125; Node query(int p, int l, int r) &#123; if (l &lt;= tree[p].l &amp;&amp; tree[p].r &lt;= r) return tree[p]; int mid = (tree[p].l + tree[p].r) &gt;&gt; 1; if (r &lt;= mid) return query(p &lt;&lt; 1, l, r); else if (l &gt; mid) return query(p &lt;&lt; 1 | 1, l, r); Node res = update(query(p &lt;&lt; 1, l, mid), query(p &lt;&lt; 1 | 1, mid + 1, r)); return res; &#125;&#125;;int main() &#123; std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int n; std::cin &gt;&gt; n; [&amp;] &#123; base.resize(n + 1), rd.resize(n + 1); base[0] = 1; for (int i = 1; i &lt;= n; i++) base[i] = base[i - 1] * P, rd[i] = rng(); &#125;(); std::vector&lt;std::pair&lt;u64, int&gt;&gt; vec; std::vector&lt;std::vector&lt;int&gt;&gt; nodes(n + 1); for (int i = 3; i &lt; n * 2; i++) &#123; u64 x; std::cin &gt;&gt; x; vec.emplace_back(x, i); &#125; std::vector&lt;int&gt; fa(n + 1, 0); std::iota(fa.begin(), fa.end(), 0); std::function&lt;int(int)&gt; find = [&amp;](int x) &#123; return fa[x] == x ? x : fa[x] = find(fa[x]); &#125;; ModTree tree; tree.init(n); tree.build(rd, 1, 1, n); for (int i = 1; i &lt;= n; i++) nodes[i].push_back(i); auto unite = [&amp;](int u, int v) &#123; u = find(u), v = find(v); if (u == v) return; if (nodes[u].size() &gt; nodes[v].size()) std::swap(u, v); fa[u] = v; for (int i : nodes[u]) &#123; nodes[v].emplace_back(i); rd[i] = rd[v]; tree.modify(1, i, rd[i]); &#125; nodes[u].clear(); &#125;; std::sort(vec.begin(), vec.end()); long long ans = 0; for (auto &amp;[E, id] : vec) &#123; int l = (id - 1) / 2, r = id - l; int size = std::min(l, n - r + 1); int L = l - size + 1, R = r + size - 1; while (r &lt;= R) &#123; // std::cerr &lt;&lt; l &lt;&lt; &#x27; &#x27; &lt;&lt; r &lt;&lt; &#x27; &#x27; &lt;&lt; L &lt;&lt; &#x27; &#x27; &lt;&lt; R &lt;&lt; &#x27; &#x27;; // std::cerr &lt;&lt; tree.query(1, L, l).fhash &lt;&lt; &#x27; &#x27; &lt;&lt; tree.query(1, r, R).bhash &lt;&lt; &#x27; &#x27;; // for (int i = 1; i &lt;= n; i++) std::cerr &lt;&lt; i &lt;&lt; &quot;: &quot; &lt;&lt; rd[i] &lt;&lt; &#x27; &#x27;; if (tree.query(1, L, l).fhash == tree.query(1, r, R).bhash) break; int lb = 0, ub = R - r; while (lb &lt;= ub) &#123; int mid = (lb + ub) &gt;&gt; 1; if (tree.query(1, l - mid, l).fhash != tree.query(1, r, r + mid).bhash) ub = mid - 1; else lb = mid + 1; &#125; l -= lb, r += lb; unite(l, r); ans += E; &#125; &#125; std::cout &lt;&lt; ans &lt;&lt; &#x27; &#x27;; return 0;&#125;"},{"title":"使用 Dify 的“节点”完成数据预处理","path":"/wiki/dify/custom-data-preprocess.html","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"CAPM 资本资产定价模型","path":"/wiki/fina/CAPM.html","content":"公式 E[Rp]=Rf+βp(RM−Rf) \\mathbb E[R_{p}]=R_f+\\beta_{p}(R_M-R_f) E[Rp​]=Rf​+βp​(RM​−Rf​)市场风险溢价 例题"},{"title":"安装与部署 Dify","path":"/wiki/dify/install-n-use.html","content":"下载 Dify 的 docker compose 文件 1git clone 启动 docker 确保 docker 可以共享文件夹 在 docker desktop -&gt; settings -&gt; resource share 里查看 folder 是否存在。 进入本地部署的 Dify 使用 ip a 查看 docker0 对应的 IP 地址（inet），然后用这个 IP 进入，而不是 localhost"},{"title":"IRR","path":"/wiki/fina/IRR.html","content":"Definition The IRR of the project is the single annual discount rate at which the NPV of the project is equal to zero. 公式 NPV=C0+∑i=1m(11+IRR)iCi=0 NPV=C_0+\\sum_{i=1}^{m} \\Big(\\frac{1}{1+IRR}\\Big)^i C_i=0 NPV=C0​+i=1∑m​(1+IRR1​)iCi​=0 IRR Rule 定义 Minimum required return 计算 IRRIRRIRR，与 required return 进行比较 问题 还需要将 Interest Rate 纳入考量 解决办法 先算出两个 project 的 NPV 相等时的利率 RRR，然后根据现在的利率，判断选择那个 project. Amortization Schedule monthly: IRR12\\frac{IRR}{12}12IRR​"},{"title":"Bonds","path":"/wiki/fina/bonds.html","content":"Bonds 债券 不拥有 Ownership 不能投票 无论是否盈利，盈利多少，企业都必须支付本息；否则视为破产 有法律义务支付本息 企业先支付本息，再支付分红 由于支付利息视作企业运营的开支，因此可以抵扣税款 Terms Maturity Date Face Value (Par Value) FFF Coupon Payment CCC Variations Zero-Coupon Bonds: 无利息 Bond Valuation NPV Approach Yield to Maturity (YTM) YTM 使得债券 NPV 为 000 时的 discount rate 假设一年付 mmm 次，那么每次付的比率是 YTMm\\frac{YTM}{m}mYTM​；假设 nnn 年 −P0+C×1−(1+YTM/m)−nmYTM/m+F×(1+YTM/m)−nm=0 -P_0+C\\times\\frac{1-(1+YTM/m)^{-nm}}{YTM/m}+F\\times\\Big( 1+YTM/m \\Big)^{-nm}=0 −P0​+C×YTM/m1−(1+YTM/m)−nm​+F×(1+YTM/m)−nm=0 The investors are getting an annual rate of return equal to the return they require on the investment The YTM can be obtained ONLY IF we hold the bond until maturity Risk of Investment 债券投资的风险 利率风险：市场利率上升导致债券价格下跌。 信用风险：发行人违约可能性（如公司破产）。 流动性风险：债券难以快速变现。 通胀风险：通胀削弱固定收益的实际购买力。"},{"title":"Capital Investment Decision","path":"/wiki/fina/capital-investment-decision-01.html","content":"Incremental Cash Flow=Operating Cash Flow−Incremental Cash Flow on Capital Spending−Incremental Cash Flow on Change in Net Working Capital \\begin{aligned} &amp;\\text{Incremental Cash Flow}\\\\ &amp;\\quad =\\text{Operating Cash Flow}\\\\ &amp;\\quad -\\text{Incremental Cash Flow on Capital Spending}\\\\ &amp;\\quad -\\text{Incremental Cash Flow on Change in Net Working Capital} \\end{aligned} ​Incremental Cash Flow=Operating Cash Flow−Incremental Cash Flow on Capital Spending−Incremental Cash Flow on Change in Net Working Capital​ EBIT approach 先计算 EBIT Tax Shield approach OCF=(PQ−FC−VC)(1−Tc)+Dep⋅Tc OCF=(PQ-FC-VC)(1-T_c)+Dep\\cdot T_c OCF=(PQ−FC−VC)(1−Tc​)+Dep⋅Tc​ 例题 Opportunity Cost 相关 Parker &amp; Stone, Inc. is considering building a new manufacturing plant in South Park to produce garden tools. The company purchased land six years ago for $2.8\\$2.8$2.8 million with the intention of using it as a warehouse and distribution site. However, the company later decided to lease these facilities from a competitor instead. If sold today, the land could generate $3.2\\$3.2$3.2 million in net proceeds. The company now plans to build the new manufacturing plant on this land, which will cost $14.3\\$14.3$14.3 million to construct. Additionally, the site requires $825,000\\$825,000$825,000 in grading expenses to prepare it for construction. Question: What is the appropriate cash flow amount to use as the initial investment in fixed assets when evaluating this project? Explain your reasoning."},{"title":"Capital Structure 资产结构","path":"/wiki/fina/capital-structure.html","content":"Handout10: Key Take-Away 企业现值：无负债 V=EV=EV=E；有负债 V=E+DV=E+DV=E+D Cost of Equity Cost of Debt MM Proportion 1 在无税收、无破产成本的情况下，有 VU=VLV_U=V_LVU​=VL​. 这是因为无税收无破产成本的情况下，所有的 EBIT 只在企业、股权所有者、债权所有者之间流通。 MM Proportion 2: 股权、债权、资产对风险的敏感程度的关系为 DVβD+EVβE=βA\\frac{D}{V}\\beta_D+\\frac{E}{V}\\beta_E=\\beta_AVD​βD​+VE​βE​=βA​ 股权、债权、资产的期望回报率 (Expected Return) 为 DVE[RD]+EVE[RE]=E[RA]\\frac{D}{V}\\mathbb E[R_D]+\\frac{E}{V}\\mathbb E[R_E]=\\mathbb E[R_A]VD​E[RD​]+VE​E[RE​]=E[RA​] 改变股权债权结构 不影响股价 平衡点：ENE=DND\\frac{E}{N_E}=\\frac{D}{N_D}NE​E​=ND​D​，即股权价格等于债权价格。 Handout11: Key Take-Away Without Tax and Backruptcy Costs 企业可以通过 发行股票 issue Equity 举债 debt, bonds, bank loan 进行融资。 Value of Firm=Value of Equity+Value of Debt \\text{Value of Firm}=\\text{Value of Equity}+\\text{Value of Debt} Value of Firm=Value of Equity+Value of Debt MM Proportion I 在无税收、无破产成本的情况下，公司价值 VVV 不受资本结构影响，即无杠杆公司的价值等于有杠杆的公司 VU=VL=OCF V_U=V_L=OCF VU​=VL​=OCF With Tax and Bankruptcy Costs MM Proportion I 在存在企业所得税的情况下，公司价值（VLV_LVL​​）随财务杠杆增加而提升 ，主要因利息税盾（Interest Tax Shield）的税收优惠效应。 VL=VU+D×Tc V_L=V_U+D\\times T_c VL​=VU​+D×Tc​ MM Proportion II 在有税环境下，股权成本（RER_ERE​​）仍随杠杆增加而上升 ，但公式需调整以反映税盾效应： RE​=RU+(RU​−RD​)×ED​×(1−Tc​) R_E​=R_U+(R_U​−R_D​)\\times E_D​\\times (1−T_c​) RE​​=RU​+(RU​​−RD​​)×ED​​×(1−Tc​​)税收降低了债务的实际成本（因利息税盾），但股权风险和成本仍随杠杆上升而增加。"},{"title":"Investment Decision Rule","path":"/wiki/fina/invest-decision-rule.html","content":"Investment Decision Rule … based on Returns 就是看最后拿到的钱 RewardRewardReward 是不是初始投资 InvestInvestInvest 多就行， … based on NPV NPV定义​ 净现值（Net Present Value, NPV）是评估投资项目价值的核心指标，计算方式为项目所有现金流（含初始投资）按贴现率折算后的现值总和。公式为： NPV=C0​+∑i=1TCi(1+R)iNPV=C_0​+\\sum_{i=1}^T\\frac{C_i}{(1+R)^i}NPV=C0​​+∑i=1T​(1+R)iCi​​ CtC_tCt​​: 第 ttt 期的现金流（C0C_0C0​​ 为初始成本，通常为负值）。 RRR: 贴现率（通常为金融市场可获得的回报率）。 ​决策规则​ ​NPV &gt; 0：项目收益高于金融市场回报，应接受。 ​NPV &lt; 0：项目收益低于金融市场回报，应拒绝。 ​NPV = 0：项目收益与金融市场相当，决策无差异（可结合其他因素考虑）。 ​关键原则​ ​基准比较：以金融市场回报率为基准，衡量项目是否创造额外价值。 ​现金流方向： 现金流入（收入）为正值（Ct​&gt;0）。 现金流出（成本）为负值（Ct​&lt;0）。 沉没成本忽略：过去已发生且不可逆的成本（如前期调研费用）不计入NPV，仅考虑未来现金流。 ​注意事项​ ​时间价值：现金流的时点影响现值，需准确对应贴现期数。 ​零NPV的意义：项目回报率等于贴现率（金融市场回报率），而非无收益。 总结：NPV规则通过量化项目相对于金融市场的净收益，为投资决策提供清晰标准，强调未来现金流和沉没成本的正确处理。 … based on IRR 预设项目的最少回报 (Minimum Return Required)，然后判断项目的 IRR 是否高于预期。 Internal Rate of Return (IRR) 是将单笔资金拓展到多笔资金，IRRIRRIRR 是年利率 (Annual Rate of Return)，使得整个项目周期结束后的 NPV 为零 NPV=0=C0+∑i=1T(11+IRR)iCi NPV=0=C_0+\\sum_{i=1}^T \\Big(\\frac{1}{1+IRR}\\Big)^i C_i NPV=0=C0​+i=1∑T​(1+IRR1​)iCi​ NPV or IRR 实际上，IRR 和 NPV 大致成反比关系。 Notice the role of the return from the financial sector (e.g., interest rate on bank deposit) in the NPV rule and IRR rule: in the NPV rule, it is the discount rate in the IRR rule, it is the (minimum) required return of the real investment project under consideration. conventional: 初始投资都是 cash outflow，后续所有现金流都是入账 cash inflow non-conventional: 不符合 conventional 的现金流情况 IRR Rule 的问题 当同时考虑多个项目时，先计算 xxx，使得这几个项目在 Discount Rate 为 xxx 时的 NPV 相同。 Payback Rule 考虑多久可以回本（不考虑 discount） Discounted Payback Rule 先 discount cash flow，再应用 Payback Rule Profitability Index PI=PV of future cash flowsinitial cost PI=\\frac{\\text{PV of future cash flows}}{\\text{initial cost}} PI=initial costPV of future cash flows​"},{"title":"Agency Problem 和 Market Efficiency","path":"/wiki/fina/market-efficiency.html","content":"Agency Problem 什么是 Agency Problem? 代理问题指公司管理层（代理人）与股东（委托人）之间的利益冲突。管理层可能牺牲股东利益，追求自身利益最大化。 例如，接受负净现值（NPV）项目以获取回扣。 ​​委托——代理关系​​ 股东（委托人）委托管理层（代理人）管理公司，但代理人可能以牺牲委托人利益为代价谋取私利。 Compensation Package 薪酬结构 股权激励​​：将管理层薪酬与公司股票表现挂钩，使其利益与股东一致。 例子​​：若管理层持有公司股票，接受负NPV项目会导致其持股价值下降，从而抑制此类行为。 ​​固定薪酬的局限性​​：固定工资无法激励管理层为公司价值最大化努力。 合伙制中的代理问题​​ 普通合伙​​（无限责任）：合伙人需以个人财产承担公司债务，降低冒险行为。 有限合伙​​：部分合伙人仅承担有限责任，可能增加代理问题。 例子​​：普通合伙人在面临破产风险时更谨慎，因其个人资产可能被追偿。 Efficient Market Hypothesis 有效市场假设 Technical Analysis基于股票的历史交易数据从历史交易的价格检测出规律，并总结为交易策略 Fundamental Analysis基于股票的内在价值从企业的商业运营衡量股票的价值例如 Dividend Discount Model (DDM): PV=∑iDi(1+r)iPV=\\sum_i \\frac{D_i}{(1+r)^i}PV=∑i​(1+r)iDi​​常见做法：track the performance of actively managed mutual funds, 因为……这些基金由专家管理这些专家也只能通过公开数据、公开信息来对股票进行股价和选股CAPM 模型可以用来看是否可以 outperform market Fundamental Analysis 的暗示：有的时候连专家也无法保证持续从股票获利，那么为什么要交昂贵的管理费？于是诞生了指数 (index funds)，进一步演化为 EFT (Exchange Traded Funds) 使得一群股票可以像一支股票那样进行买卖。 Weak Form Efficiency 【定义】股价已反映所有历史交易信息（如价格、成交量），Technical Analysis 无效。 Semi Strong Form Efficiency 股价已反映所有公开信息（如财报、行业新闻），Fundamental Analysis 无效。 Strong Form Efficiency 股价反映所有信息（包括内幕信息），内幕交易也无法获利。 但内幕交易违法，现实中几乎不存在 IPO IPO (Initial Public Offering) 指公司首次向公众发行股票并在证券交易所上市的过程，是私有企业转变为上市公司的关键步骤。 IPO 流程与参与者 前期准备与风险投资 (Venture Capital, VC) VC的作用​​： 资金与指导​​：VC 在 IPO 前为公司提供资金和战略支持，帮助其扩展业务、优化管理。 持股与退出​​：VC 通过持有公司股份（通常为40%以上）并在 IPO 后出售股票获利。 投资银行 (Investment Banks) 核心职责： 承销 (Underwriting)​​：投行承诺购买全部新股并转售给公众，承担发行风险。从企业购入股票的价格会低于售卖给公众的价格，从中获利。 firm commitment underwriting: 买下企业全部的股票 定价​​：确定发行价，需平衡公司融资需求与市场接受度。 组建承销团 (Syndicate)：多家投行联合承销以分散风险（如阿里巴巴 IPO 由高盛、瑞银等牵头）。 费用结构： 承销费通常为融资额的 4%∼7%4\\%\\sim 7\\%4%∼7% Under-Pricing IPO 发行价低于首日收盘价，导致投资者首日可获得超额收益。 原因： 信息不对称：投行可能刻意低估发行价以确保发行成功（如吸引长期投资者）。 市场热度：高抑价可制造“赚钱效应”，吸引更多投资者参与后续 IPO。 风险补偿：新股不确定性高，抑价作为对投资者的风险补偿。 可能带来的损失： 公司损失：抑价导致公司融资额减少 投机行为：散户可能因追逐首日涨幅盲目申购，面临破发风险"},{"title":"PV, FV, NPV","path":"/wiki/fina/pv-fv-npv.html","content":"PV, NPV Present Value: 一笔在未来会获得的钱在当下的价值 Future Value: 一笔现在的钱在未来的价值 实际上 PV 和 FV 非常简单，主要就是考虑利滚利 (Compounding of Interest)，把指数算清楚即可。 某一笔钱的 PV/FV 钱的 PV 相当于说，如果某笔 TTT 年后的钱 QQQ，且利率 rrr 保持不变，那么现在要存 PVPVPV 块钱，这样经过 TTT 年的利滚利，这 PVPVPV 块钱就变成了 QQQ 块钱。 PV×(1+r)T=Q PV\\times (1+r)^T=Q PV×(1+r)T=Q反过来，Future Value 就是，现在存的 QQQ 块钱，在 TTT 年后会变成 FVFVFV 块钱。 FV=Q×(1+r)T FV=Q\\times(1+r)^T FV=Q×(1+r)T 现金流（多笔钱）的 PV/FV 本质就是多笔钱的 FV/PV 全部换算到当前的时间点， PVaggregate=∑PViFVaggregate=∑FVi PV_{aggregate}=\\sum PV_{i}\\\\ FV_{aggregate}=\\sum FV_{i}\\\\ PVaggregate​=∑PVi​FVaggregate​=∑FVi​由于每笔钱的利滚利时间不同，因此右式的和式通常又可以写成有限项等比数列求和的形式 Annuity, Perpetuity Perpetuity 表示永久持续的恒定现金流，用 CCC 表示每年的现金流（且第一笔现金在一年后） 必须满足两个条件： The cash flows and the interest rates are constant over time, The first cash flow occurs one year from today. 那么所有这些钱的 PV 就是 PV=∑i=1∞C×(11+r)i=Cr \\begin{aligned} PV&amp;=\\sum_{i=1}^{\\infin} C\\times(\\frac{1}{1+r})^i\\\\ &amp;=\\frac{C}{r} \\end{aligned} PV​=i=1∑∞​C×(1+r1​)i=rC​​ Present Value of Annuity 与 Perpetuity 的区别在于 Annuity 有时限。假设经过 TTT 年，那么 Annuity 的 PV 就等于 PV=C(11+r)+C(11+r)2+⋯+C(11+r)T=C×1−(11+r)Tr PV=C(\\frac{1}{1+r})+C(\\frac{1}{1+r})^2+\\dots+C(\\frac{1}{1+r})^T=C\\times\\frac{1-(\\frac{1}{1+r})^T}{r} PV=C(1+r1​)+C(1+r1​)2+⋯+C(1+r1​)T=C×r1−(1+r1​)T​在一笔现金的时候我们知道，(11+r)T(\\frac{1}{1+r})^T(1+r1​)T 就是 Present Value Factor，所以也可以直接代入写成 PV=1−Present Value Factor(T)rC PV=\\frac{1-\\text{Present Value Factor}(T)}{r}C PV=r1−Present Value Factor(T)​C Future Value of Annuity 如果以第 TTT 年的价值作为基准，把每一笔钱的 FV 都加起来，就能得到 FV=(1+r)T−1rC=Future Value Factor(T)−1rC FV=\\frac{(1+r)^T-1}{r}C=\\frac{\\text{Future Value Factor}(T)-1}{r}C FV=r(1+r)T−1​C=rFuture Value Factor(T)−1​C Effects of Inflation 由于通胀 (Inflation) 的存在，尽管手上的钞票数量变多了，但这并不意味着购买力 (Purchasing Power) 提升。 Purchasing Power the quantity of goods and services that we can buy with our money. … on Nominal/Real Interest Rate Fisher’s Equation Nominal IR RRR: interest rate in terms of money Real IR rrr: interest rate in terms of purchasing power 我们用 hhh 表示物价的变化，即通胀率 (Inflation Rate)，则可以得出他们之间的关系 (Fisher Equation) (1+r)(1+h)=(1+R) (1+r)(1+h)=(1+R) (1+r)(1+h)=(1+R) 证明 考虑一开始的钱 QQQ，一开始的物价 PPP，则今年的购买力为 QP\\frac{Q}{P}PQ​，明年的购买力（即经过一年的通胀）为 Q(1+R)P(1+h)\\frac{Q(1+R)}{P(1+h)}P(1+h)Q(1+R)​ 根据 Real Interest Rate 的定义，我们有 Purchase Poweri+1−Purchase PoweriPurchase Poweri=Real IRQ(1+R)P(1+h)QP=1+r(1+r)(1+h)=1+R \\begin{aligned} \\frac{\\text{Purchase Power}_{i+1}-\\text{Purchase Power}_i}{\\text{Purchase Power}_i}&amp;=\\text{Real IR}\\\\ \\frac{\\frac{Q(1+R)}{P(1+h)}}{\\frac{Q}{P}}&amp;=1+r\\\\ (1+r)(1+h)&amp;=1+R \\end{aligned} Purchase Poweri​Purchase Poweri+1​−Purchase Poweri​​PQ​P(1+h)Q(1+R)​​(1+r)(1+h)​=Real IR=1+r=1+R​ 由于这些值都很小，所以我们通常直接近似为 r≊R−hr\\approxeq R-hr≊R−h … on PV &amp; NPV Inflation 并不影响 PV 和 NPV。但必须 discount nominal cash at a nominal rate 或者 discount real cash at a real rate 证明 考虑 inflation rate 为 hhh，nominal interest rate 为 RRR，考虑 nnn 年后的一笔钱 CCC (nominal)，那么用 Nominal Interest Rate 算的话 PVnominal=C(1+R)n PV_{nominal}=\\frac{C}{(1+R)^n} PVnominal​=(1+R)nC​用购买力计算的话，nnn 年后的购买力为 C(1+h)n\\frac{C}{(1+h)^n}(1+h)nC​，因此 discount at a real rate 的话，即为 PVreal=C(1+h)n(1+r)n PV_{real}=\\frac{\\frac{C}{(1+h)^n}}{(1+r)^n} PVreal​=(1+r)n(1+h)nC​​代入 Fisher’s Equation 1+R=(1+h)(1+r)1+R=(1+h)(1+r)1+R=(1+h)(1+r) 可得 PVreal=PVnominal PV_{real}=PV_{nominal} PVreal​=PVnominal​因此其实并不影响 Present Value。对于 Net PV，由于基准年的金额有 Nominal=RealNominal=RealNominal=Real，因此也不影响 NPV"},{"title":"Risk of Return","path":"/wiki/fina/risk-and-return.html","content":"Risk of Return 现实世界中，未来的 Return 并非确定的，而是一个概率分布。 Probability 我们可以计算 Expected Return E[R]=∑P(r)⋅r=4.30% \\mathbb E[R]=\\sum P(r)\\cdot r=4.30\\% E[R]=∑P(r)⋅r=4.30%进一步的，可以计算其方差： Var(R)= Var(R)= Var(R)=我们可以把 return 的方差视为 volatility，方差越大，股价越不稳定。 Risk Free Risk Free 的意思就是方差为 000，通常只有国债才能做到。 Portfolio Portfolio 就是 a basket of assets，每一个 asset 都有一定的比重 Risk Systematic 经济体内的每一家企业都会遇到的风险（例如政治稳定、税收等等） Unsystematic 这类风险只会影响个别企业（例如舆论） Risk Diversification"},{"title":"Valuation of Stocks","path":"/wiki/fina/valuation-of-stocks.html","content":"Stock 股票 拥有对企业的所有权 Ownership 可以投票 以分红的形式分享利益 没有法律义务支付一定数额的分红 企业先付 bonds 产生的利息，再支付分红 支付的分红不能用于抵扣税款 Dividend Discount Model (DDM 模型) stock 会产生分红现金流， PV of Dividend Stream=∑i=1+∞Di(1+R)i \\text{PV of Dividend Stream}=\\sum_{i=1}^{+\\infin}\\frac{D_i}{(1+R)^i} PV of Dividend Stream=i=1∑+∞​(1+R)iDi​​也被称为 funcdamental value of stock. 在市场完全竞争的情况下，价格 P0=PV of Dividend StreamP_0=\\text{PV of Dividend Stream}P0​=PV of Dividend Stream. 这个模型被称为 Dividend Discount Model. Special Case 1: 恒常分红现金流 当 Di=DjD_i=D_jDi​=Dj​ 时，通过等比数列求和可以简便地计算 P0P_0P0​ P0=D1R P_0=\\frac{D_1}{R} P0​=RD1​​ Special Case 2: 现金流等比增长 也被称为 Gordon’s Growth Model，设分红以每年 ggg 的速度增长，即 Di=(1+g)Di−1D_i=(1+g)D_{i-1}Di​=(1+g)Di−1​，则有 P0=D1R−g P_0=\\frac{D_1}{R-g} P0​=R−gD1​​ 一些指标 Dividend Yield 计算产生的分红 Dividend Yield=D1P0 \\text{Dividend Yield}=\\frac{D_1}{P_0} Dividend Yield=P0​D1​​ Capital Gains Yield 如果在 ttt 时刻卖出 stock，可以计算获得的资本 Capital Gains Yield=Pt−P0P0 \\text{Capital Gains Yield}=\\frac{P_t-P_0}{P_0} Capital Gains Yield=P0​Pt​−P0​​ Common vs. Preferred Common stock 有投票权 Preferred stock 享有优先分红的权利 由于 Preferred stock 的期限是无穷的，我们可以直接按 Perpetual Bond 来看待。如果每年分红 DpD_pDp​，利率 RpR_pRp​，初始股价 P0P_0P0​，根据 DDM 模型，有 P0=DpRp P_0=\\frac{D_p}{R_p} P0​=Rp​Dp​​"},{"title":"SVD","path":"/wiki/linear-algebra/SVD.html","content":"SVD 分解"},{"title":"MoE 架构","path":"/wiki/llm/Mixture-of-experts.html","content":"MoE 架构 MoE 代码实现：以 MiniMind 为例 Experts 首先定义专家模块，Experts 是 Experts(FeedForward) Code 12345678910class FeedForward(nn.Module): def __init__(self, config: LMConfig): super().__init__() self.w1 = nn.Linear(config.dim, config.hidden_dim, bias=False) self.w2 = nn.Linear(config.dim, config.hidden_dim, bias=False) self.w3 = nn.Linear(config.hidden_dim, condig.dim, bias=False) self.dropout = nn.Dropout(config.dropout) def forward(self, x): return self.dropout(self.w3(F.silu(self.w1(x)) * self.w2(x))) Router 然后，我们来实现 Router 路由器。Router 接收一个 Token，计算出概率取 Top K 后转发给对应的专家。 Code 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990class MoEGate(nn.Module): def __init__(self, config: LMConfig): super().__init__() self.config = config self.top_k = config.num_experts_per_token self.n_routed_experts = config.n_routed_experts self.scoring_func = config.scoring_func self.alpha = config.aux_loss_alpha self.seq_aux = config.seq_aux self.norm_topk_prob = config.norm_topk_prob self.gating_dim = config.dim self.weight = nn.Parameter( torch.empty((self.n_routed_experts, self.gating_dim)) ) self.reset_parameter() def reset_parameter(self) -&gt; None: import torch.nn.init as init init.kaiming_uniform_(self.weight, a=math.sqrt(5)) def forward(self, tokens: torch.Tensor): batch, seq_len, d = tokens.shape tokens = einops.rearrange(tokens, &quot;batch seq dim -&gt; (batch seq) dim&quot;) logits = F.linear(tokens, self.weight, None) if self.scoring_func == &quot;softmax&quot;: scores = logits.softmax(dim=-1) else: raise NotImplementedError( &quot;Unsupported scoring function&quot;, ) topk_weight, topk_idx = torch.topk( scores, k=self.top_k, dim=-1, sorted=False, ) if self.top_k &gt; 1 and self.norm_topk_prob: denominator = topk_weight.sum(dim=-1, keepdim=True) + 1e-20 topk_weight = topk_weight / denominator if self.train and self.alpha &gt; 0.0: scores_for_aux = scores aux_topk = self.top_k topk_idx_for_aux_loss = topk_idx.view(batch, -1) if self.seq_aux: scores_for_seq_aux = scores_for_aux.view(batch, seq_len, -1) ce = torch.zeros( batch, self.n_routed_experts, device=tokens.device, ) ce.scatter_add_( 1, topk_idx_for_aux_loss, torch.ones( batch, seq_len * aux_topk, device=tokens.device ) ).div_(seq_len * aux_topk / self.n_routed_experts) aux_loss = ( (ce * scores_for_seq_aux.mean(dim=-1)) .sum(dim=1) .mean() * self.alpha ) else: mask_ce = F.one_hot( topk_idx_for_aux_loss.view(-1), num_classes=self.n_routed_experts, ) ce = mask_ce.float().mean(0) Pi = scores_for_aux.mean(0) fi = ce * self.n_routed_experts aux_loss = (Pi * fi).sum() * self.alpha else: aux_loss = 0.0 return topk_idx, topk_weight, aux_loss 以下分析约定： Batch size BBB，即一个 batch 包含 BBB 句句子 Sequence Length SSS，即一句句子包含 SSS 个 Token 词嵌入向量维度 HHH 专家数量 EEE 每个 Token 被转发到 Top KKK 个专家 参数含义 top_k 为每一个 Token 选择几个专家进行训练 n_routed_experts 为专家总数 scoring_func 用于计算 Token 和专家之间的评分 aux_loss_alpha 辅助损失的 alpha 参数 seq_aux 控制是否在序列级别上计算辅助损失 norm_topk_prob 是否对概率进行归一化 由于我们对每一个 Token 计算它被发送到某一个专家的概率，在 __init__() 函数里，我们令 Token 的维度为 d=d=d= self.gating_dim，专家数量为 n=n=n= self.n_routed_experts，那么我们希望 Router 输出的矩阵大小就是 Router:RB×S×H↦RB×S×E \\text{Router}:\\R^{B\\times S\\times H}\\mapsto \\R^{B\\times S\\times E} Router:RB×S×H↦RB×S×E因此这里的 self.weight 是 RH×E\\R^{H\\times E}RH×E 大小的矩阵，负责计算一个 Token 的被转发到 Expert 的概率。 前向传播 forward() Tensor 输入是 B×S×HB\\times S\\times HB×S×H，因为我们只关心 Token 发送到哪个专家，所以我们首先把 Tensor 拍成二维 BS×HBS\\times HBS×H，并用 self.weight 计算概率，用 softmax() 归一化。F.linear(x, A, bias=None) 计算 y=xA⊺ y=xA^\\intercal y=xA⊺因此，这里的 score 大小为 BS×EBS\\times EBS×E 接着，我们调用 torch.topk() 选取前 KKK 个专家，返回 score 中对应的权重和下标。此时 topk_weight, topk_idx 大小均为 BS×KBS\\times KBS×K 然后对选择出来的 KKK 个专家的权重再进行一次归一化（除以 denominator）。不过这一步是可选的 接着进入 if self.train and self.alpha &gt; 0.0: 判断，目的是为了平衡专家之间的负载。首先，代码确保只在训练模式以及需要平衡负载的时候才会启用。 如果需要计算 sequence level 的 loss，那么 topk_idx 首先被拍平成 (B,SK)(B,SK)(B,SK) 因为要对 sequence level 计算专家负载损失，所以我们先定义每一句句子上专家的负载损失，其大小为 (B,E)(B,E)(B,E). 然后遍历 topk_idx 中的每一个元素，用 scatter_add_() 将 topk_idx 中的每一个元素添加到对应的 sequence 里对应的专家中。 这个流程结束之后，ce (count experts) 保存的就是每一句句子的专家负载。随后，我们对每一句句子都归一化其专家负载：一句句子会产生 SKSKSK 个 counting，总数为 SKSKSK 我们沿 SSS 轴对 scores_for_seq_aux 计算平均值 scores.mean(dim=1) 这就表示每句句子与每个 expert 之间的得分（token 与 experts 得分的平均），其大小变为 (B,E)(B, E)(B,E). 然后再将 ce 与 scores.mean() 对应位置相乘，ce 可以理解为每句句子中 expert 的频率（这个 expert 在这句句子里总是被分配处理 token），scores.mean() 可以理解为每句句子中 expert 对于每个 token 的重要程度（这个 expert 总是被 MoEGate 认为与 token 关联很大），大小变为 (B,E)(B,E)(B,E)，但此时仍然是每句句子与 expert 的关联。 因此再对 EEE 求和取平均 .sum(dim=1).mean()，把 expert 与不同句子之间的频率与关联度整合起来，即对于这些句子 expert 的频率与关联度，也即 expert 的负载，其大小先变为 (E,)(E,)(E,)，再变为 (1,)(1,)(1,)。最后再乘上标量 self.alpha. 这就是我们的 sequence level 的 aux loss. 值得一提的是，这里还额外乘了一个 EEE，推测是为了让梯度不至于太小 Why It Makes Sense 因为我们的训练目标是让 Loss 尽可能的小，对于这个 Aux Loss 而言，如果某一个专家的负载特别大，那么就说明 每一个 Batch 内的所有 Tokens，这个专家对应的 scores 都会比较大 由于 torch.topk 总是都把这个专家选上，因此 ce 计算出来的加权也比较大 所以根据排序不等式，负载越不均衡，计算出来的 aux_loss 也就越大。那么反过来说，如果 aux_loss 越小，说明专家之间的负载越均衡。 如果不关心 sequence level 的 loss，那么我们直接把这一个 batch 的所有 token 拍到一起（总共 B⋅SB\\cdot SB⋅S 个 token，总共被分配 BSKBSKBSK 个专家），我们把 (BSK,1)(BSK, 1)(BSK,1) 的专家重新 encode 为 one-hot vector，即 (BSK,E)(BSK,E)(BSK,E) 那么我们对 BSKBSKBSK 轴求平均，fi 向量大小变为 (1,E)(1,E)(1,E)，就计算出来了某个专家处理的 token 数占所有 token 的比值（即频率）。因为 one-hot vector 不是 000 就是 111. 类似的，我们也对 scores (大小为 (BS,E)(BS,E)(BS,E)) 做 token level 的计算，直接按 BSBSBS 轴取平均即可，Pi 大小变为 (1,E)(1,E)(1,E)，即每个专家在所有 token 上的平均得分（关联度） 同样地，我们直接将 fi 与 Pi 对应位置相乘，求和乘上 self.alpha，这一步的目的和 sequence level 的 aux loss 是一样的。 MoE Feed Forward (MoEFFN) 然后我们来把他们组合到一起：首先，我们为 MoEFFN 定义好门控和专家，以及共享专家（无论如何都要处理 token） 1234567891011121314class MOEFeedForward(nn.Module): def __init__(self, config: LMConfig): super().__init__() self.config = config self.experts = nn.ModuleList( [ FeedForward(config) for _ in range(config.n_routed_experts) ] ) self.gate = MoEGate(config) if config.n_shared_experts is not None: self.shared_experts = FeedForward(config) 然后编写训练和推理。训练和推理的区别在于 推理模式下，Token 只转发给最优的 Expert。但在训练模式下，Token 会被转发给每一个 Expert Training 我们来考察一下训练时的代码。 这里，x.repeat_interleave() 重复输入数据，目的是让一个 token 可以多次被不同的 expert 处理，提升 expert 的泛化性 然后 y 就是计算 token 经过专家计算后输出的结果，并且将类型转为半精度浮点数 float16，此时的张量形状为 (BS×K,H)(BS\\times K, H)(BS×K,H)，经过 .view(*topk_weight.shape, -1) 之后变为 12345678910if self.training: # 训练模式下，重复输入数据 x = x.repeat_interleave(self.config.num_experts_per_tok, dim=0) y = torch.empty_like(x, dtype=torch.float16) for i, expert in enumerate(self.experts): y[flat_topk_idx == i] = expert(x[flat_topk_idx == i]).to( y.dtype ) # 确保类型一致 y = (y.view(*topk_weight.shape, -1) * topk_weight.unsqueeze(-1)).sum(dim=1) y = y.view(*orig_shape) Inferencing 我们来考察前向传播过程。 提取出 x (输入的 Batch of sequence of tokens) 的维数信息之后，先经由 self.gate(x) 计算每一个 token 对应的专家，然后直接拍成 a sequence of tokens (BS,H)(BS,H)(BS,H)，topk_idx 则直接拍成 (BSK,)(BSK,)(BSK,) 1234567identity = xorig_shape = x.shapebsz, seq_len, _ = x.shape# 使用门控机制选择专家topk_idx, topk_weight, aux_loss = self.gate(x)x = x.view(-1, x.shape[-1])flat_topk_idx = topk_idx.view(-1) 随后进入 y = self.moe_infer(x, flat_topk_idx, topk_weight.view(-1, 1)).view(*orig_shape) 进行计算。 这里 .argsort() 的逻辑是：因为 flat_expert_indices 的值是专家的编号，通过 argsort()，idxs 把同一个专家要处理的 token 下标聚集到一起。 tokens_per_expert 以前缀和的方式，计算每一个专家处理的 token 下标的范围。 token_idxs 从 idxs 出发计算某一个 idxs[i] 对应的是第 token_idxs[i] 个 token。这是因为每一个 token 都会分给 top KKK 个专家，因此从下标来说，i∗K→(i+1)∗K−1i*K\\to (i+1)*K-1i∗K→(i+1)∗K−1 (idxs 保存的正好都是下标) 对应的都是第 iii 个 token，因此直接整数出除法可以计算出对应第几个 token. 123456@torch.no_grad()def moe_infer(self, x, flat_expert_indices, flat_expert_weights): expert_cache = torch.zeros_like(x) idxs = flat_expert_indices.argsort() tokens_per_expert = flat_expert_indices.bincount().cpu().numpy().cumsum(0) token_idxs = idxs // self.config.num_experts_per_tok 接着，我们枚举每一个专家，拿出它需要处理的所有 tokens (即代码里的 token_idxs[start_idx : end_idx] 以及 x[exp_token_idx]) 我们把这些 token 经过 expert(expert_tokens) 计算、输出，得到 expert_out，乘上（对于这个 token 而言）每一个 expert 的权重。通过 scatter_add_()，expert_cache 包含了每个 token 位置的加权专家输出总和。 123456789101112131415for i, end_idx in enumerate(tokens_per_expert): start_idx = 0 if i == 0 else tokens_per_expert[i - 1] if start_idx == end_idx: continue expert = self.experts[i] exp_token_idx = token_idxs[start_idx:end_idx] expert_tokens = x[exp_token_idx] expert_out = expert(expert_tokens).to(expert_cache.dtype) expert_out.mul_(flat_expert_weights[idxs[start_idx:end_idx]]) # 使用 scatter_add_ 进行 sum 操作 expert_cache.scatter_add_( 0, exp_token_idx.view(-1, 1).repeat(1, x.shape[-1]), expert_out )return expert_cache 除此之外，还需要加上共享专家的输出。不过这里的话，如果在推理模式，self.aux_loss 其实没作用 1234if self.config.n_shared_experts is not None: y = y + self.shared_experts(identity)self.aux_loss = aux_lossreturn y"},{"title":"Attention 中的 KV Cache","path":"/wiki/llm/attn-kv-cache.html","content":"KV Cache KV Cache（键值缓存）是 Transformer 模型推理优化中的核心技术，其核心思想是缓存 Attention 机制中已计算的 Key 和 Value 矩阵，避免重复计算，从而减少计算量并提升推理效率。"},{"title":"Transformer 架构","path":"/wiki/llm/classic-transformer.html","content":"Before Transformer: RNN, Attention 在 RNN 里，我们用一个隐藏变量 hth_{t}ht​ 记录前 ttt 个 Input Token 所代表的 Context。如果要生成第 t+1t+1t+1 个 Output Token 的话，就利用输入的第 t+1t+1t+1 个 Input Token 和代表了前文信息的隐藏状态 hth_{t}ht​ 做 Attention Alignment 计算出一个向量，再转换成 Word. 这样一个 AutoRegressive 模型有两个显著的问题 由于是时序生成（必须一个一个 Token 地生成），无法并行 由于时序生成，如果要保存很久远的信息，隐藏状态 hth_tht​ 的大小就必须非常大，导致了 Computation &amp; Memory Overhead Model Arch Transformer 总体是 Encoder-Decoder 架构。Encoder 将 Input 杂谈 其实 Transformer 的本质也是概率统计模型，其生成过程就是给定前 iii 个词的情况下生成第 i+1i+1i+1 个词；训练过程的 Loss Function 是 max⁡∑ilog⁡Pθ(wi∣wi−k,…,wi−1) \\max \\sum_i \\log P_\\theta(w_i|w_{i-k},\\dots,w_{i-1}) maxi∑​logPθ​(wi​∣wi−k​,…,wi−1​)这里的 kkk 其实就是 Context Length 的意思。"},{"title":"Decoder-Only Transformer","path":"/wiki/llm/decoder-only-transformer.html","content":"Decoder-only Transformers Decoder-only 架构通常用于生成任务，代表作包括 GPT，GPT-2 等。 什么是生成任务 简单来说，Decoder-only 解决的生成任务是指：给定前 nnn 个单词 x1,x2,…,xnx_1,x_2,\\dots,x_nx1​,x2​,…,xn​，要求输出第 n+1n+1n+1 个单词。可以看出，这类生成任务的本质是 AutoRegressive 的。 近年来，出现了使用 Diffusion 作为 Language Model 的生成，达到了极快的生成速度。"},{"title":"RoPE 旋转位置编码","path":"/wiki/llm/rotary-emb.html","content":"RoPE RoPE 的出发点是：通过绝对位置编码的方式实现相对位置编码 什么意思呢？比如说考虑某个英文词组总是以 A xx yy B 的形式出现，但是出现位置有可能是 1,2,3,4、也可能是 10,11,12,13，RoPE 就可以只通过这些单词的下标计算出代表相对位置的 embedding."},{"title":"Self Attention","path":"/wiki/llm/self-attn.html","content":"Self Attention 所谓的 Self Attention 其实只是 Q=K=VQ=K=VQ=K=V 的一种特例 Self-Attn(X)=Attention(X,X,X) \\text{Self-Attn}(X)=\\text{Attention}(X,X,X) Self-Attn(X)=Attention(X,X,X)直觉理解的话，可以认为是在句子的内部做 Attention，寻找句子内部的联系。"},{"title":"Tokenizer, BPE 算法","path":"/wiki/llm/tokenizer-bpe.html","content":"Byte-Pair Encoding 算法 Byte-Pair Encoding（BPE）算法是一种常用于分词器（Tokenizer）中的无监督分词方法，其主要思想是将文本中最常见的字符对（或子词对）不断合并，从而构建出一个词汇表。由于进行多轮 （假设 kkk 轮）合并，而每一次合并都会基于统计频率将一对 Token 合并为一个新 Token，因此在 kkk 轮迭代后，BPE 算法可以将长度为 kkk 的单词合并为一个 Token 将输入的文本转化为 UTF-8 Encoding 统计 Byte-Pair 的频率 计算频率最高的 Byte-Pair，合并为一个新的 Token 用新的 Token 替换旧 Byte-Pair 出现的位置 回到第 222 步，重新统计 Byte-Pair (Token-Pair) 频率 直到词汇表大小达到预设值 BPE 算法通过这种逐步合并的方式，不仅能有效地表示常见词汇，还能灵活处理低频词和新词，对于大型语言模型的分词和词表构建有很大的优势。 BPE 代码实现"},{"title":"Tokenizer 分词器","path":"/wiki/llm/tokenizer.html","content":"Tokenizer Tokenizer 在 LLM（大型语言模型）的上下文中指的是负责将输入文本分解成称为 tokens 的更小单元的组件。这些 tokens 是模型处理的基本元素（例如单词、子词或字符）。Tokenizer 将原始文本转换为模型可以处理的数字表示，并且在处理之后，还能将 tokens 转换回人类可读的文本。 Hugging Face Tokenizer: tokenizer.json"},{"title":"Attention 机制","path":"/wiki/llm/vanilla-attn.html","content":"Attention 机制 Attention 机制的直观理解就是：给定字典 D={K,V}D=\\{K,V\\}D={K,V}，和一个 Token QQQ。Attention 基于一个朴素的理解，例如英语里，如果两个单词长得差不多，那么语义应该也差不多（也就是词性变换）。如果可以量化出相似度，那么我们就可以一定程度上可以表示出这个单词的意思 对于 Token 而言，其都是长度为 ddd 的词向量，不同的相似度计算方式会产生不同的 Attention 计算公式。一般而言，可以写成下面这种形式 Attention(Q,K,V)=score(Q,K)⋅V \\text{Attention}(Q,K,V)=\\text{score}(Q,K)\\cdot V Attention(Q,K,V)=score(Q,K)⋅V这里，如果字典的大小为 mmm，查询 nnn 个词，每个词的 Embedding 维度为 ddd，代表“意义”的 Value 的维度为 dvd_vdv​，则这三个矩阵的大小分别为 Q∈Rn×dK∈Rm×dV∈Rm×dv Q\\in \\R^{n\\times d}\\\\ K\\in \\R^{m\\times d}\\\\ V\\in \\R^{m\\times d_v} Q∈Rn×dK∈Rm×dV∈Rm×dv​例如经典的 Scaled Dot Product Attention，其 score function 就是 softmax(QKTd)\\text{softmax}(\\frac{QK^T}{\\sqrt d})softmax(d​QKT​) Attention(Q,K,V)=softmax(QK⊺d)⋅V \\text{Attention}(Q,K,V)=\\text{softmax}\\Big( \\frac{QK^\\intercal}{\\sqrt{d}} \\Big)\\cdot V Attention(Q,K,V)=softmax(d​QK⊺​)⋅V"},{"title":"Comparative Statics","path":"/wiki/microecon/comparative-statics.html","content":"Change of Demand Curve 令 xxx 表示商品，那么其 Demand Curve 可以表示为 Qxd=a+bPxd+… Q^d_x=a+bP^d_x+\\dots Qxd​=a+bPxd​+… Increase in Demand 直线向右上移动，可以是向上平移，也可以是向右平移 Movement 影响因素：Income Normal Good Income↑ ⟹ Qxd↑\\text{Income}\\uparrow \\implies Q^d_x\\uparrowIncome↑⟹Qxd​↑ Inferior Good Income↑ ⟹ Qxd↓\\text{Income}\\uparrow \\implies Q^d_x\\downarrowIncome↑⟹Qxd​↓ 影响因素：Population 影响因素：Price of Substitutes Psubstitute↑ ⟹ Qxd↑ P_{\\text{substitute}}\\uparrow \\implies Q^d_x\\uparrow Psubstitute​↑⟹Qxd​↑当其他平替的价格上涨，消费者自然而然会转向价格更低的 xxx 影响因素：Price of Complement Pcomplement↑ ⟹ Qxd↓ P_{\\text{complement}}\\uparrow \\implies Q^d_x\\downarrow Pcomplement​↑⟹Qxd​↓ 影响因素：Expectation The expectation of a higher (lower) price for a good in the future increases (decreases) current demand for the good. 影响因素：Tastes Supply Movement of Supply Curve Increase in Supply Technology Entry implies more sellers in the market increasing supply. Exit implies fewer sellers in the market decreasing supply. Sellers will supply less of a good if the price of an alternate good using the same inputs rises (and vice versa). (-)"},{"title":"Cost Benefit Analysis","path":"/wiki/microecon/cost-benefit.html","content":"Rational Decision 对每一件事进行衡量，其付出为 C(x)C(x)C(x)，获得为 B(x)B(x)B(x)，那么定义 Economic Surplus ES(x)ES(x)ES(x) 为 ES(x)=B(x)−C(x) \\boxed{ES(x)=B(x)-C(x)} ES(x)=B(x)−C(x)​Cost Benefit Principle当且仅当 ES(x)≥0ES(x)\\ge 0ES(x)≥0 时，才会做 xxx，此时收益大于付出；否则不做。 Cost/Benefit 只包含会影响被决策的 Cost 和 Benefit Sunk Cost Marginal(Additional) Cost/Benefit Only if Marginal Benefit≥Marginal Cost \\text{Marginal Benefit}\\ge\\text{Marginal Cost} Marginal Benefit≥Marginal Cost Allocation of Resources 优先分配给 Marginal Benefit 多的 Opportunity Cost 所有不选的选项里，Economic Surplus(不选的选项的 Cost = Benefit，没有这部分的开销了) 最大的那个"},{"title":"竞争下的 Cost 与 Profit Maximization","path":"/wiki/microecon/cost-maxprofit-under-competition.html","content":"大前提 在完全竞争的市场下，任何一家企业都无法操控市场价格，只能根据市场价格调整自身的产量。即市场价格决定每一家企业的定价。 逻辑 由于企业无法操控市场价格，如果企业的定价高于市场价格，那么消费者必然转向其替代品；如果企业定价低于市场价格 企业运行的驱动动力：利益 企业必然追求利益。当产量为 QQQ 时，利润 Profit π(Q)\\pi(Q)π(Q) 定义为 π(Q)=TR(Q)−TC(Q) \\boxed{\\pi(Q)=TR(Q)-TC(Q)} π(Q)=TR(Q)−TC(Q)​这里的 Total Cost TC(Q)TC(Q)TC(Q) 包含 explicit cost 和 implicit cost. Economic Profit 与 Accounting Profit 这两个概念会在分析长期行为时提到，简而言之 Economic Profit 需要包含 Implicit Cost Accounting Profit 则不需要包含 后文提到的 Profit 若无特殊说明都是指 Economic Profit. 利益最大化 根据 Cost-Benefit Analysis，利润最大化的时候对应的产量 Q∗Q^\\astQ∗ 必然有 MR(Q∗)=MC(Q∗) MR(Q^\\ast)=MC(Q^\\ast) MR(Q∗)=MC(Q∗)而且，此处的 MRMRMR 恒等于市场价格，即 MR(Q∗)=PMR(Q^\\ast)=PMR(Q∗)=P。因此，在完全竞争的市场下，总是有 P=MC(Q∗) \\boxed{P=MC(Q^\\ast)} P=MC(Q∗)​ 企业的成本 分为两种： 固定成本 (Fixed Cost)：短期内无法改变 Quantity，例如生产机器、办公楼等等 可变成本 (Variable Cost)：短期内可以改变 QUantity，例如劳动力、生产原料等等 在后面分析企业行为的时候也会用到这两个概念。简单来说，如果考察企业的短期行为，由于固定成本可以看作是已经产生费用，因此应当看作 Sunk Cost，不应参与短期行为决策；但对于长期行为而言，也应将固定成本考虑进去。 企业的市场行为 既然要赚取利益，那么企业是否继续参与市场必然与 Profit 有关。当 π(Q∗)&lt;0\\pi(Q^\\ast)\\lt 0π(Q∗)&lt;0 时，企业的利润小于零，企业会选择退出市场；否则就有利可图，会继续参与市场。 也可以理解为 π(Q=Q∗)\\pi(Q=Q^\\ast)π(Q=Q∗) 与 π(Q=0)\\pi(Q=0)π(Q=0) 之间进行比较 短期行为 从短期来看，企业的 Fixed Cost 不应计入决策过程，企业是否退出市场取决于利润 π(Q∗)≥π(0)TR(Q∗)−TC(Q∗)≥TR(0)−TC(0)PQ∗−TVC(Q∗)−TFC≥0−TVC(0)−TFCPQ∗≥TVC(Q∗) \\begin{aligned} \\pi(Q^\\ast)&amp;\\ge \\pi(0)\\\\ TR(Q^\\ast)-TC(Q^\\ast)&amp;\\ge TR(0)-TC(0)\\\\ PQ^\\ast-TVC(Q^\\ast)-TFC&amp;\\ge 0-TVC(0)-TFC\\\\ PQ^\\ast&amp;\\ge TVC(Q^\\ast)\\\\ \\end{aligned} π(Q∗)TR(Q∗)−TC(Q∗)PQ∗−TVC(Q∗)−TFCPQ∗​≥π(0)≥TR(0)−TC(0)≥0−TVC(0)−TFC≥TVC(Q∗)​所以有 P≥AVC(Q∗) \\boxed{P\\ge AVC(Q^\\ast)} P≥AVC(Q∗)​因此从短期来看，企业是否会退出市场，取决于市场价格（会影响收入）和自身生产的平均可变成本 (Average Variable Cost, AVC)。此时的利润为 π(Q∗)=(P−AC)×Q∗ \\boxed{\\pi(Q^\\ast)=\\Big( P-\\textcolor{red}{AC} \\Big)\\times Q^\\ast} π(Q∗)=(P−AC)×Q∗​ 注意！ 计算利润时要注意包含 Fixed Cost。只有在做决策时才不计算 FC. 曲线的性质 MC 曲线总是和 AVC 曲线交于 AVC 曲线的最低点。 证明 略。 进一步的，我们可以推断，企业短期内的生产曲线 Supply Curve 由 MC Curve 和 Shutdown Decision 共同决定。 Supply Curve 长期行为 对于长期而言，Fixed Cost 此时也应该算入（例如办公楼续约费可以视为支出）。类似的，应有 P≥AC(Q∗) \\boxed{P\\ge AC(Q^\\ast)} P≥AC(Q∗)​当且仅当市场价格高于平均成本（含固定成本），企业才会考虑进入市场（不然无法收回固定成本）。 合并来看，Supply Curve 差不多长这样： Aggregate Supply Curve 例题 2020 Spring Final 题目 There are many identical firms (having the same production costs and producing the same product) in a competitive market. Their product is assumed to be perfectly divisible. When one firm produces qqq units, its marginal cost is MC(q)=qMC(q) = qMC(q)=qand the corresponding total variable cost is TVC(q)=0.5q2TVC(q) = 0.5q^2TVC(q)=0.5q2The demand curve in the market is Q=9000−90PQ = 9000 - 90PQ=9000−90PMoreover, assume that the industry is constant cost. The market is currently in a long-run equilibrium, and the equilibrium price is $45\\$45$45 per unit. Using the information, we conclude that there are [ Answer36 ] firms in the market. Using this information, we conclude that the fixed cost of an individual firm is [ Answer37 ] dollars. Using this information, we conclude that the short-run supply curve of this industry is of the form Q=A+B×PQ = A + B \\times PQ=A+B×Pwhere AAA is equal to [ Answer38A ], and BBB is equal to [ Answer38B ] Suppose now the market demand has become Q=15300−153PQ = 15300 - 153PQ=15300−153PUsing the information, we can calculate that in the long run, an individual firm will produce [ Answer39 ] units. 解答 Question Bank Q1 Determine whether the following statements about a perfectly competitive market are TRUE OR FALSE. Statement 1: The demand curve facing the market is horizontal. Statement 2: Entry of new firms will drive the accounting profits of the existing firms to zero in the long run. 【解答】False, False 【解说】对于 Statement 1，完全竞争市场的 Demand Curve 应该是 Downward Sloping 的。陈述错误。 对于 Statement 2，长期来看，完全竞争市场下，企业的 Economic profit 会趋于 000，但是 Accounting profit 相比 Economic profit 无须考虑 implicit cost，因此即使 economic profit 为 000，accounting profit 依旧可能 &gt;0\\gt 0&gt;0。因此陈述错误。 Q2 Determine whether the following statements are TRUE OR FALSE. Statement 1: Competitive firms can still earn positive accounting profits in the long run. Statement 2: A higher total cost to a firm must imply a lower level of output. 【解答】True, False 对 Statement 1 的解说见 Q1 statement 2 对于 statement 2，因为 Total cost=Variable Cost+Fixed Cost \\text{Total cost}=\\text{Variable Cost}+\\text{Fixed Cost} Total cost=Variable Cost+Fixed Cost如果 Fixed cost 增加，那么短期内企业仍然会维持产量。因此陈述错误。 Q3 Suppose the government reduces a commercial registration fee for all firms in a competitive industry. Evaluate whether the following statements are TRUE or FALSE. Statement 1: A typical firm of the industry will raise its output in the short run. Statement 2: A typical firm of the industry will see an increase in producer surplus in the short run. 题目减少的是 fixed cost，对于 short run 没有影响。 生产者剩余=总收益−可变成本 \\text{生产者剩余}=\\text{总收益}-\\text{可变成本} 生产者剩余=总收益−可变成本 Q4 The government invested $10 million in an infrastructure project two years ago. The amount of money was spent on wages and material costs, which cannot be recovered. This year, the government realizes that she needs to invest another $4 million in the project because of construction delays, while the $11 million expected revenue remains unchanged and can only be generated upon the completion of the project. The government should ________ the additional budget because ________. Select one: a. approve; the project can generate positive revenue. b. approve; marginal benefit of the extra payment is greater than its marginal cost. c. disapprove; the cost is higher than expected d. disapprove; the government will suffer from a $3 million loss. 【解答】B 【解说】A 为什么错误呢？分析应该基于边际成本与收益。 Q5 There are 100100100 firms in a perfectly competitive decreasing cost industry at the long-run equilibrium. A typical firm faces the following cost curves (qqq is firm quantity, nnn is number of firms): Average Variable Cost ($): AVC=q+50AVC=q+50AVC=q+50 Marginal Cost ($): MC=2q+50MC=2q+50MC=2q+50 Fixed Cost ($): FC=810000/nFC=810000/nFC=810000/n What are the market price and market quantity? Select one: a. $230\\$230$230, 900090009000 units b. $15.5\\$15.5$15.5, 810081008100 units c. $155\\$155$155, 818181 units d. $230\\$230$230, 909090 units 长期平衡的话，考虑 TC=TVC+TFCTC=TVC+TFCTC=TVC+TFC，AC=AVC+AFCAC=AVC+AFCAC=AVC+AFC。这里，单个企业的 Total Fixed Cost 为 8.1×105100=8100\\frac{8.1\\times 10^5}{100}=81001008.1×105​=8100，因此平均固定成本为 AFC=8100qAFC=\\frac{8100}{q}AFC=q8100​，因此平均总成本为 AC=AVC+AFC=q+50+8100q AC=AVC+AFC=q+50+\\frac{8100}{q} AC=AVC+AFC=q+50+q8100​考虑市场价格，对于单个企业有 MC=ACMC=ACMC=AC，因此 q=90,p=230q=90,p=230q=90,p=230。 这里要求市场上总的产量，因此 Q=nq=9000Q=nq=9000Q=nq=9000 units. Q6 (2020 Spring Final Exam Q31-34) The market of fortune cookies is perfectly competitive. John’s Fortune Cookies is one of the many perfectly competitive firms. Assume that the only variable input required for the production is workers. The following table shows the relationship between the number of workers hired and the total output (packs of fortune cookies produced). # of workers Total output (packs) 1 98 2 183 3 264 4 330 5 391 6 441 7 482 8 517 9 536 10 552 John pays a fixed cost of $380 per day, and to each employee a wage of $54 per day. The price of fortune cookies is $1.14 per pack. Given such information, we can calculate the marginal product due to the 3-rd worker is [Answer1]. Given such information, in the short run, John should hire [Answer2] workers. Given such information, in the short run, John should [Answer3] packs of fortune cookies. Consequently, in the short run, John will make a profit of [Answer4] dollars. Suppose the fixed cost has become $570 per day. In the short run, John should hire [Answer5] workers. 【解答】 决定产量的时候不需要考虑 fixed cost，但是计算利润的时候还是要计算固定成本的。 Q7 (2020 Spring Final Exam Q36-39) There are many identical firms (having the same production costs and producing the same product) in a competitive market. Their product is assumed to be perfectly divisible. When one firm produces qqq units, its marginal cost is MC(q)=qMC(q) = qMC(q)=qand the corresponding total variable cost is TVC(q)=0.5q2TVC(q) = 0.5q^2TVC(q)=0.5q2The demand curve in the market is Q=9180−90PQ = 9180 - 90PQ=9180−90PMoreover, assume that the industry is constant cost. The market is currently in a long-run equilibrium, and the equilibrium price is $45 per unit. Using the information, we conclude that there are [Answer1] firms in the market. Using this information, we conclude that the fixed cost of an individual firm is [Answer2] dollars. Using this information, we conclude that the short-run supply curve of this industry is of the form Q=A+B×PQ = A + B \\times PQ=A+B×P AAA is equal to [Answer3]. BBB is equal to [Answer4]. Suppose now the market demand has become Q=15300−150PQ = 15300 - 150PQ=15300−150P Using the information, we can calculate that in the long run, an individual firm will produce [Answer5] units. 【解答】 对于单个企业而言，其 supply curve 就是 MC curve，也就是单个企业的 P−QP-QP−Q 曲线为 q=0+1Pq=0+1Pq=0+1P，但是这里题目要的是社会总产量 Q=nqQ=nqQ=nq，因此 Q=0+114PQ=0+114PQ=0+114P Q8 In a perfectly competitive constant cost industry, all firms are identical. A typical firm possesses the cost curves: TC=q2+80q+100TC=q^2+80q+100TC=q2+80q+100 MC=2q+80MC=2q+80MC=2q+80 (q is firm quantity). The market demand is P=1100−QP=1100-QP=1100−Q (Q is market quantity). The industry is initially at the long-run equilibrium. (a) A typical firm will shut-down and produce zero quantity in the short run if the price is lower than [Answer1] dollars. (Hint: P_shutdown = min AVC) A typical firm will exit from the industry in the long run if the price is lower than [Answer2] dollars. (Hint: P_exit = min AC, where MC=AC). (b) At initial long-run equilibrium, the price is [Answer3] dollars. (Hint: What is the relationship between long-run equilibrium price and firm exit price?) At initial long-run equilibrium, each firm produces [Answer4] units. © At initial long-run equilibrium, there are [Answer5] firms in the market. (Hint: number of firms = market quantity / firm quantity.) (d) Because of change in environmental regulation that affects production cost, the marginal cost is reduced by 17 dollars but the fixed cost is increased by 300 dollars permanently. The post-regulation short-run supply curve of this industry is: P=A+B×QP = A + B \\times QP=A+B×Qwhere A is equal to [Answer6]. (Hint: What will be the new MC curve?) Continue above, B is equal to [Answer7]. (e) At the post-regulation short-run equilibrium, the price is [Answer8] dollars. At the post-regulation short-run equilibrium, each hotel produces [Answer9] units. At the post-regulation short-run equilibrium, each firm earns a profit of [Answer10] dollars. (Hint: What will be the new TC curve?) (f) With free entry and exit of firms, at the post-regulation long-run equilibrium, the price will be [Answer11] dollars. At the post-regulation long-run equilibrium, there will be [Answer12] firms in the market. (h) Suppose the government wants to induce the market to generate a post-regulation long-run equilibrium quantity the same as the pre-regulation long-run equilibrium quantity. The government should impose per-unit subsidy of [Answer13] dollars. 【解答】 分析 MCMCMC 的表达式，发现当 shutdown 即 q=0q=0q=0 时，对应的价格为 808080，也就是说当价格低于 808080 企业就会选择不生产。因此短期 shutdown price 为 808080. exit price 的话只需要列出方程即可，即 AVC=MCAVC=MCAVC=MCq2+80q+100q=2q+80 \\frac{q^2+80q+100}{q}=2q+80 qq2+80q+100​=2q+80解得 q=10q=10q=10，所以 exit price 为 2q+80=1002q+80=1002q+80=100. 长期平衡价格等于企业 exit price 上面刚刚解出来的 q=10q=10q=10 代入 Demand curve 可知，市场总产量为 Q=1000Q=1000Q=1000，因此，总共有 n=Qq=100n=\\frac{Q}{q}=100n=qQ​=100 家企业 (7.) Marginal Cost 降低 171717 而 fixed cost 增加 300300300，于是，MCMCMC 和 TCTCTC 变成了MC=2q+63TC=q2+63q+400 MC=2q+63\\\\ TC=q^2+63q+400 MC=2q+63TC=q2+63q+400从 P=MC=2q+63P=MC=2q+63P=MC=2q+63 和 q=Qnq=\\frac{Q}{n}q=nQ​，可知 P=0.02Q+63P=0.02Q+63P=0.02Q+63，所以 A=63A=63A=63 B=0.02B=0.02B=0.02 联立 P=0.02Q+63P=0.02Q+63P=0.02Q+63 和 P=1100−QP=1100-QP=1100−Q，可知 Q=1017.67,P=83.33Q=1017.67,P=83.33Q=1017.67,P=83.33 由于 Q=1017.67Q=1017.67Q=1017.67，由于市场刚刚变化，因此此时还不会有企业退出，所以 q=Q/n=10.17q=Q/n=10.17q=Q/n=10.17 把 q=10.17q=10.17q=10.17 代入，Profit=Pq−TC=−296.67\\text{Profit}=Pq-TC=-296.67Profit=Pq−TC=−296.67 h. 最后可以分析出来原来的长期市场价格为 100100100 而当前为 103103103，在 Demand Curve 上我们可以发现，要想让 Q′Q&#x27;Q′ 恢复到 QQQ 的水平，长期均衡的价格必须是 100100100，但是企业现在的 ACACAC 最低点是 103103103，需要降到 100100100. 因此需要补贴 103−100=3103-100=3103−100=3 块钱。"},{"title":"Elasticity 弹性","path":"/wiki/microecon/elasticity.html","content":"弹性 量化某个变量随着另一个变量的变化而变化的程度 弹性大：因变量对自变量的变化很敏感 弹性小：因变量对自变量的变化不怎么敏感 Price Elasticity of Demand 量化 PED=percentage change in Quantity demandedpercentage change in Price=%ΔQd%ΔP PED=\\frac{\\textbf{percentage}\\text{ change in Quantity demanded}} {\\textbf{percentage}\\text{ change in Price}}=\\boxed{\\frac{\\%\\Delta Q^d}{\\%\\Delta P}} PED=percentage change in Pricepercentage change in Quantity demanded​=%ΔP%ΔQd​​ 两点 PED 计算公式 我们用中点代为计算 Percentage Change Percentage=New−Old(New+Old)/2 \\text{Percentage}=\\frac{\\text{New}-\\text{Old}}{(\\text{New+Old})/2} Percentage=(New+Old)/2New−Old​那么 PEDPEDPED 的计算公式可以改写成 PED=Qnewd−QolddPnew−Pold×Pnew+PoldQnewd+Qoldd \\boxed{ PED=\\frac{Q^d_{new}-Q^d_{old}}{P_{new}-P_{old}}\\times \\frac{P_{new}+P_{old}}{Q^d_{new}+Q^d_{old}} } PED=Pnew​−Pold​Qnewd​−Qoldd​​×Qnewd​+Qoldd​Pnew​+Pold​​​当某个点 oldoldold 已经被固定了的时候，考虑其差值 ΔQ→0\\Delta Q\\to 0ΔQ→0，就有 PED=ΔQdΔP×2Pold+ΔP2Qoldd+ΔQd→ΔQdΔP×PoldQoldd→PQd×1slope \\begin{aligned} PED&amp;=\\frac{\\Delta Q^d}{\\Delta P}\\times \\frac{2P_{old}+\\Delta P}{2Q^d_{old}+\\Delta Q^d}\\\\ &amp;\\to \\frac{\\Delta Q^d}{\\Delta P}\\times\\frac{P_{old}}{Q^d_{old}}\\\\ &amp;\\to \\boxed{\\frac{P}{Q^d}\\times \\frac{1}{\\text{slope}}} \\end{aligned} PED​=ΔPΔQd​×2Qoldd​+ΔQd2Pold​+ΔP​→ΔPΔQd​×Qoldd​Pold​​→QdP​×slope1​​​ Observation Price Elasticity 随着点在 Quantity of Demand 曲线上的移动而变化；并且在中点处为 −1-1−1，往上 &lt;−1\\lt -1&lt;−1，往下 &gt;−1\\gt -1&gt;−1 如果两条 QdQ^dQd 曲线有交点，那么更加平缓的那条直线在这个点上的弹性更大。 Elasticity 与 Revenue 收入基本公式 Revenue=Quantity×Price \\text{Revenue}=\\text{Quantity}\\times\\text{Price} Revenue=Quantity×Price因此考虑 Elasticity 的话，Revenue 是关于 Price 的二次函数，并且在 PED=−1PED=-1PED=−1 的时候，取到最大值 弹性需求（∣η∣&gt;1∣\\eta∣&gt;1∣η∣&gt;1）：降价增加总收益（需求量增幅 &gt;&gt;&gt; 价格降幅）。 非弹性需求（∣η∣&lt;1∣\\eta∣&lt;1∣η∣&lt;1）：降价减少总收益（需求量增幅 &lt;&lt;&lt; 价格降幅）。 单位弹性（∣η∣=1∣\\eta∣=1∣η∣=1）：总收益最大。 也可以在 QdQ^dQd 直线上直观地进行比较：找到点变化前后对应的矩形变化面积。更一般的，如果点在中点上方，则总收益一定增加；在下方则总收益减少。 Constant Elasticity 如果一条曲线在每一个点的 PPP Elasticity of QQQ 都相等为 −k-k−k，那么其曲线可以表示为 f(P,Q):PkQ=C f(P,Q):\\boxed{P^{\\textcolor{red}{k}}Q=C} f(P,Q):PkQ=C​ 证明（不考） 考虑 Q-P 曲线 fff 在这一个点的 Elasticity，用点斜式即为 Elasticity=−k=PQ×dQdP \\text{Elasticity}=-k=\\frac{P}{Q}\\times\\frac{dQ}{dP} Elasticity=−k=QP​×dPdQ​把 xdxx\\mathop{dx}xdx 放到一起： −kPdP=1QdQ -\\frac{k}{P}\\mathop{dP}=\\frac{1}{Q}\\mathop{dQ} −Pk​dP=Q1​dQ两边积分 −kln⁡P+CP=ln⁡Q+CQln⁡Q+kln⁡P=cPkQ=C \\begin{aligned} -k\\ln{P}+C_P&amp;=\\ln{Q}+C_Q\\\\ \\ln Q+k\\ln P&amp;=c\\\\ P^kQ&amp;=C \\end{aligned} −klnP+CP​lnQ+klnPPkQ​=lnQ+CQ​=c=C​ 左右取对数，曲线方程也可以写作 ln⁡Q=−kln⁡P+c \\boxed{ \\ln Q=\\textcolor{red}{-k} \\ln P+c } lnQ=−klnP+c​ 影响 Price Elasticity of Demand 的因素 Availability of Substitutes Time Horizon 产品有效期 Category of product (specific or broad) Necessities vs. Luxuries Purchase Size Substitutes Fewer substitutes makes it harder for consumers to adjust QQQ when PPP changes… so demand is more inelastic. Many substitutes? Switching brands when prices change is easy, so demand is more elastic. Time Horizon Category 另外两种 Elasticity Cross-Elasticity Exy=%ΔQd of X%ΔP of Y=PyQxd×ΔQxΔPy \\begin{aligned} E_{xy}&amp;=\\frac{\\%\\Delta Q^d \\text{ of X}}{\\%\\Delta P \\text{ of Y}}\\\\ &amp;=\\boxed{\\frac{P_y}{Q^d_x}\\times\\frac{\\Delta Q_x}{\\Delta P_y}} \\end{aligned} Exy​​=%ΔP of Y%ΔQd of X​=Qxd​Py​​×ΔPy​ΔQx​​​​Exy&gt;0E_{xy}&gt;0Exy​&gt;0 说明是 Substitute ；反之，说明是 complement Income Elasticity EI=%ΔQd%ΔIncome=IQx×ΔQxΔI \\begin{aligned} E_I&amp;=\\frac{\\%\\Delta Q^d}{\\%\\Delta \\text{Income}}\\\\ &amp;=\\boxed{\\frac{I}{Q_x}\\times\\frac{\\Delta Q_x}{\\Delta I}} \\end{aligned} EI​​=%ΔIncome%ΔQd​=Qx​I​×ΔIΔQx​​​​ EI&gt;1E_I\\gt 1EI​&gt;1 说明是 Luxury EI&gt;0E_I\\gt 0EI​&gt;0 说明是 Normal Goods EI&lt;0E_I\\lt 0EI​&lt;0 为 Inferior Goods Price Elasticity of Supply 类似的，也有中点公式和点斜公式 性质 PES&gt;0PES\\gt 0PES&gt;0 若截距 &gt;0\\gt 0&gt;0，那么随着 QsQ^sQs 增加，PESPESPES 降低，但永远 &gt;1\\gt 1&gt;1 若过原点，则 PES≡1PES\\equiv 1PES≡1 影响因素 Change in Per-Unit Costs with Increased Production Time Horizon Share of Market for Inputs Geographic Scope Elasticity and Quick Predictions 把基准点放在 Equilibrium Point，记 ηs\\eta_sηs​ 为 Price Elasticity of Supply，ηd\\eta_dηd​ 为 Price Elasticity of Demand，则有 % change in Price from a shift in Demand ΔQd=% change in Demand ΔQdηs+∣ηd∣% change in Price from a shift in Supply ΔQs=−% change in Supply ΔQsηs+∣ηd∣ \\begin{array}{rll} \\text{\\% change in \\textbf{Price} from a shift in \\textbf{Demand} }\\Delta Q^d\\\\ =\\frac{\\text{\\% change in \\textbf{Demand} }\\Delta Q^d}{\\eta_s+|\\eta_d|}\\\\ \\text{\\% change in \\textbf{Price} from a shift in \\textbf{Supply} }\\Delta Q^s \\\\ =\\textcolor{red}{-}\\frac{\\text{\\% change in \\textbf{Supply} }\\Delta Q^s}{\\eta_s+|\\eta_d|} \\end{array} % change in Price from a shift in Demand ΔQd=ηs​+∣ηd​∣% change in Demand ΔQd​% change in Price from a shift in Supply ΔQs=−ηs​+∣ηd​∣% change in Supply ΔQs​​ 例题 2024 Summer Suppose there is only an initial shift of demand or supply (but not both), and we observe that the equilibrium price of computers increases by 2.1%2.1\\%2.1%, and the equilibrium quantity increases by 8.1%8.1\\%8.1%, we conclude that: A) The price elasticity of demand is elastic. B) The price elasticity of demand is inelastic. C) The price elasticity of supply is elastic. D) The price elasticity of supply is inelastic. 解答 Price 和 Quantity 都上涨了，因此这一定是 Demand 增加引起的 (Demand Curve right shift)。 上涨的幅度由 Supply Curve 的斜率决定，这里 %ΔP=2.1%,%ΔQ=8.1%\\% \\Delta P=2.1\\%,\\% \\Delta Q=8.1\\%%ΔP=2.1%,%ΔQ=8.1%，所以 price elasitcity of supply 等于 Es=%ΔQ%ΔP&gt;1 E_s=\\frac{\\% \\Delta Q}{\\% \\Delta P}\\gt 1 Es​=%ΔP%ΔQ​&gt;1由此，price elasticity of supply 是 elastic 的。"},{"title":"externalities","path":"/wiki/microecon/externalities.html","content":"Market Failure total surplus (both of the consumer and producer) is maximized in free markets. The market equilibrium price and quantity are socially optimal… (1) when all relevant production costs are incurred by sellers (2) when all relevant consumption benefits accrue to buyers. Sometimes costs or benefits that result from an activity accrue to people not directly involved in the activity Ex ternal cost = a cost paid by people other than the consumer or the producer trading in the market Social cost = the cost to everyone o Social cost = private cost + external cost Deadw eight Loss is the welfare loss because of quantity traded deviating from social optimal level"},{"title":"Monopoly 垄断","path":"/wiki/microecon/monopoly.html","content":"垄断定义 拥有定价权 价格不受 Demand Quantity 影响 Profit Maximizing Rule 依然遵循利益最大化原则，对于垄断企业来说，只需要考虑在 Demand Curve 上找到 Marginal Revenue =0=0=0 的那个点即可。 Marginal Revenue 对于离散的 Quantity，有 MR(Q)=TR(Q)−TR(Q−1) MR(Q)=TR(Q)-TR(Q-1) MR(Q)=TR(Q)−TR(Q−1)对于连续的 Quantity，有 P(Q)=a−bQ ⟹ MR(Q)=a−2bQ P(Q)=a-bQ\\implies MR(Q)=a-2bQ P(Q)=a−bQ⟹MR(Q)=a−2bQ 证明 由于是连续性变量，考虑极小值 ΔQ\\Delta QΔQ 的 Marginal Revenue，则有 MR(Q)=lim⁡ΔQ→0(a−b(Q+ΔQ))(Q+ΔQ)−(a−bQ)QΔQ=a−2bQ \\begin{aligned} MR(Q)&amp;=\\lim_{\\Delta Q\\to 0}\\frac{\\Big(a-b(Q+\\Delta Q)\\Big)(Q+\\Delta Q)-(a-bQ)Q}{\\Delta Q}\\\\ &amp;=a-2bQ \\end{aligned} MR(Q)​=ΔQ→0lim​ΔQ(a−b(Q+ΔQ))(Q+ΔQ)−(a−bQ)Q​=a−2bQ​ Select Price 选定 Quantity 之后，根据 Demand Curve 计算 Price。 Price Elasticity of Demand 与 Monopoly Markup 完全竞争的市场里，无法有溢价，即必须满足 P=MCP=MCP=MC。但垄断市场里可以有溢价： P=ϵ1+ϵMCMarkup=P−MCMC=−11+ϵ P=\\frac{\\epsilon}{1+\\epsilon}MC\\\\ Markup=\\frac{P-MC}{MC}=\\frac{-1}{1+\\epsilon} P=1+ϵϵ​MCMarkup=MCP−MC​=1+ϵ−1​The More Inelastic the Demand Curve the More the Monopolist Raises Price Above Marginal Cost Welfare Analysis Producer Surplus FC=0 Monopoly Profit FC>0 政府干预 垄断企业相比其他企业，由于生产规模更大，其平均生产成本也更低，此时一定会将新入行的企业（其平均生产成本更高）挤出市场。 若政府设置价格上限…… 如果设置在 MCMCMC，垄断企业会退出市场，因为 AC&gt;MCAC&gt;MCAC&gt;MC。所以如果要让垄断企业留在行业内，最低的上限必须设置为 ACACAC. the price that corresponding to the same quantity Q∗Q^\\astQ∗ depends on the demand. 例题 Q1 A monopolist possesses the cost curves: TC=Q2+80Q+90000TC = Q^2 + 80Q + 90000TC=Q2+80Q+90000, MC=2Q+80MC = 2Q + 80MC=2Q+80. The market demand is P=1100−QP = 1100 - QP=1100−Q. (a) To maximize profit, the monopolist charges [Answer1]. (b) Continue above, the deadweight loss is [Answer2]. © If the government imposes a price ceiling at $700. The monopoly will earn a profit of [Answer3]. (Hint: Be careful with where MR(Q)&gt;=MC(Q)MR(Q) &gt;= MC(Q)MR(Q)&gt;=MC(Q) in price ceiling case.) (d) Suppose the government instead imposes a price ceiling to completely eliminate deadweight loss in the short run. The monopolist will earn a profit of [Answer4]. (e) Ignore price ceiling. Suppose the marginal cost of production is increased by $20 per unit sold. The monopolist will earn a profit of [Answer5]. (Hint: What are the new TC and MC curves?) (f) Suppose instead only the fixed cost of production is increased by $20000. The monopolist will produce earn a profit of [Answer6]. (Hint: What are the new TC and MC curves?) (g) Suppose instead the government provides a 20 per-unit subsidy to the monopoly. The monopolist will earn a profit of $[Answer7]. (Hint: What are the new TC and MC curves?) (h) Suppose instead the government provides a 20 per-unit subsidy to consumers. The monopolist will earn a profit of $[Answer8]. (i) Suppose instead the government wants to completely eliminate deadweight loss. It can do so by providing per-unit subsidy of [Answer9][Answer9][Answer9] to consumers."},{"title":"Price Ceiling/Floor","path":"/wiki/microecon/price-ceiling-floor.html","content":"Price Ceiling 价格上限在 P−QP-QP−Q 图像上表示为一条水平线 Ceiling Line 黑色实线为坐标轴，纵轴 PPP，横轴为 QQQ 橙色线表示 P=F(Qs)P=F(Q^s)P=F(Qs) 黄色线表示 P=F(Qd)P=F(Q^d)P=F(Qd) 蓝色线表示 Price Ceiling， 注意！ 只有当蓝色低于 Equilibrium 点的时候才需要额外分析，如果价格上限高于市场价，那么对于市场完全没有影响 于是此时我们可以看到，需求量远远大于供给量，于是在供给量固定的情况下，市场上的买家需要争夺这些稀缺的供给……我们来看四种情况 Bribery 第一种解决办法，加价/拍卖。Total Value of bribery 会计入 Surplus 中 Waiting in Line Total Value of Time，会算作损失 例题 2024 Summer Suppose the demand and supply of Cannabis in Neverland community are given as follows: Demand: P=930−589QP = 930 - 589QP=930−589Q Supply: P=180+2.5QP = 180 + 2.5QP=180+2.5Q In which PPP is the price per kg in thousand dollars and QQQ is the quantity in thousand kgs. Note: 1 thousand×(1 thousand)=1 million1 \\text{ thousand} \\times (1 \\text{ thousand}) = 1 \\text{ million}1 thousand×(1 thousand)=1 million 18. The unregulated equilibrium Cannabis price is [ Answer18A ] thousand dollars per kg and the equilibrium quantity is [ Answer18B ] thousand kgs. 19. Suppose the government purchases 101010 thousand kgs of Cannabis back from the market regardless of price. After the government enters the market, on the new market demand curve, when the price is 555555555 thousand dollars per kg, the total quantity demanded is [ Answer19 ] thousand kgs. 20. Suppose the government wants to use a buyback program to reduce the quantity of Cannabis traded in the community to zero. The government will need to buy at least [ Answer20A ] thousand kgs from the market and spend at least [ Answer20B ] million dollars. 21. Suppose the government wants to use a price floor to reduce the quantity of Cannabis traded in the community to zero. The government will need to implement a price floor of [ Answer21A ] (A. at most; B. at least) [ Answer21B ] thousand dollars per kg. 22. Knowing that the government is determined to reduce the quantity of Cannabis traded in the community to zero through either buyback or price floor, the Cannabis suppliers are actively thinking of lobbying the government for a policy they favor. The Cannabis suppliers as a group are willing to spend up to [ Answer22 ] million dollars to lobby the government to adopt the policy they favor. 解答 这一小问的核心在于，生产商是从这两个政策里选出最利于自己（收益最大化）的政策，也就是贿赂政府选择 buyback 政策。而 buyback 政策下，Producer Surplus 为 0.5×(930−180)×300=1125000.5\\times (930-180)\\times 300=1125000.5×(930−180)×300=112500 million，因此最多可以支付 112500112500112500 来贿赂政府。"},{"title":"Price Discrimination 价格歧视","path":"/wiki/microecon/price-discrimination.html","content":"Single-Price Monopoly Single-Price Monopoly（单一价格垄断）是指垄断企业在同一市场中对所有消费者收取相同价格的行为 仅考虑企业自身的利润，不考虑 Social Surplus. 价格歧视 本质目的还是为了提升利润。 First Degree (Perfect) Price Discrimination PPD: 企业对每位消费者收取不同的价格，等于其保留价格，完全提取消费者剩余（Consumer Surplus），将其转化为企业利润。此时 DWL=0DWL=0DWL=0 Q↑ ⟹ MB↓ ⟹ P↓ Q\\uparrow \\implies MB\\downarrow \\implies P\\downarrow Q↑⟹MB↓⟹P↓ Secodn Degree Price Discrimination (using Hurdles) Discrimination using Hurdles（使用障碍进行价格歧视） 是一种通过设置特定门槛或障碍，将市场分割为不同子市场，并对各子市场实施差异化定价的策略。 并非 Social Efficient，但是比 Single-Price Monopoly 好很多 DWL 分析 DWL Third Degree PD 根据可观察特征（如年龄、地区）划分市场，对不同子市场设定不同价格. 例题"},{"title":"Public Goods","path":"/wiki/microecon/public-goods.html","content":"Excludability and Rivalry Excludability: 排他性 Non-excludable goods: Cannot exclude non-payers (e.g., national defense, radio signals). Excludable goods: Can exclude non-payers (e.g., jeans, paid e-books). Rivalry: 竞争性 Rival goods : Use by one person reduces availability for others. Non-rival goods : One person’s use does not diminish availability for others. Excludability Rivalry Type Examples Excludable Rival Private Goods Jeans, hamburgers, gasoline Excludable Non-rival Nonrival Private Wi-Fi, satellite TV Non-excludable Rival Common Resources Timber in public land, bluefin tuna Non-excludable Non-rival Public Goods National defense, lighthouses 四种商品类型 Private Goods 可以直接高效地进入竞争市场 因为 rival，所以 excludable 不导致 inefficiency 因为 excludable，所以有 incentive 去消费和生产 经典微观经济学的假设： 所有生产成本由生产者承担 所有消费收益由消费者享受 Public Goods Under-provision : Free-rider problem leads to insufficient supply. Collective Action : Difficult to negotiate joint purchases, especially with large groups. 需要政府介入 Taxes to buy public goods (e.g., streetlights, highways). Optimal quantity determined where Marginal Social Benefit (MSB) = Marginal Social Cost (MSC) . MSB curve: 分段加和 Non-rival Private Common Resources 私人决策的低效性 个人在做决策的时候，指针方针仅考虑私人的边际收益和私人的边际成本 MB(Qi)≥MC(Qi) MB(Q_i)\\ge MC(Q_i) MB(Qi​)≥MC(Qi​)然而从社会的角度看，社会成本 === 私人成本 +++ 外部成本，导致市场均衡产量 QmktQ_{mkt}Qmkt​ 远大于社会均衡产量 QsocQ_{soc}Qsoc​. 为防止 Tragedy of the Commons 需要政府干预： 核心思想 当前的 quantity 为 QmktQ_{mkt}Qmkt​，其满足 MB(Qmkt)=MC(Qmkt) MB(Q_{mkt})=MC(Q_{mkt}) MB(Qmkt​)=MC(Qmkt​)既然想让它达到 QsocQ_{soc}Qsoc​ 的水平，那么我们可以列出两个式子 {MB(Qsoc)=MC(Qsoc)MC(Qsoc)=MC(Qmkt)+Extra Cost \\begin{cases} MB(Q_{soc})=MC(Q_{soc})\\\\ MC(Q_{soc})=MC(Q_{mkt})+\\text{Extra Cost} \\end{cases} {MB(Qsoc​)=MC(Qsoc​)MC(Qsoc​)=MC(Qmkt​)+Extra Cost​那么我们只需要限制 Extra Cost\\text{Extra Cost}Extra Cost 的范围即可。 通过税收干预 通过 Tradable Permit 干预 例题 2020 Fall Final Q1 Please refer to the background information below to answer the following three questions. Factory X produces 101010 tons of wastewater every day. Each ton of wastewater caused 17.517.517.5 (in thousand dollars) worth of damage to nearby residents. It costs the factory n2n^2n2 (in thousand dollars) to remove pollutants from nnn tons of wastewater. Suppose nnn can only take integer numbers. If pollution is unregulated and negotiation is impossible, Factory X will discharge [ Answer38 ] tons of untreated wastewater to the sea every day. It is socially efficient for Factory X to treat [ Answer39 ] tons of wastewater. Consider levying a tax on wastewater. In order to achieve the socially efficient outcome, the minimum amount of tax should be [ Answer40 ] thousand dollars per ton of wastewater. 【解答】 我们不妨 38. 由于工厂并不对环境污染负责，所以其 cost 仅由废水处理构成 arg min⁡xx2\\argmin_x x^2argminx​x2，所以 x=0x=0x=0，即不处理任何污水 考虑社会环境效益，假设工厂处理 xxx 吨废水，则社会的成本由废水处理和废水污染构成，即 arg min⁡xx2+17.5(10−x)\\argmin_x x^2+17.5(10-x)argminx​x2+17.5(10−x)，因为 x∈Zx\\in \\Zx∈Z 故 x=9x=9x=9 仅考虑工厂的成本，工厂的成本由废水处理和税构成，假设处理 xxx 吨废水其余排放，每吨废水收税 ppp，则成本为 arg min⁡xx2+p(10−x)\\argmin_x x^2+p(10-x)argminx​x2+p(10−x)，现在要求达到社会最大效益，即这个二次函数的最小值在 x=9x=9x=9 取到。所以解得 p≥17p\\ge 17p≥17 Q2 Please refer to the background information below to answer the following three questions. There is a small public beach in Utopia. The residents of Utopia, in total 20 of them, love to go to the beach but prefer not to when it is too crowded. In particular, if n people share the beach together, each individual gets an economic surplus of 10.5 − n dollars. Suppose n can only take integer numbers. If the residents make their decisions individually, then [ ] residents will go to the beach in equilibrium. The socially optimal number of beach occupants is [ ]. If the government charges an entrance fee of $2.62, [ ] residents will go to the beach in equilibrium."},{"title":"Supply Demand","path":"/wiki/microecon/supply-demand.html","content":"Demand Curve Normal good: When we have more income, we choose to buy more of the good. Inferior good: When we have more income, we choose to buy less of the good. Combination of Demand Curves Qtotald=Q1d+Q2d Q^d_{total}=Q^d_{1}+Q^d_2 Qtotald​=Q1d​+Q2d​ Supply Curve Horizontally: How many suppliers are willing and able to sell at a certain price. Vertically: The minimum price for which suppliers are willing to sell a certain quantity. Combination of Supply Curves Qtotals=Q1s+Q2s Q^s_{total}=Q^s_{1}+Q^s_2 Qtotals​=Q1s​+Q2s​ 计算 Equilibrium: Supply Curve 与 Demand Curve 的交点 Economic Surplus 这个 Surplus 可以这样理解：如果我预期 100100100 元买下，而我实际只花了 606060，那么其实我会觉得我赚了 100−60=40100-60=40100−60=40。 而在 Equilibrium 的情况下，交易价为 Equi Price，在 Demand Curve 上不同预期价（Price，纵坐标）有对应的人数（Quantity，横坐标，实际上应该是 ΔQ\\Delta QΔQ），因此对于这个预期价而言，他们获得的“赚了”感是 P×ΔQP\\times \\Delta QP×ΔQ 因此在下图的公式里，所有的 Surplus 是一个三角形 Total Economic Surplus=Consumer Surplus+Producer Surplus \\text{Total Economic Surplus}=\\text{Consumer Surplus}+\\text{Producer Surplus} Total Economic Surplus=Consumer Surplus+Producer Surplus如果 Economic Surplus &lt;0\\lt 0&lt;0 那么交易就不会发生 红色部分就是 Total Economic Surplus 分别计算 Consumer 和 Producer 的 Surplus"},{"title":"Tax and Subsidy","path":"/wiki/microecon/tax-subsidy.html","content":"本章最核心的理论是，无论税收或者补贴，假设为 TTT 元，那么当达到新的平衡点时，消费者支付价格与生产者成本价格之间的差值必为 TTT 元 Pd−Ps=T \\boxed{P^d-P^s=T} Pd−Ps=T​Tax Subsidy"},{"title":"Trading 交易与分工","path":"/wiki/microecon/trading.html","content":"Unit Requirement Table 与 Unit Productivity Table Requirement 和 Productivity Table 最重要的区别就是：前者给出生产一个物品需要的资源，后者给出在限定资源的情况下能生产多少物品。 有一个简单的转化： 1Requirement=Productivity \\frac{1}{\\text{Requirement}}=\\text{Productivity} Requirement1​=Productivity Opportunity Cost Opportunity Cost Copp()C_{opp}()Copp​() 描述某个人在生产某件物品的时候，能够生产多少的其他物品；直观理解就是这个人生产这件物品有多 efficient 重要公式Copp(A)=Time of ATime of B=Productivity of BProductivity of AC_{opp}(A)=\\frac{\\text{Time of }A}{\\text{Time of }B}=\\frac{\\text{Productivity of }B}{\\text{Productivity of }A}Copp​(A)=Time of BTime of A​=Productivity of AProductivity of B​ 这里的 Quantity 是在一段长度确定的时间内的。并且可以注意到 Copp(A)=1Copp(B)C_{opp}(A)=\\frac{1}{C_{opp}(B)}Copp​(A)=Copp​(B)1​ 如果对于两个人 X,YX,YX,Y，如果 Copp,X(A)&lt;Copp,Y(A)C_{opp,X}(A)\\lt C_{opp,Y}(A)Copp,X​(A)&lt;Copp,Y​(A)，即 XXX 在 AAA 上的 Opportunity Cost 更小，我们称 XXX 在 AAA 上有 Comparative Advantage. Specialization 分工 一个经济体里肯定会有分工，理性经济体里的分工由 Opportunity Cost 的大小来决定：让 Copp(A)C_{opp}(A)Copp​(A) 最小的人来负责这件 AAA （总是让最高效的人来处理这件事） 分工的存在，也可以让经济体达到 1+1&gt;21+1\\gt 21+1&gt;2 的效果。 Term of Trade (TOT) TOTTOTTOT 描述交易时的换算比例（例如 1.11.11.1 Tea/Cake 说明 111 个蛋糕能交易 1.11.11.1 包茶） 因为交易的双方都需要从交易中获利（否则根本不会进行交易），此时 Term of Trade 叫需要满足一些条件，使得双方都能获利。这里的获利的意思是，我从你这里买东西比我自己生产这个东西要好（你更加熟练，需要的资源更少）。 一个重要的公式就是，对于交易的双方，TOTAperBTOT_{A\\mathop{per}B}TOTAperB​（表示 1 unit B=TOT unit A\\text{\\(1\\) unit \\(B=TOT\\) unit \\(A\\)}1 unit B=TOT unit A）应该满足 Copp,X(A)≤TOTAperB≤Copp,Y(A) C_{opp,X}(A)\\le TOT_{A\\mathop{per}B}\\le C_{opp,Y}(A) Copp,X​(A)≤TOTAperB​≤Copp,Y​(A) 证明 我们假设经济体只生产 A,BA,BA,B 两件物品，且生产 AAA 的 XXX 与生产 BBB 的 YYY 进行交易。那么我们首先知道，根据分工，有 Copp,X(A)&lt;Copp,Y(A)Copp,X(B)&gt;Copp,Y(B) C_{opp,X}(A)\\lt C_{opp,Y}(A)\\\\ C_{opp,X}(B)\\gt C_{opp,Y}(B) Copp,X​(A)&lt;Copp,Y​(A)Copp,X​(B)&gt;Copp,Y​(B)交易双方判断能否获利的准则是： （Requirement）生产相同数量时，相比自己生产，能否获得资源上的节约？ （Quantity）拥有相同数量资源时，相比自己生产，能否获得产品数量上的提升？ 现在假设 TOT 的计算是 111 个单位 BBB 能交易 TOTTOTTOT 单位的 AAA（那么其单位就是 A/BA/BA/B），用资源的节省量推导。 那么，对 XXX 而言，他生产的是 AAA，购买的是 BBB，那么他生产的 111 个单位的 AAA 能换来 1TOT\\frac{1}{TOT}TOT1​ 的 BBB，理论应该节约 RX(B)−1TOTRX(A)≥0 ⟺ TOT≥RX(A)RX(B)=Copp,X(A) \\begin{aligned} &amp;R_{X}(B)-\\frac{1}{TOT}R_X(A)\\ge 0\\\\ \\iff &amp;TOT\\ge \\frac{R_X(A)}{R_X(B)}=C_{opp,X}(A) \\end{aligned} ⟺​RX​(B)−TOT1​RX​(A)≥0TOT≥RX​(B)RX​(A)​=Copp,X​(A)​同理，对 YYY 而言，他生产的每单位 BBB 能换 TOTTOTTOT 单位的 AAA，理论上，生产 AAA 可以节约 RY(A)−TOT×RY(B)≥0 ⟺ TOT≤RY(A)RY(B)=Copp,Y(A) \\begin{aligned} &amp;R_Y(A)-TOT\\times R_Y(B)\\ge 0\\\\ \\iff&amp;TOT\\le\\frac{ R_Y(A)}{R_Y(B)}=C_{opp,Y}(A) \\end{aligned} ⟺​RY​(A)−TOT×RY​(B)≥0TOT≤RY​(B)RY​(A)​=Copp,Y​(A)​所以，对于交易的双方，TOTAperBTOT_{A\\mathop{per}B}TOTAperB​（表示 1 unit B=TOT unit A\\text{\\(1\\) unit \\(B=TOT\\) unit \\(A\\)}1 unit B=TOT unit A）应该满足 Copp,X(A)≤TOTAperB≤Copp,Y(A) C_{opp,X}(A)\\le TOT_{A\\mathop{per}B}\\le C_{opp,Y}(A) Copp,X​(A)≤TOTAperB​≤Copp,Y​(A) (PPC) Production Possibility Curve PPC 上的一条直线 我们假设纵轴表示 AAA 的生产，横轴表示 BBB 的生产，那么截距表示全力生产某一样物品的情况下，该物品的产量。 我们来考察这条直线的斜率 kkk，则有 k=−Productivity of AProductivity of B=−Copp(B)=−1Copp(A) \\begin{aligned} k&amp;=-\\frac{\\text{Productivity of }A}{\\text{Productivity of }B}\\\\ &amp;=-C_{opp}(B)\\\\ &amp;=-\\frac{1}{C_{opp}(A)} \\end{aligned} k​=−Productivity of BProductivity of A​=−Copp​(B)=−Copp​(A)1​​我们更关心 ∣k∣|k|∣k∣，这个绝对值的意义更加鲜明：多生产 111 个单位的 BBB 的 Opportunity Cost 为 ∣k∣|k|∣k∣ 的单位的 AAA.，而 ∣k∣=Copp(B)|k|=C_{opp}(B)∣k∣=Copp​(B) 多条直线：分工 Low-Hanging-Fruit Principle 这个原理描述一个经济体内多人合作分工时，若要扩大生产，一定先让 Lowest Opportunity Cost 的人去做（因为最高效） 如果扩大的是 BBB 的生产（横轴），那么从左向右斜率的绝对值越来越大，越来越陡峭；图像呈现向上凸。 如果扩大的是 AAA 的生产（纵轴），那么从下往上直线的斜率的绝对值越来越小，越来越平缓（因为 Copp(A)C_{opp}(A)Copp​(A) 与 Copp(B)C_{opp}(B)Copp​(B) 成反比）；不过图像仍是上凸的。 直线的相交位置：(Bi−1,Ai)(B_{i-1},A_i)(Bi−1​,Ai​) 影响 PPC 的因素 资源增多 科技进步 总结 通常来说，如果交易双方的 Copp()C_{opp}()Copp​() 差距越大，那么双方交易带来的资源节省和产能提升也会越大。 (CPC) Consumption Probalitity Curve Closed Economy: 无开放贸易 在无开放贸易的情况下，一个经济体的 CPC 和 PPC 是重合的。因为除了这几个人没有人需要生产的物品，因此这些人生产出来的东西只能被自己消耗。 有浪费会趋于减产，有不够会趋于增产，最终都会回归到 PPC 上，因此 CPC 与 PPC 重合。 Open Economy and Open Trade 我们可以从几个角度来看 Open Trade 对 Production 和 Consumption 的影响，然后来看一看相关的计算。 以下假设假设贸易市场上 AAA 的价格为 aaa，BBB 的价格为 bbb，假设 TOTTOTTOT 用 AperBA\\mathop{per} BAperB 计算，此时对于贸易市场来说，TOT=TOTAperB=abTOT=TOT_{A\\mathop{per}B}=\\frac{a}{b}TOT=TOTAperB​=ba​ 例子：如何生产使得收益最大化 贸易市场的价格可以用一根斜率确定、截距不定的直线在 PPC 图像（纵轴为 AAA，横轴为 BBB）上表示出来，这条直线的斜率就是 −TOT-TOT−TOT 为了让利益最大化，我们平移这条直线，让他和 PPC 产生交点，对于每一个交点计算收益，取最大值即可。 从交点倒推 TOT 和市场价格 一个很 tricky 的点是，图像上 PPC 的斜率是 −Copp(B)-C_{opp}(B)−Copp​(B)，但市场的直线的斜率是 −TOTAperB-TOT_{A\\mathop{per}B}−TOTAperB​。记得取倒数。 最大化组合消费 通常会问，若消费 nnn 单位的 AAA，那么最多能消费多少 BBB？ 我们把这个过程转化为，X,YX,YX,Y 两人先生产，通过贸易市场换成钱，再用钱在市场上买所需的物品。这里不考虑成“生产后的东西先拿出一部分满足消费”，是因为这两个思路是等价的 计算：在这个市场下，通过交易最多能赚多少钱 通过计算 TOTTOTTOT，判断出每一个应该生产什么（贸易市场的 TOTAperBTOT_{A\\mathbb{per}B}TOTAperB​ 更大，则生产 AAA；否则生产 BBB） 把生产出来的东西卖成钱 先购买需要消费的东西 然后就能计算最多能买多少了"},{"title":"VAE: Variational AutoEncoders","path":"/wiki/multimodal/VAE.html","content":"Representation 图像生成模型的本质是一个概率模型：如果我们知道了真实图像 xxx 的分布规律 p(x)p(x)p(x)，那么我们只需要从这个分布里随便采样 x′∼p(x)x&#x27;\\sim p(x)x′∼p(x)，那么 x′x&#x27;x′ 就是我们想要生成的图像。 不过通常，p(x)p(x)p(x) 很难表示和学习。我们考虑通过两个步骤生成图像： 先生成图片的特征，例如想要生成二次元图片，就先指定 tags 例如发色、动作等等 在根据特征，去生成图像 我们用 zzz 表示图像的“特征” (latent variable)，那么这样的过程就是如同下面所示 z⟶guidex \\boxed{z}\\overset{\\text{guide}}{\\longrightarrow} \\boxed{x} z​⟶guide​x​用数学语言描述就是这样一个恒等式 p(x)=∑zp(x∣z)⋅p(z) p(x)=\\sum_z p(x|z)\\cdot p(z) p(x)=z∑​p(x∣z)⋅p(z)VAE 的推理从数学的角度也就变成了 Sample zzz from p(z)p(z)p(z) Sample xxx from p(x∣z)p(x|z)p(x∣z) 当然，由于我们的目的是简化 p(x)p(x)p(x) 的建模，因此我们通常假设 p(z)∼N(0,1)p(x∣z)∼N(μθ(z),Σθ(z)) \\begin{aligned} p(z)&amp;\\sim \\mathcal N(0,1)\\\\ p(x|z)&amp;\\sim \\mathcal N(\\mu_\\theta(z),\\Sigma_\\theta(z)) \\end{aligned} p(z)p(x∣z)​∼N(0,1)∼N(μθ​(z),Σθ​(z))​其中 μθ(⋅),Σθ(⋅)\\mu_\\theta(\\cdot),\\Sigma_\\theta(\\cdot)μθ​(⋅),Σθ​(⋅) 是神经网络。 这里也不一定非得是正态分布，其他容易计算的分布也可以。简单起见直接用正态分布了 Inference Inferencing Objective Function 给定一个数据集 D={x1,x2,…,xm}\\mathcal D=\\{x^{1}, x^{2}, \\dots, x^{m}\\}D={x1,x2,…,xm}，模型训练目标就是，从数据集 D\\mathcal DD 里训练的图像分布 pθ(x)p_\\theta(x)pθ​(x) 和真实的图像分布 p(x)p(x)p(x) 尽可能接近。衡量两个分布接近程度可以用 KL 散度，即训练目标为最小化 KL 散度： min⁡θDKL(pθ(x)∥p(x)) \\min_\\theta D_{KL}\\Big( p_\\theta(x) \\big\\| p(x) \\Big) θmin​DKL​(pθ​(x)​p(x))最小化 KL 散度等同于最大化 Marginal Log-Likelilhood log⁡pθ(x)\\log p_\\theta(x)logpθ​(x) over D\\mathcal DD max⁡θ∑xi∈Dlog⁡pθ(xi)=max⁡θ∑xi∈Dlog⁡(∑zpθ(xi,z)) \\begin{aligned} &amp;\\max_\\theta \\sum_{x^{i} \\in\\mathcal D} \\log p_\\theta(x^{i})\\\\ =&amp;\\max_\\theta \\sum_{x^{i} \\in\\mathcal D} \\log \\Big(\\sum_z p_\\theta(x^{i},z)\\Big) \\end{aligned} =​θmax​xi∈D∑​logpθ​(xi)θmax​xi∈D∑​log(z∑​pθ​(xi,z))​然而，zzz 是高维空间的隐变量，∑z\\sum_z∑z​ 需要遍历所有可能的 zzz、计算 pθ(xi,z)p_\\theta(x^{i},z)pθ​(xi,z)、再相加，几乎是不可能做到的，我们只能用各种方法去近似求解 log-likelihood via Monte Carlo 我们随机采样一些 zi∼p(z)z^{i} \\sim p(z)zi∼p(z)，用这些采样的 ziz^{i}zi 计算平均值： log⁡pθ(x)≈log⁡1k∑i=1kp(x∣zi),zi∼p(z) \\log p_\\theta(x)\\approx \\log \\frac{1}{k}\\sum_{i=1}^k p(x|z^{i}), \\quad z^{i}\\sim p(z) logpθ​(x)≈logk1​i=1∑k​p(x∣zi),zi∼p(z)尽管理论上，蒙特卡洛估计方法是 no-bias 的，但是在实战中，用蒙特卡洛计算出来的梯度具有很大的方差。 via Importance Sampling 比起直接 maximize 目标，我们也可以构造出目标的 lower bound 然后通过 maximize 这个 lower bound 从而 maximize 目标。 此处，log⁡pθ(x)\\log p_\\theta(x)logpθ​(x) 的一个下界被称为 ELBO (Evidence Lower Bound) pθ(x)=∑zq(z)q(z)pθ(x,z)=∑zq(z)⋅pθ(x,z)q(z)=Ez∼q(z)[pθ(x,z)q(z)]log⁡pθ(x)=log⁡Ez∼q(z)[pθ(x,z)q(z)]=log⁡∑zq(z)⋅pθ(x,z)q(z)≥∑zq(z)⋅log⁡pθ(x,z)q(z)‾by Jensen’s Inequality=Ez∼q(z)[log⁡pθ(x,z)q(z)]≔ELBO(x;θ)=Lθ(x) \\begin{aligned} p_\\theta(x) &amp;=\\sum_z \\frac{q(z)}{q(z)}p_\\theta(x,z)\\\\ &amp;=\\sum_z q(z)\\cdot \\frac{p_\\theta(x,z)}{q(z)}\\\\ &amp;=\\mathbb E_{z\\sim q(z)}\\Big[\\frac{p_\\theta(x,z)}{q(z)}\\Big]\\\\ \\log p_\\theta(x)&amp;=\\log \\mathbb E_{z\\sim q(z)}\\Big[ \\frac{p_\\theta(x,z)}{q(z)} \\Big]\\\\ &amp;= \\log \\sum_z q(z)\\cdot \\frac{p_\\theta(x,z)}{q(z)}\\\\ &amp;\\ge \\underset{\\scriptsize\\text{by Jensen&#x27;s Inequality}}{\\underline{\\sum_z q(z)\\cdot \\log\\frac{p_\\theta(x,z)}{q(z)}}}\\\\ &amp;=\\mathbb E_{z\\sim q(z)}\\Big[ \\log\\frac{p_\\theta(x,z)}{q(z)} \\Big]\\\\ &amp;\\coloneqq \\text{ELBO}(x;\\theta)=\\mathcal L_{\\theta}(x) \\end{aligned} pθ​(x)logpθ​(x)​=z∑​q(z)q(z)​pθ​(x,z)=z∑​q(z)⋅q(z)pθ​(x,z)​=Ez∼q(z)​[q(z)pθ​(x,z)​]=logEz∼q(z)​[q(z)pθ​(x,z)​]=logz∑​q(z)⋅q(z)pθ​(x,z)​≥by Jensen’s Inequalityz∑​q(z)⋅logq(z)pθ​(x,z)​​​=Ez∼q(z)​[logq(z)pθ​(x,z)​]:=ELBO(x;θ)=Lθ​(x)​ 从 KL 散度的视角理解 ELBO 而实际上 log⁡pθ(x)=Ez∼q(z)[log⁡pθ(x,z)]+H(q)entropy of q(z)‾ \\log p_\\theta(x)=\\mathbb E_{z\\sim q(z)}\\Big[ \\log p_\\theta(x,z) \\Big] + \\underset{\\overline{\\scriptsize\\text{entropy of }q(z)}}{H(q)} logpθ​(x)=Ez∼q(z)​[logpθ​(x,z)]+entropy of q(z)​H(q)​直觉上理解，我们选取的 q(z)q(z)q(z) 应该同模型从图像出发对特征的预测接近，即 DKL(q(z)∥pθ(z∣x)) D_{KL}\\Big( q(z) \\big\\| p_\\theta(z|x) \\Big) DKL​(q(z)​pθ​(z∣x))越小越好。而 DKL()D_{KL}()DKL​() 具有非负性，移项后便是 ELBO 的形式。一般形式的，也有 log⁡pθ(x)=ELBO+DKL(q(z)∥pθ(z∣x)) \\log p_\\theta(x)=\\text{ELBO}+D_{KL}\\Big( q(z)\\big\\|p_\\theta(z|x) \\Big) logpθ​(x)=ELBO+DKL​(q(z)​pθ​(z∣x)) 然后我们就又可以用 Monte Carlo 方法估计 ELBO 了。 ELBO(x;θ)≈1k∑i=1klog⁡pθ(x,zi)q(zi),zi∼q(z) \\text{ELBO}(x;\\theta)\\approx \\frac{1}{k}\\sum_{i=1}^k \\log\\frac{p_\\theta(x,z^{i})}{q(z^{i})},\\quad z^{i}\\sim q(z) ELBO(x;θ)≈k1​i=1∑k​logq(zi)pθ​(x,zi)​,zi∼q(z) VAE: Decoder 与 Encoder from Decoder to Encoder: Variational Inference 到目前位置，我们实际上只讨论了 Decoder 部分：pθ(x∣z)p_\\theta(x|z)pθ​(x∣z)。为了训练模型，我们肯定还需要 x→zx\\to zx→z 的推理与训练。这就是 VAE 里 Encoder 的作用。 Encoder 负责的就是 pθ(z∣x)p_\\theta(z|x)pθ​(z∣x)，但是 pθ(z∣x)p_\\theta(z|x)pθ​(z∣x) 很难从神经网络模型中推导出来。不过，根据上文对 ELBO 与 KL 散度 DKL(q(z)∥pθ(z∣x))D_{KL}\\Big( q(z)\\big\\| p_\\theta(z|x) \\Big)DKL​(q(z)​pθ​(z∣x)) 的分析，我们其实也可以通过优化 q(z)q(z)q(z) 让其近似 pθ(z∣x)p_\\theta(z|x)pθ​(z∣x) 来达成相同的目的。 所以，我们把 q(z)q(z)q(z) 也用神经网络建模为 qϕ(z)q_\\phi(z)qϕ​(z)，其中 ϕ\\phiϕ 为 Encoder 模型的参数，此时 ELBO 改写为 ELBO=Lθ,ϕ(x)=∑zqϕ(z)log⁡pθ(z,x)+H(qϕ(z)) \\text{ELBO}=\\mathcal L_{\\theta,\\phi}(x)=\\sum_z q_\\phi(z)\\log p_\\theta(z,x)+H(q_\\phi(z)) ELBO=Lθ,ϕ​(x)=z∑​qϕ​(z)logpθ​(z,x)+H(qϕ​(z)) Amortized Inference 注意：这里的 Decoder 与 Encoder 本质上是对分布进行建模，即给定张量，输出一个分布。 如果 Encoder 部分我们为每一个输入的图像都训练一个 Encoder qϕ(z)q_\\phi(z)qϕ​(z)，计算代价无法承受。 因此，我们用神经网络对分布进行拟合，即 gλ:xi↦qϕi(z)g_\\lambda:x^{i} \\mapsto q_{\\phi^{i}}(z)gλ​:xi↦qϕi​(z)，这样就可以避免反复求解 ϕi\\phi^{i}ϕi 了。 而对 Decoder 部分就不用了，因为 pθ(x∣z)p_\\theta(x|z)pθ​(x∣z) 的 zzz 是由 Encoder 完成的，而每一个而 Encoder 总是输出的 qϕ(z)≈pθ(z∣x)q_\\phi(z)\\approx p_\\theta(z|x)qϕ​(z)≈pθ​(z∣x) 总是映射到同一个 random variable space 里. Training VAE 有一个 Encoder 架构，负责将图像 xxx 编码为 latent variable zzz；Decoder 架构则负责从 latent variable zzz 生成出图像 xxx. VAE 上文的 ELBO 则为我们优化 VAE 模型提供了一个良好的目标函数：（其实应该是求解上文的 λ\\lambdaλ） max⁡θ,ϕELBO=max⁡θ∑x∈Dmax⁡ϕEqϕ(z)[log⁡pθ(z,x)qϕ(z)]⇒max⁡θ,λ∑x∈Dmax⁡λEgλ(x)[log⁡pθ(z,x)gλ(x)] \\begin{aligned} \\max_{\\theta,\\phi}\\text{ELBO}&amp;=\\max_{\\theta}\\sum_{x\\in\\mathcal D}\\max_{\\phi}\\mathbb E_{q_\\phi(z)}\\Bigg[ \\log\\frac{p_\\theta(z,x)}{q_\\phi(z)} \\Bigg]\\\\ &amp;\\Rightarrow\\max_{\\theta,\\lambda}\\sum_{x\\in\\mathcal D}\\max_\\lambda\\mathbb E_{g_\\lambda(x)}\\Bigg[ \\log\\frac{p_\\theta(z,x)}{g_\\lambda(x)} \\Bigg] \\end{aligned} θ,ϕmax​ELBO​=θmax​x∈D∑​ϕmax​Eqϕ​(z)​[logqϕ​(z)pθ​(z,x)​]⇒θ,λmax​x∈D∑​λmax​Egλ​(x)​[loggλ​(x)pθ​(z,x)​]​ Stochastic Variational Inference 用随机梯度下降法进行学习 初始化 θ,ϕ1…m\\theta,\\phi^{1\\dots m}θ,ϕ1…m 随机一个 xi∈Dx^{i} \\in\\mathcal Dxi∈D 先优化 ϕi\\phi^{i}ϕi： ϕi←ϕi+η∇ϕiLθ,ϕ(xi)\\phi^{i}\\gets \\phi^{i}+\\eta abla_{\\phi^{i}}\\mathcal L_{\\theta,\\phi}(x^{i})ϕi←ϕi+η∇ϕi​Lθ,ϕ​(xi) 直到收敛为止 更新 θ\\thetaθ：θ←θ+η∇θLθ,ϕi(xi)\\theta\\gets\\theta+\\eta abla_{\\theta}\\mathcal L_{\\theta,\\phi^{i}}(x^{i})θ←θ+η∇θ​Lθ,ϕi​(xi)。回到 step 2 继续执行。 那么我们如何计算梯度呢？因为很有可能这个式子并不存在 closed form，我们依然采用 Monte Carlo 的方法解决问题，即 Eqϕ(z)[log⁡pθ(z,x)−log⁡qϕ(z)]≈1K∑i=1Klog⁡pθ(zi,x)−log⁡qϕ(zi) \\mathbb E_{q_\\phi(z)}\\Bigg[ \\log p_\\theta(z,x)-\\log q_\\phi(z) \\Bigg]\\approx \\frac{1}{K}\\sum_{i=1}^{K}\\log p_\\theta(z^{i},x)-\\log q_\\phi(z^{i}) Eqϕ​(z)​[logpθ​(z,x)−logqϕ​(z)]≈K1​i=1∑K​logpθ​(zi,x)−logqϕ​(zi)其中 qϕ(z)q_\\phi(z)qϕ​(z) 应该容易采样和计算。由此，ELBO 关于 θ\\thetaθ 的导数即为 ∇θEqϕ(z)[log⁡pθ(z,x)−log⁡qϕ(z)]≈1K∑i=1K∇θlog⁡pθ(zi,x) abla_\\theta \\mathbb E_{q_\\phi(z)}\\Bigg[ \\log p_\\theta(z,x)-\\log q_\\phi(z) \\Bigg]\\approx \\frac{1}{K}\\sum_{i=1}^K abla_\\theta \\log p_\\theta(z^{i},x) ∇θ​Eqϕ​(z)​[logpθ​(z,x)−logqϕ​(z)]≈K1​i=1∑K​∇θ​logpθ​(zi,x)然而 ELBO 关于 ϕi\\phi^iϕi 的导数不那么好算，因为期望本身依赖于这个参数。一般而言，可以使用强化学习的方法进行学习，也可以使用 Reparameterization 的方法。 Reparam 我们把 qϕ(z)∼N(μ,σ2I)q_\\phi(z)\\sim \\mathcal N(\\mu, \\sigma^2 I)qϕ​(z)∼N(μ,σ2I)，即 ϕi=(μ,σ)\\phi^i=(\\mu,\\sigma)ϕi=(μ,σ)，那么从这个正态分布采样就等同于 ϵ∼N(0,1)z=μ+σϵ=gϕ(ϵ) \\epsilon\\sim \\mathcal N(0,1)\\\\ z=\\mu+\\sigma\\epsilon=g_\\phi(\\epsilon) ϵ∼N(0,1)z=μ+σϵ=gϕ​(ϵ)借用这个想法，我们可以改写 ELBO，这里先让 r(z)=log⁡qϕ(z)r(z)=\\log q_\\phi(z)r(z)=logqϕ​(z) 简化计算，稍后再代入 Ez∼qϕ(z)[r(z)]=∑zqϕ(z)r(z)=Eϵ∼N(0,1)[r(gϕ(ϵ))]=∫N(ϵ)r(μ+σϵ)dϵ∇ϕEqϕ(z)[r(z)]=∇ϕEϵ[r(gϕ(ϵ))]=Eϵ[∇ϕr(gϕ(ϵ))]≈1K∑i=1Kr(gϕ(ϵi))‾Monte Carlo Estim \\begin{aligned} \\mathbb E_{z\\sim q_\\phi(z)}[r(z)]&amp;=\\sum_z q_\\phi(z)r(z)\\\\ &amp;=\\mathbb E_{\\epsilon\\sim\\mathcal N(0,1)}[r(g_\\phi(\\epsilon))]\\\\ &amp;=\\int \\mathcal N(\\epsilon) r(\\mu+\\sigma\\epsilon) d\\epsilon\\\\ abla_\\phi \\mathbb E_{q_\\phi(z)}[r(z)]&amp;= abla_\\phi \\mathbb E_\\epsilon [r(g_\\phi(\\epsilon))]\\\\ &amp;=\\mathbb E_{\\epsilon}[ abla_\\phi r(g_\\phi(\\epsilon))]\\\\ &amp;\\approx \\underset{\\text{Monte Carlo Estim}}{\\underline{\\frac{1}{K}\\sum_{i=1}^K r(g_\\phi(\\epsilon^i))}} \\end{aligned} Ez∼qϕ​(z)​[r(z)]∇ϕ​Eqϕ​(z)​[r(z)]​=z∑​qϕ​(z)r(z)=Eϵ∼N(0,1)​[r(gϕ​(ϵ))]=∫N(ϵ)r(μ+σϵ)dϵ=∇ϕ​Eϵ​[r(gϕ​(ϵ))]=Eϵ​[∇ϕ​r(gϕ​(ϵ))]≈Monte Carlo EstimK1​i=1∑K​r(gϕ​(ϵi))​​​"},{"title":"ViT","path":"/wiki/multimodal/ViT.html","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"基于 Nano GraphRAG 的二次开发","path":"/wiki/rag/build-on-nano-graphrag.html","content":"本地部署 LLM"},{"title":"LightRAG","path":"/wiki/rag/LightRAG.html","content":"LightRAG Overview LightRAG 是由 香港大学研究团队 推出的一种轻量级检索增强生成（Retrieval-Augmented Generation, RAG）系统，通过整合 图结构索引 和 双层检索机制，显著提升了大型语言模型（LLM）在信息检索中的准确性与效率 。其核心特点是： 轻量化设计 相较于传统的 GraphRAG，LightRAG 通过简化知识图谱构建流程和减少冗余计算，大幅降低了资源消耗和 API 调用成本，在动态数据环境中更新速度更快、维护更灵活 。 双层检索架构 LightRAG 结合关键词匹配与语义向量检索：第一层快速定位实体及关联关系，第二层通过向量数据库（如 Milvus 或 TiDB Vector）补充相关片段，兼顾效率与精度 。 动态数据支持 系统支持增量更新，能够高效处理实时变化的数据源，适应动态环境下的检索需求 。 成本效益 实验表明，LightRAG 在保证检索质量的同时，能显著降低大模型问答的计算成本，适用于高并发或预算受限的场景 。 LightRAG"},{"title":"Dify 中使用 HTTP Request 配合 Flask 进行高级数据处理","path":"/wiki/rag/custom-data-process.html","content":"Flask Server"},{"title":"GraphRAG 解读","path":"/wiki/rag/graph-rag.html","content":"算法流程 GraphRAG WorkFlow Overview NanoGraphRAG 工作流程 Chunk Documents graph LR A(Document) --> B(Text Chunk 1) A --> C(Text Chunk 2) 像普通的 VectorRAG 一样，提取出来的 Text Chunk 可以用于后续 LLM 的知识来源。 NanoGraphRAG 源码解读 Extract Entity and Relationships Graph Indexing Graph Decomposition"},{"title":"NanoGraphRAG项目思路（一）：文档分块","path":"/wiki/rag/nano-graph-rag-p1.html","content":"Phase 1: 文档预处理 (论文 3.1.1) 在 Nano GraphRAG 里，预处理文档的任务在 GraphRAG.ainsert() 中完成。GraphRAG.ainsert() 由 GraphRAG.insert() 调用，并且使用了 asyncio.get_event_loop() 保证执行完毕。 文档去重 ainsert() 首先计算文档的 MD5 哈希值，检查文档是否已经添加过了。如果已经添加过了，那么就不用再插入数据库。 new_docs 首先准备所有待检查的字符串，计算其哈希值。 1234new_docs = &#123; compute_mdhash_id(c.strip(), prefix=&quot;doc-&quot;): &#123;&quot;content&quot;: c.strip()&#125; for c in string_or_strings&#125; 然后丢入 self.full_docs 检查是否有重复的字符串并剔除 1_add_doc_keys = await self.full_docs.filter_keys(list(new_docs.keys())) 剔除完成后的字符串拼接成 &#123; hash: str &#125; 形式的字典重新赋值回 new_docs. 1new_docs = &#123;k: v for k, v in new_docs.items() if k in _add_doc_keys&#125; 如果没有新文档，直接退出。然后输出一点调试日志 1234if not len(new_docs): logger.warning(f&quot;All docs are already in the storage&quot;) returnlogger.info(f&quot;[New Docs] inserting &#123;len(new_docs)&#125; docs&quot;) 文档分块 Text Chunk 否则，准备插入文档。先对文档 get_chunk() 拆分成若干个 text chunks 12345678910111213inserting_chunks = get_chunks( new_docs=new_docs, # 要切分的文档 chunk_func=self.chunk_func, # chunk 切分方法，默认按 token 数量 overlap_token_size=self.chunk_overlap_token_size, # chunk 之间重叠的 token 数量，充当上下文的作用 max_token_size=self.chunk_token_size, # 一个 chunk 最多多少 token) 然后 get_chunk() 加载 Tokenizer (这里调用的是 OpenAI tiktoken 的库)，将 docs（纯文本）转化为 Tokens，再调用 chunk_func 进行切块，每一块都标注成 123456&#123; &quot;tokens&quot;: token 个数, &quot;content&quot;: token 内容（已经不是文本了）, &quot;chunk_order_index&quot;: 是第几个 chunk, &quot;full_doc_id&quot;: 所属文档的哈希值,&#125; 标注完成后，再为每一个 text chunk 计算哈希值 chunk-xxxxx，放入 inserting_chunk 并返回 Text Chunk 去重 对 text chunks 也进行去重 12345678910111213_add_chunk_keys = await self.text_chunks.filter_keys( list(inserting_chunks.keys()))inserting_chunks = &#123; k: v for k, v in inserting_chunks.items() if k in _add_chunk_keys&#125;if not len(inserting_chunks): logger.warning(f&quot;All chunks are already in the storage&quot;) returnlogger.info(f&quot;[New Chunks] inserting &#123;len(inserting_chunks)&#125; chunks&quot;)if self.enable_naive_rag: logger.info(&quot;Insert chunks for naive RAG&quot;) await self.chunks_vdb.upsert(inserting_chunks) 和文档去重的逻辑很相似，就是在 KVStorage 里按哈希值查找，去重 更新数据库 这里有另一点比较重要的是，如果需要插入新的 chunk，那么首先需要把 self.community_reports 清空。因为插入新块后，可能这个文档的 community 就会改变 1await self.community_reports.drop()"},{"title":"PCA","path":"/wiki/ml/PCA.html","content":"PCA 主成分分析 算法流程 代码实现 SciKit Learn 我们使用 sklearn 库实现（这个库可以通过 pip install scikit-learn 进行安装） 先导入 PCA 库，这是 scikit-learn 封装好的 PCA 类，后续可以直接调用 .fit_transform() 对数据进行 Projection. 以及，由于 PCA 对数据量级敏感，我们需要先 standardization，将数据点放缩到正态分布 N(0,1)N(0,1)N(0,1)，即 X′=X−μσX&#x27;=\\frac{X-\\mu}{\\sigma}X′=σX−μ​。这一步操作 scikit-learn 里也有封装好的类 sklearn.preprocessing.StandardScaler 使用 standardization 而非 normalization 的原因是，PCA 需要计算 Data point 矩阵的协方差矩阵，而 normalization 无法保留数据点的协方差信息，只有 standardization 可以。 12from sklearn.decomposition import PCAfrom sklearn.preprocessing import StandardScaler 我们可以指定 PCA 将 Dimension 减少到多少个，例如减少到 505050 个 1pca = PCA(n_components=50)"},{"title":"RANSAC 线性回归算法","path":"/wiki/ml/RANSAC.html","content":"RANSAC 线性回归算法 用于解决普通线性回归算法里对 outlier 敏感的缺点 随机挑选出 mmm 个点 用这 mmm 个点拟合一个线性模型 对剩下的所有点，计算模型误差，筛选出在 tolerance ϵ\\epsilonϵ 内的点 用新挑选出来的点对模型进行重新拟合（例如最小二乘法） 最后选择性能最好的模型"},{"title":"Bagging","path":"/wiki/ml/bagging.html","content":"Bagging Algorithm 核心思想：对原数据集采样多次（可以有漏，可以有重）分别用于训练"},{"title":"Bisecting K-Means","path":"/wiki/ml/bisecting-k-means.html","content":"Bisecting K-Means"},{"title":"Cluster Analysis","path":"/wiki/ml/clustering.html","content":"Cluster 分类 Cluster Type Description Well-Separated 簇间完全分离，无重叠。 Center-Based 每个簇由中心点（如均值、中位数）定义，数据点靠近所属簇中心。 Contiguity-Based 基于空间邻近性，形成连通区域。 Density-Based 高密度区域形成簇，低密度区域分隔簇（如DBSCAN）。 Objective Function 通过优化目标函数（如最小化误差平方和）划分簇。 Partitional Clustering Hierarchical Clustering 聚合式 (Agglomerative): 自底向上，初始每个点为独立簇，逐步合并最近簇。 分裂式 (Divisive): 自顶向下，初始一个簇，逐步分裂为更小簇。 Agglomerative 使用 Distance/Similarity/Proximity Matrix Space: O(n2)O(n^2)O(n2) Time: O(n3)O(n^3)O(n3), O(n2log⁡n)O(n^2\\log n)O(n2logn) 计算 Proximity Matrix 循环，直到只剩一个 cluster 合并两个最近的 cluster 更新 Proximity Matrix 如何更新 Proximity Matrix? MIN: 簇间距离取最近点距离，易处理非球形簇但易受噪声影响。 MAX: 取最远点距离，抗噪但易分裂大簇. Biased towards globular clusters Group Avg: 取所有点对的平均距离，平衡抗噪与形状适应性。Biased towards globular clusters Distance between Centroids Ward’s Method: 最小化簇内误差平方和 Divisive: 最小生成树 构建 MST 计算点对之间的距离矩阵 生成 Proximity Graph 的 MST 分裂 MST 从 MST 中选出一条边，断开。 形成的两个连通块对应两个不同的 cluster"},{"title":"Evaluating Regression","path":"/wiki/ml/eval-regression.html","content":"SSE R2 R2=1−SSESST R^2=1-\\frac{SSE}{SST} R2=1−SSTSSE​"},{"title":"K-Means","path":"/wiki/ml/k-means.html","content":"K-Means Partitional Clustering 每一个 cluster 与一个 centroid 相联系，每一个点分配到其最近的 centroid KKK 是超参数 算法流程 选定初始的 KKK 个点作为 centroid 循环，直到 KKK 个 centroid 不再发生变化 把所有点分配到这 KKK 个 cluster 重新计算 KKK 个 centroid O(n×K×I×d)O(n×K×I×d)O(n×K×I×d)，其中 nnn 为数据量，KKK 为簇数，III 为迭代次数，ddd 为特征数。 我们用平均距离衡量 K-Means 算法的优劣： SSE=∑i=1K∑x∈Cidist2(x,mi) SSE=\\sum_{i=1}^K \\sum_{x \\in C_i} \\text{dist}^2(x, m_i) SSE=i=1∑K​x∈Ci​∑​dist2(x,mi​) 局限性 对初始中心的选取很敏感 需要预先指定 KKK 可能出现空聚类 针对这些问题，我们可以作出一些改进： 多运行几次算法，增加找到最优解的概率 用 Hierarchical Clustering 优化初始点的选取 K-Means 算出多于 KKK 个 centroid，再从其中选出 KKK 个 后处理 Bisecting K-Means 空聚类的处理 将距离所有簇中心最远的样本点选为空簇的新中心。该点对当前聚类的误差（SSE）贡献最大，重新分配它有助于优化整体聚类效果。 从SSE（误差平方和）最高的非空簇中选择一个点，将其作为空簇的新中心。该簇的误差较大，说明其内部数据分布分散，分裂或调整其中心可能改善聚类质量。 If there are several empty clusters, the above can be repeated several times. 增量法更新 不会产生空簇 前、后处理 前处理： Normalization 去除异常值 后处理： 去除小聚类（可能由异常值组成） 分裂稀疏、分散的聚类 合并close, 紧密的聚类 使用 ISODATA"},{"title":"Particle Filter 粒子滤波","path":"/wiki/ml/particle-filter.html","content":"Particle Filter: Overview 现实世界里，xxx 的维度太大、数量太多，计算的时间复杂度爆炸。我们很难精确计算出 P(X)P(X)P(X) 的 closed form，一个比较经典的方法就是利用蒙特卡罗方法，化连续为离散，用若干个点近似 P(X)P(X)P(X)，这就是粒子滤波的思想。 我们通过对这些点进行追踪，从而得到大致的分布。粒子的平均值代表对 state 的近似，粒子的分布代表对 state distribution 的近似 HMM view of PF PF 对于粒子滤波而言有这么几个东西比较重要： 粒子滤波算法流程 粒子滤波的流程大致可以分为这么几步 获得 observation oto_tot​，得到每一个粒子对真实 state 的近似程度 对粒子进行重采样 (resample)，越近似的粒子比重越大。重采样将近似程度低的粒子替换为近似程度高的粒子 sample：对每一个粒子进行状态转移，即 xt+1=sample(P(Xt+1∣Xt=xt))x_{t+1}=\\text{sample}(P(X_{t+1}|X_t=x_t))xt+1​=sample(P(Xt+1​∣Xt​=xt​))"},{"title":"Plurality Majority Voting","path":"/wiki/ml/plurality-majority.html","content":"Majority Voting 多个模型分别输出预测结果，然后取投票最多的那个标签作为最后的输出。 Voting 用数学语言描述就是 y^=model{Ci(x)},1≤i≤m \\hat y=model\\Big\\{ C_i(x) \\Big\\},1\\le i\\le m y^​=model{Ci​(x)},1≤i≤m其中 CiC_iCi​ 表示训练的第 iii 个 Classifier 多个模型组合带来准确率提升 考虑训练了 2n+12n+12n+1 个分类器，每一个分类器的准确率为 rrr，那么组合后，由于需要超过半数投票，因此正确分类的概率为 ∑k=n+12n+1(kn)rk(1−r)2n+1−k \\sum_{k=n+1}^{2n+1} \\binom{k}{n}r^k(1-r)^{2n+1-k} k=n+1∑2n+1​(nk​)rk(1−r)2n+1−k当 n=5,r=0.7n=5,r=0.7n=5,r=0.7 时，这个值约为 0.92180.92180.9218，可以看到，准确率有很大提升。 Weighted Majority Vote 在此基础上，给每一个模型的预测结果添加权重 y^=arg max⁡i∈A∑j=1mwj[Cj(x)=i] \\hat y=\\argmax_{i\\in A} \\sum_{j=1}^m w_j \\Big[ C_j(\\bold{x})=i \\Big] y^​=i∈Aargmax​j=1∑m​wj​[Cj​(x)=i]其中 AAA 是所有的标签，方括号函数表示如果第 jjj 的分类器对于样本 x\\bold xx 给出的预测结果是 iii 类别的话则为 111，否则为 000. 因此，Weighted Vote 就相当于是枚举标签，然后看每一个模型预测结果的加权平均，取均值最大的那个对应的标签。 Soft Voting 有的模型可以输出概率，所以我们也可以对概率进行加权，最后取最高 y^=arg max⁡i∈A∑j=1mwj⋅Pj(i) \\hat y=\\argmax_{i\\in A}\\sum_{j=1}^m w_j\\cdot P_{j}(i) y^​=i∈Aargmax​j=1∑m​wj​⋅Pj​(i) 代码实现 下面的代码实现了一个 Majority Vote Classifier (vote='classlabel') 和 Soft Vote (vote='probability') 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768from sklearn.base import BaseEstimator, ClassifierMixin, clonefrom sklearn.preprocessing import LabelEncoderfrom sklearn.pipeline import _name_estimatorsimport numpy as npimport operatorclass MajorityVoteClassifier(BaseEstimator, ClassifierMixin): def __init__(self, classifiers, vote=&quot;classlabel&quot;, weights=None): &#x27;&#x27;&#x27; __init__ 函数接收分类器列表，进行初始化 vote 表示投票方法 &#x27;&#x27;&#x27; self.classifiers = classifiers self.named_classifiers = &#123; key: value for key, value in _name_estimators(classifiers) &#125; self.vote = vote self.weights = weights def fit(self, X, y): &#x27;&#x27;&#x27; fit() 根据输入的数据 + 标签， 对标签进行 encoding（方便 Soft Vote 获取概率） 然后对 classifier 模型进行训练，并存起来 &#x27;&#x27;&#x27; self.label_enc = LabelEncoder() self.label_enc.fit(y) self.classes = self.label_enc.classes_ self.trained_classifiers = [] for classifier in self.classifiers: trained_clf = clone(classifier).fit( X, self.label_enc.transform(y), ) self.trained_classifiers.append(trained_clf) return self def predict(self, X): &#x27;&#x27;&#x27; probability 部分比较容易理解 classlabel 部分的话，我们首先获取每一个模型的输出结果（`predictions`）， 然后 &#x27;&#x27;&#x27; if self.vote == &#x27;probability&#x27;: maj_vote = np.argmax(self.predict_proba(X), axis=1) else: predictions = np.asarray( [ clf.predict(X) for clf in self.trained_classifiers ] ).T maj_vote = np.apply_along_axis( lambda x: np.argmax(np.bincount(x, weights=self.weights)), axis=1, arr=predictions) maj_vote = self.label_enc.inverse_transform(maj_vote) return maj_vote def predict_proba(self, X): probas = np.asarray([clf.predict_proba(X) for clf in self.classifiers_]) avg_proba = np.average(probas, axis=0, weights=self.weights) return avg_proba"},{"title":"Regression","path":"/wiki/ml/regression.html","content":"Linear Regression Polynomial Regression 对每一个 feature xix_ixi​ 都映射到 xi1,xi2,…xidx_i^1,x_i^2,\\dots x_i^dxi1​,xi2​,…xid​，以及可能的交叉项。 Decision Tree (Random Forest) Regression Random Forest: 视为 ensemble of 多个 linear functions Impurity for continuous variables I(t)=MSE(t)=1Nt⋅∑i∈Dt(y(i)−y^t)2 I(t)=MSE(t)=\\frac{1}{N_t}\\cdot \\sum_{i\\in D_t}\\Big( y^{(i)}-\\hat y_t \\Big)^2 I(t)=MSE(t)=Nt​1​⋅i∈Dt​∑​(y(i)−y^​t​)2其中 NtN_tNt​ 是节点 ttt 内的样本数量，DtD_tDt​ 代表这个节点对应的所有样本，y^t\\hat y_ty^​t​ 代表预测样本值（其实是 sample mean），y(i)y^{(i)}y(i) 表示样本真实值 y^t=1Nt∑i∈Dty(i) \\hat y_t=\\frac{1}{N_t}\\sum_{i\\in D_t}y^{(i)} y^​t​=Nt​1​i∈Dt​∑​y(i)使用随机森林时，在构建单棵决策树的时候，predicted target variable is calculated as the average prediction over all decision trees"},{"title":"Regularization","path":"/wiki/ml/regularization.html","content":"Regularization shrink the parameter values L2 正则化: Ridge 在原始的损失函数上加上 L2\\mathcal{L}_2L2​ Penalty JRidge=J(θ)+α⋅∥θ∥22 J_{Ridge}=J(\\theta)+\\alpha\\cdot\\|\\theta\\|_2^2 JRidge​=J(θ)+α⋅∥θ∥22​ L1 正则化: LASSO 加上 L1\\cal L_1L1​ Penalty JLASSO=J(θ)+α⋅∥θ∥ J_{LASSO}=J(\\theta)+\\alpha\\cdot\\|\\theta\\| JLASSO​=J(θ)+α⋅∥θ∥ 有些权重容易变成 000 折中: Elastic Net λ\\lambdaλ 控制比例，α\\alphaα 控制正则程度 JElastic=J(θ)+α⋅[λ∥θ∥2+(1−λ)∥θ∥] J_{Elastic}=J(\\theta)+\\alpha\\cdot\\Bigg[ \\lambda\\|\\theta\\|^2+(1-\\lambda)\\|\\theta\\| \\Bigg] JElastic​=J(θ)+α⋅[λ∥θ∥2+(1−λ)∥θ∥]"},{"title":"Support Vector Machine","path":"/wiki/ml/svm.html","content":"Linear SVM Kernel SVM 通过映射函数 ϕ()\\phi()ϕ()，将低维的特征向量 feature vector xxx 映射到高维空间中 vxv_xvx​，以期望在低维空间不可线性分割的 feature vector 在高维空间可以被线性分割。 但是当映射到高维空间之后，高维向量之间的点乘运算比较耗时，因此利用核函数 Kernel Function K(v1,v2)\\mathcal{K}(v_1,v_2)K(v1​,v2​) 替换点乘运算。例如常见的做法是 K(x(i),x(j))=exp⁡(−γ∥x(i)−x(j)∥2) \\mathcal{K}(x^{(i)},x^{(j)})=\\exp\\Big( -\\gamma\\|x^{(i)}-x^{(j)} \\|^2 \\Big) K(x(i),x(j))=exp(−γ∥x(i)−x(j)∥2)当 γ=12σ2\\gamma=\\frac{1}{2\\sigma^2}γ=2σ21​ 时，就是高斯核函数。"},{"title":"HMM","path":"/wiki/rl/HMM.html","content":"Hidden Markov Model 以下约定： 大写字母表示随机变量，脚标表示时刻，小写字母表示变量具体的取值 Distri(Xt)\\text{Distri}(X_t)Distri(Xt​) 表示第 ttt 时刻的状态（的分布），xtx_txt​ 表示第 ttt 时刻具体的状态（例如具体的位置） Distri(Et)\\text{Distri}(E_t)Distri(Et​) 表示第 ttt 时刻的观测（的分布），ete_tet​ 表示第 ttt 时刻观测到的具体的值 HMM 主要有三个概率模型： Component Distribution Initial Distribution Distri(X0)\\text{Distri}(X_0)Distri(X0​) Transition Model Distri(Xt+1∣xt)\\text{Distri}(X_{t+1} | x_t)Distri(Xt+1​∣xt​) Observation Model Distri(Et∣xt)\\text{Distri}(E_t | x_t)Distri(Et​∣xt​) Model 因此，利用 Bayes Net 的概率分析方法，我们可以得出，整个网络的概率模型 P(x0,e1,x1,e2,x2,…,et,xt)=P(x0)⋅∏tP(xt∣xt−1)⋅P(et∣xt) P(x_0,e_1,x_1,e_2,x_2,\\dots, e_t,x_t)=P(x_0)\\cdot \\prod_t P(x_t|x_{t-1})\\cdot P(e_t|x_t) P(x0​,e1​,x1​,e2​,x2​,…,et​,xt​)=P(x0​)⋅t∏​P(xt​∣xt−1​)⋅P(et​∣xt​) Filtering 给定所有时刻的观测，Filter 关注当前时刻的状态，即求解 P(xt∣e1:t) P(x_t|e_{1:t}) P(xt​∣e1:t​)Filter Forward Filtering P(xt∣e1:t)=P(xt∣et,e1:t−1)=P(xt,et,e1:t−1)P(e1:t)=P(xt,et∣e1:t−1)⋅P(e1:t−1)P(e1:t)=α⋅P(xt,et∣e1:t−1)=α⋅∑xt−1P(xt,et,xt−1∣e1:t−1)=α⋅∑xt−1P(et∣xt,xt−1,e1:t−1)⋅P(xt∣xt−1,e1:t−1)⋅P(xt−1∣e1:t−1)=α⋅∑xt−1P(et∣xt)⋅P(xt∣xt−1)⋅P(xt−1∣e1:t−1)=α⋅P(et∣xt)⋅∑xt−1P(xt∣xt−1)⋅P(xt−1∣e1:t−1) \\begin{aligned} P(x_t|e_{1:t})&amp;=P(x_t|e_t,e_{1:t-1})\\\\ &amp;=\\frac{P(x_t,e_t,e_{1:t-1})} {P(e_{1:t})}\\\\ &amp;=\\frac{P(x_t,e_t|e_{1:t-1})\\cdot P(e_{1:t-1})}{P(e_{1:t})}\\\\ &amp;=\\alpha\\cdot P(x_t,e_t|e_{1:t-1})\\\\ &amp;=\\alpha\\cdot \\sum_{x_{t-1}} P(x_t,e_t,x_{t-1}|e_{1:t-1})\\\\ &amp;=\\alpha\\cdot\\sum_{x_{t-1}}P(e_t|x_t,x_{t-1},e_{1:t-1})\\cdot P(x_t|x_{t-1},e_{1:t-1})\\cdot P(x_{t-1}|e_{1:t-1})\\\\ &amp;=\\alpha\\cdot\\sum_{x_{t-1}}P(e_t|x_t)\\cdot P(x_t|x_{t-1})\\cdot P(x_{t-1}|e_{1:t-1})\\\\ &amp;=\\alpha\\cdot P(e_t|x_t)\\cdot\\sum_{x_{t-1}}P(x_t|x_{t-1})\\cdot P(x_{t-1}|e_{1:t-1}) \\end{aligned} P(xt​∣e1:t​)​=P(xt​∣et​,e1:t−1​)=P(e1:t​)P(xt​,et​,e1:t−1​)​=P(e1:t​)P(xt​,et​∣e1:t−1​)⋅P(e1:t−1​)​=α⋅P(xt​,et​∣e1:t−1​)=α⋅xt−1​∑​P(xt​,et​,xt−1​∣e1:t−1​)=α⋅xt−1​∑​P(et​∣xt​,xt−1​,e1:t−1​)⋅P(xt​∣xt−1​,e1:t−1​)⋅P(xt−1​∣e1:t−1​)=α⋅xt−1​∑​P(et​∣xt​)⋅P(xt​∣xt−1​)⋅P(xt−1​∣e1:t−1​)=α⋅P(et​∣xt​)⋅xt−1​∑​P(xt​∣xt−1​)⋅P(xt−1​∣e1:t−1​)​ Prediction 给定所有时刻的观测，希望知道后续时刻的状态，因为后续时刻的状态还没有被观测，因此是 Prediction。即求解 P(xt+k∣e1:t),k&gt;0 P(x_{t+k}|e_{1:t}),\\quad k\\gt 0 P(xt+k​∣e1:t​),k&gt;0Prediction Smoothing Smoothing 关注的给定所有时刻的观测，更新过去的状态（Filter 关注的是当前状态），即求解 P(xk∣e1:t),k&lt;t P(x_k|e_{1:t}),\\quad k\\lt t P(xk​∣e1:t​),k&lt;tSmoothing Explanation 给定所有时刻的观测 e1:te_{1:t}e1:t​，我们希望找到这样一组 sequential state x1:tx_{1:t}x1:t​，这一组 x1:tx_{1:t}x1:t​ 最有可能产生这些观测。 arg max⁡x1:tP(x1:t∣e1:t) \\argmax_{x_{1:t}} P(x_{1:t}|e_{1:t}) x1:t​argmax​P(x1:t​∣e1:t​)Explanation CS188 Project 4 解析 CS188 Project 4 是用 HMM, Bayes Net, Particle Filter 的概念完成 Pacman 小游戏"},{"title":"Actor Critic Methods","path":"/wiki/rl/actor-critic.html","content":"Actor-Critic Methods Actor-Critic 是一种强化学习方法，强调的是：LLM 作为动作执行者 Actor，其输出的 Token 经过第三方评判之后 (Critic)，得到 Loss 并用于优化自身的模型。 Advantage Function Advantage Function 定义为在当前状态 sts_tst​ 下采取某个动作 ata_tat​ 能够带来的 Reward Aπθ(st,at)=Qπθ(st,at)−Vπθ(st) A^{\\pi_\\theta}(s_t,a_t)=Q^{\\pi_\\theta}(s_t,a_t)-V^{\\pi_\\theta}(s_t) Aπθ​(st​,at​)=Qπθ​(st​,at​)−Vπθ​(st​)有了这个定义之后，我们可以等价改写 Policy Gradient Objective Function 了： ∇θJ(θ)=Eτ∼πθ[∑t=0T∇θlog⁡πθ(at∣st)Aπθ(st,at)] abla_\\theta J(\\theta)=\\mathbb E_{\\tau\\sim\\pi_\\theta}\\Big[ \\sum_{t=0}^T abla_\\theta \\log\\pi_\\theta(a_t|s_t)A^{\\pi_\\theta}(s_t,a_t) \\Big] ∇θ​J(θ)=Eτ∼πθ​​[t=0∑T​∇θ​logπθ​(at​∣st​)Aπθ​(st​,at​)] Generalized Advantage Estimation"},{"title":"Bayes Network","path":"/wiki/rl/bayes-net.html","content":"Bayes Net 通过有向边表示变量间的概率依赖关系 核心三要素：节点（随机变量）、有向边（直接依赖）、条件概率表（CPT，量化依赖关系） 不一定代表因果关系 P(x1,x2,…,xn)=∏i=1nP(xi∣Parent(xi)) P(x_1,x_2,\\dots,x_n)=\\prod_{i=1}^n P(x_i | \\text{Parent}(x_i)) P(x1​,x2​,…,xn​)=i=1∏n​P(xi​∣Parent(xi​))这里的小写随机变量代表具体取值。 随机变量独立性分析: D-Separation 任何一个复杂的贝叶斯网络都可以分解为 333 种基础形式： Causal Chain: A→B→CA\\to B\\to CA→B→C Common Cause: B→A,CB\\to A,CB→A,C Common Effect: A,C→BA,C\\to BA,C→B 给定 Evidence，检查 xix_ixi​ 和 xjx_jxj​ 是否独立。 D-Separation 检查两个节点之间所有的无向路径 对于每一条路径，检查是否 active 一条路径是 active 的，当且仅当其上的每三个连续节点 (triple) 都是下面三个之一： Causal Chain A→B→CA\\to B\\to CA→B→C，其中 A,CA,CA,C 已观测，BBB 未观测 Common Cause B→A,CB\\to A,CB→A,C，其中 BBB 未观测 Common Effect A,C→BA,C\\to BA,C→B，其中 BBB 或其后继节点被观测 只要有一个 triple 不是，那么整条路径都是 inactive 的 注意：虽然路径提取的时候按无向边看，但是看 triple 的时候需要按原贝叶斯网络的有向边来看。 最后检查 xi,xjx_i,x_jxi​,xj​ 之间的所有路径是否都是 inactive，是的话则相互独立，否则不相互独立。 Inference Inference 考虑的是这么一个问题，给定 可观测随机变量的观测值 e1,e2,…,eke_1,e_2,\\dots,e_ke1​,e2​,…,ek​ 待查询的随机变量 QQQ 隐藏随机变量（无法观测） H1,H2,…,HrH_1,H_2,\\dots,H_rH1​,H2​,…,Hr​ 求解待观测随机变量的分布： P(Q=q∣e1,e2,…ek) P(Q=q|e_1,e_2,\\dots e_k) P(Q=q∣e1​,e2​,…ek​) 例如求解后验概率，或者求解最可能解释 arg max⁡qP(Q=q∣e1:k)\\argmax_q P(Q=q|e_{1:k})argmaxq​P(Q=q∣e1:k​)。 By Enumeration 即通过枚举所有 QQQ 的可能值进行求解： 提取所有符合观测的 CPT Entry (尤其是包含 HiH_iHi​ 的 Entry) 加和，然后 Normalize P(Q=q,e1:k)=∑h1:rP(Q=q,h1:r,e1:k)P(e1:k)=∑qP(Q=q,e1:k)P(Q=q∣e1:k)=P(Q=q,e1:k)P(e1:k) \\begin{aligned} P(Q=q,e_{1:k})&amp;=\\sum_{h_{1:r}} P(Q=q,h_{1:r},e_{1:k})\\\\ P(e_{1:k})&amp;=\\sum_q P(Q=q, e_{1:k})\\\\ P(Q=q|e_{1:k})&amp;=\\frac{P(Q=q,e_{1:k})}{P(e_{1:k})} \\end{aligned} P(Q=q,e1:k​)P(e1:k​)P(Q=q∣e1:k​)​=h1:r​∑​P(Q=q,h1:r​,e1:k​)=q∑​P(Q=q,e1:k​)=P(e1:k​)P(Q=q,e1:k​)​​所以这里是条件概率的定义的直接应用。虽然简单，但是其时间复杂度是指数级的。 Variable Elimination 更一般地说，我们想要计算的分布是 P(Y1:n∣X1:m) P(Y_{1:n}|X_{1:m}) P(Y1:n​∣X1:m​)其值为 P(y1:n∣x1:m)P(y_{1:n}|x_{1:m})P(y1:n​∣x1:m​)，每一个这样的分布被称为 factor，yyy 为 unconditioned variables，xxx 为 conditioned variables Join Factors 合并两个 factor f1,f2f_1,f_2f1​,f2​，新的 factor f′f&#x27;f′ 的 uncond var 为 uncond(f′)=uncond(f1)∪uncond(f2) \\text{uncond}(f&#x27;)=\\text{uncond}(f_1)\\cup \\text{uncond}(f_2) uncond(f′)=uncond(f1​)∪uncond(f2​)f′f&#x27;f′ 的 cond var 为 cond(f′)=cond(f1)∪cond(f2)−uncond(f′) \\text{cond}(f&#x27;)=\\text{cond}(f_1)\\cup\\text{cond}(f_2) - \\text{uncond}(f&#x27;) cond(f′)=cond(f1​)∪cond(f2​)−uncond(f′)这里的减号指差集，出现在前者但不出现在后者的元素。 CS188 Assignment 示例代码 主要是演示操作 1 Elimination 考虑查询 P(Q∣e1:k)P(Q|e_{1:k})P(Q∣e1:k​) 从所有的 CPT 出发 每次提取一个 Hidden Var H∉e1:kH otin e_{1:k}H∈/e1:k​ 每一个涉及到 HHH 的 Factor 对 H=hH=hH=h 进行加和 ∑hf′(…H=h… )\\sum_h f&#x27;(\\dots H=h\\dots)∑h​f′(…H=h…) 于是就 Sum out HHH 了 最后只会剩下包含 Q,e1:kQ,e_{1:k}Q,e1:k​ 的 factors，加和并 normalize Decision Network 效用函数 (Utility Function): 将状态映射为实数，量化智能体对状态的偏好。 最大期望效用原则 (MEU): 理性智能体应选择最大化期望效用的行动. EU(x∣y)=∑wP(w∣y)U(x,w)EU(x|y)=\\sum_w P(w|y) U(x,w)EU(x∣y)=∑w​P(w∣y)U(x,w) Action a=max⁡xEU(x∣y)a=\\max_x EU(x|y)a=maxx​EU(x∣y) Utility 其实类似于 Q-Value? Utility 通过 Standard Lottery 来定义 对于当前 State SSS 和动作 AAA，考虑其会产生的所有结果（新 state）SiS_iSi​ 和对应的概率，考虑 U(Si)U(S_i)U(Si​) 的期望，就是当前 state 的 Utility U[pi,Si]=∑ipiSi U[p_i,S_i]=\\sum_i p_iS_i U[pi​,Si​]=i∑​pi​Si​ Value of Information VPI(E′∣e)VPI(E&#x27;|e)VPI(E′∣e) 在决策 E′E&#x27;E′ 的时候，信息 eee 是否有作用？ VPI(E′∣e)=∑e′P(e′∣e)MEU(e′,e)−MEU(e) VPI(E&#x27;|e)=\\sum_{e&#x27;}P(e&#x27;|e)MEU(e&#x27;,e)-MEU(e) VPI(E′∣e)=e′∑​P(e′∣e)MEU(e′,e)−MEU(e)"},{"title":"GRPO 算法","path":"/wiki/rl/deepseek-math.html","content":"GRPO GRPO 算法在 GAE 的基础上更进一步：既然计算 VπθV^{\\pi_\\theta}Vπθ​ 和估算 A^πθ\\hat A^{\\pi_\\theta}A^πθ​ 那么费劲，那么我直接不计算了，我直接使用 Monte Carlo 方法对 A^π\\hat A^\\piA^π 进行估计"},{"title":"Markov","path":"/wiki/rl/markov-model.html","content":"Markov Model 符号约定： 当前 state sts_tst​ 采样于机器人当前的 state space St\\mathbb S_tSt​ 机器人可以采取的 action ata_tat​ 采样于当前的 action space At\\mathbb A_tAt​ 机器人在 state sss，采取 action aaa，进入新 state s′s&#x27;s′，可以得到 Reward rrr。这个 rrr 由奖励模型 R(s,a,s′)R(s,a,s&#x27;)R(s,a,s′) 给出 Markov Decision Process V(s)V(s)V(s) Q(s,a)Q(s,a)Q(s,a) π(s)\\pi(s)π(s) Value Iteration Policy Iteration Policy Iteration 的核心是，在 Value Iteration 的基础上增加对 Policy 的更新与迭代。 \\begin{algorithm} \\caption{Policy Iteration} \\begin{algorithmic} \\input First, init $\\pi_0(s)$ with some default actions $a$ for each state $s$ \\output Converged $\\pi_{final}(s)$ \\for{$i$ \\to max number of policy iterations} \\state Fix our policy $\\pi_i(s)$ \\for {$j$ \\to max number of value iterations} \\state Execute value iterations with fixed policy \\state $V^{\\pi_i}_j(s) \\gets \\sum_{s'}T(s,\\pi_i(s), s')\\Big[ R(s, \\pi_i(s), s') + V^{\\pi_i}_{j-1}(s') \\Big]$ \\endfor \\state Update our policy based on values $V(s)$ \\state $\\pi_{i+1}(s)=\\argmax_{a} \\sum_{s'}T(s,a,s')\\Big[ R(s,a,s')+\\gamma V^{\\pi_i}_{final}(s') \\Big]$ \\endfor \\end{algorithmic} \\end{algorithm}"},{"title":"PPO 算法","path":"/wiki/rl/ppo.html","content":"PPO 算法 PPO 想处理的一个问题是，在 Actor-Critic 架构下，我们训练的过程是：πt−1\\pi_{t-1}πt−1​ 里计算 mmm 步 Trajectory 用于更新 πt\\pi_tπt​，这样的一个显著的问题就是计算开销太大，每一次都需要用刚刚训练好的大模型进行采样（而且大模型通常 32B 参数以上，训练成本极大） 于是一个想法就是，我们能否将采样的 mmm 步 Trajectory 给缓存下来呢？ Importance Sampling Importance Sampling 的核心是，从已知的分布里进行采样 E(st,at)∼πθ[∇θlog⁡πθ(at∣st)Aπθ(st,at)]= E(st,at)∼πref[πθ(at∣st)πref(at∣st)∇θlog⁡πθ(at∣st)Aπθ(st,at)] \\begin{aligned} &amp;\\mathbb E_{(s_t,a_t)\\sim \\pi_\\theta}\\Big[ abla_\\theta\\log\\pi_\\theta(a_t|s_t)A^{\\pi_\\theta}(s_t,a_t) \\Big]\\\\ =\\ &amp;\\mathbb E_{(s_t,a_t)\\sim \\boxed{\\pi_{ref}}}\\Big[ \\boxed{\\frac{\\pi_\\theta(a_t|s_t)}{\\pi_{ref}(a_t|s_t)}} abla_\\theta\\log\\pi_\\theta(a_t|s_t)A^{\\pi_\\theta}(s_t,a_t) \\Big] \\end{aligned} = ​E(st​,at​)∼πθ​​[∇θ​logπθ​(at​∣st​)Aπθ​(st​,at​)]E(st​,at​)∼πref​​​[πref​(at​∣st​)πθ​(at​∣st​)​​∇θ​logπθ​(at​∣st​)Aπθ​(st​,at​)]​直观上理解的话，我们从 πref\\pi_{ref}πref​ 采样出来的 Trajectory 显然不能完全以相同权重直接用于更新后几步的 Policy πθ\\pi_{\\theta}πθ​，因此，用 πθ(at∣st)πref(at∣st) \\pi_\\theta(a_t|s_t)\\over{\\pi_{ref}(a_t|s_t)} πref​(at​∣st​)πθ​(at​∣st​)​对每一步 Trajectory 的权重进行调整后再反向传播更新参数。 Training Constraint: KL Penalty Training Constraint: Clip Objective"},{"title":"Q Learning","path":"/wiki/rl/q-learning.html","content":"Q-Learning 我们的 Agent 每次从环境接收 transition=(s,a,r,s′)\\texttt{transition}=(s,a,r,s&#x27;)transition=(s,a,r,s′) 的反馈，以此进行学习。由于无法建模出转移概率 T(s,a,s′)T(s,a,s&#x27;)T(s,a,s′)，我们用采样的方式（蒙特卡洛）来训练 Qt+1(s,a)←(1−α)Qt(s,a)+α[R(s,a,s′)+γmax⁡a′Qt(s′,a′)] Q_{t+1}(s,a) \\gets (1-\\alpha)Q_{t}(s,a)+\\alpha\\Big[ R(s,a,s&#x27;)+\\gamma \\max_{a&#x27;} Q_t(s&#x27;,a&#x27;) \\Big] Qt+1​(s,a)←(1−α)Qt​(s,a)+α[R(s,a,s′)+γa′max​Qt​(s′,a′)]这个式子也可以等价地写作 Qt+1(s,a)←Qt(s,a)+α[r+γmax⁡a′Qt(s′,a′)−Qt(s,a)] Q_{t+1}(s,a)\\gets Q_t(s,a)+\\alpha\\Big[ r+\\gamma \\max_{a&#x27;}Q_t(s&#x27;,a&#x27;)-Q_t(s,a) \\Big] Qt+1​(s,a)←Qt​(s,a)+α[r+γa′max​Qt​(s′,a′)−Qt​(s,a)] Approx Q-Learning 在 Approx Q-Learning 算法里，我们把 Q(s,a)Q(s,a)Q(s,a) 分解为多个关于 state sss 和行动 aaa 的 feature\\tt featurefeature 之线性组合（feature\\tt featurefeature 不一定需要和 s,as,as,a 成线性） Q(s,a)=∑iwi×fi(s,a) \\boxed {Q(s,a)=\\sum olimits_i w_i \\times f_i(s,a)} Q(s,a)=∑i​wi​×fi​(s,a)​令当次从环境的采样为 (s,a,s′,r)(s,a,s&#x27;,r)(s,a,s′,r)，表示从状态 sss 执行动作 aaa 转移到状态 s′s&#x27;s′ 得到奖励 rrr，定义 Sample Difference 为 Δ=r+γmax⁡a′Q(s′,a′)−Q(s,a) \\Delta=r+\\gamma\\max_{a&#x27;}Q(s&#x27;,a&#x27;)-Q(s,a) Δ=r+γa′max​Q(s′,a′)−Q(s,a)feature weights\\texttt{feature weights}feature weights 的更新则为 wi←wi+α×Δ×fi(s,a) w_i\\gets w_i+\\alpha\\times\\Delta\\times f_i(s,a) wi​←wi​+α×Δ×fi​(s,a) 推导 核心公式 GetAction()π(s)=arg max⁡aQ(s,a)UpdateWeights()wi←wi+α×[Δ]×fi(s,a) \\begin{array}{|r|cl|} \\hline \\text{GetAction()}&amp;\\pi(s)&amp;=\\argmax_{a}Q(s,a)\\\\ \\hline \\text{UpdateWeights()}&amp;w_i&amp;\\gets w_i+\\alpha\\times[\\Delta]\\times f_i(s,a)\\\\ \\hline \\end{array} GetAction()UpdateWeights()​π(s)wi​​=argmaxa​Q(s,a)←wi​+α×[Δ]×fi​(s,a)​​ 实现代码 12345678910111213141516171819class ApproxQLearningAgent(): def __init__(self): self.gamma = # reward discount rate self.alpha = # weight update factor self.epsilon = # learning rate self.weights = &#123; &quot;f1&quot;: 0.0, # correspond to w1*f1(s,a) &quot;f2&quot;: 0.0, # correspond to w2*f2(s,a) # ... &#125; def get_legal_actions(self): &#x27;&#x27;&#x27; 获取 &#x27;&#x27;&#x27; pass def"},{"title":"强化学习、与大语言模型","path":"/wiki/rl/rl-and-llm.html","content":"什么是强化学习 RL 强化学习在大模型语言里的应用 我们考虑大模型语言的生成过程： 123token1 token2 | token3 | token4 token5 ... ^ ^ ^ state action state(next) 如图所示，现阶段的大模型都是采用自回归生成的。我们可以将“大模型生成的前 t−1t-1t−1 个单词”视为状态 sts_tst​，那么生成第 ttt 个单词视作第 ttt 时刻采取的动作 ata_tat​，得到下一时刻的状态 st+1s_{t+1}st+1​。与上图进行对应的话：大模型本身就是智能体，环境和 Reward 可以抽象地理解为人类偏好（人类依据自己的偏好，给模型的输出打分，大模型的目标就是得分尽可能得高，对应着更加优秀的大模型）。 Trajectory 在普通的强化学习过程中，Trajectory 指的是一连串的 state, action, reward，记作 τ\\tauτ τ=(s0,a0,r1,s1,a1,r2,… ) \\tau=(s_0,a_0,r_1,s_1,a_1,r_2,\\dots) τ=(s0​,a0​,r1​,s1​,a1​,r2​,…) Policy Gradient Theorem: Directly Learn Policy (LLM) 如果我们想直接学习 Policy π()\\pi()π() 的话，我们考虑把 π()\\pi()π() 参数化为函数 πθ()\\pi_\\theta()πθ​()，因此将 Objective Function 建模为梯度上升问题（这里的 ∼\\sim∼ 表示 trajectory 从 πθ\\pi_\\thetaπθ​ 中采样得到） J(θ)=Eτ∼πθ[R(τ)] J(\\theta)=\\mathbb E_{\\tau \\sim \\pi_\\theta}[R(\\tau)] J(θ)=Eτ∼πθ​​[R(τ)]设 trajectory τ\\tauτ 包含 TTT 步，每一步为 ttt，计算其梯度，得到 ∇θJ(θ)=Eτ∼πθ[∑t=0T∇θlog⁡πθ(at∣st)⋅R(τ)] abla_\\theta J(\\theta)=\\mathbb E_{\\tau\\sim\\pi_\\theta}\\Big[ \\sum_{t=0}^T abla_\\theta \\log \\pi_\\theta(a_t|s_t)\\cdot R(\\tau) \\Big] ∇θ​J(θ)=Eτ∼πθ​​[t=0∑T​∇θ​logπθ​(at​∣st​)⋅R(τ)]"},{"title":"强化学习：Markov Chain 与贝尔曼方程","path":"/wiki/rl/rl-bellman-equation.html","content":"Markov Decision Process 因此进一步定义： 世界（环境）模型 T(s,a,s′)T(s,a,s&#x27;)T(s,a,s′)，表示++机器人在状态 sss 时，如果采取 aaa 行动，那么有 T(s,a,s′)T(s,a,s&#x27;)T(s,a,s′) 的概率进入状态 s′s&#x27;s′。++这个模型也就是机器人与环境交互的入口 奖励函数 R(s,a,s′)R(s,a,s&#x27;)R(s,a,s′)，表示如果机器人在状态 sss 时采取 aaa 行动并进入状态 s′s&#x27;s′，就能获得 R(s,a,s′)R(s,a,s&#x27;)R(s,a,s′) 的奖励。 我们希望，机器人在世界模型和奖励函数（这两个是事先给定的）中，学习到在某个环境下该采取何种行动这一个 objective，这样一个 objective 的数学本质是 π:S↦A\\pi:\\mathbb S\\mapsto\\mathbb Aπ:S↦A，即 π(s)=a\\pi(s)=aπ(s)=a，函数输入状态，输出该采取什么行动。我们把这个 π(s)\\pi(s)π(s) 称为 Policy How to Learn a Policy Evaluation 很显然，我们需要一个 criterion 才能评判一个 Policy 到底好不好。 当我们的机器人根据 πi()\\pi_i()πi​() 运行了一段时间后，会得到一连串的 Reward 和一个 Accumulative Reward，而由于世界模型是概率模型，因此同一个 πi()\\pi_i()πi​() 可能会产生不同的 Reward Sequence 和不同的 Accumulative Reward。 我们也要考虑步数的影响（不然机器人来回踱步刷分数），因此引入 Discount，在每一步的 Reward 上乘的衰减系数 γ\\gammaγ，表明 Reward 随着步数的增长而减少。 我们在此基础上定义，即为 Policy 的 Utility 为 Reward 的期望值。 State 的 Utility 为从这个 State sss 出发的 Expected Utility，即为 V(s)V(s)V(s)，用上标 ∗\\ast∗ 表示最优策略 MDP Search Tree MDP Search Tree Value of State 定义： Q-State 为机器人选择完行动后，但还没有执行（还没有转移到 s′s&#x27;s′）的中间状态。 根据这棵树的结构可以推导出 V∗(s)=max⁡aQ∗(s,a)Q∗(s,a)=∑s′T(s,a,s′)[R(s,a,s′)+γV∗(s′)]so we get…⟹V∗(s)=max⁡a∑s′T(s,a,s′)[R(s,a,s′)+γV∗(s′)] \\begin{aligned} V^\\ast(s)&amp;=\\max_a Q^\\ast(s,a)\\\\ Q^\\ast(s,a)&amp;=\\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V^\\ast(s&#x27;)\\Big]\\\\ &amp;\\textbf{so we get}\\dots\\\\ \\Longrightarrow V^\\ast(s)&amp;=\\max_a \\sum_{s&#x27;}T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V^\\ast(s&#x27;)\\Big] \\end{aligned} V∗(s)Q∗(s,a)⟹V∗(s)​=amax​Q∗(s,a)=s′∑​T(s,a,s′)[R(s,a,s′)+γV∗(s′)]so we get…=amax​s′∑​T(s,a,s′)[R(s,a,s′)+γV∗(s′)]​ 求解 Policy 从 V(s) 求解 policy 数值迭代算法 从 V0(s)=0V_0(s)=0V0​(s)=0 开始 用上一次的 Vt(s)V_t(s)Vt​(s) 更小当次的 Vt+1(s)V_{t+1}(s)Vt+1​(s) Vt+1(s)←max⁡a∑s′T(s,a,s′)[R(s,a,s′)+γVt(s′)] V_{t+1}(s)\\gets \\max_a\\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V_t(s&#x27;) \\Big] Vt+1​(s)←amax​s′∑​T(s,a,s′)[R(s,a,s′)+γVt​(s′)]这里的 γ\\gammaγ 表示步数的 Discount 直到收敛 V∗(s)V^\\ast(s)V∗(s)，时间复杂度 O(S2A)O(S^2A)O(S2A) 从 V∗(s)V^\\ast(s)V∗(s) 提取 Policy π∗(s)=arg max⁡a∑s′T(s,a,s′)[R(s,a,s′)+γV∗(s′)] \\pi^\\ast(s)=\\argmax_a\\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V^\\ast(s&#x27;) \\Big] π∗(s)=aargmax​s′∑​T(s,a,s′)[R(s,a,s′)+γV∗(s′)]为每一个 state 选择一个 action 策略迭代算法 当 Policy 固定为 πi()\\pi_i()πi​() 时，此时不用考虑最优策略，等同于不需要取 max⁡a\\max_amaxa​，因此从 state sss 出发的 expected utility 就只有单纯的求和了，为 Vπi(s)=∑s′T(s,πi(s),s′)[R(s,πi(s),s′)+γVπi(s′)] V^{\\pi_i}(s)=\\sum_{s&#x27;} T(s,\\pi_i(s),s&#x27;)\\Big[R(s,\\pi_i(s),s&#x27;)+\\gamma V^{\\pi_i}(s&#x27;)\\Big] Vπi​(s)=s′∑​T(s,πi​(s),s′)[R(s,πi​(s),s′)+γVπi​(s′)] Policy Evaluation. 为选定的 Policy 计算 Utility（非 Optimal Utility） Vt+1πi(s)←∑s′T(s,πi(s),s′)[R(s,πi(s),s′)+γVtπi(s′)] V_{t+1}^{\\pi_i}(s)\\gets \\sum_{s&#x27;}T(s,\\pi_i(s), s&#x27;)\\Big[R(s,\\pi_i(s),s&#x27;)+\\gamma V^{\\pi_i}_{t}(s&#x27;) \\Big] Vt+1πi​​(s)←s′∑​T(s,πi​(s),s′)[R(s,πi​(s),s′)+γVtπi​​(s′)] Policy Improvement. 优化 Policy πt+1(s)←arg max⁡a∑s′T(s,a,s′)[R(s,a,s′)+γVπi(s′)] \\pi_{t+1}(s)\\gets \\argmax_a \\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma V^{\\pi_i}(s&#x27;) \\Big] πt+1​(s)←aargmax​s′∑​T(s,a,s′)[R(s,a,s′)+γVπi​(s′)] 直到 Policy 收敛 从 Q∗(s,a)Q^\\ast(s,a)Q∗(s,a) 提取 Policy π∗(s)=arg max⁡aQ∗(s,a) \\pi^\\ast(s)=\\argmax_a Q^\\ast(s,a) π∗(s)=aargmax​Q∗(s,a) 从 Q-State 求解 Policy Q∗(s,a)=∑s′T(s,a,s′)[R(s,a,s′)+γmax⁡a′Q∗(s′,a′)] Q^\\ast(s,a)=\\sum_{s&#x27;} T(s,a,s&#x27;)\\Big[R(s,a,s&#x27;)+\\gamma\\max_{a&#x27;}Q^\\ast(s&#x27;,a&#x27;) \\Big] Q∗(s,a)=s′∑​T(s,a,s′)[R(s,a,s′)+γa′max​Q∗(s′,a′)]提取 Policy： π∗(s)=arg max⁡aQ∗(s,a) \\pi^\\ast(s)=\\argmax_a Q^\\ast(s,a) π∗(s)=aargmax​Q∗(s,a) Summary","categories":[null]},{"title":"基础","path":"/wiki/rustbook/basics.html","content":"流程控制"},{"title":"泛型、模板","path":"/wiki/rustbook/generic.html","content":"泛型（对标 C++ 模板） 函数、方法、结构体、枚举都可以使用泛型。 Type Annotation 明确指出泛型的类型需要满足什么条件。 函数泛型/函数模板 12fn func&lt;T&gt;(a: T) &#123;&#125; 12template &lt;typename T&gt;void function(T a) &#123;&#125; 方法泛型/方法模板 可以包含其他的类型 12345impl&lt;T&gt; Point&lt;T&gt; &#123; fn func&lt;U&gt;(&amp;self) -&gt; &amp;T &#123; &#125;&#125;// 等价于 ...... 12345template &lt;typename T&gt;class Point &#123; template &lt;typename U&gt; T func() &#123;&#125;&#125; const 泛型、模板参数 对应 C++ 中 template &lt;int N&gt; 这样的模板参数。 12fn func&lt;T, const N: usize&gt;(arr: [T; N]) &#123;&#125; 12template &lt;typename T, size_t N&gt;void func(std::array&lt;T, N&gt; arr) &#123;&#125; 针对 const 泛型做检查 这个在 C++ 里应该需要使用 require 做检查，我还没有研究过。Rust 里使用 Assert&lt;&gt;: IsTrue 泛型限制即可。 1234567fn something&lt;T&gt;(val: T)where Assert&lt;&#123; core::mem::size_of::&lt;T&gt;() &lt; 768 &#125;&gt;: IsTrue, // ^ 这里是一个 const 表达式，换成其它的 const 表达式也可以&#123; //&#125; const fn 对应 C++ 的 constexpr，在编译期求值。"},{"title":"深入特征","path":"/wiki/rustbook/more-traits.html","content":"关联类型 12345pub trait Iterator &#123; type Item; fn next(&amp;mut self) -&gt; Option&lt;Self::Item&gt;;&#125; why not Generics? 使用泛型：1234567trait Container&lt;A, B&gt; &#123; fn contains(&amp;self, a: A, b: B) -&gt; bool;&#125;fn difference&lt;A, B, C&gt;(container: &amp;C) -&gt; i32 where C : Container&lt;A, B&gt; &#123;...&#125; 使用关联类型1234567trait Container&#123; type A; type B; fn contains(&amp;self, a: &amp;Self::A, b: &amp;Self::B) -&gt; bool;&#125;fn difference&lt;C: Container&gt;(container: &amp;C) &#123;&#125; 特征和类型都有同名方法 优先调用类型上的方法 显示通过特征调用方法 12// for example ...Trait.method(&amp;object); 用完全限定语法，让类型使用某个特征的方法（也可适用于 2） 12// like this&lt;Type as Trait&gt;::function(receiver_if_method, other_arguments...); 特征定义中的特征约束 12trait X: Y&#123;&#125; 如果你想要实现 X 特征，首先你需要实现 Y 特征。 外部类型上实现外部特征"},{"title":"所有权","path":"/wiki/rustbook/ownership.html","content":"所有权"},{"title":"特征、特征对象","path":"/wiki/rustbook/traits.html","content":"Traits 特征定义了一组可以被共享的行为，只要实现了特征，你就能使用这组行为。 Trait 实现：孤儿规则 如果你想要为类型 A 实现特征 T，那么 A 或者 T 至少有一个是在当前作用域中定义的！ 使用特征作为函数参数 意义：所有实现了 Trait 这个特征的类型 12fn func(item: &amp;impl Trait)&#123;&#125; 本质是泛型的语法糖： 12fn func&lt;T: Trait&gt;(item: &amp;T)&#123;&#125; derive 派生 特征作为返回值 返回一个对象，这个对象实现了 Summary 特征 12fn func(...) -&gt; impl Summary &#123;&#125; 问题：最终 impl Summary 只能对应一个类型，如果想做到 if .. &#123; return A &#125; else &#123; return B &#125; 是不行的 在 C++ 里，我们可以用继承的方式，返回父类指针。在 Rust 里应该怎么做呢？ 在 Rust 里，我们使用 Box&lt;dyn Trait&gt; 或者 &amp;dyn Trait，两者的区别在于：前者是通过 Box::new() 在堆上创建的新变量，后者是对已有的变量的引用。 特征对象的动态分发 当使用特征对象时，Rust 必须使用动态分发。编译器无法知晓所有可能用于特征对象代码的类型，所以它也不知道应该调用哪个类型的哪个方法实现。为此，Rust 在运行时使用特征对象中的指针来知晓需要调用哪个方法。动态分发也阻止编译器有选择的内联方法代码，这会相应的禁用一些优化。 trait object 虽然特征对象没有固定大小，但它的引用类型的大小是固定的，它由两个指针组成（ptr 和 vptr），因此占用两个指针大小 一个指针 ptr 指向实现了特征 Draw 的具体类型的实例，也就是当作特征 Draw 来用的类型的实例，比如类型 Button 的实例、类型 SelectBox 的实例 另一个指针 vptr 指向一个虚表 vtable，vtable 中保存了类型 Button 或类型 SelectBox 的实例对于可以调用的实现于特征 Draw 的方法。当调用方法时，直接从 vtable 中找到方法并调用。之所以要使用一个 vtable 来保存各实例的方法，是因为实现了特征 Draw 的类型有多种，这些类型拥有的方法各不相同，当将这些类型的实例都当作特征 Draw 来使用时(此时，它们全都看作是特征 Draw 类型的实例)，有必要区分这些实例各自有哪些方法可调用 但是虚表里只会保存 Draw 特征的方法 12345678910111213141516171819202122232425262728293031323334353637struct A &#123;&#125;impl A &#123; fn foo(&amp;self) &#123; println!(&quot;A::foo&quot;); &#125;&#125;struct B &#123;&#125;impl B &#123; fn foo(&amp;self) &#123; println!(&quot;B::foo&quot;); &#125;&#125;trait Bar &#123; fn bar(&amp;self);&#125;impl Bar for A &#123; fn bar(&amp;self) &#123; println!(&quot;A::bar&quot;); &#125;&#125;impl Bar for B &#123; fn bar(&amp;self) &#123; println!(&quot;B::bar&quot;); &#125;&#125;fn main() &#123; let mut v = Vec::&lt;Box&lt;dyn Bar&gt;&gt;::new(); v.push(Box::new(A&#123;&#125;)); v.push(Box::new(B&#123;&#125;)); for item in v.iter() &#123; item.bar(); // item.foo(); // This line will cause a compile-time error &#125;&#125; 特征对象的限制 必须满足下列所有条件： 返回类型不能是 Self 如果特征方法返回了具体的 Self 类型，但是特征对象忘记了其真正的类型（特征对象只知道这个类型实现了某个 Trait），那这个 Self 就非常尴尬，因为没人知道它是谁了。 没有泛型参数 对于泛型类型参数来说，当使用特征时其会放入具体的类型参数：此具体类型变成了实现该特征的类型的一部分。而当使用特征对象时其具体类型被抹去了，故而无从得知放入泛型参数类型到底是什么。 针对第一点的解释 考虑这么一段代码 12345678trait Trait &#123; fn foo(&amp;self) -&gt; Self;&#125;fn call_foo(x: Box&lt;dyn Trait&gt;) &#123; let y = x.foo(); // What type is y? // ...&#125; 我们只能推断出 y 的类型是某个实现了 Trait 特征的类型， 针对第二点的解释 123456789101112131415161718trait Trait &#123; fn foo&lt;T&gt;(&amp;self, on: T); // more methods&#125;impl Trait for String &#123; fn foo&lt;T&gt;(&amp;self, on: T) &#123; // implementation 1 &#125;&#125;impl Trait for u8 &#123; fn foo&lt;T&gt;(&amp;self, on: T) &#123; // implementation 2 &#125;&#125;// 8 more implementations 考虑这样的调用 12345fn call_foo(thing: Box&lt;dyn Trait&gt;) &#123; thing.foo(true); // this could be any one of the 8 types above thing.foo(1); thing.foo(&quot;hello&quot;);&#125; Rust 针对泛型的处理又是单态化，这意味着这样一结合，Rust 代码会出现 303030 种实现，全都是泛型的单态化展开。"},{"title":"Isaac Lab(Sim) 简介","path":"/wiki/simulation/isaac-lab-brief.html","content":"Assets Isaac Sim Has more built-in scenes and robots available Classic: Cartpole, Humanoid, Ant Fixed-Arm and Hands: UR10, Franka, Allegro, Shadow Hand Quadrupeds: Anybotics Anymal-B, Anymal-C, Anymal-D, Unitree A1, Unitree Go1, Unitree Go2, Boston Dynamics Spot Humanoids: Unitree H1, Unitree G1 Quadcopter: Crazyflie Procedure Isaac Lab: Manager Method: More specified control Direct Method: Similar to Maniskill. Example of Direct Method: 1234567891011121314151617181920212223242526272829303132333435def _get_rewards(self) -&gt; torch.Tensor: total_reward = compute_rewards( self.cfg.rew_scale_alive, self.cfg.rew_scale_terminated, self.cfg.rew_scale_pole_pos, self.cfg.rew_scale_cart_vel, self.cfg.rew_scale_pole_vel, self.joint_pos[:, self._pole_dof_idx[0]], self.joint_vel[:, self._pole_dof_idx[0]], self.joint_pos[:, self._cart_dof_idx[0]], self.joint_vel[:, self._cart_dof_idx[0]], self.reset_terminated, ) return total_reward@torch.jit.scriptdef compute_rewards( rew_scale_alive: float, rew_scale_terminated: float, rew_scale_pole_pos: float, rew_scale_cart_vel: float, rew_scale_pole_vel: float, pole_pos: torch.Tensor, pole_vel: torch.Tensor, cart_pos: torch.Tensor, cart_vel: torch.Tensor, reset_terminated: torch.Tensor,): rew_alive = rew_scale_alive * (1.0 - reset_terminated.float()) rew_termination = rew_scale_terminated * reset_terminated.float() rew_pole_pos = rew_scale_pole_pos * torch.sum(torch.square(pole_pos).unsqueeze(dim=1), dim=-1) rew_cart_vel = rew_scale_cart_vel * torch.sum(torch.abs(cart_vel).unsqueeze(dim=1), dim=-1) rew_pole_vel = rew_scale_pole_vel * torch.sum(torch.abs(pole_vel).unsqueeze(dim=1), dim=-1) total_reward = rew_alive + rew_termination + rew_pole_pos + rew_cart_vel + rew_pole_vel return total_reward Tasks"},{"title":"ManiSkill 物理仿真：编写 Tasks for RL","path":"/wiki/simulation/maniskill-testcase.html","content":"Task Components 较为繁琐的说法 Setting up the Task Class Loading (Robots, Assets, Sensors, etc.) (run once) Episode initialization / Randomization (run every env.reset) Success/Failure Condition (run every env.step) Extra Observations (run every env.step) (Optional) Dense Reward Function (run every env.step) (Optional) Setting up cameras/sensors for observations and rendering/recording (run once) 最简工作流示例 env init env.step 负责根据 Action，然后在物理仿真，模拟无理式解的变化，并计算 Reward。 env.step 简单来说，一个类包含这些元素： @register_env() 方便外部调用 class CustomEnv(BaseEnv) 使用继承，快速开发新 Testcase （成员变量）SUPPORTED_ROBOTS = [] 定义该 Testcase 里使用的 Robot （成员变量）agent: Union[...] Robot，也即 Agent Environment Class 首先，我们定义一个类继承 BaseEnv，这个类是我们初始化 Environment 的入口。同时需要调用 mani_skill.utils.registeration.register_env() 函数进行“注册”（主要是定义名称和限定最大迭代步数） 12@register_env(&quot;CustomEnv-v1&quot;, max_episode_steps=200)class CustomEnv(BaseEnv): 然后我们在这个环境里定义我们需要的 Agent 定义物体 位置与朝向 建议在 _load_scene() 的时候就设置一次位置与朝向，然后在 _initialize_episode() 中"},{"title":"llama.cpp 常用 API","path":"/wiki/usefulAPIs/llama-cpp.html","content":"Preliminary: 启动一个 llama.cpp server llama-server 的 API"},{"title":"vllm 服务器 API 与示例","path":"/wiki/usefulAPIs/vllm-server.html","content":"vllm 部署 embedding 模型 vllm 部署 Vision Language Model, LLM 选用的是 Qwen/Qwen2.5-VL-3B-Instruct vllm 部署命令： $"},{"title":"django 表单","path":"/wiki/web_fullstack/django-forms.html","content":"django.forms.Form 类 在 Form 里定义需要填写的栏目，这样就可以直接在 template 里渲染了"},{"title":"Django 模板","path":"/wiki/web_fullstack/django-template.html","content":"Django 模板 Django 模板的作用是，可以根据数据动态地展示网页。例如，可以根据用户的权限，选择向用户展示 dashboard 或者登录界面。 与 views.py 交互"}]