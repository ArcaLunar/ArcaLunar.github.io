[{"title":"JOISC2021 - IOI 热病","path":"/joisc2021-ioi-netsubyou/","content":"太难写了，吐了 bro IOI 热病 我们不妨钦定居民 a1a_1a1​ 的方向为 d1=(1,0)d_1=(1, 0)d1​=(1,0)（向右走）。首先，我们需要推理出关于居民方向的有关性质。 性质 aia_iai​ 的方向 did_idi​ 满足"},{"title":"P3631 [APIO2011] 方格染色","path":"/topic/dailycf/LuoguP3631/","content":"P3631 [APIO2011] 方格染色[1] 题目里说把 111 看成红色，000 看成蓝色，那么任意一个 2×22\\times 22×2 的区域，其异或和为 111. xi,j⊕xi−1,j⊕xi,j−1⊕xi−1,j−1=1 x_{i,j}\\oplus x_{i-1,j}\\oplus x_{i,j-1}\\oplus x_{i-1,j-1}=1 xi,j​⊕xi−1,j​⊕xi,j−1​⊕xi−1,j−1​=1接着考虑和这个 2×22\\times 22×2 区域相交了两个格子的区域 [i−2,i−1]×[j−1,j][i-2,i-1]\\times[j-1,j][i−2,i−1]×[j−1,j]，由于异或相消，有 xi,j⊕xi−1,j⊕xi,j−1⊕xi−1,j−1=1⊕xi−1,j⊕xi−2,j⊕xi−1,j−1⊕xi−2,j−1=1xi,j⊕xi−2,j⊕xi,j−1⊕xi−2,j−1=0 \\begin{array}{c|lllll} x_{i,j}\\oplus \\cancel{x_{i-1,j}}\\oplus x_{i,j-1}\\oplus \\cancel{x_{i-1,j-1}}=1\\\\ \\oplus \\cancel{x_{i-1,j}}\\oplus x_{i-2,j}\\oplus \\cancel{x_{i-1,j-1}}\\oplus x_{i-2,j-1}=1\\\\ \\hline x_{i,j}\\oplus x_{i-2,j}\\oplus x_{i,j-1}\\oplus x_{i-2,j-1}=0 \\end{array} ⊕​xi,j​xi−1,j​​xi,j​​⊕xi−1,j​​⊕xi−2,j​⊕xi−2,j​​⊕xi,j−1​⊕xi−1,j−1​​⊕xi,j−1​​⊕xi−1,j−1​​⊕xi−2,j−1​⊕xi−2,j−1​​=1=1=0​​进一步代入 i′←i−2i\\gets i-2i′←i−2 可以推广到 xi,j⊕xi−2k,j⊕xi,j−1⊕xi−2k,j−1=0 x_{i,j}\\oplus x_{i-2k,j}\\oplus x_{i,j-1} \\oplus x_{i-2k,j-1}=0 xi,j​⊕xi−2k,j​⊕xi,j−1​⊕xi−2k,j−1​=0把 j′←j−1j\\gets j-1j′←j−1 代入发现 xi,j⊕xi−2k,j⊕xi,j−1⊕xi−2k,j−1=0⊕xi,j−1⊕xi−2k,j−1⊕xi,j−2⊕xi−2k,j−2=0xi,j⊕xi−2k,j⊕xi,j−2⊕xi−2k,j−2=0 \\begin{array}{c|lllll} x_{i,j}\\oplus x_{i-2k,j}\\oplus \\cancel{x_{i,j-1}}\\oplus \\cancel{x_{i-2k,j-1}}=0\\\\ \\oplus\\cancel{x_{i,j-1}}\\oplus \\cancel{x_{i-2k,j-1}}\\oplus x_{i,j-2}\\oplus x_{i-2k,j-2}=0\\\\ \\hline x_{i,j}\\oplus x_{i-2k,j}\\oplus x_{i,j-2}\\oplus x_{i-2k,j-2}=0\\\\ \\end{array} ⊕​xi,j​xi,j−1​​xi,j​​⊕xi−2k,j​⊕xi−2k,j−1​​⊕xi−2k,j​​⊕xi,j−1​​⊕xi,j−2​⊕xi,j−2​​⊕xi−2k,j−1​​⊕xi−2k,j−2​⊕xi−2k,j−2​​=0=0=0​​所以可以推广到 xi,j⊕xi−2k,j⊕xi,j−t⊕xi−2k,j−t=0 x_{i,j}\\oplus x_{i-2k,j}\\oplus x_{i,j-t}\\oplus x_{i-2k,j-t}=0 xi,j​⊕xi−2k,j​⊕xi,j−t​⊕xi−2k,j−t​=0同理有 xi,j⊕xi,j−2k⊕xi−t,j⊕xi−t,j−2k=0 x_{i,j}\\oplus x_{i,j-2k}\\oplus x_{i-t,j}\\oplus x_{i-t,j-2k}=0 xi,j​⊕xi,j−2k​⊕xi−t,j​⊕xi−t,j−2k​=0也就是说 Code #include algorithm#include iostream#include utility#include vectorusing namespace std;constexpr int N = 1e5 + 5;constexpr int M = 1e9;using vi = vectorint;using constraint = pairint, int;struct ColouredCell int x, y, c; cc[N];int n, m, k;int mapping(int x, int y) if (y == 0) return x; else return y + n;vectorconstraint G[N 1];int vis[N 1], val[N 1];int main() cin n m k; for (int i = 1; i = k; i++) cin cc[i].x cc[i].y cc[i].c; if (cc[i].x % 2 == 1 cc[i].y % 2 == 1) int a = mapping(cc[i].x, 0); int b = mapping(0, cc[i].y); G[a].push_back(b, cc[i].c); G[b].push_back(a, cc[i].c); else int a = mapping(cc[i].x, 0); int b = mapping(0, cc[i].y); G[a].push_back(b, cc[i].c ^ 1); G[b].push_back(a, cc[i].c ^ 1); auto dfs = [](auto F, int u) - bool vis[u] = 1; // cerr u ; for (auto [v, cons] : G[u]) if (vis[v]) if ((val[v] ^ val[u]) != cons) return false; continue; val[v] = val[u] ^ cons; if (!F(F, v)) return false; return true; ; int cnt = -2; for (int i = 0; i = n + m; i++) if (vis[i]) continue; cnt++; if (!dfs(dfs, i)) cout 0 ; return 0; // cerr ; int b = 2, p = cnt; int res = 1; while (p) if (p 1) res = 1ll * res * b % M; b = 1ll * b * b % M; p = 1; cout res ; LuoGu Blog ↩︎"},{"title":"P3632 [APIO2011] 寻路","path":"/topic/dailycf/LuoguP3632/","content":"寻路 因为只能横平竖直地移动，且不能穿过矩形，所以，我们希望能够建出下图的绿色点 格点 这样的绿色点的特征是：我们确保了可以在绿色点上换飞行方向，从而沿着建出来的边走。这样我们就可以跑最短路算法了。 现在考虑怎么建出这样的点。假定在某个点 (a,b)(a,b)(a,b) 并且向左走，那么我们画一条 y=by=by=b 的直线，在 (a,b)(a,b)(a,b) 左侧且最靠近 (a,b)(a,b)(a,b) 的点 (c,d)(c,d)(c,d) 就是 Dee 的落脚点，所以在 (c,d),(a,b)(c,d),(a,b)(c,d),(a,b) 之间连边。 处理完不同矩形之间的边后，我们还需要处理同一个矩形上的点之间的边，因为上面扫描线这一过程可能会产生不在角上的点（图中在边上的绿色点）。我们需要把这些点连接到矩形的角点上。具体而言，我们把扫描线产生的额外点 assign 到矩形的上、下、左、右边上，然后对每个矩形枚举四条边，sort - unique 之后相邻的点之间连边。 最后，我们在 start 和 end 之间跑一个裸的最短路即可。 Code 实现细节：我们处理两次，一次处理矩形的长 x=Lix=L_ix=Li​，一次处理矩形的宽 y=Hiy=H_iy=Hi​. 处理长的时候，我们按 yyy 坐标从小到大加入待处理队列（我用 mapint,int 同时维护顺序和线段范围），那么我们可以直接遍历 map，尝试在 it 代表的矩形边和 next(it) 代表的矩形边之间建一条边（如果这两条矩形边在不同的矩形上）。 #include algorithm#include cassert#include chrono#include ext/pb_ds/assoc_container.hpp#include ext/pb_ds/hash_policy.hpp#include iostream#include map#include queue#include utility#include vectorusing ll = long long;using edge = std::pairint, ll;using vi = std::vectorint;using pil = std::pairint, ll;using vpil = std::vectorpil;constexpr int N = 1e3 + 5;struct Rec int l, r, t, b; vi onl, onr, ont, onb; R[N];int n, index0;std::mapstd::pairint, int, int ind; // (x, y) - indexstd::mapint, std::pairint, int ind2; // index - (x, y)std::vectorvpil G;int insert(int x, int y) if (ind.find(x, y) != ind.end()) return ind[x, y]; ind[x, y] = ++index; ind2[index] = x, y; G.push_back(); return index;void run() G.push_back(); // index 0 is unused [] int a, b, c, d; std::cin a b c d; std::cin n; for (int i = 1; i = n; i++) std::cin R[i].l R[i].b R[i].r R[i].t; if (R[i].l R[i].r) std::swap(R[i].l, R[i].r); if (R[i].b R[i].t) std::swap(R[i].b, R[i].t); R[n + 1] = a, a, b, b; // start rectangle R[n + 2] = c, c, d, d; // end (); [] struct segment int id, x, y, end; // end: 0 = bottom, 1 = top segment(int i, int x, int y, int e) : id(i), x(x), y(y), end(e) ; std::vectorsegment cand; for (int i = 1; i = n + 2; i++) cand.emplace_back(i, R[i].l, R[i].b, 0); // left bottom cand.emplace_back(i, R[i].l, R[i].t, 1); // left top cand.emplace_back(i, R[i].r, R[i].b, 0); // right bottom cand.emplace_back(i, R[i].r, R[i].t, 1); std::sort(cand.begin(), cand.end(), [](const segment a, const segment b) if (a.y == b.y) if (a.x == b.x) return a.end b.end; // bottom before top else return a.x b.x; // sort by x first else return a.y b.y; ); std::mapint, int mp; // x - id for (auto it = cand.begin(); it != cand.end();) int y = it-y; auto tit = it; while (tit != cand.end() tit-y == y) mp.insert(tit-x, tit-id), tit++; // create points std::vectorint indexes; for (auto [x, id] : mp) assert(x == R[id].l || x == R[id].r); int k = insert(x, y); if (x == R[id].l) R[id].onl.push_back(k); else R[id].onr.push_back(k); indexes.push_back(k); // connect edges auto p = indexes.begin(); for (auto pit = mp.begin(); std::next(pit) != mp.end(); pit++, p++) auto nit = std::next(pit); auto np = std::next(p); if (nit-second == pit-second) continue; // 同一个蜂巢 ll len = nit-first - pit-first; G[*p].emplace_back(*np, len); G[*np].emplace_back(*p, len); // update segments for (; it != tit; it++) if (it-end == 1) mp.erase(it-x); (); [] struct segment int id, x, y, end; ; std::vectorsegment cand; for (int i = 1; i = n + 2; i++) cand.emplace_back(i, R[i].l, R[i].t, 0); cand.emplace_back(i, R[i].r, R[i].t, 1); cand.emplace_back(i, R[i].l, R[i].b, 0); cand.emplace_back(i, R[i].r, R[i].b, 1); std::sort(cand.begin(), cand.end(), [](const segment a, const segment b) if (a.x == b.x) if (a.y == b.y) return a.end b.end; else return a.y b.y; else return a.x b.x; ); std::mapint, int mp; // y - id for (auto it = cand.begin(); it != cand.end();) int x = it-x; auto tit = it; while (tit != cand.end() tit-x == x) mp.insert(tit-y, tit-id), tit++; // create points vi indexes; for (auto [y, id] : mp) assert(y == R[id].t || y == R[id].b); int k = insert(x, y); indexes.push_back(k); if (y == R[id].t) R[id].ont.push_back(k); else R[id].onb.push_back(k); // update edges auto p = indexes.begin(); for (auto pit = mp.begin(); std::next(pit) != mp.end(); pit++, p++) auto nit = std::next(pit); auto np = std::next(p); if (nit-second == pit-second) continue; ll len = nit-first - pit-first; G[*p].push_back(*np, len); G[*np].push_back(*p, len); // update segments for (; it != tit; it++) if (it-end == 1) mp.erase(it-y); (); auto clean = [](int which) // onl vi *v = R[which].onl; std::sort(v-begin(), v-end(), [](int i, int j) return ind2[i].second ind2[j].second; ); v-erase(std::unique(v-begin(), v-end()), v-end()); for (int i = 0; i + 1 v-size(); i++) int low = v-at(i), high = v-at(i + 1); int len = ind2[high].second - ind2[low].second; G[low].push_back(high, len); G[high].push_back(low, len); // onr v = R[which].onr; std::sort(v-begin(), v-end(), [](int i, int j) return ind2[i].second ind2[j].second; ); v-erase(std::unique(v-begin(), v-end()), v-end()); for (int i = 0; i + 1 v-size(); i++) int low = v-at(i), high = v-at(i + 1); int len = ind2[high].second - ind2[low].second; G[low].push_back(high, len); G[high].push_back(low, len); // onb v = R[which].onb; std::sort(v-begin(), v-end(), [](int i, int j) return ind2[i].first ind2[j].first; ); v-erase(std::unique(v-begin(), v-end()), v-end()); for (int i = 0; i + 1 v-size(); i++) int low = v-at(i), high = v-at(i + 1); int len = ind2[high].first - ind2[low].first; G[low].push_back(high, len); G[high].push_back(low, len); // ont v = R[which].ont; std::sort(v-begin(), v-end(), [](int i, int j) return ind2[i].first ind2[j].first; ); v-erase(std::unique(v-begin(), v-end()), v-end()); for (int i = 0; i + 1 v-size(); i++) int low = v-at(i), high = v-at(i + 1); int len = ind2[high].first - ind2[low].first; G[low].push_back(high, len); G[high].push_back(low, len); ; for (int i = 1; i = n + 2; i++) clean(i); int s = ind[R[n + 1].l, R[n + 1].b]; int e = ind[R[n + 2].l, R[n + 2].b]; std::vectorll dis(G.size(), 1e18); vi vis(G.size(), false); dis[s] = 0; std::priority_queuepil, vpil, std::greaterpil pq; pq.push(0, s); while (!pq.empty()) auto [d, u] = pq.top(); pq.pop(); if (vis[u]) continue; vis[u] = true; for (auto [v, len] : G[u]) if (vis[v]) continue; if (dis[v] dis[u] + len) dis[v] = dis[u] + len; pq.push(dis[v], v); if (dis[e] == 1e18) std::cout No Path ; else std::cout dis[e] ; [] // clear!! G.clear(); ind.clear(); ind2.clear(); index = 0; for (int i = 1; i = n + 2; i++) R[i].onl.clear(); R[i].onr.clear(); R[i].ont.clear(); R[i].onb.clear(); ();int main() int T; std::cin T; while (T--) run();"},{"title":"P9368 [ICPC2022 Xi'an] Streets","path":"/topic/dailycf/LuoguP9368/","content":"P9368 [ICPC 2022 Xi’an R] Streets 根据题意，我们可以想到的一个式子，假设选择 x1≤x2,y1≤y2x_1\\le x_2, y_1\\le y_2x1​≤x2​,y1​≤y2​，则 max⁡(x2−x1)(y2−y1)s.t.(x2−x1)(b1+b2)+(y2−y1)(a1+a2)≤C \\begin{array}{rc} \\max(x_2-x_1)(y_2-y_1)\\\\ s.t.(x_2-x_1)(b_1+b_2)+(y_2-y_1)(a_1+a_2)\\le C \\end{array} maxs.t.​(x2​−x1​)(y2​−y1​)(x2​−x1​)(b1​+b2​)+(y2​−y1​)(a1​+a2​)≤C​这个式子里，a1+a2,b1+b2a_1+a_2,b_1+b_2a1​+a2​,b1​+b2​ 都是单独给定的，无法进行合并，而且我们发现 x2−x1,y2−y1x_2-x_1,y_2-y_1x2​−x1​,y2​−y1​ 都是以这个形式一起出现的。而且，倘若 Δx\\Delta xΔx 值相同，那么我们肯定希望选择 ai+aja_i+a_jai​+aj​ 最小的那对 xi,xjx_i,x_jxi​,xj​. 所以，我们考虑处理出 f(dx)=min⁡∣xj−xi∣=dxai+ajf(dx)=\\min\\limits_{|x_j-x_i|=dx} a_i+a_jf(dx)=∣xj​−xi​∣=dxmin​ai​+aj​ 和 g(dy)=min⁡∣yj−yi∣=dybi+bjg(dy)=\\min\\limits_{|y_j-y_i|=dy}b_i+b_jg(dy)=∣yj​−yi​∣=dymin​bi​+bj​. 这一步可以在 O(n2+m2)O(n^2+m^2)O(n2+m2) 的时间内完成。 所以，我们的目标就变成了 max⁡dx⋅dys.t.dx⋅g(dy)+f(dx)⋅dy≤C \\begin{array}{rc} \\max dx\\cdot dy\\\\ s.t. dx\\cdot g(dy)+f(dx)\\cdot dy\\le C \\end{array} maxs.t.​dx⋅dydx⋅g(dy)+f(dx)⋅dy≤C​我们有 TTT 次询问。一个想法是，如果给定 (dy,g(dy))(dy,g(dy))(dy,g(dy))，那么我们就需要找一个满足约束条件且最大的 dxdxdx。改写式子可以得到： f(dx)≤−g(dy)dy⋅dx+Cdy f(dx)\\le -\\frac{g(dy)}{dy}\\cdot dx+\\frac{C}{dy} f(dx)≤−dyg(dy)​⋅dx+dyC​把 (dx,f(dx))(dx, f(dx))(dx,f(dx)) 标在坐标系上，所以其实我们想要的是直线 y=−g(dy)dyx+Cdyy=-\\frac{g(dy)}{dy}x+\\frac{C}{dy}y=−dyg(dy)​x+dyC​ 这条直线下方 xxx 最大的那个点。如果可以以 O(F)O(F)O(F) 的时间求出单次查询，那么我们遍历 (dy,g(dy))(dy,g(dy))(dy,g(dy)) 就可以对每一次查询求出其答案，TTT 次查询的总时间复杂度就是 O(TVF),V=105O(TVF),V=10^5O(TVF),V=105. 那么很显然，我们不能直接遍历 dxdxdx，这样 O(F)=O(V)O(F)=O(V)O(F)=O(V) 会直接 TLE. 这里，我初始的想法是直接对 (dx,f(dx))(dx,f(dx))(dx,f(dx)) 构造凸包后，直接在凸包上二分，找到一个在凸包上的点。 但是这样会有一个错误的点，就是虽然点 (x′,f(x′))(x,f(x))(x′,f(x′)) 不在凸包上，但是在直线下方，且比找到的凸包上的点靠右。 Illustration 图里，蓝色边是凸包上的边，其两个端点是凸包上的点；黄色线是约束条件变形而来的直线；zi色的点就是刚刚说的“可能会被遗漏的点”。 那么我们怎么才能算上这样的紫色点呢？我们把优化问题转化成存在性问题：既然我们要找直线下方最靠右的点 (x′,f(x′))(x,f(x))(x′,f(x′))，也就是说当 dx≤x′dx\\le xdx≤x′ 的时候，凸包上都至少有一个点在直线下方（要么是 x′xx′ 在凸包上，要么是 dx0x′dx_0\\lt xdx0​x′ 在凸包上）；当 dxx′dx\\gt xdxx′ 的时候，没有点在直线下方。 所以，我们就可以通过二分把优化问题转化成存在性问题。二分答案 xmidx_{mid}xmid​，判断 dx≥xmiddx\\ge x_{mid}dx≥xmid​ 形成的凸包中，是否有点在直线下方。 判断凸包上是否有点在一条直线下方，可以先在凸包上找到点 (x′,f(x′))(x,f(x))(x′,f(x′))，使得直线平移后会和凸包在这个点相切，再判断这个点是否在直线下方. 时间复杂度是 O(log⁡V)O(\\log V)O(logV) 的. 这个算法的时间复杂度由二分套二分决定：O(V)O(V)O(V) 枚举 (dy,g(dy))(dy,g(dy))(dy,g(dy))；对于每个 dydydy，O(log⁡V)O(\\log V)O(logV) 在 dx∈[1,V]dx\\in[1,V]dx∈[1,V] 里二分最靠右的点，每次二分里的 check_mid 还需要 O(log⁡V)O(\\log V)O(logV) 在凸包上二分找点。不过，考虑到同时维护凸包的话，把点从凸包里弹出、插入又需要 O(V)O(V)O(V)，所以整体时间复杂度会来到 O(T(V2log⁡V+Vlog⁡2V))O(T(V^2\\log V+V\\log^2 V))O(T(V2logV+Vlog2V)) 能不能再优化一下呢？答案其实具有不劣性：因为我们希望 max⁡dx⋅dy\\max dx\\cdot dymaxdx⋅dy，如果对于 dydydy 来说 dx0dx_0dx0​ 是可行的，那么对于 dy−1dy-1dy−1 来说，我们其实不需要关心 dx≤dx0dx\\le dx_0dx≤dx0​ 的所有 dxdxdx，因为 (dy−1)dx≤(dy−1)dx0dy⋅dx0(dy-1)dx\\le (dy-1)dx_0\\lt dy\\cdot dx_0(dy−1)dx≤(dy−1)dx0​dy⋅dx0​ 根本不可能更新 dydydy 计算出的答案。这就是答案的不劣性（虽然是我自己起的名字） 所以，上文里，我们并不需要每次都“在 dx∈[1,V]dx\\in[1,V]dx∈[1,V]” 里二分最靠右的点，而是可以维护一个下界的指针 ppp 并且从大到小枚举 dydydy。假设 dydydy 对应最大的 dxdxdx 是 dx0dx_0dx0​，那么对于 dy−1dy-1dy−1，我们只需要从 dx0+1dx_0+1dx0​+1 开始 find 对应的 dx′dxdx′ 即可。 由于当 dydydy 递减的时候，查找的下界也会至少 +1+1+1，所以我们最多进行 O(V)O(V)O(V) 次 find。但是考虑到如果在 [dx0+1,V][dx_0+1,V][dx0​+1,V] 上使用二分，不断地从凸包里删点、加点很可能超时。我们还需要想办法优化掉凸包的频繁删点、加点。 凸包的删点加点的复杂度来源就是虽然二分中 mid→mid′mid\\to midmid→mid′ 可以 O(1)O(1)O(1) 跳跃，但是对应的凸包却需要 O(mid′−mid)O(mid-mid)O(mid′−mid) 的时间删点加点进行维护，这部分的时间很有可能达到 O(V2)O(\\frac{V}{2})O(2V​)。 我们在预处理凸包的时候，记录下尝试加入 dx′dxdx′ 时删掉了哪些点 p[dx′]p[dx]p[dx′]（这说明点集 p[dx′]p[dx]p[dx′] 加上原本就在凸包里的点就是 dx≥dx′dx\\ge dxdx≥dx′ 对应的凸包）。那么直接考虑顺序枚举 dxdxdx，这样我们的凸包只需要弹掉 dxdxdx，加入 dx+1dx+1dx+1 和 p[dx+1]p[dx+1]p[dx+1]。而每个点最多加入、弹出 stack 各一次，因此这样维护的话总体是 O(V)O(V)O(V) 的，即均摊 O(1)O(1)O(1)。于是优化掉凸包维护后，整体的时间复杂度就是 O(TVlog⁡V)O(TV\\log V)O(TVlogV) Code #include algorithm#include cassert#include cstdio#include iostream#include ostream#include vectorusing i64 = long long;using vi = std::vectorint;constexpr int NM = 5e3 + 5;constexpr int V = 1e5 + 5;constexpr int inf = 1e9;int n, m, T;i64 C;int x[NM], y[NM], a[NM], b[NM];int vdx[V], vdy[V];int root-1;int stp = -1;vi stack, tstack;vi popped[V];bool left_side(int i, int j, int k) assert(i = j j = k); int xs = j - k; int ys = vdx[j] - vdx[k]; int xx = i - k; int yx = vdx[i] - vdx[k]; return 1ll * xs * yx = 1ll * ys * xx;i64 cost(int dx, int dy) return 1ll * dx * vdy[dy] + 1ll * dy * vdx[dx]; std::ostream operator(std::ostream os, vi v) os [; for (auto x : v) os x ,; os ] ; return os;int main() std::cin n m T; for (int i = 1; i = n; i++) std::cin x[i]; for (int i = 1; i = n; i++) std::cin a[i]; for (int i = 1; i = m; i++) std::cin y[i]; for (int i = 1; i = m; i++) std::cin b[i]; for (int i = 0; i V; i++) vdx[i] = vdy[i] = inf; for (int i = 1; i = n; i++) for (int j = i; j = n; j++) vdx[x[j] - x[i]] = std::min(vdx[x[j] - x[i]], a[j] + a[i]); for (int i = 1; i = m; i++) for (int j = i; j = m; j++) vdy[y[j] - y[i]] = std::min(vdy[y[j] - y[i]], b[j] + b[i]); for (int dx = V - 1; dx = 0; dx--) if (vdx[dx] == inf) continue; while (stp = 1 left_side(dx, stack[stp], stack[stp - 1])) popped[dx].push_back(stack.back()); stack.pop_back(); stp--; if (root == -1) root = dx; stack.push_back(dx); stp++; tstack.resize(stack.size()); std::copy(stack.begin(), stack.end(), tstack.begin()); while (T--) std::cin C; int now_dx = 0; i64 ans = 0; stack.clear(); for (auto v : tstack) stack.push_back(v); auto next = [] if (now_dx root) return; // 维护凸包，先弹掉顶部的点 assert(stack.back() == now_dx stack not match); stack.pop_back(); // 再加入点 for (auto it = popped[now_dx].rbegin(); it != popped[now_dx].rend(); it++) stack.push_back(*it); now_dx++; // 移动到下一个可以得到的 dx while (now_dx = root vdx[now_dx] == inf) now_dx++; if (now_dx = root) assert(stack.back() == now_dx stack not match after next()); ; // 二分，判断是否有点 x, f(x) 在直线下方，且 x = dx. auto BS = [](int dx, int dy) if (dx == 0) return true; std::reverse(stack.begin(), stack.end()); stack.push_back(V - 1); int l = -1, r = stack.size() - 1; while (l + 1 r) int mid = l + ((r - l) 1); int middx = stack[mid]; int nxtdx = stack[mid + 1]; if (cost(middx, dy) cost(nxtdx, dy)) l = mid; else r = mid; bool res = cost(stack[r], dy) = C; stack.pop_back(); std::reverse(stack.begin(), stack.end()); return res; ; for (int dy = V - 1; dy = 1 now_dx = root; dy--) if (vdy[dy] == inf) continue; // 跳过无法取到的 dy. // std::fprintf(stderr, dy=%d, now_dx=%d , dy, now_dx); while (now_dx = root BS(now_dx, dy)) ans = std::max(ans, 1ll * dy * now_dx); next(); std::cout ans ;"},{"title":"P4151 [WC2011] 最大XOR和路径","path":"/topic/dailycf/LuoguP4151/","content":"P4151 [WC2011] 最大XOR和路径 这道题的关键在于对路径的处理。 我们先考虑如果给定的图是树的特殊情况。这种情况下，1→n1\\to n1→n 的最大异或和必定是 1→n1\\to n1→n 的简单路径，因为如果走分支，那么分支上边一定会走两次（沿着边往下走，沿着边走回来），其值异或两次后抵消。 然后我们给树加上一些非树边。比如说考虑 1 21 33 43 52 4 2 4 是非树边，我们想求 1→51\\to 51→5 的最大异或和路径。不同于 1→3→51\\to 3\\to 51→3→5，我们这次可以选择先绕 1→3→4→2→1→31\\to 3\\to 4\\to 2\\to 1\\to 31→3→4→2→1→3 走一圈，再走到 555. 这条路径的异或和就是 1→51\\to 51→5 的树上简单路径加上 1,2,3,41,2,3,41,2,3,4 这个环的异或值。 所以，类似的，我们对原图求出一棵 DFS 树，对于非树边 (u,v)(u,v)(u,v)，记下环 (u,v,LCA(u,v))(u,v,LCA(u,v))(u,v,LCA(u,v)) 上的异或和 Cu,vC_{u,v}Cu,v​；同时找出 1→n1\\to n1→n 的树上简单路径的异或和 PPP。我们的答案，一定就是 P,Ci,jP,C_{i,j}P,Ci,j​ 异或出来的最大值（其中 PPP 是必选的）。我们对 Ci,jC_{i,j}Ci,j​ 构造线性基，用贪心法找最大值即可。 Code #include iostream#include tuple#include vectorconstexpr int N = 5e4 + 5;constexpr int M = 1e5 + 5;constexpr int B = 63;using i64 = long long;using pil = std::tupleint, i64;using pii = std::tupleint, int;using edge = std::tupleint, i64;using vpil = std::vectorpil;using vi = std::vectorint;int n, m;vi G[N], T[N];edge E[M];int on_tree[M], vis[N];std::vectori64 basis;i64 sinceRoot[N];void tree(int u, int fa) vis[u] = true; for (auto eid : G[u]) auto [uv, w] = E[eid]; int v = uv ^ u; if (v == fa) continue; if (vis[v]) basis.push_back(w ^ sinceRoot[u] ^ sinceRoot[v]); continue; sinceRoot[v] = sinceRoot[u] ^ w; on_tree[eid] = 1; T[u].push_back(eid); T[v].push_back(eid); tree(v, u); int main() // std::cin.tie(0)-sync_with_stdio(0); std::cin n m; for (int i = 1, u, v; i = m; i++) i64 w; std::cin u v w; E[i] = u ^ v, w; G[u].emplace_back(i), G[v].emplace_back(i); tree(1, 0); // linear basis int row = 0; int len = basis.size(); auto checkbit = [](i64 x, int b) return (x b) 1; ; for (int col = B; col = 0 row len; col--) for (int to = row; to len; to++) if (checkbit(basis[to], col)) std::swap(basis[to], basis[row]); break; if (not checkbit(basis[row], col)) continue; for (int i = 0; i len; i++) if (i == row) continue; if (checkbit(basis[i], col)) basis[i] ^= basis[row]; row++; i64 ans = sinceRoot[n]; for (int i = 0; i row; i++) if ((ans ^ basis[i]) ans) ans ^= basis[i]; std::cout ans ;","tags":["线性基"]},{"title":"软件工程基础：面向对象编程","path":"/topic/swe/swe-basic-oop/","content":"抽象 Abstraction 建模，模拟真实对象的特定属性和行为。 封装 Capsulation 接口 interface: 它是对象的公有部分， 能够同其他对象进行交互 封装是指一个对象对其他对象隐藏其部分状态和行为，而仅向程序其他部分暴露有限的接口的能力 继承 Inheritance 多态 多态是指程序能够检测对象所属的实际类，并在当前上下文不知道其真实类型的情况下调用其实现的能力"},{"title":"Vim 快捷键操作","path":"/vim-keys-001/","content":"基础移动 h j k l 当移动的命令为小写时，连续的标点也会被视为单词。 w 移动到下一个单词的开头 word b 上一个单词的开头 backward e 下一个单词的末尾 end ge 上一个单词的末尾 go end 但是当移动的命令为大写时，夹在字母中间的标点会被视为单词的一部分： W B E gE 还有比较实用的移动是搜索 (find)下一个字符并移动： fcharacter 搜索到下一个 character 字符，然后光标移动到其上。 Fcharacter 搜索上一个 character 字符，移动到其上 tcharacter 搜索到下一个 character 字符，然后光标移动到它之前。 until Tcharacter 搜索到上一个 character 字符，然后移动到它之前。 输入 ; 快速查找下一个相同的字符，输入 , 查找上一个相同的字符。 例如 fd;;v -- v ------ v ------- viniti dext tump dtaius tytyd Advanced Movings 行内移动： 0 直接移动到开头 ^ 直接移动到当前行第一个非空白字符 $ 行末 g_ 最后一个非空白字符 行间移动： 跳过下一个段落（段落是连续的行，中间没有空行隔开） 类似，但是跳到上一个段落之前 ctrl + d (down) 往下翻半页 ctrl + u (up) 往上翻半页 搜索并移动：（之前提到的 fcharacter 之内在行内搜索单个字符） /pattern 搜索下一个匹配 pattern 的字符串并移动到那里。可以是字符串，也可以是正则 ?pattern 类似，但是是上一个匹配的字符串 输入完后会高亮匹配的字符串，输入 Enter 进行跳转 再输入 n 跳转到下一个匹配的字符串，N 则是上一个 (next) /enter 直接输入斜杠然后回车，vim 会执行上一次搜索过的 pattern。?enter 也是同理。 或者，输入 * 搜索下一个当前光标所在的单词，# 则是上一个 文件跳转 gd (goto definition) 跳转到光标所在的东西的定义（例如函数定义、变量定义） gf (goto file) jump to a file in an import Some More gg 文件开头 G 文件末尾 % 如果光标不在括号上，跳转到包含当前单词的左括号上；如果在左/右括号上，跳到与之匹配的另一个括号上 linegg 快速跳转到行"},{"title":"ManiSkill 里的 MuJoCo Robot File","path":"/mjcf-urdf/","content":"MuJoCo XML in ManiSkill MuJoCo 物件由 .xml 定义的，这个 .xml 真的巨复杂，而且疑似 ManiSkill 里 .xml 的标准和 LIBERO 里的还不一样，醉了…… asset.texture asset.mesh asset.material geom.contype 如果 geom 里有 contype=1 属性，那么代表这个部件有碰撞体积. contype: int，默认值 1 该属性和下一个属性共同定义了 32 位整型的位掩码，用于对动态生成的接触对进行过滤。详见 “Computation” 章节中的 Collision detection。一对几何体只有在「几何体 A 的 contype 与几何体 B 的 conaffinity 兼容」或「几何体 B 的 contype 与几何体 A 的 conaffinity 兼容」时才会碰撞。所谓“兼容”，指的是两个位掩码至少有一个相同的比特被置为 1。 conaffinity: int，默认值 1 用于接触过滤的位掩码；说明参见上文 contype。[1] geom.group MuJoCo XML 里，group=0, 1, 2 则可见，否则不可见（但是 ManiSkill/SAPIEN 里 group=1 却是不可见） MuJoCo XML Reference ↩︎"},{"title":"HuggingFace, GitHub 添加 SSH Key","path":"/git-hf-sshkey/","content":"本地生成 SSH Key 首先需要本地生成一个 SSH Key，这个 Key 可以和之前已经创建过的相同，也可以放到别的地方。只需要自己指定存放位置即可。 ssh-keygen -t ed25519 -C ...# -t 选择加密算法，-C 后面是注释 这样就会生成两个 keygen，一个是 private key（后缀无 .pub），一个是 public key（后缀带 .pub）。 然后重要的一点：一定要把 keygen 加入 ssh agent ssh-add ssh private key location"},{"title":"Haskell, Parameterized Types","path":"/topic/functional/haskell/haskell-param-types/","content":"Maybe T 和 Rust 里的 OptionT 差不多。 Just (something) Nothing Either T U 保存着两个类型中的一个。例如 Either Int Bool 可以是 Left 0, Right False i_want_a_string :: Either Int String - Stringi_want_a_string (Left num) = show numi_want_a_string (Right str) = str"},{"title":"Haskell 快速入门","path":"/topic/functional/haskell/haskell-crash-course/","content":"Variables Variables: Local Definition 使用 let ... in 语法，或者 where 语法。where 后置变量定义，let ... in 则是前置。 示例： solve :: Int - Int - [Int] - Stringsolve n m doors = do case indices of [] - YES _ - case end - start + 1 of x | x = m - YES _ - NO where -- 这里就是 local definition 定义的局部变量 indices = elemIndices 1 doors end = last indices start = head indices Pattern Matching Pattern Matching 定义函数的时候，可以根据参数的不同，触发不同分支。 greet :: String - String - Stringgreet Finland name = Hei, ++ namegreet Italy name = Ciao, ++ namegreet England name = How do you do, ++ namegreet _ name = Hello, ++ name Guards Condition Guards 和 Pattern Matching 类似，用 Condition 代替具体的值进行 Matching. 示例： describe :: Int - Stringdescribe n | n == 2 = Two | even n = Even | n == 3 = Three | n 100 = Big!! | otherwise = The number ++ show n 当然，Guards 和 Pattern Matching 也可以一起用。 guessAge :: String - Int - StringguessAge Griselda age | age 47 = Too low! | age 47 = Too high! | otherwise = Correct!guessAge Hansel age | age 12 = Too low! | age 12 = Too high! | otherwise = Correct!guessAge name age = Wrong name! case ... of 我觉得 case ... of 语法也算 Pattern Matching 的一部分 case xxx of value1 - return_value1 value2 - return_value2 case ... of 可以用在“当多个分支都需要使用同一个函数时” Recursion Helper Function: arguments of the helper function are variables you update in your loop; Tail Recursion Optimization Haskell programs often use the apostrophe to name helper functions and alternative versions of functions. Haskell 常用数据结构 List / [a] head :: [a] - a -- returns the first elementlast :: [a] - a -- returns the last elementtail :: [a] - [a] -- returns everything except the first elementinit :: [a] - [a] -- returns everything except the last elementtake :: Int - [a] - [a] -- returns the n first elementsdrop :: Int - [a] - [a] -- returns everything except the n first elements(++) :: [a] - [a] - [a] -- lists are catenated with the ++ operator(!!) :: [a] - Int - a -- lists are indexed with the !! operatorreverse :: [a] - [a] -- reverse a listnull :: [a] - Bool -- is this list empty?length :: [a] - Int -- the length of a list 实用函数 show :: Any - String: 将任何东西变成可以输出的字符串"},{"title":"OCaml 代码文档","path":"/topic/functional/ocaml/ocaml-in-source-documentation/","content":"基础语法 文档注释的形式为 (** some comments *)。在 [] 内部的文字会显示为 Coding Font. 和其他语言类似的，OCaml 也有 @author, @return 等等注释项。 (** [sum lst] is the sum of [lst] *)let rec sum lst = ..."},{"title":"数学分析一 Ep.2：实数、有理数","path":"/topic/analysis/math-analysis-2/","content":"从这里开始，我们开始开从实数拓展到有理数 命题一：实数包括有理数 实数定理 R\\RR 包含所有有理数 Q\\mathbb QQ，即存在单射 f:Q↦Rf:\\mathbb{Q}\\mapsto \\Rf:Q↦R，使得对 ∀x,y∈Q\\forall x, y\\in\\mathbb{Q}∀x,y∈Q，有 f(x+Qy)=f(x)+f(y)f(x⋅Qy)=f(x)⋅f(y)x≤Qy ⟹ f(x)≤f(y) f(x+_{\\mathbb{Q}}y)=f(x)+f(y)\\\\f(x\\cdot_{\\mathbb{Q}}y)=f(x)\\cdot f(y)\\\\x\\le_\\mathbb{Q}y\\implies f(x)\\le f(y) f(x+Q​y)=f(x)+f(y)f(x⋅Q​y)=f(x)⋅f(y)x≤Q​y⟹f(x)≤f(y)其中，+Q,⋅Q+_{\\mathbb{Q}},\\cdot_{\\mathbb{Q}}+Q​,⋅Q​ 是有理数上的加法和乘法。映射 fff 依然保持序关系和域关系。"},{"title":"OCaml 构建系统：Dune","path":"/topic/functional/ocaml/ocaml-build-system/","content":"OCaml 构建系统 OCaml 使用 Dune 作为构建系统，地位和 CMake、Meson Build 差不多。Dune 本身使用类似 Lisp 的括号语法。 # 目录结构如图所示taste1├── bin│ ├── dune│ └── main.ml├── dune-project├── lib│ └── dune├── taste1.opam└── test ├── dune └── test_taste1.ml dune-project 定义了整个项目，需要指明使用的 dune 版本号。 # dune-project 文件(lang dune 3.19) dune 包含要编译的可执行文件 (executable (name hello)) 指令 编译：dune build 运行：dune exec taste1"},{"title":"OCaml 快速入门","path":"/topic/functional/ocaml/ocaml-lec1/","content":"关于终端解释器 OCaml 和 Python 类似也有终端解释器 utop，输入 utop 后，在 # 后面输入指令（和 Python 的 一个作用）。输入 quit;; 退出解释器。 如果要使用文件里定义的东西，需要先 use someFile.ml;;，和 Python import 类似。 Variables and Functions 在 OCaml 里，function 也是 first-class，因此可以像 assign variable 那样把 function assign 给 variable name. let inc x = x+1;;let x = 1;;inc x(* 输出 2 *) OCaml 使用 (* ...... *) 表示行内注释和跨行注释 OCaml 类型和基础操作 * 整数乘法，*. 浮点数乘法，^ 字符串拼接，xxxxx.[0] 下标取出字符 (char 类型) float_of_int: int - float，int_of_string 字符串转成数字 let x = e1 in e2 计算 e1，赋值给 x 把值代入 e2，计算的结果作为 let expression 的结果 OCaml 条件控制 if xxxx then yyyyelse if xxxx then yyyyelse yyyy OCaml 函数 (* 定义递归函数 *)let rec factorial x = if x = 0 then 1 else x * factorial (x-1)(* 两个参数 *)let rec power x y = if y = 0 then 1 else x * power x (y-1) Mutually recursive function, 螺旋递归，使用 and 语法进行定义. 本质就是递归直到 base case. (* 语法： let rec f x1 ... xn = e1 and g y1 ... yn = e2*)let rec even n = n = 0 || odd (n-1)and odd n = n 0 even (n-1) 匿名函数 (* 语法：fun x1 ... xn - e *)let inc = fun x - x + 1 pipeline 把上一个函数的输出作为下一个函数的输入。 let inc x = x + 1let sqr x = x * x(* 使用 | 记号 *)5 | inc | sqr Labelled, Optional Arguments (*定义了一个函数，两个必填参数和一个可选参数：在函数体里，用 arg1, arg2 参与运算，但是调用函数时，指定 name1, name2 的参数。~ 表示必填参数，? 表示可选参数，可选参数需要有默认值f ~name1:2 ~name2: 4= 结果为*)let F ~name1:arg1 ~name2:arg2 ?option:(op1=8) = arg1 + arg2 + op1 Tail Recursion Optimization 作为递归函数的优化，考虑 let rec count n = if n = 0 then 1 else 1 + count (n-1) 这个函数的问题在于，当 nnn 很大的时候，递归可能报栈。Tail Recursion 就是为了优化这一个情况，它要求： 递归完成返回时，不会对返回的结果进行操作 这样，我们的函数实际上可以重复利用当前的 stack frame 而不用去另开辟一块栈上空间。"},{"title":"Tokenization, BPE 算法","path":"/topic/llm/tokenization-bpe/","content":"BPE Training 的流程和实现 CAUTION 本部分对应的是 Section 2 的 BPE. Tokenization 是如何工作的呢？假定我们的文本放在 corpus.txt 文件里（这里的文本带有 special tokens 如 |endoftext|） 通常，我们的文本文件很大，例如几个 GB，我们不可能把这些字符全都载入内存里（肯定爆炸），因此，第一步，我们需要对训练文本分块，以便发挥多线程的优势，让计算机并行处理多个任务。分块需要注意，每一块都必须是以 special token 结尾的，否则如果横跨了某个单词，那么这个单词被 tokenize 的结果很可能与 expected 的不同。 chunkify 实现 根据上面所说的，我们把文本进行分块。我们用 Binary IO 的方式打开文本，最后返回 List[int] 表示 chunk 的边界为 B[i-1] ~ B[i] 具体实现的话，我们用 file.tell() 的方式获取 bytes 数量后，直接先均分成 num 块（或者按内存大小计算块的大小，然后反过来计算块的数量）。然后，对每一块寻找下一个 special token 出现的位置，调整这一块的 boundary，这样，boundary 的每一个 int 都表示了 special token 的位置，也就满足了对 special token 出现位置的约束。最后排序去重就是最终的 boundary 了。 def chunkify(file: BinaryIO, specials: List[bytes], num_chunks: int) - List[int]: # get total bytes file.seek(0, os.SEEK_END) file_size = file.tell() file.seek(0) chunk_size = file_size // num_chunks boundaries = [i * chunk_size for i in range(num_chunks + 1)] boundaries[-1] = file_size mini_chunk = 4096 for i in range(1, len(boundaries) - 1): init_pos = boundaries[i] file.seek(init_pos) # 这里就是不断读取 4096 个字节，然后找有没有 special token while True: sub_chunk = file.read(mini_chunk) if sub_chunk == b: boundaries[i] = file_size break special_pos = [ sub_chunk.find(token) for token in specials if sub_chunk.find(token) != -1 ] # 读进来的小 chunk 有 special token，那么直接截断 if len(special_pos) != 0: special_pos = min(special_pos) boundaries[i] = init_pos + special_pos break # 否则继续找 special token init_pos += mini_chunk return sorted(set(boundaries)) 然后就要 tokenize 了。但是对于很大的语料库而言，会包含很多相同的单词（例如 the 这个单词可以在很多地方出现很多次），如果我们 naive 地对一长串 bytes 计算 byte-pair count，时间复杂度是很高的（bytes 实在太多了）。比如说…… print(len(这是一段文字))6 print(len(这是一段文字.encode(utf-8)))18 bytes 数量差了 2 倍！所以我们需要基于“很多单词是重复的，如果单词出现 aaa 次，那么这个单词所构成的 byte-pairs 也至少出现 aaa 次”这一观察，对 chunk of text 进行 Pre-Tokenization，得到词频统计。而词频统计字典的单词数通常比 byte string 长度短太多了。 对于英文文本来说，OpenAI 在 GPT2 里曾使用过 RegEx 分割单词（主要通过空格、句号等）；对于中文、日文等不依赖空格的语言，基本上也有对应的库，如 jieba 等等。这里就只展示英文 pre-tokenization 的做法。Pre-Tokenization 也可以利用多线程并行。 # file: 文件# specials: 特殊 token，需要先按 special token 将段落分割成互不干扰的小段落。# start, end: 因为是多线程进行 pre-tokenization，这里的 start, end 对应 chunkify 出来的一个 chunkdef count_token(file: BinaryIO, specials: List[str], start: int, end: int): file.seek(start) data = file.read(end - start).decode(utf-8, errors=ignore) # Pretokenization, using split # regex.escape 用来转义 |endoftext| 中的竖线，正则里的竖线表示“或者” sentences = regex.split( |.join(regex.escape(special) for special in specials), data, ) # 正则分割出 pre-token 然后计数 PAT = r(?:[sdmt]|ll|ve|re)| ?\\pL+| ?\\pN+| ?[^\\s\\pL\\pN]+|\\s+(?!\\S)|\\s+ tokens_count = defaultdict(int) for sentence in sentences: # 注意这里必须逐个句子处理 # 如果 .join 的话，可能 join 的 也会被当成 token 的一部分。 pre_tokens = regex.finditer( PAT, sentence, ) for token in pre_tokens: tokens_count[token.group(0)] += 1 assert not any(tok in tokens_count for tok in specials) # assert | not in tokens_count return tokens_count 得到词频统计后，我们就可以 merge bytes 了。merge bytes 的过程是不断合并出现次数最多的 byte-pair，具体来说就是： 我们首先需要把单词表示成 a sequence of bytes，我们的字典保存的是 Dict[Tuple[bytes, ...], int]，即词频（但是词是 tuple of bytes） 遍历词典，统计 byte-pair count 取出 count 最多的 byte-pair，如果有多个，则取 byte value 更大的那个 merges 记录下这个要合并的 byte-pair，vocabulary 也新增一个条目记录这个 byte-pair（他们即将成为一个新的 token） 遍历词典，如果某个单词含有这个 byte-pair 则合并，在词典里更新其 tuple of bytes representation。 如，我想合并 x 和 y，而某个单词的 tuple of bytes 是 [a, b, c, x, y, d, f, e]，那么合并后就变成了 [a, b, c, xy, d, f, e]. 这里有一个小小的优化：显然，合并完一个 byte-pair 之后，只有“在这个单词里和这个 byte-pair 相交的其他 byte-pair 的数量会受到影响”。基于这一点，我们遍历单词的时候，同时检查和当前 byte-pair 相交的其他 byte-pair，然后减去单词的出现次数，并新增条目（受影响的 byte-pair 的一部分和新的 byte-pair 形成的 token）。这样就可以相对高效地进行 merge. def bytepair( tokens: defaultdict[str, int], vocab_size: int, init_vocab: defaultdict[int, bytes], init_merge: List[Tuple[bytes, bytes]],) - Tuple[Dict[int, bytes], List[Tuple[bytes, bytes]]]: vocabulary = init_vocab merges = init_merge # 这一步，我们先把所有 str 表示的单词转成 tuple of bytes toks = defaultdict(int) for token, count in tokens.items(): btoken = token.encode(utf-8) toks[tuple(btoken[i : i + 1] for i in range(len(btoken)))] = count # 先插入初始的 256 的 bytes for i in range(256): insert_vocabulary(vocabulary, bytes([i])) # bp_cnt 的作用就是统计 byte-pair counting bp_cnt = construct(toks) for _ in tqdm( # 这里加了一个进度条可视化 range(vocab_size - len(vocabulary)), desc=merging byte token pairs, total=vocab_size, initial=len(vocabulary), ): # 提取出现次数最多的 byte-pair count, pair = max([(cnt, tokpair) for tokpair, cnt in bp_cnt.items()]) newbyte = pair[0] + pair[1] logger.debug(fmerging pair[0] and pair[1]) # 插入词汇表 insert_vocabulary(vocabulary, pair[0] + pair[1]) # 记录 merge merges.append(pair) # 当前的 pair 会被记录成一个 token，不算 byte-pair 了 # 因此从 byte-pair counting 里删除 bp_cnt.pop(pair) affected = [] for token in toks: # 如果单词不包含这个 byte-pair 那么直接跳过 if not contain(token, pair): continue new_token = [] # 下面的循环是将 token 里的 byte-pair 合并起来 skip_next = False for i in range(len(token)): if skip_next: skip_next = False continue if i len(token) - 1 and (token[i], token[i + 1]) == pair: new_token.append(pair[0] + pair[1]) # 这里就是上面说的优化，只影响与 byte-pair 相交的 bytes # 两个 if 语句考虑的边界的情况 if i != 0: bp_cnt[(token[i - 1], token[i])] -= toks[token] bp_cnt[(token[i - 1], newbyte)] += toks[token] if i + 1 != len(token) - 1: bp_cnt[(token[i + 1], token[i + 2])] -= toks[token] bp_cnt[(newbyte, token[i + 2])] += toks[token] skip_next = True else: new_token.append(token[i]) new_token = tuple(new_token) affected.append((token, toks[token], new_token)) # 由于更新了单词的 bytes 表示，所以单词表也要同步更新 for old, cnt, new in affected: toks.pop(old) toks[new] = cnt return (vocabulary, merges) Serialization 注意事项 我们把 merges 和 vocabulary 写入文件时，如果直接写入，会遇到一个问题： 有一些 bytes 无法以 ASCII 的形式呈现，比如说 b'\\x80' 有一些空白字符比如空格，如果直接写入文件，日后再读取的时候解析就会比较困难。merges.txt 有时 面对这些情况我们有一些处理方法：我们考虑把所有无法以 ASCII 呈现的字符映射到 ≥256\\ge 256≥256 的字符上。可以使用 utility 工具 gpt2_bytes_to_unicode()。其原理就是先筛选出 256\\lt 256256 里 printable 的字符，然后对于剩下的字符，映射到 ≥256\\ge 256≥256 的字符上，返回一个字典。 def bytes2unicode_serializer() - Dict[int, str]: bytes_list = ( list(range(ord(!), ord(~) + 1)) + list(range(ord(¡), ord(¬) + 1)) + list(range(ord(®), ord(ÿ) + 1)) ) copy = bytes_list[:] n = 0 for b in range(256): if b in bytes_list: continue bytes_list.append(b) copy.append(256 + n) n += 1 d = dict(zip(bytes_list, [chr(x) for x in copy])) return d Tokenizer Encode/Decode 的流程和实现 regex.split() 的使用 regex.split(REGEX, STRING) 可以按 REGEX 分割字符串，但是默认不会保留匹配了 REGEX 的部分。可以通过在外面加一个圆括号 (REGEX) 让 regex 能够保留匹配的部分。 Encoding Tokenizer Encoding 的过程是接受一个字符串 str，然后输出 List[int]。 我们现在已有的是 What We Have Type Meaning vocabulary Dict[int, bytes] 记录了 bytes 对应的编码 merges List[Tuple[bytes, bytes]] 记录了 bytes 合并的先后顺序 这里，合并的先后顺序很重要，因为我们需要正确模拟出 training 过程中它是怎么被合并的。 不能使用贪心法进行合并！ 例如，考虑单词 abcde，我们在 training 时先合并 b c 然后再合并 a b，这意味着 b c 的数量比 a b 多。如果使用贪心法合并，我们会得到 ab c d e，而正确的是 a bc d e。和正确的 tokenization 会有出入。 Encoding 和 Train BPE 的时候类似，我们都先把文本划分成多个 chunks 以利用多线程优势，这里的 chunk 仍然需要以 special tokens 作为结尾来保证不会横跨某个 token. 不过 chunkify 其实是可选的，因为通常 encode 的文本相比训练文本短很多。 def _chunkify(self, text: str, num_chunks: int) - List[int]: chunk_size = len(text) // num_chunks boundaries = [i * chunk_size for i in range(num_chunks + 1)] boundaries[-1] = len(text) mini_chunk_size = 4096 for i in range(1, len(boundaries) - 1): init_pos = boundaries[i] while True: sub_chunk = text[init_pos : init_pos + mini_chunk_size] if sub_chunk == : boundaries[i] = len(text) break special_pos = [ sub_chunk.find(token) for token in self.special_tokens if sub_chunk.find(token) != -1 ] if len(special_pos) != 0: special_pos = min(special_pos) boundaries[i] = init_pos + special_pos break init_pos += mini_chunk_size return sorted(set(boundaries)) 接下来，我们还需要将文本转化为 pretokens，和 train BPE 时一致. 这里的一个优化是用 yield 返回迭代器，而不是直接返回一个 list，可以大大减少内存消耗 def _pretokenize(self, text: str) - Iterable[List[str]]: data = ( regex.splititer( f(|.join(regex.escape(s) for s in self.special_tokens)), text, ) if self.special_tokens else [text] ) # split into sentences, and special_tokens for each_sentence in data: if each_sentence in self.special_tokens: yield [each_sentence] else: yield regex.findall(self.pretoken_pattern, each_sentence) 然后我们需要把每一个 pretoken 转化成 a list of bytes，对 bytes 执行合并，最后转化成 a list of index，整段文本的 encoding 结果就是所有的 list of index 拼接起来. 下面的 _apply_merge() 是针对单个 pretoken 分解的结果。具体做法就是不断从前往后遍历 merge list（注意必须是这个顺序），能合并则合并。 _convert_to_index() 则接受迭代器，负责把 pretoken 的 index list 拼接在一起。 def _apply_merge(self, token: bytes) - List[int]: words = [bytes([i]) for i in token] for merge in self.merges: if len(words) == 1: break # no more merges possible new_word = [] skip_next = False for i in range(len(words)): if skip_next: skip_next = False continue if ( i != len(words) - 1 and words[i] == merge[0] and words[i + 1] == merge[1] ): new_word.append(merge[0] + merge[1]) skip_next = True else: new_word.append(words[i]) words = new_word return [self.inverse_vocab[word] for word in words]def _convert_to_index(self, pre_tokens: Iterable[str]) - List[int]: tokens_bytes = [tok.encode(utf-8) for tok in pre_tokens] result: List[int] = [] for token_byte in tokens_bytes: if token_byte in self.special_tokens_bytes: result.append(self.inverse_vocab[token_byte]) continue token_ids = self._apply_merge(token_byte) result.extend(token_ids) return result 最后，我们就可以实现 encode() 的逻辑了（实际上就是把上面的部分拼在一起）. def encode(self, text: str) - List[int]: pre_tokens_list = self._pretokenize(text) with Pool(processes=10) as pool: tokens = pool.map( self._convert_to_index, pre_tokens_list, ) tokens = [token for sublist in tokens for token in sublist] return tokens Decoding Decoding 就很简单了，因为 decoding 接受 a list of index，所以我们直接查词汇表找出对应的 bytes，拼接起来，然后转成字符串即可。 这个 _chunkify_token_list() 的思路和上文 _chunkify() 的思路其实差不多。decode 也不是特别需要利用多线程。 def decode(self, tokens: List[int]) - str: boundaries = self._chunkify_token_list(tokens, 25) with Pool(processes=10) as pool: results = pool.map( self._decode_chunk, [tokens[i:j] for i, j in zip(boundaries[:-1], boundaries[1:])], ) decoded_bytes = b.join(results) decoded_str = decoded_bytes.decode(utf-8, errors=replace) return decoded_str"},{"title":"南洋理工交换指北","path":"/topic/exchanging/ntu-exchange-guide/","content":"HKUWW 阶段 实际上这一个阶段"},{"title":"数学分析一 Ep.1 ：实数的公理化描述、四条公理","path":"/topic/analysis/math-analysis-1/","content":"实数 我们定义实数 R\\RR 是一个集合，上面有两个操作： 加法 +:R×R↦R,(x,y)↦x+y+:\\R\\times\\R\\mapsto\\R, (x,y)\\mapsto x+y+:R×R↦R,(x,y)↦x+y 乘法 ⋅:R×R↦R,(x,y)↦x⋅y\\cdot: \\R\\times\\R\\mapsto\\R, (x,y)\\mapsto x\\cdot y⋅:R×R↦R,(x,y)↦x⋅y 同时还有序关系 (Order Relation) ≤:x≤y\\le: x\\le y≤:x≤y. 域公理 (Axioms of Field) 加法交换律：x+y=y+xx+y=y+xx+y=y+x 加法结合律：x+(y+z)=(x+y)+zx+(y+z)=(x+y)+zx+(y+z)=(x+y)+z 加法单位元：存在 0∈R0\\in\\R0∈R 使得对 ∀x∈R\\forall x\\in\\R∀x∈R 有 0+x=x0+x=x0+x=x 成立 加法逆元的存在性、唯一性：对 ∀x∈R\\forall x\\in\\R∀x∈R，存在且只存在一个 −x∈R-x\\in\\R−x∈R，使得 x+(−x)=0x+(-x)=0x+(−x)=0 这里，我们还没有证明 (−1)⋅x=−x(-1)\\cdot x=-x(−1)⋅x=−x，−x-x−x 整体应该被当作一个记号，用于表示 xxx 的加法逆元。 乘法结合律：x⋅(y⋅z)=(x⋅y)⋅zx\\cdot (y\\cdot z)=(x\\cdot y)\\cdot zx⋅(y⋅z)=(x⋅y)⋅z 乘法交换律：x⋅y=y⋅xx\\cdot y=y\\cdot xx⋅y=y⋅x 乘法单位元：存在 1∈R,1≠01\\in\\R,1 e 01∈R,1=0，使得对任意 ∀x∈R\\forall x\\in\\R∀x∈R 都有 1⋅x=x1\\cdot x=x1⋅x=x 乘法逆元的存在性、唯一性：对任意 ∀x∈R−{ 0 }\\forall x\\in\\R-\\set{0}∀x∈R−{0}，存在 x−1∈Rx^{-1}\\in\\Rx−1∈R 使得 x⋅x−1=1x\\cdot x^{-1}=1x⋅x−1=1 乘法分配律：x⋅(y+z)=x⋅y+x⋅zx\\cdot (y+z)=x\\cdot y+x\\cdot zx⋅(y+z)=x⋅y+x⋅z 练习题 证明 对任意的 x,y∈R,b≠0x,y\\in\\R,b e0x,y∈R,b=0，有 x+a=y+a ⟹ x=yx⋅b=y⋅b ⟹ x=yx+a=y+a\\implies{x=y}\\\\x\\cdot{b}=y\\cdot{b}\\implies{x=y}x+a=y+a⟹x=yx⋅b=y⋅b⟹x=y 先证明第一个。我们在方程两边同时加上 aaa 的加法逆元 −a-a−a，则 x+a+(−a)=y+a+(−a)x+[a+(−a)]=y+[a+(−a)]x+0=y+0x=y \\begin{aligned} x+a+(-a)=y+a+(-a)\\\\ x+[a+(-a)]=y+[a+(-a)]\\\\ x+0=y+0\\\\ x=y \\end{aligned} x+a+(−a)x+[a+(−a)]x+0x​=y+a+(−a)=y+[a+(−a)]=y+0=y​再证明第二个。 证明 对任意 x,y,z,wx,y,z,wx,y,z,w，若 y,w≠0y,w e 0y,w=0，则有 xy+zw=xw+zyyw \\frac{x}{y}+\\frac{z}{w}=\\frac{xw+zy}{yw} yx​+wz​=ywxw+zy​ 序公理 (Axioms of Order) 序的传递性：x≤y, y≤z ⟹ x≤z.x \\le y,\\; y \\le z\\;\\Longrightarrow\\;x \\le z.x≤y,y≤z⟹x≤z. 序可以决定元素：x≤y, y≤x ⟹ x=yx\\le y,\\; y\\le x \\implies x=yx≤y,y≤x⟹x=y 全序关系：∀x,y∈R, x≤y\\forall x,y\\in\\R,\\; x\\le y∀x,y∈R,x≤y 或者 y≤xy\\le xy≤x 二者至少有一个正确 与加法相容：x≤y ⟹ x+z≤y+zx\\le y\\implies x+z\\le y+zx≤y⟹x+z≤y+z 与乘法相容：x≥0∧y≥0 ⟹ xy≥0x\\ge 0\\land y\\ge 0 \\implies xy\\ge 0x≥0∧y≥0⟹xy≥0 练习题 证明题 10 1\\gt 0 10证明 证明 反证法：若 101\\lt 010，则 −10-1\\gt 0−10，由于和乘法相容，有 1⋅(−1)0⋅(−1)−10 1\\cdot (-1)\\lt 0\\cdot (-1)\\\\ -1\\lt 0 1⋅(−1)0⋅(−1)−10矛盾！故 101\\gt 010 证明： x≥0 ⟹ −x≤0 x\\ge 0 \\implies -x\\le 0 x≥0⟹−x≤0证明 证明 因为和加法相容，则 x+(−x)≥0+(−x)x+(-x)\\ge 0+(-x)x+(−x)≥0+(−x)，故有 0≥−x ⟺ −x≤00\\ge -x \\iff -x\\le 00≥−x⟺−x≤0. 证明： y∈R,y0 ⟹ 0y−11 y\\in\\R,y\\gt 0 \\implies 0\\lt y^{-1}\\lt 1 y∈R,y0⟹0y−11证明 证明 首先证明，y1 ⟹ y−10y\\gt 1\\implies y^{-1}\\gt 0y1⟹y−10. 反证法，假设 y−1=0y^{-1}= 0y−1=0，那么根据 Field Axioms，我们有 1=y−1⋅y≤0⋅y=0 1=y^{-1}\\cdot y\\le 0\\cdot y=0 1=y−1⋅y≤0⋅y=0而这与 1≠01 e 01=0 的定义不符。 假设 y−10y^{-1}\\lt 0y−10，则根据上面证明的，有 −y−10-y^{-1}\\gt 0−y−10，由于和乘法相容，故 y⋅(−y−1)0+(−y−1)−1−(y−1)y−11 \\begin{aligned} y\\cdot (-y^{-1})\\gt 0+(-y^{-1})\\\\ -1\\gt -(y^{-1})\\\\ y^{-1}\\gt 1 \\end{aligned} y⋅(−y−1)−1y−1​0+(−y−1)−(y−1)1​再由 y10y\\gt 1\\gt 0y10，故 y−1⋅y1⋅y ⟺ 1yy^{-1}\\cdot y\\gt 1\\cdot y \\iff 1\\gt yy−1⋅y1⋅y⟺1y，矛盾！ 故必有 y−10y^{-1}\\gt 0y−10，再由于和乘法相容，有 y⋅y−11⋅y−11y−1 y\\cdot y^{-1}\\gt 1\\cdot y^{-1}\\\\ 1\\gt y^{-1} y⋅y−11⋅y−11y−1所以，0y−110\\lt y^{-1}\\lt 10y−11 Achimedes 公理 Achimedes Axioms 对任意 x0x\\gt 0x0 和 yyy，总存在正整数 nnn，使得 n⋅x≥yn\\cdot x\\ge yn⋅x≥y."},{"title":"Rust 原子操作与内存顺序","path":"/topic/rust-grammar/rust-atomic/","content":"AtomicT 内存顺序"},{"title":"Rust 同步：Semaphore, 条件变量, 互斥锁","path":"/topic/rust-grammar/rust-concurrency-condvar-sema-mutex/","content":"MutexData 数据被 MutexT 拥有，获得锁用 m.lock()（会阻塞线程，返回 Result），在作用域结束后锁会自动释放。 准确地说，mutex.lock() 返回一个智能指针 MutexGuardT。它实现了 Deref，会自动解引用，指向 MutexT 内的数据。还实现了 Drop，作用域结束之后自动释放锁。 mutex.try_lock() 则尝试获取锁，返回包含数据或者错误的 Result 读写锁 RwLockT 相比于 MutexT 同一时间允许多个 read，但只允许一个 write。读写不允许同时存在 多个 read 的时候不会阻塞 std::sync::CondVar 条件变量 tokio::sync::Semaphore 信号量"},{"title":"Rust 泛型","path":"/topic/rust-grammar/rust-generics/","content":"泛型（对标 C++ 模板） 函数、方法、结构体、枚举都可以使用泛型。 Type Annotation 明确指出泛型的类型需要满足什么条件。 函数泛型/函数模板 fn funcT(a: T) template typename Tvoid function(T a) 方法泛型/方法模板 可以包含其他的类型 implT PointT fn funcU(self) - T // 等价于 ...... template typename Tclass Point template typename U T func() const 泛型、模板参数 对应 C++ 中 template int N 这样的模板参数。 fn funcT, const N: usize(arr: [T; N]) template typename T, size_t Nvoid func(std::arrayT, N arr) 针对 const 泛型做检查 这个在 C++ 里应该需要使用 require 做检查，我还没有研究过。Rust 里使用 Assert: IsTrue 泛型限制即可。 fn somethingT(val: T)where Assert core::mem::size_of::T() 768 : IsTrue, // ^ 这里是一个 const 表达式，换成其它的 const 表达式也可以 // const fn 对应 C++ 的 constexpr，在编译期求值。"},{"title":"Rust 线程同步：消息传递","path":"/topic/rust-grammar/rust-concurrency-msg-passing/","content":"单发送者，单接受者 使用 std::sync::mpsc::channel() (multiple producer, single consumer) use std::sync::mpsc;use std::thread;fn main() // 创建一个消息通道, 返回一个元组：(发送者，接收者) let (tx, rx) = mpsc::channel(); // 创建线程，并发送消息 thread::spawn(move || // 发送一个数字1, send方法返回ResultT,E，通过unwrap进行快速错误处理 tx.send(1).unwrap(); // 下面代码将报错，因为编译器自动推导出通道传递的值是i32类型，那么Optioni32类型将产生不匹配错误 // tx.send(Some(1)).unwrap() ); // 在主线程中接收子线程发送的消息并输出 println!(receive , rx.recv().unwrap()); 接受数据的时候，recv() 是阻塞的；try_recv() 是不阻塞的，当通道中没有消息时，它会立刻返回一个错误 Result (Ok 或者 Err())。 多发送者 mpsc 支持多发送者，我们需要将 sender 进行 clone() 后，给每一个线程一个拷贝即可。 use std::sync::mpsc;use std::thread;fn main() let (tx, rx) = mpsc::channel(); let tx1 = tx.clone(); thread::spawn(move || tx.send(String::from(hi from raw tx)).unwrap(); ); thread::spawn(move || tx1.send(String::from(hi from cloned tx)).unwrap(); ); for received in rx println!(Got: , received); 需要注意的是： 需要所有的发送者都被 drop 掉后，接收者 rx 才会收到错误，进而跳出 for 循环，最终结束主线程 通道与所有权的转移 如果值的类型实现了 Copy，则直接复制该值，传输到 channel 里. 如果没有实现 Copy，则其所有权会转移到 channel，随后给 receiver. 同步通道、异步通道 异步通道：无论接收者是否正在接收消息，消息发送者在发送消息时都不会阻塞 同步通道：发送消息是阻塞的，只有在消息被接收后才解除阻塞 mpsc::sync_channel(N) 这里可以通过设置 N，使得发送者可以无阻塞地发送 N 条消息。当消息缓冲队列满了后，新发送的消息将被阻塞。 use std::sync::mpsc;use std::thread;use std::time::Duration;fn main() let (tx, rx)= mpsc::sync_channel(0); // 设置 0 条消息可以无阻塞发送 let handle = thread::spawn(move || println!(发送之前); tx.send(1).unwrap(); println!(发送之后); ); println!(睡眠之前); thread::sleep(Duration::from_secs(3)); println!(睡眠之后); println!(receive , rx.recv().unwrap()); handle.join().unwrap(); 关闭通道 所有发送者被 drop 或者所有接收者被 drop 后，通道会自动关闭。"},{"title":"Rust 多线程与并发","path":"/topic/rust-grammar/rust-concurrency/","content":"thread::spawn 可以使用 thread::spawn 创建线程： 线程内部的代码用闭包来执行 main 进程一旦结束，所有子线程也会立刻结束。所以需要先确保子线程都结束，再结束程序。 use std::thread;use std::time::Duration;fn main() thread::spawn(|| for i in 1..10 println!(hi number from the spawned thread!, i); thread::sleep(Duration::from_millis(1)); ); for i in 1..5 println!(hi number from the main thread!, i); thread::sleep(Duration::from_millis(1)); .join(): 等待线程结束 和其他语言里的 join() 作用一样： use std::thread;use std::time::Duration;fn main() let handle = thread::spawn(|| for i in 1..5 println!(hi number from the spawned thread!, i); thread::sleep(Duration::from_millis(1)); ); handle.join().unwrap(); for i in 1..5 println!(hi number from the main thread!, i); thread::sleep(Duration::from_millis(1)); 线程屏障 Barrier 是用于同步的机制. 类似于初始值非零的 semaphore. use std::sync::Arc, Barrier;use std::thread;fn main() let mut handles = Vec::with_capacity(6); let barrier = Arc::new(Barrier::new(6)); for _ in 0..6 let b = barrier.clone(); handles.push(thread::spawn(move|| println!(before wait); b.wait(); println!(after wait); )); for handle in handles handle.join().unwrap(); 线程局部变量 使用 thread_local! 宏初始化线程内部的局部变量，然后在线程内部使用该变量的 with 方法获取变量值。每个新的线程访问它时，都会使用它的初始值作为开始，各个线程中的值彼此互不干扰。 use std::cell::RefCell;use std::thread;thread_local!(static FOO: RefCellu32 = RefCell::new(1));FOO.with(|f| assert_eq!(*f.borrow(), 1); *f.borrow_mut() = 2;);// 每个线程开始时都会拿到线程局部变量的FOO的初始值let t = thread::spawn(move|| FOO.with(|f| assert_eq!(*f.borrow(), 1); *f.borrow_mut() = 3; ););// 等待线程完成t.join().unwrap();// 尽管子线程中修改为了3，我们在这里依然拥有main线程中的局部值：2FOO.with(|f| assert_eq!(*f.borrow(), 2);); 这里，线程对 FOO 的使用方式是借用。我们无法在每个线程里获取 FOO 的独立拷贝最后汇总。 只调用一次的函数（初始化全局变量） use std::thread;use std::sync::Once;static mut VAL: usize = 0;static INIT: Once = Once::new();fn main() let handle1 = thread::spawn(move || INIT.call_once(|| unsafe VAL = 1; ); ); let handle2 = thread::spawn(move || INIT.call_once(|| unsafe VAL = 2; ); ); handle1.join().unwrap(); handle2.join().unwrap(); println!(, unsafe VAL );"},{"title":"Rust Cell&lt;T&gt;: 在不可变引用的同时修改目标数据","path":"/topic/rust-grammar/rust-internal-changeable-cell-refcell/","content":"CellT Cell 和 RefCell 在功能上没有区别，区别在于 CellT 适用于 T 实现 Copy 的情况： use std::cell::Cell;fn main() let c = Cell::new(asdf); let one = c.get(); c.set(qwer); let two = c.get(); println!(,, one, two); 输出： asdf,qwer 因为实现了 Copy，所以 asdf 这个值被复制了一份，给了 one 变量. Cell 没有可变引用 use std::cell::Cell;fn main() // code snipet 1 let x = Cell::new(1); let y = x; let z = x; x.set(2); y.set(3); z.set(4); println!(, x.get()); 这里，y, z 都是 x 的不可变引用，调用 y.set() 的时候，会自动 dereference 为 (x).set() === x.set() 因此，y, z 调用 set() 都会修改 x 这个指针指向的数据，因此输出为 444 Cell::from_mut(), Cell::as_slice_of_cells() 使用技巧 Cell::from_mut()，该方法将 mut T 转为 CellT Cell::as_slice_of_cells()，该方法将 Cell[T] 转为 [CellT] // Wrongfn is_even(i: i32) - bool i % 2 == 0fn retain_even(nums: mut Veci32) let mut i = 0; for num in nums.iter().filter(|num| is_even(*num)) nums[i] = *num; i += 1; nums.truncate(i); // Trueuse std::cell::Cell;fn retain_even(nums: mut Veci32) let slice: [Celli32] = Cell::from_mut(mut nums[..]) .as_slice_of_cells(); let mut i = 0; for num in slice.iter().filter(|num| is_even(num.get())) slice[i].set(num.get()); i += 1; nums.truncate(i); 这个例子里，我们希望通过 iter().filter() 遍历元素，此时迭代器是对元素的不可变借用，因此无法通过不可变借用来修改元素值（因为会违反 Rust 的借用规则）。而 CellT 允许使用 .get() 和 .set() 方法，在不可变借用的上下文里修改值，从而绕过 Rust 的限制。所以我们需要的是 an immutable reference of a list of CellTs. RefCellT RefCellT 解决的问题更进一步：解决可变引用、不可变引用共存的问题。本质只是将编译阶段的共存检查，推迟到运行时阶段，即如果运行时阶段里还是出现了 mutable borrow 和 immutable borrow 同时存在的情况下，依然会报运行时错误 Panic. Rust 规则 智能指针带来的额外规则 一个数据只有一个所有者 RcT/ArcT 让一个数据可以拥有多个所有者 要么多个不可变借用，要么一个可变借用 RefCellT 实现编译期可变、不可变引用共存 违背规则导致编译错误 违背规则导致运行时 panic 什么是内部可变性？ 在某些场景中，一个值可以在其方法内部被修改，同时对于其它代码不可变。例如说考虑下面这个例子： // 定义在外部库中的特征pub trait Messenger fn send(self, msg: String);// --------------------------// 我们的代码中的数据结构和实现struct MsgQueue msg_cache: VecString,impl Messenger for MsgQueue fn send(self, msg: String) self.msg_cache.push(msg) 我们有个变量 x: MsgQueue，我们调用 x.send() 希望修改数据结构里的一部分，但是不希望 x 变量本身被修改。然而，send() 方法的签名是 self，而且 .push() 修改了 x 的数据，因此 self 会报错。 这个时候 RefCellT 就派上用场了。我们把 msg_cache 用 RefCellVecString 包裹，就可以实现保持 x 不可变的情况下修改内部的数据。 // 定义在外部库中的特征pub trait Messenger fn send(self, msg: String);// --------------------------// 我们的代码中的数据结构和实现struct MsgQueue msg_cache: VecString,impl Messenger for MsgQueue fn send(self, msg: String) self.msg_cache.push(msg) use std::cell::RefCell;pub trait Messenger fn send(self, msg: String);pub struct MsgQueue msg_cache: RefCellVecString,impl Messenger for MsgQueue fn send(self, msg: String) self.msg_cache.borrow_mut().push(msg) fn main() let mq = MsgQueue msg_cache: RefCell::new(Vec::new()), ; mq.send(hello, world.to_string());注意这里的 borrow_mut() Rc + RefCell 一个常见的用法是 RcRefCellT，这样，多个 x = RcRefCellT 可以共享底层的数据。 use std::cell::RefCell;use std::rc::Rc;fn main() let s = Rc::new(RefCell::new(我很善变，还拥有多个主人.to_string())); let s1 = s.clone(); let s2 = s.clone(); // let mut s2 = s.borrow_mut(); s2.borrow_mut().push_str(, oh yeah!); println!(:? :? :?, s, s1, s2); 输出： RefCell value: 我很善变，还拥有多个主人, oh yeah! RefCell value: 我很善变，还拥有多个主人, oh yeah! RefCell value: 我很善变，还拥有多个主人, oh yeah!"},{"title":"Rust Arc&lt;T&gt;：在多线程里共享对象","path":"/topic/rust-grammar/rust-multithread-arc/","content":"ArcT: Atomic RcT ArcT 和 RcT 具有完全相同的 API，和 RcT 的区别就在于原子化或者其它锁虽然可以带来的线程安全，但是都会伴随着性能损耗，而且这种性能损耗还不小。 use std::sync::Arc;use std::thread;fn main() let s = Arc::new(String::from(多线程漫游者)); for _ in 0..10 let s = Arc::clone(s); let handle = thread::spawn(move || println!(, s) );"},{"title":"Rust 中的计数指针","path":"/topic/rust-grammar/rust-shared-pointer-rc/","content":"RcT 希望在堆上分配一个对象供程序的多个部分使用且无法确定哪个部分最后一个结束时，就可以使用 Rc 成为数据值的所有者。使用 Rc::clone(ptr) 进行指针复制。 use std::rc::Rc;fn main() let a = Rc::new(String::from(hello, world)); let b = Rc::clone(a); assert_eq!(2, Rc::strong_count(a)); assert_eq!(Rc::strong_count(a), Rc::strong_count(b)) 这里的 Rc::clone()，仅仅复制了智能指针并增加了引用计数，并没有克隆底层数据，因此 a 和 b 是共享了底层的字符串 s. RcT 与 mutable reference 事实上，RcT 是指向底层数据的不可变的引用，因此你无法通过它来修改数据，这也符合 Rust 的借用规则：要么存在多个不可变借用，要么只能存在一个可变借用。 那么如何需要修改数据该怎么办呢？这就需要 RefCellT 或者互斥锁 MutexT 了。而在多线程里需要共享对象的话，需要 ArcT"},{"title":"智能指针：Deref, Drop","path":"/topic/rust-grammar/smart-pointer-deref-drop/","content":"Deref Deref 可以访问被分配的资源。 dereference 类似于 C++ 中的指针 * 操作符，并且只能在 ... 上或者实现了 Deref trait 的类型上使用。仅引用类型的实参才会触发自动解引用 隐式 Deref 转换 Rust 编译器在碰到实参与形参的类型对不上的时候，会考虑将实参自动 Deref 以匹配函数的形参类型。考虑这样的代码： fn main() let s = Box::new(String::from(hello world)); display(s)fn display(s: str) println!(, s); s 的类型是 BoxString，而函数的形参类型是 str，出现对不上号的情况。于是 Rust 编译器做了如下的自动 dereference: BoxString == String == str 连续的 Deref 转换（引用归一化） 先前提到，Rust 只能对 进行 dereference，当遇到多个 或者智能指针的时候，Rust 是怎么处理的呢？简而言之，可以概括为以下几点： 智能指针 BoxT 展开成 T（包括其他类型的智能指针，如 RcT, ArcT） 把多重 归一为单个 第二点在标准库里是这样实现的： impl T: ?Sized Deref for T type Target = T; fn deref(self) - T *self Deref 与 DerefMut dereference 还支持将 mutable reference 转换成 immutable reference，或者 immutable reference 转换成 mutable reference. 当 T: DerefTarget=U 时，T 可以转换成 U，immutable ref →\\to→ immutable ref 当 T: DerefTarget=U 时，mut T 可以转换成 U 当 T: DerefMutTarget=U 时，mut T 可以转换成 mut U 并且，从标准库实现上说，DerefMut 是继承了 Deref. Drop Drop 特征可以释放资源。在变量超出作用域的时候，执行一段特定的代码，最终编译器将帮助自动插入这段收尾代码。 当然也可以手动调用 xxx.drop() 进行手动回收。 Drop 的顺序 我们考察下面这段代码： struct HasDrop1;struct HasDrop2;impl Drop for HasDrop1 fn drop(mut self) println!(Dropping HasDrop1!); impl Drop for HasDrop2 fn drop(mut self) println!(Dropping HasDrop2!); struct HasTwoDrops one: HasDrop1, two: HasDrop2,impl Drop for HasTwoDrops fn drop(mut self) println!(Dropping HasTwoDrops!); struct Foo;impl Drop for Foo fn drop(mut self) println!(Dropping Foo!) fn main() let _x = HasTwoDrops two: HasDrop2, one: HasDrop1, ; let _foo = Foo; println!(Running!); 输出为 Running!Dropping Foo!Dropping HasTwoDrops!Dropping HasDrop1!Dropping HasDrop2! 由此可以得出 drop 的顺序： 变量级别，按照逆序的方式，_x 在 _foo 之前创建，因此 _x 在 _foo 之后被 drop 结构体内部，按照顺序的方式，结构体 _x 中的字段按照定义中的顺序依次 drop Copy 与 Drop 互斥 我们无法为一个类型同时实现 Copy 和 Drop 特征。因为实现了 Copy 特征的类型会被编译器隐式的复制，因此非常难以预测析构函数执行的时间和频率。因此这些实现了 Copy 的类型无法拥有析构函数。"},{"title":"Rust 中的智能指针","path":"/topic/rust-grammar/rust-smart-pointers/","content":"BoxT 基础智能指针 特意的将数据分配在堆上 数据较大时，虽然可以放在栈上，但是不想在转移所有权时进行数据拷贝（栈上的数据只会拷贝） 当栈上数据转移所有权时，实际上是把数据拷贝了一份，最终新旧变量各自拥有不同的数据，因此所有权并未转移。 而堆上则不然，底层数据并不会被拷贝，转移所有权仅仅是复制一份栈中的指针，再将新的指针赋予新的变量，然后让拥有旧指针的变量失效，最终完成了所有权的转移 类型的大小在编译期无法确定，但是我们又需要固定大小的类型时 特征对象，用于说明对象实现了一个特征，而不是某个特定的类型 Box::leak 可以消费掉 Box 并且强制目标值从内存中泄漏，使用场景：需要一个在运行期初始化的值，但是可以全局有效，也就是和整个程序活得一样久。Box::leak 可以完成动态初始化。"},{"title":"迭代器：消费、适配","path":"/topic/rust-grammar/iterator-consumer-adapter/","content":"Consume Iterator 只要迭代器上的某个方法 A 在其内部调用了 next 方法，那么 A 就被称为消费性适配器：因为 next 方法会消耗掉迭代器上的元素，所以方法 A 的调用也会消耗掉迭代器上的元素。 注意，这里会拿走的是迭代器的所有权，而非原来变量的所有权。例如，sum() 方法 fn main() let v1 = vec![1, 2, 3]; let v1_iter = v1.iter(); let total: i32 = v1_iter.sum(); assert_eq!(total, 6); // v1_iter 是借用了 v1，因此 v1 可以照常使用 println!(:?,v1); // 以下代码会报错，因为 `sum` 拿到了迭代器 `v1_iter` 的所有权 // println!(:?,v1_iter); Adapt Iterator 会返回一个新的迭代器。迭代器仍然是惰性的，不操作就不会进行求值。这也意味着我们需要一个 consumer 来消费这个迭代器，如 .collect() 方法。"},{"title":"Rust 迭代器","path":"/topic/rust-grammar/rust-iterator/","content":"转化为迭代器 .into_iter() 拿走所有权，并转化为迭代器 .iter() 对元素进行不可变借用的迭代器 .iter_mut() 对元素进行可变借用的迭代器，可以修改元素 Iterator Trait, IntoIterator Trait 两者稍有区别。前者定义了 next 方法使得可以访问元素，后者则定义了 into_iter(), iter(), iter_mut() 等迭代器转化方法 pub trait Iterator type Item; fn next(mut self) - OptionSelf::Item; // 省略其余有默认实现的方法implI: Iterator IntoIterator for I type Item = I::Item; type IntoIter = I; #[inline] fn into_iter(self) - I self"},{"title":"把 closure 作为函数的返回值","path":"/topic/rust-grammar/closure-as-return-value/","content":"闭包作为函数返回值 回想到我们如何将特征对象作为函数的返回类型，这里的 FnOnce, FnMut, Fn 也都是特征，那么我们可以用相同的方法进行处理： fn factory(x:i32) - Boxdyn Fn(i32) - i32 let num = 5; if x 1 Box::new(move |x| x + num) else Box::new(move |x| x - num)"},{"title":"Rust 与函数式编程：闭包","path":"/topic/rust-grammar/rust-closure/","content":"what is closure? Rust 里的 closure 是一种匿名函数，可以保存在变量里用于日后的调用，也可以作为参数传递给函数。而且相比于函数，closure 可以在其定义域内捕获变量。 closure 的类型推导 closure 不是泛型，因此当编译器推导出一种类型后，它就会一直使用该类型。 let example_closure = |x| x;let s = example_closure(String::from(hello));// example_closure 的类型为 Fn(String) - Stringlet n = example_closure(5); // 但这里希望以 Fn(i32) - i32 调用// 报错！ Rust 闭包可以用泛型吗？ struct CacherT, Ewhere T: Fn(E) - E, E: Clone, query: T, value: OptionE,implT, E CacherT, Ewhere T: Fn(E) - E, E: Clone, fn new(query: T) - CacherT, E Cacher query, value: None fn value(mut self, arg: E) - E match self.value Some(ref v) = v.clone(), None = let v = (self.query)(arg.clone()); self.value = Some(v.clone()); v.clone() fn main() let mut test = Cacher::new(|d: String| d + world); println!(first cache: , test.value(wtf.to_string())); println!(second cache: , test.value(hello.to_string())); closure 与内存 当闭包从环境中捕获一个值时，会分配内存去存储这些值。对于有些场景来说，这种额外的内存分配会成为一种负担。与之相比，函数就不会去捕获这些环境值，因此定义和使用函数不会拥有这种内存负担。 三种闭包特征 (Trait) 闭包捕获变量有三种途径，恰好对应函数参数的三种传入方式：转移所有权、可变借用、不可变借用，因此相应的 Fn 特征也有三种： 这三种的关系并不是说，我定义了闭包类型满足 FnOnce 那么这个闭包就只能调用一次，而是会根据捕获和使用方式，自动推导闭包属于哪一种 Trait FnOnceFnMutFn 可以移动变量所有权 只能调用一次（除非也实现 Copy trait） 来看这么一个例子 fn fn_onceF(func: F)where F: FnOnce(usize) - bool, println!(, func(3)); println!(, func(4)); // 报错fn main() let x = vec![1, 2, 3]; fn_once(|z| z == x.len()) 这里一个问题是，FnOnce 特征的 func 变量为什么只能被调用一次？怎么从所有权的角度进行解释？ 从捕获的变量的角度来说，闭包捕获了变量的所有权，根据 Rust 的语言设计，所有权只能在一个人手里，于是第二次再调用闭包就会无法拿到所有权。 那么闭包自身的所有权转移给谁了呢？闭包 func 的所有权会转移到调用闭包的代码上下文。此时，闭包可能释放其捕获的资源（如 x），或者将这些资源的所有权转移给其他逻辑（即使没有显式转移，闭包本身的调用也意味着其自身被“销毁”） 这里 func(4) 的报错其实与 fn_once(|z| z == x.len()) 这个匿名函数本身没关系，只是泛型函数自己做的类型检查。 使用变量的可变借用 (mut) 闭包变量本身也需要定义为 let mut，或者作为函数参数时以 mut 的方式借用 使用变量的不可变借用 move 与 Fn Trait 实际上使用了 move 的闭包依然可以使用 Fn 或 FnMut 特征 一个闭包实现了哪种 Fn 特征取决于该闭包如何使用被捕获的变量，而不是取决于闭包如何捕获它们 这个点怎么理解呢？考虑下面的代码 let f = move || println!(, s.len()); 这里 f 闭包同时实现了 FnOnce, FnMut, Fn，尽管 move 把所有权都转移走了（“闭包如何捕获他们”）但是 s.len() 仅仅只使用了不可变借用（“该闭包如何使用被捕获的变量”），因此还是 Fn，也因此可以作为 FnOnce, FnMut 泛型的参数。 更具体的，一个闭包并不仅仅实现某一种 Fn 特征，规则如下： 所有的闭包都自动实现了 FnOnce 特征，因此任何一个闭包都至少可以被调用一次 没有移出所捕获变量的所有权的闭包自动实现了 FnMut 特征 不需要对捕获变量进行改变的闭包自动实现了 Fn 特征 我们可以看成是一个继承的关系： FnOnce⟶FnMut⟶Fn \\boxed{\\texttt{FnOnce}}\\longrightarrow\\boxed{\\texttt{FnMut}}\\longrightarrow\\boxed{\\texttt{Fn}} FnOnce​⟶FnMut​⟶Fn​通过源码可以看得更清晰： pub trait FnOnceArgs: Tuple /// The returned type after the call operator is used. #[lang = fn_once_output] #[stable(feature = fn_once_output, since = 1.12.0)] type Output; /// Performs the call operation. #[unstable(feature = fn_traits, issue = 29625)] extern rust-call fn call_once(self, args: Args) - Self::Output;pub trait FnMutArgs: Tuple: FnOnceArgs /// Performs the call operation. #[unstable(feature = fn_traits, issue = 29625)] extern rust-call fn call_mut(mut self, args: Args) - Self::Output;pub trait FnArgs: Tuple: FnMutArgs /// Performs the call operation. #[unstable(feature = fn_traits, issue = 29625)] extern rust-call fn call(self, args: Args) - Self::Output;"},{"title":"具身智能（一）：数据集","path":"/topic/researchthoughts/rl-agent-dataset-01/","content":"6f592527dfcf14273982642650ba23d6edaaa319c53634fffd49af368ca2244ff121d6d4d6d9b5a0f205c8cfa1e33a595c27b300ef383bbfbb5f35d2cc1d01b520ae805a34d3e829467a1ed1ae7f0dcaff5733b6ca2fcb015558be80773daa867f670a8998b36f6496f92daea65a57d6e3845dc63c1295a691e3e903259826288db38a4f6e20dfd5b0d6293d55f80745809c83e9d6cafb311393ec8c86ced8260f62dc0872dddc041e62f7fc6591ef02f6e2fa6ffb194a70f8561863f1c55848b07469ebe114cf3445440105b9997cf3540569da3b5674038cf74efa9b94357d2f5fc9e1208f599289991d3aece7cb9278ab9cb1796f4f659eac4a9e405670d92fe9770822db56d036936c958c1c80db06349236ca3cc3a8e72f0c64ff35fa762e1f90fc935099da4d17e272b12fdc3276a0b506ab13a01ee799c4f48d2d09b977a2877514bc00b1eadbe45a91c7afc1d0fd9c5db430d2c7f2859bbf2d9da6924bf7e7e00afdf436f80191c97c82b5108b5c3cf9880a4a524d33f2235da6205b31a6bd230e7a52fff92e63fbbecf7eec2c853af0e616ef111cf8839658443aefc1c38c8aeb7343a20529a187b1c138861518ea6e7376bb9c18cdd68afb1b2c2e8af102673b0ea6678239f95e952be7f5c5635abf3e4e680315e329e3fe9d5d9ef30c6c00e0acc3fef090e453a33dcf8083217f530bf0092f1027249234fa28738ad83e911bd3cff56a4338b7d1191f7b11a50e4f1b4c935bbb13af17d3cc8d6e69082724ace558126efedc4cae8217c23c057b5f99c03da1b92980ccf8e081a511f89f377433ad47424d3970a5fc825c44937a24c3c13257401d073723d524be4b067e233037c7a929665586cbdd983f55a060f84ad539599e51ab0bc7028e533288030a37b66240a95e40095257bb3612654a8a2aad638602612b1a52ce1e9bc266669c8e17b12fa6cd34ec8e505c9d18cd7bc21b7fda77cbe8eba408de887d1cc09f5891c51271e250f33f8b380024a4f6fdb32279a9cb8913214a7b3af403d07d3f243bfaaef5741bfd370ba3f8bdd3d5bf269a8c986d00db6b470ecf96c43c5677bfed2b90414b5276de67fe2360121b904276f1c3ab2f3cf5a664b28e1437575642ead7a6badae64bbb92671e38e83a7f8ea3f61614a84b769c4e71e064ed69066b84819b0506f91d11a1b70b28 Password is needed."},{"title":"Sublime Text 4 Crack","path":"/sublime-text-4200-crack/","content":"Linux 下破解 一行命令即可： sudo perl -pi -e s/\\x0F\\xB6\\x51\\x05\\x83\\xF2\\x01/\\xC6\\x41\\x05\\x01\\xB2\\x00\\x90/ /opt/sublime_text/sublime_text"},{"title":"MoE (Mixture of Experts) 技术","path":"/about-moe/","content":"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 Password is needed."},{"title":"Model Context Protocol","path":"/topic/mcp/mcp-intro/","content":"MCP Introduction MCP 本质上像是一个转接口，一侧是由厂商提供的 Pretrained LLM，另一侧是自己实现的工具、文本等等，这两者通过实现 MCP 的接口实现无缝切换，这样个人开发者就不需要为每一个模型都适配接口了。 然而听说 CLine 的 MCP 的实现方式只是在 Prompt 里添加包含工具的信息…… 感觉 Token 用量会直接爆炸啊 以下使用 Python 的 Official MCP SDK. 日后应该会加上 LangChain 的 MCP Adapter MCP Server MCP Server 就是提供工具服务的一方。简单来说，创建一个 MCP Tool 只需要正常地写完功能函数后，用 @mcp.tool(name=, description=, annotation=) Decorator 包装一下即可。 Python SDKTypeScript SDKfrom mcp.server.fastmcp import FastMCPservice = FastMCP(ServiceProviderName)# 使用 decorator 注册 MCP 工具@service.tool(name=Tool Name, description=Description of Tool, annotation=Input/Output Claim) def some_function(): # 或者 async def 也可以 确保返回的字符串是结构化的，以便让 LLM 读懂. return Some retured (structured) data. 还不会 TS（ 当然最重要的，MCP 作为服务的提供方需要向外暴露自己的功能： service.run(transport=stdio) MCP Client","categories":["MCP","Agent"]},{"title":"RoPE","path":"/topic/papers/RoPE/","content":"旋转位置编码 旋转位置编码的核心诉求就是需要让 embedding 同时体现出相似度和相对位置这两个信息 ⟨RoPE(Q,i),RoPE(K,j)⟩=PosSim(QKT,j−i) \\lang\\text{RoPE}(Q,i), \\text{RoPE}(K,j)\\rang=\\text{PosSim}(QK^T,j-i) ⟨RoPE(Q,i),RoPE(K,j)⟩=PosSim(QKT,j−i) 我们先考虑如果 Q,KQ,KQ,K 都只是二维向量，即 Q=[ab],K=[cd] Q=\\begin{bmatrix}a\\\\ b\\end{bmatrix}, K=\\begin{bmatrix}c\\\\ d\\end{bmatrix} Q=[ab​],K=[cd​]那么通常的 Scaled Dot Product Attention 的计算结果应为 QKT=ac+bdQK^T=ac+bdQKT=ac+bd，考虑写成复数的话，令 cq=a+bi,ck=c+dic_q=a+bi,c_k=c+dicq​=a+bi,ck​=c+di，且 ckc_kck​ 的共轭为 ck∗c_k^\\astck∗​，则有 ⟨q,k⟩=ℜ[cqck∗]\\lang q,k \\rang=\\Re[c_qc_k^\\ast]⟨q,k⟩=ℜ[cq​ck∗​]，其中 ℜ[c]\\Re[c]ℜ[c] (Latex Code: \\real) 表示 ccc 的实数部分，ℑ[c]\\Im[c]ℑ[c] 表示 ccc 的虚数部分 (Latex Code: \\image)。 我们假设 RoPE(x,i)\\text{RoPE}(x,i)RoPE(x,i) 可以表示为复数形式，即 RoPE(x,i)=ax+bxi=Rxeiθ(x,i)\\text{RoPE}(x,i)=a_x+b_xi=R_x e^{i\\theta(x,i)}RoPE(x,i)=ax​+bx​i=Rx​eiθ(x,i)，这里第二个等号是复数的指数表示法。 RoPE 虽然论文里是要求对 xm2ix_m^{2i}xm2i​ 与 xm2i+1x_m^{2i+1}xm2i+1​ 加上 cos⁡,sin⁡\\cos,\\sincos,sin 的 embedding，不过从数学的角度来说，这里的配对实际上不影响最终的结果，“不同的配对方式本质上不影响模型的表达能力，并且可以相互转化”。因此在工程上，考虑到内存连续性，我们通常不用这种相邻配对，而是 xix^{i}xi 与 xi+d/2x^{i+d/2}xi+d/2 进行配对计算。","categories":["位置编码"]},{"title":"学习 PyQT6 (1)——事件循环 (Event Loop)","path":"/topic/qt/pyqt-001/","content":"Event Loop QT 的核心是 QApplication 类（每个应用程序只需要一个 QApplication 类），它维护了 Event Loop，负责管理用户和应用程序的交互：每一次互动（摁键盘、点鼠标）都会生成一个 event 放在 event queue 里. 然后每一次 iteration 中，我们检查一次 queue，查找是不是有正在 waiting 的 event，然后 QT 把 event 和 control 交给对应的 event handler 进行处理。处理完毕后，handler 再把 control 交还给 QApplication. Event Loop Extending Qt Classes 需要总是先 super().__init__()"},{"title":"Swin Transformer","path":"/topic/papers/swin-transformer/","content":"Swin Transformer 视觉 Transformer 面临两大核心挑战： 视觉实体尺度变化大 (Scale Variation)； 图像像素分辨率远高于文本单词 (High Resolution)。 而现有的解决方法 ViT 存在一下几个问题： 单一尺度特征图 全局自注意力计算复杂度随图像尺寸呈平方增长 (Quadratic Complexity) 难以直接应用于密集预测任务 (Dense Prediction)","categories":["Transformer 架构"]},{"title":"Agentic 模式","path":"/agentic-patterns/","content":"Prompt Chaining 链式调用 Chaining Prompt Chaining 的实现思路比较简单：上一个 LLM 的输出作为下一个 LLM 的输入。这样的 agentic 范式适合那些可以被分解成 sequential assembly line 的任务。 然而这样的方法也有局限性：这样的任务也依赖于人工对任务进行拆解。 Routing 路由转发 Routing 顾名思义，Routing Flow 下，一个小型的 LLM 负责解析用户的指令，判断指令所属的任务，然后转发给对应的 LLM 进行处理。 这样做的一个好处就是可以控制 API 调用成本。例如用小模型进行解析工作，如果指令比较简单，则转发给小模型进行指令处理；否则把复杂指令交给 API 调用费更贵的大模型进行进一步的处理。 Parallelization 并行处理 Parallel A task is broken down into independent subtasks that are processed simultaneously by multiple LLMs, with their outputs being aggregated. RAG with Query Decomposition 分析复杂文档 Reflection 生成并反思 Reflection Reflection 是让 LLM 重新评判自己生成的内容是否满足要求，如果不满足，则继续生成（修正）。这种范式已经出现在诸如 VSCode Copilot 等产品上 Tool Use 工具使用 在我看来，Tool Use 只是 Reflection 的一种形式：评判的过程换成了外部工具的调用。 Tool Use Planning Planning 中央 LLM 将任务拆解为多个子任务，然后转发给专门的 LLM 进行处理并汇总。和 Routing 很像，但区别在于 Routing 直接转发一整个任务，而 Planning 先拆分大任务，再将小人物转发处理。 Multi-Agent Manager 形式 Multi-Agent (Manager) Manager 形式实现的 MultiAgent 分多个角色：manager 和 worker. 每个 worker 具有特定领域的专业知识和特定工具的访问权限，manager 则可以分析任务进展，指定 worker 进行任务协作。 Swarm 形式 Multi-Agent (Swarm) Swarm 形式实现的 Multi Agent 相比于 Manager 形式来说，去掉了负责协调的 central manager，直接让 worker 之间自行合作。"},{"title":"Prompt Engineering Techniques","path":"/prompt-engineering/","content":"算是介绍一下当下的一些 Prompt Engineering 技术 Zero-Shot zero-shot prompting 非常常见，其实就是直接给 chatbot 一个情况，然后直接要求“帮我解决这个问题”。prompt 里不包含其他例子，就称为 zero-shot prompting 好处是非常简短，很符合人与人之间的交流方式；但坏处也很明显，因为指令简短，LLM 要么回答得不尽如人意，要么干脆出现幻觉. Few-Shot"},{"title":"ACM：字符串算法","path":"/strings-oi/","content":"字符串哈希 例题 P4391 [BalticOI 2009] Radio Transmission 无线传输 字典树"},{"title":"HKU COMP3270 目录","path":"/comp3270-menu/","content":"课程笔记兼目录 Minimax Alpha-beta 剪枝"},{"title":"Agentic 系统","path":"/what-is-agentic/","content":"Agentic System"},{"title":"LightRAG 论文","path":"/lightrag-paper/","content":"RAG 任务概述 我们可以把 RAG 任务用一个统一的框架来描述： M=(G,R=(I,S))M(q;D)=G(q,S(q;D^))D^=I(D) \\begin{aligned} M=(G, R=(I, S))\\\\ M(q;D)=G(q, S(q; \\hat D))\\\\ \\hat D=I(D) \\end{aligned} MM(q;D)D^​=(G,R=(I,S))=G(q,S(q;D^))=I(D)​这里的字母变量都是什么意思呢？有必要搞这么复杂的数学描述吗……原论文甚至还用上了希腊字母和花体字…… MMM 是整个 RAG 框架。 M(q;D)M(q;D)M(q;D) 代表一次查询：给定问题 qqq 和知识库 DDD 让模型给出回答。 这里的 GGG 是 Generation Module，即模型生成。 R=(I,S)R=(I,S)R=(I,S) 是 RAG 里的 Retrieval-Augment 部分 其中 III 用于处理知识库 DDD，将原始文档 DDD 转化为特定的数据结构 D^\\hat DD^，以期更好质量的 retrieval SSS 是 Search，其实更像 Augment 的过程，从处理好的数据库 D^\\hat DD^ 里获取相关的信息，传递给 Generation 模块 GGG 让模型进行输出。"},{"title":"另一种视角下的网络流体系","path":"/networkflow-another-view/","content":"DFS/BFS 如何证明路径不存在？"},{"title":"ManiSkill Task Definition Snippet","path":"/maniskill-snippets/","content":"转动容器，移动小球以插入柱子"},{"title":"RecursiveCharacterTextSplitter 具体实现","path":"/langchain-RecursiveCharacterTextSplitter/","content":"RecursiveCharacterTextSplitter split 首先是调用了 Python 的 re.split(sep, text) 做了一次基本的分割，同时用 [s for s in re.split(sep, text) if s != ] 做基础的过滤，过滤掉那些为空的字符串。 merge 然后针对切割出来的块进行 merge"},{"title":"自然语言处理（NLP）的发展与关键技术：从词义到大模型","path":"/nlp-development/","content":"词义表示的进化：从规则到分布式语义 WordNet 近义词表示 早期的NLP系统依赖人工构建的规则和词典，如 WordNet。这类工具通过同义词集合和上下位关系 (Hyponymy) 描述词义，例如将“proficient”标记为“good”的同义词。然而，这种方法存在明显局限： 静态性：无法捕捉新兴含义（如“wicked”在俚语中的“酷”意）；一些单词仅在特定情况下意义相近 主观性：词语意义需要人工界定 实时性：依赖人工标注，更新缓慢； 缺乏相似性计算 ：无法量化“hotel”和“motel”的语义相似度。 Localist: One-Hot 编码与词袋模型 2013 年前，NLP 普遍采用 One-Hot 编码 表示词汇，即用高维稀疏向量（如长度为 101010 万的向量中仅一个位置为 111）表示单词。这种“局部表示”导致： 维度灾难 ：101010 万词汇需 101010 万维空间； 零相似性 ：正交向量无法反映词义关联（如“hotel”与“motel”）。 Distributed Semantics 与 Word2Vec Word2Vec 是一种通过无监督学习生成词向量的工具，其核心思想是基于词的上下文共现规律，将词映射到低维稠密向量空间中，使得语义相似的词在向量空间中距离较近。主要有两种模型：一种是根据上下文推理中心词的 CBOW 模型，另一种是根据中心词推理上下文的 Skip-Gram 模型。 这里的 Word Vector 也被称为 Word Embedding 或者 Word Representations Skip Gram 给定上下文长度为 mmm，对于样本数据中心词为 wtw_twt​，其上下文为 wt−m,…,wt+mw_{t-m},\\dots,w_{t+m}wt−m​,…,wt+m​，Skip Gram 训练的目标就是最大化上下文词的条件概率 ∏j=−mmP(wt+j∣wt) \\prod_{j=-m}^m P(w_{t+j}|w_t) j=−m∏m​P(wt+j​∣wt​)对于全部语料库，那么就要最大化每一个这样的中心词和上下文的条件概率，把他们乘起来（假设 Skip Gram 的参数为 θ\\thetaθ） 这里的 θ\\thetaθ 其实是一个矩阵。假设我们把词汇编码为 ddd 维稠密向量，词汇表大小为 VVV，则 θ\\thetaθ 的大小应该为 R2dV\\mathbb R^{2dV}R2dV，我们这里直接把 θ\\thetaθ 当作词汇表来看。 其本质是一个将词汇映射到 embedding 空间的函数 f:{0,1}V↦Rdf:\\mathbb \\{0,1\\}^V\\mapsto R^{d}f:{0,1}V↦Rd。要取出 viv_ivi​ 向量，可以通过矩阵乘法，设置每一行为 111、其余全部置 000 来取出这一行的词向量，相当于 θ\\thetaθ 乘上了一个常数。 即 vw=θTCv(w)v_w=\\theta^TC_v(w)vw​=θTCv​(w)，uw=θTCu(w)u_w=\\theta^TC_u(w)uw​=θTCu​(w)，这里的 Cv,CuC_v,C_uCv​,Cu​ 可以是 www 的 One-Hot Vector. θ=arg max⁡θ∏t=1T∏−m≤j≤mj≠0Pθ(wt+j∣wt) \\theta=\\argmax_\\theta \\prod_{t=1}^T \\prod_{-m \\le j\\le m}^{j e 0} P_\\theta(w_{t+j}|w_t) θ=θargmax​t=1∏T​−m≤j≤m∏j=0​Pθ​(wt+j​∣wt​)这也等同于最小化其负对数 θ=arg min⁡θJ(θ)=arg min⁡θ−1T∑t=1T∑−m≤j≤mj≠0log⁡Pθ(wt+j∣wt) \\theta=\\argmin_\\theta J(\\theta)=\\argmin_\\theta -\\frac{1}{T}\\sum_{t=1}^T \\sum_{-m \\le j\\le m}^{j e 0} \\log P_\\theta(w_{t+j}|w_t) θ=θargmin​J(θ)=θargmin​−T1​t=1∑T​−m≤j≤m∑j=0​logPθ​(wt+j​∣wt​)这里概率的计算就是老套路 softmax 了，我们把整个词汇库的 context vector 和当前词的中心词向量点乘起来，做 softmax（这里用 ooo 表示上下文词，uwu_wuw​ 表示单词 www 作为上下文时的向量，vwv_wvw​ 表示 www 作为中心词时的向量） P(o∣c)=exp⁡(uoTvc)∑w∈Vexp⁡(uwTvc) P(o|c)=\\frac{\\exp(u_{o}^T v_c)}{\\sum_{w\\in \\mathbb V} \\exp(u_w^T v_c)} P(o∣c)=∑w∈V​exp(uwT​vc​)exp(uoT​vc​)​于是损失函数 J(θ)J(\\theta)J(θ) 变成了 J(θ)=−1T∑t=1T∑−m≤j≤mj≠0(uoTvc−log⁡∑w∈Vexp⁡(uwTvc)) J(\\theta)=-\\frac{1}{T}\\sum_{t=1}^{T} \\sum_{-m \\le j\\le m}^{j e 0} \\Big(u_o^Tv_c-\\log\\sum_{w\\in\\mathbb V}\\exp(u_w^Tv_c)\\Big) J(θ)=−T1​t=1∑T​−m≤j≤m∑j=0​(uoT​vc​−logw∈V∑​exp(uwT​vc​))"},{"title":"Intro to AI: Searching","path":"/ai-and-searching/","content":"Searching Searching Problem 的组成部分 state space successor function (包含 action 和 cost/reward，例如路径) start state 和 goal state 搜索问题的解决方法：a sequence of action which transforms start state into goal state 于是可以表示为图论问题 节点：代表 state 有向边：代表 state transformation 目标：从一个节点走到另一个节点 这张图是全局的，包含所有 state 的信息和转移。如果我们只关注从某一个 state (例如 start state) 出发的可能性（即局部的），则得到搜索树 ……但是子树结构大量重复 ……可能有环，导致树高无限高 解决方案：只保留正在考虑的部分子树，其余的全部扔掉 DFS 令一个状态可以拓展到 bbb 个状态，最多 mmm 层，则 树中节点数量：O(bm)O(b^m)O(bm) 原图无环时，DFS 搜索树是有穷的 不一定 Optimal，因为只往 leftmost 方向走 BFS 到达一个状态，所探明的节点数量为 O(bs)O(b^s)O(bs)，sss 为当前所处在的深度 必然是 complete 的 不一定 optimal，除非 cost 均为 111"},{"title":"LightRAG: query 处理查询的深入探究","path":"/lightrag-query-method/","content":"LightRAG.query() 支持四类查询： Local: 只注重局部信息 Global: 只注重全局信息 Hybrid Naive: 当作最传统的 RAG 来使用 Bypass: 不使用额外的知识库 Mix: Naive + Hybrid 下面，我们主要来看 GraphRAG 相关的 Hybrid 查询（其实就是一个 kg_query() 的 router） 启动异步查询"},{"title":"HKU GPU Farm 指北","path":"/hku-gpu-farm/","content":"进入 GPU Farm 用 ssh 链接 gpugate1.cs.hku.hk 然后输入密码即可。 ssh [your_username]@gpugate1.cs.hku.hk 进入 GPU 模式 注意 安装任何软件、仓库都必须先进 GPU Mode. gpu-interactive"},{"title":"LightRAG: 构建索引 insert() 方法深入探究","path":"/lightrag-insert-method/","content":"LightRAG LightRAG 是针对 GraphRAG 构建索引速度慢、消耗 Token 量大而诞生的解决方案，更多详细的方法论请移步 wiki，这一篇主要聚焦与代码层面的实现。 注意事项 由于 Python 的异步模块 asyncio 不支持嵌套，.insert() 方法在执行的时候会报错：This event loop has already been running。我们需要用 nest_asyncio 打个补丁 先安装 nest_asyncio 包 pip install nest-asyncio 再导入，并 patch 一下 import nest_asyncionest_asyncio.apply() 然后就 ok 了 启动异步索引构建 .insert() 这个函数是插入文档的入口，是一个同步函数（然而 readme 里写成了异步函数，well）。它的工作实际上就是调用了异步函数进行插入文档 .insert() def insert( self, input: str | list[str], split_by_character: str | None = None, split_by_character_only: bool = False, ids: str | list[str] | None = None, file_paths: str | list[str] | None = None,) - None: Sync Insert documents with checkpoint support Args: input: 文档字符串，或者包含很多字符串的列表。用于插入的文档 split_by_character: 是否按字符（而非 token）进行切割，如果把一个 token 切开了，把 token 放进来 split_by_character_only: 只以字符切割，忽略 token ids: 文档的标识符（应该不同），不提供则用 hash 计算 file_paths: 文档的路径，只用于 citation 目的 loop = always_get_an_event_loop() loop.run_until_complete( self.ainsert( input, split_by_character, split_by_character_only, ids, file_paths ) ) 异步进行插入 .ainsert() 将处理分为两个主要阶段，真是太有异步了（ 将文档加入队列 (.apipeline_enqueue_documents()) 处理队列中的文档 (.apipeline_process_enqueue_documents()) 完整代码 其实好像没必要开一个 Heading 4 ( .ainsert() async def ainsert( self, input: str | list[str], split_by_character: str | None = None, split_by_character_only: bool = False, ids: str | list[str] | None = None, file_paths: str | list[str] | None = None,) - None: Async Insert documents with checkpoint support Args: （基本同上） input: 文档字符串，或者包含很多字符串的列表。用于插入的文档 split_by_character: 是否按字符（而非 token）进行切割，如果把一个 token 切开了，把 token 放进来 split_by_character_only: 只以字符切割，忽略 token ids: 文档的标识符（应该不同），不提供则用 hash 计算 file_paths: 文档的路径，只用于 citation 目的 await self.apipeline_enqueue_documents(input, ids, file_paths) await self.apipeline_process_enqueue_documents( split_by_character, split_by_character_only ) 对文档进行预处理 docstring 比较明晰地写明了 .apipeline_enqueue_documents() 这个函数在干什么。这里截取出代码详细解释一遍。 首先是预检查：把单个 str 放进列表方便后续统一的操作。然后检查 file_path 的数量是不是和 str 的数量对得上，毕竟file_path 的作用是引用 Pre-check if isinstance(input, str): input = [input]if isinstance(ids, str): ids = [ids]if isinstance(file_paths, str): file_paths = [file_paths]# If file_paths is provided, ensure it matches the number of documentsif file_paths is not None: if isinstance(file_paths, str): file_paths = [file_paths] if len(file_paths) != len(input): raise ValueError( Number of file paths must match the number of documents ) 检查文档的 ID。 如果提供了 ID，则 检查数量是否与文档的数量一致 检查 ID 是否重复 否则就生成 MD5 作为 ID 这个阶段还把 file_path 作为引用和文档内容打包在一起，形成 id: content: , file_path: 的 Object 格式 pack up information # 1. Validate ids if provided or generate MD5 hash IDsif ids is not None: # Check if the number of IDs matches the number of documents if len(ids) != len(input): raise ValueError(Number of IDs must match the number of documents) # Check if IDs are unique if len(ids) != len(set(ids)): raise ValueError(IDs must be unique) # Generate contents dict of IDs provided by user and documents contents = id_: content: doc, file_path: path for id_, doc, path in zip(ids, input, file_paths) else: # Clean input text and remove duplicates cleaned_input = [ (clean_text(doc), path) for doc, path in zip(input, file_paths) ] unique_content_with_paths = # Keep track of unique content and their paths for content, path in cleaned_input: if content not in unique_content_with_paths: unique_content_with_paths[content] = path # Generate contents dict of MD5 hash IDs and documents with paths contents = compute_mdhash_id(content, prefix=doc-): content: content, file_path: path, for content, path in unique_content_with_paths.items() 紧接着在输入的文档内部进行去重，意思是说，去除输入里的重复文档 Code # 2. Remove duplicate contentsunique_contents = for id_, content_data in contents.items(): content = content_data[content] file_path = content_data[file_path] if content not in unique_contents: unique_contents[content] = (id_, file_path)# Reconstruct contents with unique contentcontents = id_: content: content, file_path: file_path for content, (id_, file_path) in unique_contents.items() 为每一份文档建立一个状态，方便追踪（包括更新时间） 这里的 content_summary 并非 LLM 的总结，仅仅只是做了截取。 Code # 3. Generate document initial statusnew_docs: dict[str, Any] = id_: status: DocStatus.PENDING, content: content_data[content], content_summary: get_content_summary(content_data[content]), content_length: len(content_data[content]), created_at: datetime.now().isoformat(), updated_at: datetime.now().isoformat(), file_path: content_data[ file_path ], # Store file path in document status for id_, content_data in contents.items() def get_content_summary(content: str, max_length: int = 250) - str: Get summary of document content Args: content: Original document content max_length: Maximum length of summary Returns: Truncated content with ellipsis if needed content = content.strip() if len(content) = max_length: return content return content[:max_length] + ... 紧接着是根据已有的数据库过滤掉已经添加过的文档。 Code # 4. Filter out already processed documents# Get docs idsall_new_doc_ids = set(new_docs.keys())# Exclude IDs of documents that are already in progressunique_new_doc_ids = await self.doc_status.filter_keys(all_new_doc_ids)# Log ignored document IDsignored_ids = [ doc_id for doc_id in unique_new_doc_ids if doc_id not in new_docs]if ignored_ids: logger.warning( fIgnoring len(ignored_ids) document IDs not found in new_docs ) for doc_id in ignored_ids: logger.warning(fIgnored document ID: doc_id)# Filter new_docs to only include documents with unique IDsnew_docs = doc_id: new_docs[doc_id] for doc_id in unique_new_doc_ids if doc_id in new_docsif not new_docs: logger.info(No new unique documents were found.) return 最后把过滤出来的文档插入文档数据库终于！（笑 Code # 5. Store status documentawait self.doc_status.upsert(new_docs)logger.info(fStored len(new_docs) new unique documents) 正式处理文档 .apipeline_process_enqueue_documents() 大体的结构分成 async with 部分和 try ... finally 部分，分别对应“获取所有待处理文档”和“处理文档”的逻辑。 获取待处理文档的逻辑比较直观：获取数据库的锁之后，把数据库里的要处理的文档拿出来。但是写的比较奇怪，先不去深挖细节了（挖个坑先 Code async with pipeline_status_lock:# Ensure only one worker is processing documentsif not pipeline_status.get(busy, False): processing_docs, failed_docs, pending_docs = await asyncio.gather( self.doc_status.get_docs_by_status(DocStatus.PROCESSING), self.doc_status.get_docs_by_status(DocStatus.FAILED), self.doc_status.get_docs_by_status(DocStatus.PENDING), ) to_process_docs: dict[str, DocProcessingStatus] = to_process_docs.update(processing_docs) to_process_docs.update(failed_docs) to_process_docs.update(pending_docs) if not to_process_docs: logger.info(No documents to process) return pipeline_status.update( busy: True, job_name: Default Job, job_start: datetime.now().isoformat(), docs: 0, batchs: 0, # Total number of files to be processed cur_batch: 0, # Number of files already processed request_pending: False, # Clear any previous request latest_message: , ) # Cleaning history_messages without breaking it as a shared list object del pipeline_status[history_messages][:]else: # Another process is busy, just set request flag and return pipeline_status[request_pending] = True logger.info( Another process is already processing the document queue. Request queued. ) return 注意 以下是 LightRAG 的核心部分，针对单篇文档提取 entity 和 relation，因此忽略了其他的一些操作，例如往 chunk database 里插入 chunks，插入 full doc 等等。包括错误处理、异步同步处理等等在内的很多细节也一并选择没有展开 那么肯定要考虑多篇文档的同时处理的。项目的处理也比较容易想到，也还是用 asyncio.create_task() 后用 asyncio.gather() 并行执行 把文档和 prompt 输入大模型 这一部分由 _process_single_content() 完成。首先 patch Prompt 输入，然后调用 use_llm_func_with_cache() 获得 LLM 输出并缓存下来。 接着开始解析输出，for ... in range(entity_extract_max_gleaning) 表示如果最多尝试提取关系 entity_extract_max_gleaning 次。 注意 以下的两个步骤是针对一块 chunk 做的。也就是说，如果文档太长而被切分成很多 chunk，那么以下两个步骤也会运行多次。 那么批量处理是如何进行的呢？ 项目源码这里采用多线程的方式批量处理 chunk. 具体做法是定义了一个 semaphore，然后将所有任务都用 asyncio.create_task() 包装后，由 asyncio.wait() 统一执行并阻塞直到任务全部完成。 这里我们先忽略错误处理，先关注后面的流程。 收集完 chunk_results 后，直接用 list 的 extend() 方法合并到 all_nodes, all_edges 里面 合并 chunk # Collect all nodes and edges from all chunksall_nodes = defaultdict(list)all_edges = defaultdict(list)for maybe_nodes, maybe_edges in chunk_results: # Collect nodes for entity_name, entities in maybe_nodes.items(): all_nodes[entity_name].extend(entities) # Collect edges with sorted keys for undirected graph for edge_key, edges in maybe_edges.items(): sorted_edge_key = tuple(sorted(edge_key)) all_edges[sorted_edge_key].extend(edges) 合并完这篇文档内的 entity 和 relation 之后，就要进入 graph insert 阶段了。我们把这部分放到后面再说。 解析大模型的输出 _process_extraction_result() 是 extract_entities() 中定义的一个内部辅助函数，主要负责处理来自大语言模型 (LLM) 的提取结果，将非结构化的文本响应转换为结构化的实体和关系数据 首先将 LLM 返回的结果依照配置好的分隔符切开为 Record/Completion，每一条 Record/Completion 可能包含实体或者关系。 async def _process_extraction_result( result: str, # 从 LLM 获取的提取结果文本字符串 chunk_key: str, # 文本块的唯一标识符，用于源跟踪 file_path: str = unknown_source, # 文件路径，用于引用来源（默认为unknown_source）):# 返回一个元组 (maybe_nodes, maybe_edges)，包含提取出的实体和关系 紧接着处理每一条记录（通过正则的匹配字符串可以发现每一条 Record 都包裹在一对圆括号内），在每一条 record 的内部，再使用 tuple delimiter 分割出 Entity 与 Attribute for record in records: record = re.search(r\\((.*)\\), record) if record is None: continue record = record.group(1) record_attributes = split_string_by_multi_markers( record, [context_base[tuple_delimiter]] ) 接着分别尝试将这条 record 解析为 Entity 或者 Relation. 根据 prompt.py 里记录的 prompt，可以看到我们要求大模型输出的格式为用 tuple delimiter 分割的元组。 Format each entity as (entitytuple_delimiterentity_nametuple_delimiterentity_typetuple_delimiterentity_description) # 提取为实体if_entities = await _handle_single_entity_extraction( record_attributes, chunk_key, file_path)if if_entities is not None: maybe_nodes[if_entities[entity_name]].append(if_entities) continue # 提取为关系if_relation = await _handle_single_relationship_extraction( record_attributes, chunk_key, file_path)if if_relation is not None: maybe_edges[(if_relation[src_id], if_relation[tgt_id])].append( if_relation ) 合并实体节点和关系边 这一块就是简单地用提取的实体名称和关系名称做合并 Code # Process gleaning result separately with file pathglean_nodes, glean_edges = await _process_extraction_result( glean_result, chunk_key, file_path)# Merge results - only add entities and edges with new namesfor entity_name, entities in glean_nodes.items(): if ( entity_name not in maybe_nodes ): # Only accetp entities with new name in gleaning stage maybe_nodes[entity_name].extend(entities)for edge_key, edges in glean_edges.items(): if ( edge_key not in maybe_edges ): # Only accetp edges with new name in gleaning stage maybe_edges[edge_key].extend(edges) 为了避免 LLM 遗漏 Entity，我们再额外用 LLM 判断是否有遗漏，用 prompt.py 里的 if_loop_prompt 作为输入，直到没有遗漏了就退出循环。 最后返回从这个 chunk 提取出来的 nodes 和 edges Code if_loop_result: str = await use_llm_func_with_cache( if_loop_prompt, use_llm_func, llm_response_cache=llm_response_cache, history_messages=history, cache_type=extract,)if_loop_result = if_loop_result.strip().strip().strip().lower()if if_loop_result != yes: break 更新知识图谱 由于是异步执行，我们需要先获取锁确保数据的完整性 async with graph_db_lock: 接着是根据已有的图谱过滤掉已经添加过的点和边，这一部分比较偏工程实现，这里不做展开 根据已有知识库进行过滤 # Centralized processing of all nodes and edgesentities_data = []relationships_data = []# Use graph database lock to ensure atomic merges and updatesasync with graph_db_lock: # Process and update all entities at once for entity_name, entities in all_nodes.items(): entity_data = await _merge_nodes_then_upsert( entity_name, entities, knowledge_graph_inst, global_config, pipeline_status, pipeline_status_lock, llm_response_cache, ) entities_data.append(entity_data) # Process and update all relationships at once for edge_key, edges in all_edges.items(): edge_data = await _merge_edges_then_upsert( edge_key[0], edge_key[1], edges, knowledge_graph_inst, global_config, pipeline_status, pipeline_status_lock, llm_response_cache, ) if edge_data is not None: relationships_data.append(edge_data) 然后是更新节点数据库 更新节点数据库 # Update vector databases with all collected dataif entity_vdb is not None and entities_data: data_for_vdb = compute_mdhash_id(dp[entity_name], prefix=ent-): entity_name: dp[entity_name], entity_type: dp[entity_type], content: fdp[entity_name] dp[description], source_id: dp[source_id], file_path: dp.get(file_path, unknown_source), for dp in entities_data await entity_vdb.upsert(data_for_vdb) ……和关系数据库 更新关系数据库 if relationships_vdb is not None and relationships_data: data_for_vdb = compute_mdhash_id(dp[src_id] + dp[tgt_id], prefix=rel-): src_id: dp[src_id], tgt_id: dp[tgt_id], keywords: dp[keywords], content: fdp[src_id]\\tdp[tgt_id] dp[keywords] dp[description], source_id: dp[source_id], file_path: dp.get(file_path, unknown_source), for dp in relationships_data await relationships_vdb.upsert(data_for_vdb)"},{"title":"异步编程","path":"/async-programming/","content":"Python: asyncio 与异步编程"},{"title":"大模型实战：预训练","path":"/llm-pretrain-cookbook/","content":"Pretraining"},{"title":"llama.cpp server 端的 API","path":"/llama-cpp-server-api/","content":"llama-server 参数"},{"title":"OpenAI 流式传输与 StreamLit","path":"/openai-stream-mode-w-streamlit/","content":"流式传输 大模型的 API 通常都支持流式传输。所谓流式传输，就是指将大模型生成的文字拆分成一小块一小块发送过来，比如说每隔 555 秒就发送一次生成的文字，而不是等文字全部生成完毕才一次性全部发送。 这样做的好处在于 langchain langchain 的 ChatOpenAI 已经包装的十分完善了。"},{"title":"Python 并行库 joblib","path":"/python-joblib/","content":"joblib joblib 提供两个最核心的功能：caching 和 parallel computing. 使用 joblib.Parallel 进行并行计算 joblib.Parallel 的基础用法是通过 n_jobs 指定进程数（指定 n_jobs=-1 则表示能用多少用多少），初始化类后，用 joblib.delayed(function)(args) 指定每一个进程的工作 并行读取图片，保存为 NumPy Array import matplotlib.pyplot as plt # 读取图片from joblib import Parallel, delayed # 并行计算from rich.progress import track # 可视化进度条def read_img(path): return plt.imread(path)imgs = Parallel(n_jobs=-1)( delayed(read_img)(path) for path in track(csv[im_name], description=Loading images ... , transient=True) # transient=True 指定进度条在完成后隐藏) # parallel() 结束之后，imgs 是 List[np.ndarray]imgs = np.asarray(imgs) # 转化为 np.ndarray"},{"title":"使用 Socat 创建虚拟串口并指定名称","path":"/socat-usage/","content":"Preface 起因主要是社团……没有车的时候调试个 serial port 十分费劲，甚至根本调试不了写的对不对 所以只能用 socat 开虚拟串口模拟通讯了 socat 安装 安装比较容易，可以直接通过 apt 包管理器安装 sudo apt install socat socat 指定串口名称 指定名称时，用 link= 表示指定的串口位置，pty,raw,echo=0 表示串口的配置参数 sudo socat -d -d pty,raw,echo=0,link=/dev/ttyACM0 pty,raw,echo=0,link=/dev/ttyACM1 然后还需要给 /dev/ttyACM0, /dev/ttyACM1 这两个串口权限，方便起见，这里直接全部设为 rwx sudo chmod 777 /dev/ttyACM0sudo chmod 777 /dev/ttyACM1"},{"title":"使用 llama.cpp 在本地部署大模型","path":"/llama-cpp-locally-deploy/","content":"安装 llama.cpp 可以通过 brew 安装，一条命令行搞定，省心省力。 brew install llama.cpp"},{"title":"Python 通过 URL 获取 Embedding","path":"/python-get-embedding-through-urls/","content":"requests 需求类似于不希望内部数据上传到其他网页，于是希望在本地同时部署 Embedding Model 和 LLM. 于是，我用 llama-server 同时 serve 了 BGE-m3 和 Deepseek-R1-Distill-Llama-8B，前者作为 Embedding 模型暴露在 http://localhost:8081，后者作为 LLM 暴露在 http://localhost:8080 然后就遇到了一个小问题，怎么通过 Python 去获取 Embedding 呢？我这里的解决方案是直接用 requests 库发送请求了。好在 llama.cpp 提供的 llama-server 能够兼容 OpenAI 的 API 接口。 import requestsembedding_url = http://localhost:8081/v1/embeddings# OpenAI compatible embeddingapi_key = not_used# 因为是本地部署，所有干脆没有设置 API Keydata = input: 要嵌入的文字, model: BGE-m3, # 这里就填本地部署的模型名称headers = Authorization: fBearer api_key, content-type: application/json,result = requests.post( embedding_url, data=str(data), # 这里必须将字典以字符串的格式传入 headers=headers, # 这个 headers 其实也可以不用)embedding = result.json()[data][0][embedding]"},{"title":"Linux Mint 22.1 升级 6.11 内核和升级英伟达 560 驱动","path":"/upgrade-to-linux-kernel611-and-nvidia/","content":"升级到 Linux Kernel 6.11.0-21.21 事情的原委很简单，Update Manager 疯狂地提醒我该升级 Kernel 了，正巧想玩玩 CUDA 升级一下 nvcc，于是想顺便升级一下 nvidia-driver. 但是很快就初见端倪，升级 Kernel 提示 installed linux-image-6.11.0-21-generic package post-installation script subprocess returned error exit status 11 啊？报错了？又往前翻了翻，发现 nvidia-fs/2.22.3 autoinstall failed due to missing dependencies: nvidia OK 破案了，原来又是英伟达驱动搞的鬼，那么先处理 nvidia-drvier 吧[1] nvidia-driver-560 我现在已经在用 nvidia-driver-550 了，但是为什么会报错缺少 nvidia 呢？这里没有多想，就顺着上面的帖子，重装驱动了。 我是直接在 Driver Manager 里的 GUI 操作，但是报错安装失败。 man! 怎么个事？重启一下系统，虽然可以开机，但是默认切换到 Intel 核显了，并且 nvidia-smi 也提示无法链接 GPU. 值得一提的是，系统居然是 6.11 内核的……我还以为没安装成功呢 hhhh 那看来只能进 recovery-mode 了 Recovery Mode 进入 Recovery Mode 后，尝试用命令行删除驱动，再重新安装驱动。先移动到 network 打开网络，然后移动到 root 回车进入命令行。先删除所有英伟达的驱动 apt purge ~nnvidia 删除倒是挺简单的，然后安装驱动，我直接选择了 nvidia-driver-560-open（这个版本是英伟达官方推荐 Ubuntu 24.04 系统使用的驱动版本，而我使用的 Linux Mint 也是基于 Ubuntu 24.04 制作的） apt install nvidia-driver-560-open 回车等待结果，然而，在 Building for Linux-kernel-6.11.0-21.21-generic 的时候，却出现了报错 nvidia-dkms-560 configuration failed# 大致差不多长这样，其实就是提示你有两个组件构建失败 不过在构建失败后，也给出了一个日志文件让我们去查看，日志目录是 /var/lib/dkms/nvidia/版本号/build/make.log，我们用 vim 进行查看 cc: unrecognized command line option -ftrivial-auto-var-init=zero# 大致是这么个意思 然后又检查一下 cc -v 版本信息，发现是 11.4.0，而 nvidia-driver-560-open 是用 gcc-13 构建的 所以问题很明晰了，nvidia-driver-560-open 用 gcc-13 进行构建，但是由于编译时，可执行文件用的是 cc，而在我的机器上，我的 cc 版本为 gcc-11，所以不支持这个命令行参数（即 ftrivial-auto-var-init=zero），因此构建失败，也导致了后续一系列的问题。 好消息是，我本机已经安装过 gcc-13，因此，我先删除了 gcc-11, g++-11, gcc-11-base 等包，然后用 symlink 将 cc 直接映射为 gcc-13 ln -s /usr/bin/gcc-13 /usr/bin/cc 再次安装 nvidia-driver-560-open，成功！安装 Linux Kernel 6.11，也是成功！ 还好没有心急让电脑 remake TAT https://answers.launchpad.net/ubuntu/+question/820141 ↩︎"},{"title":"Matplotlib 快速入门指南","path":"/matplotlib-fast-tutorial/","content":"网格布局 plt.subplots() 例如，我想将 121212 张 MNIST 图片排列成 333 行 444 列的样子。 使用 fig, axes = plt.subplot() 新建图片，并划分成网格 可以搭配 axes = axes.flatten() 进一步方便处理（将二维网格拍成一维，方便循环处理） 代码 fig, axes = plt.subplot(3, 4) # 可以额外指定 fig_size 指定图片大小axes = axes.flatten()for i in range(12): axes[i].imshow(......) axes[i].set_title(......) # 每一张小图像的标题 axes[i].axis(off) 如果想要给整张图添加总标题的话，是 plt.suptitle(......) 散点图 plt.scatter()"},{"title":"conda 与 pip 配置代理服务器","path":"/conda-pip-proxy/","content":"conda 配置代理服务器 conda 配置代理服务器需要在 ~/.condarc 这个文件里配置 channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/pro/ - defaultsshow_channel_urls: truecustom_channels: conda-forge: https://mirrors.bfsu.edu.cn/anaconda/cloud msys2: https://mirrors.bfsu.edu.cn/anaconda/cloud # xxx: yyyyyyssl_verify: falseproxy_server: http: # 这里配置公司内网的 proxy server https: # 例如：http://[Account]:[Passwrod]@proxyhk.huawei.com:8080 pip 配置代理服务器 pip 需要在 ~/.pip/pip.conf 这个文件里配置。Linux 的配置文件在 ~/.pip/pip.conf，Windows 为 AnaConda: C:/Users/[Username]/pip/pip.ini MiniConda: C:/Users/[Username]/AppData/Roaming/pip/pip.ini 添加： [global]index-url = # 代理服务器地址。例如 https://mirror.tools.huawei.com/pypi/simpletrusted-host = # 主机域名。例如 mirror.tools.huawei.comtimeout = 120 uv 包管理器添加 indexing 在 uv init 初始化本地目录后，修改 pyprojects.toml 添加下面的条目 [[tool.uv.index]]url = https://mirrors.tuna.tsinghua.edu.cn/pypi/web/simple/ # 这个是清华大学的 pip 软件包源default = true"},{"title":"海康威视相机食用指北","path":"/海康威视相机食用指北/","content":"打开相机、关闭相机的流程 首先要 MV_CC_Initialize() 初始化相机 SDK 需要实现 enum_device() 找到相机设备 通过 MV_CC_CreateHandle() 创建 handle MV_CC_OpenDevice() 打开相机"},{"title":"Python LangChain 将图像当作 URL 传递","path":"/raw-image-pass-as-url/","content":"Pass Image as if URL 一个小 trick 可以将本地图片 encode 成 byte string 之后，放在 URL 栏里传递给多模态大模型。 import base64with open(path/to/image.png, rb) as image_file: b64_image = base64.b64encode(image_file.read()).decode(utf-8)def encode(path): with open(path, rb) as image_file: code = base64.b64encode(image_file.read()).decode(utf-8) return fdata:image;base64,code 然后就可以正常放在 URL 栏里了。"},{"title":"使用 Python 和 Flask 库快速构建网页后端","path":"/python-flask-framework/","content":"启动一个后端 导入库后，用 app = Flask(__name__) 初始化一个 App。 一个 function 对应一个子网页的服务，用 @app.route() 指明，最后 app.run() 启动后端。 一个后端子网页 @app.route(/upload, methods=[POST])def upload(): # ...... 启动后端 if __name__ == __main__: app.run(debug=True, host=0.0.0.0, port=5000) 当 host 为 0.0.0.0 的话，Flask 会多设置一个 IP 地址，供本机的其他程序访问后端。"},{"title":"Django 快速开始","path":"/django-kickstart/","content":"Django 组织结构 Django 大体架构是一个 Project 管理若干个小 Application，每一个 Application 负责一个功能，跟 Application 平行的还有一个用于部署网站的 Config Folder（默认和 Project 同名）. UH├── CedarsCenter│ ├── admin.py│ ├── apps.py│ ├── __init__.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py├── manage.py├── StudentCenter│ ├── admin.py│ ├── apps.py│ ├── __init__.py│ ├── migrations│ │ └── __init__.py│ ├── models.py│ ├── tests.py│ └── views.py└── UH ├── asgi.py ├── __init__.py ├── __pycache__ │ ├── __init__.cpython-311.pyc │ └── settings.cpython-311.pyc ├── settings.py ├── urls.py └── wsgi.py 管理某一个 Project 的时候，通过 manage.py 运行相应的指令。例如在当前 Project 下新增一个 Application poll，则运行 python manage.py startapp poll Django 中 Model 的作用 Model 的作用只是用来查询数据用的"},{"title":"Python 使用 C/C++ 接口","path":"/python-c-integration/","content":"Python 调用 C/C++ 代码 如何编写 C/C++ 代码？ 首先导入 Python.h 头文件，包含了必要的结构体、方法。（需要通过 sudo apt install python3-dev 提前安装好） #define PY_SSIZE_T_CLEAN#include python3.12/Python.h // 我这里需要额外指定一下路径 编译为动态库 g++ -fPIC [file_name] -shared -o [module_name].so 在 Python 里使用 直接通过这个 Module 的名字导入 import [module_name]# ......"},{"title":"MinerU Examples","path":"/MinerU-examples/","content":"uv 包管理器安装 MinerU 先用 uv 安装 setuptools wheel torch uv pip install setuptools wheel torch 然后再安装 detectron2 uv pip install --no-build-isolation git+https://github.com/facebookresearch/detectron2.git 最后安装 magic-pdf[full] uv pip install magic-pdf[full] --extra-index-url https://wheels.myhloli.com --prerelease=allow 最后检查 magic-pdf 的版本 =0.7.0，而不是 0.6.1 如果像使用 GPU 进行 PaddlePaddle OCR 的推理，继续安装 paddlepaddle-gpu uv pip install paddlepaddle-gpu MinerU Command Line MinerU API 使用指南 MinerU 的使用流程基本上是 将 PDF 加载为 magic_pdf.data.dataset.Dataset 执行 OCR 和 Layout Inference 这里还想更详细地记录一下 API，感觉 Documentation 里写的不是很全，得从 demo.py 里找。"},{"title":"image-text-database","path":"/image-text-database/","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"multi-thread","path":"/multi-thread/","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"Linux 下用 HKU 账号使用 HK eduroam WiFi","path":"/connect-to-eduroam-hku/","content":"eduroam 我是 Linux Mint 系统，所以 Ubuntu/Mint 应该比较通用。 Option Value Security WPA WPA2 Enterprise Authentication Protected EAP (PEAP) Anonymous Identity 留空 Domain hku.hk CA Certificate 选 (None)，勾选 No CA Certificate is required PEAP version Automatic Inner Authentication MSCHAPv2 Username UID@hku.hk，UID 是邮箱 @ 前的部分，这里后缀必须是 @hku.hk Password Portal 的登录密码"},{"title":"Docker Introduction","path":"/docker-intro/","content":"Dockerfile Docker Image 编写完 Dockerfile 后，我们可以用命令创建一个 docker 镜像 docker build -t [镜像名称] [Dockerfile 所在目录] 启动 container 还需要一个 container 才能运行起来 docker run -p [映射到主机的哪个端口]:[容器内的哪个端口] -d [镜像名称] -p：指定端口 -d：后台运行。想要查看终端输出的话需要到 docker desktop 里查看 用 Volume 保存 container 的数据 利用 -v 参数，把本地文件夹 ~/A 挂载到 container 里的 .../B，这样在 container 里读写 .../B 其实等于读写 ~/A. 我们先创建一个数据卷 docker volume create [数据卷位置] 然后在 docker run 的时候进行挂载 docker run -v [数据卷在本地的位置]:[数据卷在容器里的位置] -d [镜像名称] Docker Compose 多个容器共同协作：例如数据库和前端分离。 在 docker-compose.yml 里用 services 进行定义 # docker-compose.ymlservices: # 定义前端和数据库 front-end: # 前端 build: . # 镜像——从文件夹构建 ports: # 端口映射 - 80:5000 database: # 数据库 image: mysql # 镜像——从其他地方拉取 environment: # 可以定义环境变量 OPENAI_API_KEY: ... OPENAI_API_BASE: volumes: # 数据卷，等同于 -v 参数 - ~/A:.../B 定义完毕后，使用 docker compose up -d 来运行所有的 container docker compose down 来停止并删除所有的 container"},{"title":"本地部署 llama.cpp 大模型服务器并连接","path":"/local-deploy/","content":"llama.cpp 的安装、编译 alternative: llama-cpp-python 提供了 llama.cpp 的 Python 接口。通过 llama-cpp-python 也可以启动一个 LLM Server 启动一个 LLM server 直接在命令行里输入启动服务器 llama-server -m [模型路径] --port 8080 模型要保证必须是 .gguf 格式，可以使用 llama.cpp 项目根目录下的 convert_hf_to_gguf.py 进行转换。 convert_hf_to_gguf 食用方法 配置好虚拟环境后，命令行里输入 python convert_hf_to_gguf.py [模型.bin文件所在的目录] 这个目录末尾应该是哈希码，例如 ~/.cache/huggingface/hub/models--deepseek-ai--DeepSeek-R1-Distill-Qwen-1.5B/snapshots/ad9f0ae0864d7fbcd1cd905e3c6c5b069cc8b562 连接 如果用 LangChain 进行连接，必须注意要输入 http://localhost:8080 的 http://（被坑了）"},{"title":"About Me","path":"/about/index.html","content":"About Me 挖坑，基本不会填坑（嗯…… 开发计划 开发 Wallpaper engine on Linux 嗯，现在啥都不会（ 开发 RM Simulator 希望是能够自带物理建模和模拟、参数调整、数据统计、与本机程序交互等等功能 但是现在啥都不会（ Archive.yazi (compress and extract) yazi.rs 插件，用按键解压、打包 学习计划 Stanford CS336 (0/inf) Princeton 强化学习背后的数学 不是很紧急 CUDA 编程 顺带也想学 Triton/TensorRT/OpenVINO 这类的 T.T 编写一个 LLM 倒是有抄过一遍代码，但是还是有点懵 以及 VLM 和 VLA（然而甚至都没试过 课程学习！ 数学方面的话，线性代数、数学分析……感觉学得不是很深入 然后 OS, 计算机网络 感觉也需要回顾一下…… 金融课程！感觉尤其是量化金融方面的 日语！ 长期目标，偷偷润日本自驾游（ 当下需要干的事 RAG 针对 PPT 做出改进 有点紧急，还是想在实习期间搞点成果的，但确实是不会，也没有头绪不太熟练 编写 LIBERO 的数据集 科研实习……如果能搞出 task 流水线就好了……"},{"title":"friends","path":"/friends/index.html","content":"Friends XXZ’s blog"},{"title":"OpenVLA 代码解析 (1)","path":"/wiki/agentai/OpenVLA-code-p1.html","content":"5d4944576327e6e1f59f35f07afdbc7917ffe61195e5ff6f7af12e15300ba733 Password is needed."},{"title":"OpenVLA-dataproc-pipeline","path":"/wiki/agentai/OpenVLA-dataproc-pipeline.html","content":"OpenVLA 数据处理过程 normalization diff embodyment 在环境下评测 model, performance, accuracy"},{"title":"OpenVLA 论文","path":"/wiki/agentai/OpenVLA.html","content":"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 Password is needed."},{"title":"Google Gemini Robotics","path":"/wiki/agentai/google-gemini-robotics.html","content":"AI Summary Background • Core Problem: The paper addresses the challenge of bridging the gap between state‐of‐the‐art multimodal AI models and practical robotics. Although digital AI models have achieved impressive capabilities in processing text, images, and other modalities, these models traditionally lack the embodied reasoning (i.e., the ability to understand and physically interact with the real world) required for autonomous robot control. • Current Limitations and Challenges: Existing vision–language models excel at perception and symbolic tasks, yet they fall short when it comes to physical grounding. The authors point out that current research struggles with robust spatial understanding, dexterous manipulation, safe human–robot interactions, and adapting to novel object configurations and environments. Moreover, there is an absence of standardized benchmarks that cover the nuanced set of reasoning skills needed for embodied tasks. • Real-world Needs and Theoretical Gaps: The paper underscores the necessity for general-purpose robots capable of smooth, safe, and reactive movements. There is a critical need to extend digital reasoning to handle real-world cues such as 3D geometry, object affordances, and trajectory planning. The authors identify a theoretical gap in unifying multimodal understanding (visual and language) with physical action planning. Motivation • Driving Factors Behind the New Method: The motivation comes from the desire to leverage the advanced multimodal reasoning of models like Gemini 2.0 and extend these capabilities to control physical robots. The authors aim to overcome the limitations of existing systems which are typically confined to digital domains by integrating a comprehensive embodied reasoning framework into robotics. • Shortcomings of Existing Approaches: Current practices often suffer from poor generalization when faced with unseen object types, variable settings, and complex manipulation tasks. Many existing methods lack the ability to plan sequential actions under safety constraints and cannot efficiently adapt to new robot embodiments or environments. Issues such as limited computational efficiency in planning and a narrow focus on perception without actionable outputs further drive the need for an improved, unified approach. Methodology • Core Innovation: The paper introduces the Gemini Robotics family of models––a suite of vision–language–action (VLA) systems that fuse the powerful multimodal understanding of Gemini 2.0 with a dedicated robotics layer. Two principal variants are proposed: Gemini Robotics-ER (Embodied Reasoning): Enhances the base model’s spatial and temporal reasoning to perform tasks such as object detection, 2D pointing, trajectory prediction, and top-down grasp estimation. Gemini Robotics: Extends these capabilities by incorporating robot action data to achieve high-frequency, dexterous control over physical robots. • Technical Steps and Key Components: Multimodal Input Fusion: Integrates visual inputs (images) and textual instructions, using open‐vocabulary queries to detect and localize objects in both 2D and 3D (e.g., 3D bounding boxes and multi-view correspondence). Embodied Reasoning Pipeline: Employs a chain-of-thought (CoT) prompting technique, which encourages the model to generate intermediate reasoning steps, thereby ensuring precise spatial grounding and sequential planning. (Chain-of-thought prompting is a method where the model is instructed to “think out loud” through intermediate steps before giving the final answer.) Robot Control Integration: A dedicated pipeline converts high-level planning into low-level actuation commands via a robot API, managing safe and reactive motions while adhering to physical constraints. Specialization and Adaptation: An optional fine-tuning stage enables the system to adapt to long-horizon tasks, enhance dexterity (e.g., folding or playing cards), and adjust to variations in robot embodiments such as bi-arm platforms or humanoids. • Fundamental Differences from Baseline Approaches: Unlike conventional methods that may treat perception and control as separate tasks, the Gemini Robotics models offer an end-to-end, integrated solution. By combining embodied reasoning with action data, these models generalize better to novel tasks, improve adaptation with few demonstrations, and facilitate safe control in dynamic environments. Experiments Results • Experimental Setup: The models are evaluated on several benchmarks including the newly introduced Embodied Reasoning Question Answering (ERQA) benchmark, RealworldQA, and BLINK. The experimental design encompasses tasks ranging from simple object detection to complex, dexterous manipulation tasks in both simulated and real-world scenarios. Datasets include images sourced from in-house collections and publicly available datasets like OXE, UMI Data, and MECCANO. Baseline comparisons are made against existing vision–language and diffusion-based robotics models, using performance metrics such as accuracy, success rate, and continuous progress scores. • Key Findings: Gemini 2.0 variants (Flash and Pro Experimental) achieve state-of-the-art performance across multiple benchmark evaluations, often with notable improvements when chain-of-thought prompting is used. Quantitative results show improvements in tasks like 2D pointing accuracy (measured by how well predicted points fall within ground-truth regions) and successful grasp predictions in real-world robot control. In dexterous tasks such as folding an origami fox or playing a card game, Gemini Robotics outperforms baseline models in both binary success metrics and nuanced progress scores. • Ablation and Sensitivity Analyses: The paper reports ablation studies that highlight the benefits of each component—from embodied reasoning enhancements to fine-tuning stages. Sensitivity analyses reveal that prompts such as chain-of-thought can significantly affect overall performance, and that the integrated approach provides robust improvements even under distribution shifts (e.g., novel visual variations or rephrased instructions). Effectiveness Analysis • Underlying Reasons for Success: The method’s effectiveness stems from its dual focus on robust multimodal understanding and practical action integration. By augmenting a strong foundation model with specialized embodied reasoning and robot-specific training, the system manages to bridge the digital–physical divide. In particular, the use of multi-view spatial understanding and sequential reasoning ensures continuity between perception and physical manipulation. • Critical Success Factors: Model Architecture and Training: Leveraging Gemini 2.0’s large-scale, pre-trained capabilities provides a strong foundation for embodied reasoning. Effective Data Fusion: Integrating diverse data types—including images, text, and robot sensor readings—improves generalization and adaptability. Prompting Strategies: Techniques like chain-of-thought prompting contribute to clear intermediate reasoning, enhancing the decision-making process. Safety and Adaptability Protocols: The incorporation of robot API interfaces and safety guidelines enables smooth interaction in regulated physical environments. • Potential Limitations and Applicability Boundaries: While the proposed models demonstrate impressive performance, their success is tightly coupled with the quality and diversity of training data. The system may face constraints when encountering drastically different physical environments or unanticipated object configurations. Furthermore, the reliance on comprehensive safety protocols suggests that additional work is required to ensure deployment in less structured or more variable real-world settings. Contributions • Theoretical Contributions: The paper provides a unified framework that connects high-level multimodal reasoning directly with low-level robot control. It introduces new benchmark tasks (e.g., ERQA) to evaluate embodied reasoning, setting a new standard for measuring the full spectrum of capabilities required for physical interaction. • Practical Contributions: The development of the Gemini Robotics family offers an end-to-end solution for controlling robots with diverse manipulation tasks, from dexterous object handling to adaptive task execution. Detailed model cards and open-source evaluation protocols are provided, facilitating reproducibility and further research in embodied AI. The work also contributes guidelines and best practices for ensuring safety and responsible development in robotics applications. • Implications for Future Research: This research marks a significant step toward general-purpose embodied AI. Future work can build on these findings to further enhance generalization, reduce reliance on extensive fine-tuning, and tackle more complex physical interactions. The integration of multimodal reasoning with action control paves the way for robots that can adapt to diverse, unstructured real-world environments while ensuring safe and reliable operation."},{"title":"内核性能分析工具","path":"/wiki/ai-infra/performance-analysis-tools.html","content":"内核优化的常见步骤 分析 Kernel 的执行时间 统计、查看各个 Kernel 的执行时间 定位性能瓶颈，确定需要优化的 Kernel 检查 GPU 的利用率等信息 例如检查是否占用过多的寄存器 （更细粒度）确定 Kernel 的性能瓶颈 优化 Kernel 性能 通过各种技术手段（软硬件、调度、内存优化）优化 Kernel PyTorch 内置 torch.profiler TensorBoard Holistic Trace Analysis NVIDIA Nsight 工具 Nsight System Nsight Compute Triton Proton"},{"title":"Pi 0, A Vision-Language-Action Flow Model for General Robot Control","path":"/wiki/agentai/pi-zero.html","content":"AI Summary Background The paper addresses the challenge of developing a unified robot foundation model that can handle a wide range of dexterous tasks across different robot platforms. Current robot learning approaches often suffer from limited generalization, data scarcity, and brittle performance when adapting to complex practical scenarios. Existing methods typically focus on narrow tasks or use discretized models that struggle with continuous, high-frequency control. The authors identify a real-world need for models that can integrate rich semantic understanding (gained from large-scale vision-language pre-training) with fine-grained physical control to perform intricate multi-stage tasks such as laundry folding or box assembly. Motivation The direct drive behind this work is the gap between the robust, versatile behavior seen in large language and vision-language models and the limitations of current robot control systems. Existing approaches fail to meet the demands of real-world robotic manipulation due to: Limited Generalization: Models are often trained on task-specific data and do not transfer well to diverse environments or novel tasks. Discrete Outputs: Many prior methods rely on autoregressive and token-based approaches, which are not well-suited for high-frequency continuous control. Data and Recovery Challenges: Training solely on curated, high-quality data results in brittle systems that cannot efficiently recover from errors or unexpected perturbations. This motivates the integration of internet-scale semantic pre-training with a continuous action generation method, thereby combining robust, flexible understanding with high-precision control. Methodology The core innovation is the design of a vision-language-action model (π0) that unifies pre-trained semantic knowledge with a novel mechanism for continuous action prediction. Key elements include: Pre-trained VLM Backbone: The model starts with a vision-language model (VLM) pre-trained on vast internet data (e.g., PaliGemma). This allows the system to inherit rich semantic representations and language understanding. Brief explanation: A VLM (Vision-Language Model) is trained on image-text pairs to extract visual and linguistic features simultaneously. Action Expert with Flow Matching: A separate module—termed the action expert—is added to predict continuous action sequences. Instead of relying on discrete token outputs, it uses conditional flow matching. Brief explanation: Flow matching is a variant of diffusion methods where a denoising vector field is learned to progressively transform noise into data, enabling precise continuous outputs. The model predicts action chunks (e.g., 50 future steps) at once, accommodating high-frequency control (up to 50 Hz). The design employs multi-stage training where the model is first exposed to diverse, lower-quality pre-training data and later fine-tuned on high-quality, task-specific data. Architectural Separation: The transformer backbone routes standard inputs (images and language) through the pre-trained VLM segment, while robot-specific proprioceptive inputs and continuous actions are handled by an additional expert. This mixture of experts approach allows leveraging pre-existing knowledge while adapting to robotics-specific demands. Two-Phase Training Recipe: Emphasizing the importance of both data diversity and quality, the training is split into a large-scale pre-training phase (covering 10,000 hours of data across 68 tasks and 7 robot configurations) and a post-training phase that refines the model for complex downstream tasks. Experiments Results The authors evaluate their model on a wide range of dexterous manipulation tasks spanning different robots and complexities: Experimental Setup: Tasks include shirt folding, table bussing (easy and hard versions), grocery bagging, removing toast from a toaster, laundry folding, box assembly, packing eggs, and more. Diverse robot configurations such as single-arm, dual-arm, and mobile manipulators are used to test cross-embodiment performance. Evaluation metrics involve task-specific score rubrics that measure progress and success (e.g., percentage of task completion or discrete scores per subtasks). Key Findings: The full π0 model, trained with both pre-training and fine-tuning, outperforms baseline approaches like OpenVLA and smaller models (π0-small) on both direct prompting (out-of-box performance) and after fine-tuning. Ablation studies show that incorporating continuous action generation via flow matching results in significant improvements in dexterity and robustness. The approach demonstrates the capability to perform complex, multi-stage tasks that were previously challenging or unsolvable using traditional methods. Effectiveness Analysis The method works due to several critical factors: Integration of Semantic and Physical Knowledge: The use of a pre-trained VLM imparts broad semantic understanding, enabling the model to interpret language commands effectively. This, when combined with flow matching, allows the system to translate high-level instructions into accurate continuous motions. Flow Matching for Continuous Control: By modeling the entire distribution of actions as a continuous process, the approach ensures high precision and the ability to recover from errors—a necessity in real-world dexterous tasks. Robust Training Recipe: The dual-phase training method (diverse pre-training followed by targeted fine-tuning) allows the model to learn both general competencies and task-specialized behaviors while mitigating issues of overfitting and brittleness. Critical Success Factors: The modular architecture separating vision-language and robotics-specific pathways facilitates efficient processing and speed. The ability to predict action chunks supports high-frequency control, crucial for tasks that require fine motor skills. Potential limitations include the reliance on massive amounts of pre-training data and the current lack of comprehensive understanding about optimal data composition. Moreover, while promising for robot manipulation, it remains to be seen how well the approach transfers to other domains such as autonomous driving or legged locomotion. Contributions The paper makes several novel contributions: Theoretical Contributions: It introduces a novel integration of a pre-trained vision-language model with flow matching to generate continuous action distributions—bridging the gap between discrete output methods and the requirements of dexterous robot control. The work advances our conceptual understanding of how multi-modal pre-training can be leveraged to build versatile and general-purpose robot foundation models. Practical Contributions: The π0 model is demonstrated across multiple robot embodiments and a wide array of tasks, showcasing its practicality and robustness in real-world settings. The proposed multi-stage training recipe—including cross-embodiment data integration and action chunking—sets a new benchmark for large-scale robot learning experiments (using approximately 10,000 hours of diverse data). The empirical results establish a state-of-the-art performance in complex, temporally extended tasks such as laundry folding and box assembly. Implications for Future Research: This work lays the groundwork for future exploration of universal robot foundation models that might extend beyond manipulation to domains like navigation and legged locomotion. The proposed framework encourages further studies on optimal data weighting, integration techniques, and extending these methods to even broader real-world scenarios. Background Large Scale Right Model Architecture Right Trainging Recipe"},{"title":"Triton Introduction","path":"/wiki/ai-infra/triton-intro.html","content":"PyTorch 关键组件 TorchDynamo 将所有复杂算子简化到 PrimTorch 中的 250 个算子 移除未使用的算子 确实需要存储、写入内存的中间算子，以及可融合的算子，从而减少开销 PrimTorch 定义了两个算子集合：Aten ops 和 Prim ops 将 PyTorch 程序的各种计算用这些算子集里的算子表示 简化后端需要编写的算子数量 AOTAutograd 提前获取反向传播 基于完整的 forward/backward 根据算子的依赖关系进行算子调度，对算子和层进行融合 TorchInductor 进行算子融合 自动生成低级 GPU 上的 Triton 代码（或者 CPU 上的 C++/OpenMP） 编译流程 我们用下面的例子介绍一下大致的编译流程，在运行时加入调试参数 TORCH_LOGS=... python example.py 查看中间的日志输出 import torch@torch.compiledef toy_example(x: torch.Tensor) - torch.Tensor: y = x.sin() z = y.cos() return zif __name__ == __main__: x = torch.randn(1000, device=cuda, requires_grad=True) # 开启反向传播 Step 1. TorchDynamo 运行 TORCH_LOGS=dynamo uv run example.py，我们先来看第一步 TorchDynamo 的输出。 日志输出 [torch/_dynamo/symbolic_convert.py:2706] [0/0] Step 1: torchdynamo start tracing toy_example [很长的路径]/example.py:5[torch/_dynamo/symbolic_convert.py:3028] [0/0] Step 1: torchdynamo done tracing toy_example[torch/_dynamo/output_graph.py:1458] [0/0] Step 2: calling compiler function inductor[torch/_dynamo/output_graph.py:1463] [0/0] Step 2: done compiler function inductor[torch/fx/experimental/symbolic_shapes.py:4547] [0/0] produce_guards[torch/_dynamo/pgo.py:636] [0/0] put_code_state: no cache key, skipping[torch/_dynamo/eval_frame.py:398] TorchDynamo attempted to trace the following frames [ toy_example [很长的路径]/example.py:5 ][torch/_dynamo/utils.py:446] TorchDynamo compilation metrics: Function Runtimes (s) ------------------------------------ -------------- _compile.compile_inner 0.5482 OutputGraph.call_user_compiler 0.4845 _recursive_pre_grad_passes 0.0018 create_aot_dispatcher_function 0.4817 _recursive_joint_graph_passes 0.0684 compile_fx.locals.fw_compiler_base 0.3442 compile_fx_inner 0.3437 inductor_codecache_torch_key 0.0523 TritonBundler.read_and_emit 0.0002 PyCodeCache.load_by_key_path 0.0122 async_compile.precompile 0.007 async_compile.wait 0.0001 从日志中可以看到，TorchDynamo 的框架流程就是 对要编译的模型进行追踪，然后编译并生成中间表示 (FX Graph IR) 调用 compiler.inductor 对模型进行化简 1.1 Dynamo 图捕获 Dynamo 首先进行图捕获。这里，__graph_code 将原始代码的 Dataflow 进行捕获，并输出捕获的 DAG，即 FX Graph IR. FX Graph IR # [torch/fx/passes/runtime_assert.py:118] [0/0] [__graph_code] def forward(self, L_x_: f32[1000]): l_x_ = L_x_ # File: example.py:7 in toy_example, code: y = x.sin() y: f32[1000] = l_x_.sin(); l_x_ = None # File: example.py:8 in toy_example, code: z = y.cos() z: f32[1000] = y.cos(); y = None return (z,)[torch/_dynamo/output_graph.py:1353] [0/0] [__graph_code] def forward(self, L_x_: f32[1000][1]cuda:0): l_x_ = L_x_ # File: example.py:7 in toy_example, code: y = x.sin() y: f32[1000][1]cuda:0 = l_x_.sin(); l_x_ = None # File: example.py:8 in toy_example, code: z = y.cos() z: f32[1000][1]cuda:0 = y.cos(); y = None return (z,) 1.2 AOTAutograd Dynamo 的 AOTAutograd 阶段 生成正向传播图和反向传播图（也是表示为 FX Graph IR 的形式） 会将 FX Graph IR 中的算子替换为 ATen 算子库里的算子 基于完整的正向、反向传播图的视角，根据依赖关系，进行算子调度、对算子和层进行融合 将复杂的算子根据字典进一步分解为更底层的 Core ATen IR 算子或者 Prim IR 算子 AOTAutograd IR 生成的正向图与反向图 # 这个是正向图# ===== Forward graph 0 =====# torch/fx/_lazy_graph_module.py class GraphModule(torch.nn.Module): def forward(self, primals_1: f32[1000][1]cuda:0): ## File: example.py:7 in toy_example, code: y = x.sin() sin: f32[1000][1]cuda:0 = torch.ops.aten.sin.default(primals_1) ## File: example.py:8 in toy_example, code: z = y.cos() cos: f32[1000][1]cuda:0 = torch.ops.aten.cos.default(sin); sin = None return (cos, primals_1)# 这个是反向图# [torch/_functorch/_aot_autograd/jit_compile_runtime_wrappers.py:603]# [0/0] [__aot_graphs]# # TRACED GRAPH# ===== Backward graph 0 =====eval_with_key.1 class GraphModule(torch.nn.Module): def forward(self, primals_1: f32[1000][1]cuda:0, tangents_1: f32[1000][1]cuda:0): # File: example.py:7 in toy_example, code: y = x.sin() sin: f32[1000][1]cuda:0 = torch.ops.aten.sin.default(primals_1) # File: example.py:8 in toy_example, code: z = y.cos() sin_1: f32[1000][1]cuda:0 = torch.ops.aten.sin.default(sin); sin = None neg: f32[1000][1]cuda:0 = torch.ops.aten.neg.default(sin_1); sin_1 = None mul: f32[1000][1]cuda:0 = torch.ops.aten.mul.Tensor(tangents_1, neg); tangents_1 = neg = None # File: example.py:7 in toy_example, code: y = x.sin() cos_1: f32[1000][1]cuda:0 = torch.ops.aten.cos.default(primals_1); primals_1 = None mul_1: f32[1000][1]cuda:0 = torch.ops.aten.mul.Tensor(mul, cos_1); mul = cos_1 = None return (mul_1,) 2. Inductor Triton 的核心： compile() model fullgraph dynamic"},{"title":"RMSNorm","path":"/wiki/aitactics/RMSNorm.html","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"LayerNorm","path":"/wiki/aitactics/layernorm.html","content":"LayerNorm 假设是在 CNN 的语境下，我们对一个 N×H×W×CN\\times H\\times W\\times CN×H×W×C 的 tensor 做 LayerNorm。 LayerNorm 做的事实际上是对于每一个 H×W×CH\\times W\\times CH×W×C 做 Normalization."},{"title":"2023 ICPC World Final Luxor","path":"/wiki/algo_contests/2023-icpc-wf-luxor.html","content":"A. D. Carl’s Vacation 可以联想到将军饮马模型。我们把三维的金字塔侧面展平到二维上，那么答案的最短路径就可以表达为 tip1→foot1→foot2→top2 tip_1\\to foot_1\\to foot_2\\to top_2 tip1​→foot1​→foot2​→top2​于是，我们可以枚举每个金字塔的四个侧面，共 4×4=164\\times 4=164×4=16 种情况，在每种情况里求最短路径即可。 接下来考虑如何求这个最短路径。我们肯定需要找到两个 footfootfoot 的坐标。考虑用向量的模长表示线段长度，以及将两个 footfootfoot 的定比分点作为变量的话，那么路径长度 f(k1,k2)f(k_1,k_2)f(k1​,k2​) 分别关于 k1,k2k_1,k_2k1​,k2​ 是单峰函数，所以可以三分套三分。 小细节：浮点数三分或者二分的话，可以指定二分次数，而非 l,rl,rl,r 相差 eps\\texttt{eps}eps，后者容易出现浮点误差。 Code #include headers/geometry.hpp#include iostreamusing namespace Geo2D;using namespace std;Point p1[4], p2[4], tip1, tip2;Decimal h1, h2, d1, d2, len1, len2;Decimal phi = 0.618, cphi = -phi + 1;int main() cin p1[0] p1[1] h1; cin p2[0] p2[1] h2; for (int i = 2; i 4; i++) p1[i] = p1[i - 1] + (p1[i - 1] - p1[i - 2]).Perp(); p2[i] = p2[i - 1] + (p2[i - 1] - p2[i - 2]).Perp(); tip1 = (p1[0] + p1[2]) / 2; tip2 = (p2[0] + p2[2]) / 2; len1 = p1[0].Distance(p1[1]); len2 = p2[0].Distance(p2[1]); d1 = (len1.sqr() / 4 + h1.sqr()).sqrt(); d2 = (len2.sqr() / 4 + h2.sqr()).sqrt(); Decimal ans = 2e18; for (int i = 0; i 4; i++) Vector v1 = p1[(i + 1) % 4] - p1[i]; Point midp1 = (p1[i] + p1[(i + 1) % 4]) / 2; Point pt1 = midp1 + v1.Normal() * d1; for (int j = 0; j 4; j++) Vector v2 = p2[(j + 1) % 4] - p2[j]; Point midp2 = (p2[j] + p2[(j + 1) % 4]) / 2; Point pt2 = midp2 + v2.Normal() * d2; Decimal precent_l1 = 0; Decimal precent_r1 = 1; auto findfoot1 = [](Decimal precent_mid1) - Decimal Point foot1 = p1[i] + v1 * precent_mid1; Decimal precent_l2 = 0; Decimal precent_r2 = 1; auto findfoot2 = [](Decimal precent_mid2) - Decimal Point foot2 = p2[j] + v2 * precent_mid2; return foot1.Distance(foot2) + foot1.Distance(pt1) + foot2.Distance(pt2); ; for (int __ = 1; __ = 100; __++) Decimal l2 = precent_l2 * phi + precent_r2 * cphi; Decimal r2 = precent_l2 * cphi + precent_r2 * phi; if (findfoot2(l2) findfoot2(r2)) precent_l2 = l2; else precent_r2 = r2; return findfoot2(precent_l2); ; for (int _ = 1; _ = 100; _++) Decimal l1 = precent_l1 * phi + precent_r1 * cphi; Decimal r1 = precent_l1 * cphi + precent_r1 * phi; if (findfoot1(l1) findfoot1(r1)) precent_l1 = l1; else precent_r1 = r1; ans = min(ans, findfoot1(precent_l1)); std::cout ans ;"},{"title":"2024 ICPC EC 第二场网络预选赛","path":"/wiki/algo_contests/2024-icpc-ec-online-2.html","content":"这一场其实是队友带飞的，但是还是来补一下题。 A. Gambling on Choosing Regionals 最核心的点就是，对于某只队伍 tit_iti​ 最坏情况下其他学校都派最强的队伍来和这支队伍竞争，那么可想而知，如果学校越多，那么很有可能其他学校的强队全都来了，那么自己的机会就越来越小了，所以核心的点就是一定选择最小的赛站。 因为 tit_iti​ 总是有优先权，因此对于 tit_iti​ 来说，在他之上的队伍由两部分组成（假设最小的赛站，每个学校可以出 ccc 支队伍） 其他学校的所有强队，数量 ≤c\\le c≤c 本学校的强队，数量 ≤c−1\\le c-1≤c−1。因为包含 tit_iti​ 因此，我们直接对每只队伍的实力排序，先每个学校取前 ccc 个，然后如果某个队伍不在其学校的前 ccc 名，那么踢掉最后一名，把这支队伍换上来。总时间复杂度 O(nlog⁡n)O(n\\log n)O(nlogn). G. Game 首先我们要看出来平局其实没有用（因为不会产生任何影响）。我们直接令 p1=a0a0+a1,p2=a1a0+a1p_1=\\frac{a_0}{a_0+a_1},p_2=\\frac{a_1}{a_0+a_1}p1​=a0​+a1​a0​​,p2​=a0​+a1​a1​​. 然后分别考虑两人的筹码数和获胜条件，设 Alice 有 aaa 个筹码，Bob 有 bbb 个 如果 a=ba=ba=b，令 a=kb+r,r∈[0,b)a=kb+r,r\\in[0,b)a=kb+r,r∈[0,b) 此时，Alice 只要在这 kkk 次里赢一次，游戏就结束了。 这里的分布是“有 p1p_1p1​ 概率获胜， continue until first win”，其获胜概率为 ∑i=0kp1p2i=1−p2k1−p2×p1\\sum_{i=0}^k p_1 p_2^i=\\frac{1-p_2^k}{1-p_2}\\times p_1∑i=0k​p1​p2i​=1−p2​1−p2k​​×p1​ 然而，如果全输了，那么 rbr\\lt brb 会进入 2) 分支。综合一下，即为 win(a,b)=1−p2k1−p2p1+p2k×win(r,b)win(a,b)=\\frac{1-p_2^k}{1-p_2}p_1+p_2^k\\times win(r, b)win(a,b)=1−p2​1−p2k​​p1​+p2k​×win(r,b) 如果 ababab，令 b=ka+r,r∈[0,a)b=ka+r,r\\in[0, a)b=ka+r,r∈[0,a) 此时局面刚好反过来，Alice 要想获胜，必须保证这 kkk 次不能输（否则游戏结束） 当这 kkk 全赢了之后，局面回到 1)。因此 win(a,b)=p1k×win(a,r)win(a,b)=p_1^k\\times win(a, r)win(a,b)=p1k​×win(a,r) 而回顾 win(x,y)win(x,y)win(x,y) 的参数变化，这不就是辗转相除法吗！因此整体时间复杂度为 O(log⁡n)O(\\log n)O(logn)，考虑到逆元、快速幂的计算（p1,p2,kp_1,p_2,kp1​,p2​,k 与 nnn 差不多量级），其实差不多是 O(log⁡2n)O(\\log^2n)O(log2n) Code 注意最好用 int 做逆元相关的题，速度会比 uint64_t 之类的快很多。 #include iostreamconstexpr int M = 998244353;inline int smul(int a, int b) return (1ll * a * b M ? a * b : 1ll * a * b % M); inline int sadd(int a, int b) return (a + b = M ? a + b - M : a + b); int fpow(int base, int power = M - 2) int res = 1; for (; power; power = 1) if (power 1) res = smul(res, base); base = smul(base, base); return res;int answer(int a, int b, int win, int lose) if (a == 0 || b == 0) return a != 0; if (a = b) int k = a / b, r = a % b; int c = fpow(lose, k); int numerator = sadd(1, M - fpow(lose, k)); // 1 - lose^k (mod M) int denominator = sadd(1, M - lose); // 1 - lose (mod M) int tmp = smul(win, smul(numerator, fpow(denominator))); // Using modular inverse return sadd(smul(c, answer(r, b, win, lose)), tmp); else int k = b / a, r = b % a; int c = fpow(win, k); return smul(c, answer(a, r, win, lose)); void run() int a, b; int p1, p2, P; std::cin a b p1 p2 P; P = p1 + p2; p1 = smul(p1, fpow(P)), p2 = smul(p2, fpow(P)); std::cout answer(a, b, p1, p2) ;int main() std::cin.tie(0)-sync_with_stdio(0); int T; std::cin T; while (T--) run(); L. 502 Bad Gateway 当当前时刻为 1,2,3,…1,2,3,\\dots1,2,3,… 的时候，按按钮重置时间反而得不偿失；相反，如果当前时刻比较大，那么重置时间更有可能缩短用时。 于是基于这一个观察，我们可以猜测：存在一个阈值 ccc，当时刻 c\\lt cc 我们就慢慢等；反之我们就一直按按钮，直到 c\\lt cc 为止。 根据我们的猜测，每摁一次按钮，重置到 c\\lt cc 的概率为 p=ctp=\\frac{c}{t}p=tc​. “不断按成功概率为 ppp 的按钮，直到第一次成功停止”，诶，这不就是几何分布吗？"},{"title":"2024 ICPC 区域赛（西欧北欧 NWERC）","path":"/wiki/algo_contests/2024-icpc-nwerc.html","content":"A. Alphabetical Aristocrats very ez."},{"title":"2024 ICPC 区域赛：香港","path":"/wiki/algo_contests/2024-icpc-regional-hk.html","content":"E. Concave Hull 算法流程 先算一次凹包，把所有的点分成“在凸包上”和“不在凸包上”的点 SSS。 枚举 SSS 中的每一个点作为凹点 p0p_0p0​，然后对其他所有点 pip_ipi​ 计算出向量 vi=pip0→v_i=\\overrightarrow{p_ip_0}vi​=pi​p0​​ 并按极角排序。 极角排序完了之后，向量必定是 on, /, /, /, on, /, /, on, on, /, /, on ...... 这样排列（两个在凸包上的点 c1,c2c_1,c_2c1​,c2​ 中间夹着一些不在凸包上的点 djd_jdj​，记这些点的集合为 F={F0=c1,F1=d1,d2,…,Fm=dm,Fm+1=c2}F=\\{F_0=c_1,F_1=d_1,d_2,\\dots,F_m=d_m,F_{m+1}=c_2\\}F={F0​=c1​,F1​=d1​,d2​,…,Fm​=dm​,Fm+1​=c2​}）。我们尝试计算以 p0p_0p0​ 作为凹点，Fi,Fi+1F_i,F_{i+1}Fi​,Fi+1​ 作为优角的两边的凹包面积。 这里的话，如果跑暴力算法，时间复杂度会来到 O(n3)O(n^3)O(n3)。考虑到这个凹包的面积其实是凸包面积去掉一部分面积，我们可以利用这一点加速计算。 两个三角形 我们把凹包凹进去的部分分成左右两半凸壳（图中黄色和绿色部分），做两次 Andrew 凸包扫描算法（从左往右，然后从右往左）。例如 Andrew 算法从左往右扫描，只要扫描算法扫描经过这些点 FFF，那么我们就能算出由 c1→Fic_1\\to F_ic1​→Fi​ 这些点构成（且包括了 FiF_iFi​ 的）的左半凸壳的面积。同理也可以计算出右半凸壳的面积。因此以 p0p_0p0​ 为凹点、Fi,Fi+1F_i,F_{i+1}Fi​,Fi+1​ 为优角的凹包面积也就可以算出来了（大凸包面积，减掉这一个凹角对应的凸包上三角形的面积 ΔADG\\Delta ADGΔADG，再加上左右两个凸壳的面积） Code Code #include algorithm#include cassert#include cmath#include iostream#include ranges#include utility#include set#include vectorusing i64 = long long;constexpr i64 M = 1e9 + 7;struct pvec int x, y; friend std::istream operator(std::istream is, pvec a) return is a.x a.y; friend std::ostream operator(std::ostream os, const pvec a) return os a.x a.y; bool operator==(const pvec a) const return x == a.x y == a.y; pvec operator-(const pvec a) const return x - a.x, y - a.y; bool operator(const pvec a) const return x == a.x ? y a.y : x a.x; ;int sign(i64 val) return val 0 ? -1 : (val 0 ? 1 : 0); i64 cross(const pvec a, const pvec b) return 1ll * a.x * b.y - 1ll * a.y * b.x; i64 cross(const pvec a, const pvec b, const pvec c) return cross(b - a, c - a); i64 dot(const pvec a, const pvec b) return 1ll * a.x * b.x + 1ll * a.y * b.y; int scross(const pvec a, const pvec b, const pvec c) return sign(cross(a, b, c)); i64 sqrlen(const pvec a) return dot(a, a); auto convex_hull(const std::vectorpvec x) std::vectorpvec v(x); std::vectorpvec used, unused; std::sort(v.begin(), v.end()); int m = v.size(), tp = -1; for (int i = 0; i m; i++) while (tp 0 cross(used[tp-1], used[tp], v[i]) = 0) tp--, used.pop_back(); used.push_back(v[i]), tp++; int t = tp; for (int i = m - 1; i = 0; i--) while (tp t cross(used[tp-1], used[tp], v[i]) = 0) tp--; used.pop_back(); used.push_back(v[i]), tp++; used.pop_back(); std::setpvec s; for(auto d: used) s.insert(d); for(auto d: v) if (!s.contains(d)) unused.push_back(d); return std::pairused, unused;bool comp(const pvec a, const pvec b) bool upA = a.y 0 || (a.y == 0 a.x = 0); bool upB = b.y 0 || (b.y == 0 b.x = 0); if (upA != upB) return upA; auto val = cross(a, b); return val 0;i64 area(const std::vectorpvec p) i64 res = 0; for (int i = 0, m = p.size(); i m; i++) res += cross(p[i], p[(i + 1) % m]); return res;void run() int n; std::cin n; std::vectorpvec p(n); for (auto x : p) std::cin x; auto [used, un] = convex_hull(p); int sz = used.size(); i64 ans = 0; for (const auto x : un) // enum concave point. std::vectorstd::pairpvec, int al; std::vectorpvec cur(sz); std::vectori64 val(sz, 0); // area of triangle formed by on-convex points i64 sum = 0; for (const auto y : un) // compute vectors if (y == x) continue; al.push_back(y - x, -1); for (int i = 0; i sz; i++) cur[i] = used[i] - x; al.push_back(cur[i], i); // sort by angle std::sort(al.begin(), al.end(), [](const auto a, const auto b) return comp(a.first, b.first); ); // rotate to satisfy pattern: // [on-convex, not, not, ..., not, on-convex, not, not .... , not, on-convex] for (int i = 0; i al.size(); i++) if (al[i].second == -1) continue; std::rotate(al.begin(), al.begin() + i, al.end()); break; // compute convex area for (int i = 0; i sz; i++) val[i] = cross(cur[i], cur[(i + 1) % sz]); sum += val[i]; // enum all points between 2 on-convex points for (int l = 0, r = 0, al_size = al.size(); l al_size; l = r) r = l + 1; while (r al_size al[r].second == -1) r++; // (l, r) is the range of not-on-convex points // l, r are on-convex points int pos = al[l].second; std::vectori64 T(r - l, 0); assert((pos + 1) % sz == al[r % al_size].second); // left convex [al, T, l, r] std::vectorpvec pts; int top = -1; i64 ssum = 0; for (int fix = l; fix r; fix++) const auto q = al[fix].first; while (top = 1 cross(q - pts[top - 1], pts[top] - pts[top - 1]) = 0) ssum -= cross(pts[top - 1], pts[top]); top--, pts.pop_back(); pts.push_back(q), top++; if (top = 1) ssum += cross(pts[top - 1], pts[top]); T[fix - l] += ssum; (); // right convex [al, T, l, r, al_size] std::vectorpvec pts; int top = -1; i64 ssum = 0; for (int fix = r; fix l; fix--) const auto q = al[fix % al_size].first; while (top = 1 cross(pts[top - 1], pts[top], q) = 0) ssum -= cross(pts[top], pts[top - 1]); top--, pts.pop_back(); pts.push_back(q); top++; if (top = 1) ssum += cross(pts[top], pts[top - 1]); T[fix - l - 1] += ssum; (); for (int i = 0; i r - l; i++) i64 st = sum - val[pos] + T[i]; (ans += std::abs(st)) %= M; std::cout ans ;int main() std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int T = 1; // std::cin T; while (T--) run(); return 0; H. Mah-Jong 算法流程 我们先预处理出所有可能的顺子的情况 SSS，每个顺子最多出现 222 次（否则可以视为 333 个碰），最少出现 000 次，因此最多 729729729 种情况。 于是每一个合法的区间都可以视为，SSS 中的某一个顺子搭配 sss 加上 若干个碰，因此对于区间 [l,r][l, r][l,r] 而言，令这个区间有 did_idi​ 个数字为 iii 的麻将牌，而顺子组合 sss 要求 bib_ibi​ 个数字为 iii 的牌，那么区间合法这个条件等同于 di≡bi(mod3)di≥bi \\begin{aligned} d_i\\equiv b_i \\pmod 3\\\\ d_i\\ge b_i \\end{aligned} di​di​​≡bi​(mod3)≥bi​​ 考虑如何维护 di≥bid_i\\ge b_idi​≥bi​ 这个条件： 如果我们固定右端点 rrr，那么我们只需要让 l:r→1l:r\\to 1l:r→1 扫描，直到 [l,r][l,r][l,r] 的 did_idi​ 开始满足 di≥bid_i\\ge b_idi​≥bi​，那么对于所有 plp\\lt lpl，都一定会有 [p,r]:di≥bi[p,r]:d_i\\ge b_i[p,r]:di​≥bi​（因为 plp\\lt lpl，因此只会往这个区间里添加新的数，因此 did_idi​ 不可能变小） 考虑如何维护同余 di≡bi(mod3)d_i\\equiv b_i\\pmod {3}di​≡bi​(mod3) 用桶维护即可。可以开 888 维数组或者用三进制表示 时间复杂度 O(36n)O(3^6n)O(36n) Code #include iostream#include ranges#include vectorusing i64 = long long;void run() int n; std::cin n; std::vector cnt(n + 1, std::vectorint(8, 0)); std::vectorint mask(n + 1, 0); std::vectorint a(n + 1, 0); auto encode = [](int d) int s = 0; for (auto i : std::views::iota(0, 8)) s = s * 3 + cnt.at(d).at(i) % 3; return s; ; auto decode_chow = [](int pat) std::vectorint p(8, 0); for (int i : std::views::iota(0, 6)) int u = pat % 3; pat /= 3; p.at(i) += u, p.at(i + 1) += u, p.at(i + 2) += u; return p; ; for (int i = 1; i = n; i++) std::cin a.at(i); a.at(i)--; cnt.at(i) = cnt.at(i - 1); cnt.at(i).at(a.at(i))++; mask.at(i) = encode(i); i64 ans = 0; std::vectorint bucket(8000, 0); for (auto pattern : std::views::iota(0, 729)) auto pat = decode_chow(pattern); for (int i = 0; i = n; i++) bucket.at(mask.at(i))++; int r = 0; for (int l = 1; l = n; l++) for (; r = l; r++) bucket.at(mask.at(r))--; // 先去除不合法的区间（即 右端点小于左端点的区间） int target = 0; for (int t : std::views::iota(0, 8)) // 用双指针去除不满足偏序关系的 while (r = n cnt.at(r).at(t) cnt.at(l - 1).at(t) + pat.at(t)) bucket.at(mask.at(r))--; r++; target = target * 3 + (cnt.at(l - 1).at(t) + pat.at(t)) % 3; if (r n) break; ans += bucket[target]; // 加上满足同余的区间的贡献 std::cout ans ;int main() std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int T = 1; std::cin T; while (T--) run(); return 0;"},{"title":"2025 杭电多校春季赛 4","path":"/wiki/algo_contests/2025-hdu-spring-04.html","content":"战斗爽 根据题意我们可以直接模拟： 我们用 priority_queue 维护所有敌人的攻击力 atk 以及尚且存活的敌人的血量 alive，用数组 dead 记录敌人是否活着 直接在 while 循环里模拟每一轮： 从 alive 里根据规则取出一个敌人，结算伤害，更新其存活状态 接下来结算收到的伤害。从 atk 堆顶取出攻击力最大的，如果堆顶的敌人已经死亡，则弹出取下一个元素，直到堆顶的敌人是存活的。 Code #include algorithm#include iostream#include queue#include tuple#include vectorusing i64 = long long;using M = std::tupleint, int, int, int; // hp, atk, id, timesusing N = std::tupleint, int; // atk, idvoid run() int n, u, k, hq; std::cin n u k hq; std::priority_queueM, std::vectorM, std::greaterM pq; std::priority_queueN atks; i64 atk = 0; for (i64 i = 0, a, b; i n; i++) std::cin a b; pq.push(b, a, i, 0); atks.push(a, i); atk = std::max(atk, a); int cnt = 0; std::vectorint dead(n, false); while (!pq.empty() and hq = 0) auto [hp, a, id, t] = pq.top(); pq.pop(); // attack it if (t k) if (t == 0) hp -= u; else hp -= u / 2; t++; if (hp = 0) cnt++, dead.at(id) = true; else pq.push(hp, a, id, t); while (!atks.empty()) if (dead.at(std::get1(atks.top()))) atks.pop(); else break; atk = std::get0(atks.top()); hq -= atk; std::cout cnt ;int main() std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int T = 1; std::cin T; while (T--) run(); return 0; 充实 手推注意到如果只有两个数 xyxyxy 的话，有解当且仅当 y−x=2ky-x=2^ky−x=2k. 然后考虑多个数的情况，假设 a1a2a3a4…ama_1\\lt a_2\\lt a_3\\lt a_4 \\dots a_ma1​a2​a3​a4​…am​，其差分为 di=ai+1−aid_i=a_{i+1}-a_idi​=ai+1​−ai​. 只要 gcd⁡(di)=2k\\gcd(d_i)=2^kgcd(di​)=2k 就有解 Code 持家 考虑打 aaa 折，减 bbb 元，原价 PPP 元，则有 (P−b)×a=Pa−baPa−b (P-b)\\times a=Pa-ba \\lt Pa-b (P−b)×a=Pa−baPa−b所以我们应该总是先用打折券，再用减价券。时间复杂度为排序的 O(nlog⁡n)O(n\\log n)O(nlogn) Code #include algorithm#include iomanip#include iostream#include vectorusing i64 = long long;void run() int P, n, k; std::cin P n k; std::vectordouble a, b; for (int i = 0, c, t; i n; i++) std::cin t c; if (t == 0) a.push_back(c * 1.0 / 10); else b.push_back(c); std::sort(a.begin(), a.end()), a.insert(a.begin(), 1); std::sort(b.begin(), b.end(), std::greater()), b.insert(b.begin(), 0); for (int i = 1; i a.size(); i++) a[i] *= a[i - 1]; for (int i = 1; i b.size(); i++) b[i] += b[i - 1]; double ans = P; for (int i = 0; i = k; i++) if (i a.size()) ans = std::min(ans, a[i] * P - b[std::min(k - i, int(b.size()) - 1)]); std::cout std::fixed std::setprecision(2) std::max(ans, 0.0) ;int main() std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int T = 1; std::cin T; while (T--) run(); return 0;"},{"title":"香港中文大学（深圳）2025 校赛暨粤港澳国际编程比赛","path":"/wiki/algo_contests/20250419-CUHKSZ-contest.html","content":"A. Milky Loong 大致题意：给你一个字符串，提取一部分文字出来和另一部分拼一起。 实际也非常简单，用 Python 随便水一水就可以了。毕竟是照顾初学者的签到题 B. 约瑟夫问题 大致题意： 有 n≤105n\\le 10^5n≤105 个人围成一个圆，给定一个 2≤k≤92\\le k\\le 92≤k≤9，每个人轮流报数： 如果这个数是 kkk 的倍数、或者其十进制表示带有 kkk 这个数字，那么这个人就被杀死 报数的时候会跳过已经死掉的人 问最后活下来的是谁。 也毕竟简单。考虑到最多每 kkk 个数字就会干掉一个人，因此最多 nknknk 轮就会结束。 C. F. 试飞 大致题意： nnn 个人里面有 mmm 个人具有飞行经验，你的目标是选出两个有飞行经验的人试飞。 你每次可以选择任意 222 个人让其试飞，如果这两个人都具有飞行经验，则任务立刻结束；否则试飞失败。 你只能用至多 ⌊n2m⌋\\lfloor \\frac{n^2}{m}\\rfloor⌊mn2​⌋ 次试飞完成目标。 非常有意思的一道题目。考察鸽巢原理。具体做法是，把这 nnn 个人平分到 m−1m-1m−1 个组里，那么根据鸽巢原理，必然有一个组里有 222 个人具有飞行经验。 于是，我们直接对每一个组暴力枚举 pair. 由于是平分，每个组差不多 nm−1\\frac{n}{m-1}m−1n​ 人，因此一个组内的枚举次数为 12×(nm−1−1)×nm−1\\frac{1}{2}\\times(\\frac{n}{m-1}-1)\\times\\frac{n}{m-1}21​×(m−1n​−1)×m−1n​，而有 m−1m-1m−1 组，因此总枚举次数为 (m−1)×12×(nm−1−1)×nm−1=n22(m−1)−n≤n2m \\begin{aligned} (m-1)\\times\\frac{1}{2}\\times(\\frac{n}{m-1}-1)\\times\\frac{n}{m-1}\\\\ =\\frac{n^2}{2(m-1)}-n\\\\ \\le \\frac{n^2}{m} \\end{aligned} =≤​(m−1)×21​×(m−1n​−1)×m−1n​2(m−1)n2​−nmn2​​"},{"title":"AtCoder Regular Contest 198 (Div. 2)","path":"/wiki/algo_contests/arc198.html","content":"A. I hate 1 首先 111 不可能出现在 SSS 里；其次，k,k+1k,k+1k,k+1 不可能同时出现在 SSS 中。所以 ∣S∣≤⌊n2⌋|S|\\le \\lfloor\\frac{n}{2}\\rfloor∣S∣≤⌊2n​⌋. 发现取偶数的时候刚好取到 n/2n/2n/2. 一个坑是 n=1n=1n=1 时，S={1}S=\\{1\\}S={1}，因为此时无法组成任何 pair Code n = int(input())if n == 1: print(1) print(1)else: print(n // 2) print( .join([str(i) for i in range(2, n + 1, 2)])) B. Rivalry 我们考虑怎么构造一个合法解。我们先全部写上 000，因为在题目条件下，相当于 000 可以任务放置。 然后放 111，由于每一个 111 两边有且只有一个 000，我们先满足 ≥1\\ge 1≥1 个 000：在每个 000 的两侧各放一个 111。此时，我们可以推出第一个条件：如果 c12c0c_1\\gt 2c_0c1​2c0​，那么必定有一个 111 夹在两个 111 的中间，不符合条件，所以必然有 c1≤2c0\\boxed{c_1\\le 2c_0}c1​≤2c0​​. 然后再考察插入 222。因为每一个 111 必须紧邻一个 000，因此 222 不能插入 101010 之间，只能插入 111111 之间。一共有 c0c_0c0​ 个 111111 可以插入。故得到第二个条件：c2≤c0\\boxed{c_2\\le c_0}c2​≤c0​​ 然后我们考虑 222 不足的情况，比如说 000 个 222。我们可能得到这样一个情况： 101 101 101 …10_ 101\\ 101\\ 101\\ \\dots 10\\_ 101 101 101 …10_此时注意到第一个 111 其两边都是 000，而 111 又全部插入完毕，因此必须有一个 222 插入。所以若 c1=1(mod2)c_1=1\\pmod 2c1​=1(mod2)，就必须有 c2≥1c_2\\ge 1c2​≥1；否则，若 c1=0(mod2)c_1=0\\pmod 2c1​=0(mod2)，我们可以构造出这样的结构：0110110110110…0110110110110\\dots0110110110110… 一定满足条件。所以第三个条件是：c1=0(mod2)∨c2≥1c_1=0\\pmod 2\\lor c_2\\ge 1c1​=0(mod2)∨c2​≥1 故总时间复杂度为 O(T)O(T)O(T). Code def solve(): x, y, z = map(int, input().split()) if y = 2 * x and z = x and (y % 2 == 0 or z = 1): print(Yes) else: print(No)for _ in range(int(input())): solve() C. Error Swap 看到将 AAA 数列变成 BBB 数列，我们考虑数列变换模型，考虑能否用题目的操作，操作出 ai−1,aj+1a_i-1,a_j+1ai​−1,aj​+1 的形式。 手推一下，发现可以用 444 步操作模拟。具体如下： 任意两个数之间一加一减都可以用 444 次操作完成 Prefix Dec-IncIndexijkA[Index]xyzswap(i,k)z−1yx+1swap(i,j)y−1zx+1swap(i,k)xzyswap(j,k)xy−1z+1 \\text{Prefix Dec-Inc}\\\\ \\begin{array}{c|cccc} \\text{Index}ijk\\\\ \\text{A[Index]}xyz\\\\ \\hline \\texttt{swap(i,k)}z-1yx+1\\\\ \\texttt{swap(i,j)}y-1zx+1\\\\ \\texttt{swap(i,k)}xzy\\\\ \\texttt{swap(j,k)}xy-1z+1\\\\ \\end{array} Prefix Dec-IncIndexA[Index]swap(i,k)swap(i,j)swap(i,k)swap(j,k)​ixz−1y−1xx​jyyzzy−1​kzx+1x+1yz+1​​Prefix Inc-DecIndexijkA[Index]xyzswap(j,k)xz−1y+1swap(i,k)yz−1x+1swap(i,j)z−2y+1x+1swap(i,k)xy+1z−1 \\text{Prefix Inc-Dec}\\\\ \\begin{array}{c|cccc} \\text{Index}ijk\\\\ \\text{A[Index]}xyz\\\\ \\hline \\texttt{swap(j,k)}xz-1y+1\\\\ \\texttt{swap(i,k)}yz-1x+1\\\\ \\texttt{swap(i,j)}z-2y+1x+1\\\\ \\texttt{swap(i,k)}xy+1z-1\\\\ \\end{array} Prefix Inc-DecIndexA[Index]swap(j,k)swap(i,k)swap(i,j)swap(i,k)​ixxyz−2x​jyz−1z−1y+1y+1​kzy+1x+1x+1z−1​​Suffix Inc-DecIndexijkA[Index]xyzswap(i,j)y−1x+1zswap(j,k)y−1z−1x+2swap(i,k)x+1z−1yswap(j,k)x+1y−1z \\text{Suffix Inc-Dec}\\\\ \\begin{array}{c|cccc} \\text{Index}ijk\\\\ \\text{A[Index]}xyz\\\\ \\hline \\texttt{swap(i,j)}y-1x+1z\\\\ \\texttt{swap(j,k)}y-1z-1x+2\\\\ \\texttt{swap(i,k)}x+1z-1y\\\\ \\texttt{swap(j,k)}x+1y-1z\\\\ \\end{array} Suffix Inc-DecIndexA[Index]swap(i,j)swap(j,k)swap(i,k)swap(j,k)​ixy−1y−1x+1x+1​jyx+1z−1z−1y−1​kzzx+2yz​​Suffix Dec-IncIndexijkA[Index]xyzswap(j,k)xz−1y+1swap(i,k)yz−1x+1swap(j,k)yxzswap(i,j)x−1y+1z \\text{Suffix Dec-Inc}\\\\ \\begin{array}{c|cccc} \\text{Index}ijk\\\\ \\text{A[Index]}xyz\\\\ \\hline \\texttt{swap(j,k)}xz-1y+1\\\\ \\texttt{swap(i,k)}yz-1x+1\\\\ \\texttt{swap(j,k)}yxz\\\\ \\texttt{swap(i,j)}x-1y+1z\\\\ \\end{array} Suffix Dec-IncIndexA[Index]swap(j,k)swap(i,k)swap(j,k)swap(i,j)​ixxyyx−1​jyz−1z−1xy+1​kzy+1x+1zz​​Mid Dec-IncIndexijkA[Index]xyzswap(i,k)z−1yx+1swap(j,k)z−1xy+1swap(i,j)x−1zy+1swap(j,k)x−1yz+1 \\text{Mid Dec-Inc}\\\\ \\begin{array}{c|cccc} \\text{Index}ijk\\\\ \\text{A[Index]}xyz\\\\ \\hline \\texttt{swap(i,k)}z-1yx+1\\\\ \\texttt{swap(j,k)}z-1xy+1\\\\ \\texttt{swap(i,j)}x-1zy+1\\\\ \\texttt{swap(j,k)}x-1yz+1\\\\ \\end{array} Mid Dec-IncIndexA[Index]swap(i,k)swap(j,k)swap(i,j)swap(j,k)​ixz−1z−1x−1x−1​jyyxzy​kzx+1y+1y+1z+1​​Mid Inc-DecIndexijkA[Index]xyzswap(i,j)y−1x+1zswap(j,k)y−1z−1x+2swap(i,j)z−2yx+2swap(i,k)x+1yz−1 \\text{Mid Inc-Dec}\\\\ \\begin{array}{c|cccc} \\text{Index}ijk\\\\ \\text{A[Index]}xyz\\\\ \\hline \\texttt{swap(i,j)}y-1x+1z\\\\ \\texttt{swap(j,k)}y-1z-1x+2\\\\ \\texttt{swap(i,j)}z-2yx+2\\\\ \\texttt{swap(i,k)}x+1yz-1\\\\ \\end{array} Mid Inc-DecIndexA[Index]swap(i,j)swap(j,k)swap(i,j)swap(i,k)​ixy−1y−1z−2x+1​jyx+1z−1yy​kzzx+2x+2z−1​​ 有了这一点之后，我们考虑贪心算法：每次 ai≠bia_i e b_iai​=bi​ 时，都对 ai,ai+1a_i,a_{i+1}ai​,ai+1​ 进行加减操作，直到 ai=bia_i=b_iai​=bi​ 为止。但是这样的话总操作次数可能来到 4N24N^24N2 可能会爆。因此一个优化是，对于 aibia_i\\gt b_iai​bi​，找一个 jjj 使得 ajbj∧j=arg max⁡ki∣aj−bj∣a_j\\lt b_j\\land j=\\argmax_{k\\gt i}|a_j-b_j|aj​bj​∧j=argmaxki​∣aj​−bj​∣；对于 aibia_i\\lt b_iai​bi​ 也是类似。这个剪枝就可以通过此题了。 另外值得注意的是要特殊考察 N=1,2N=1,2N=1,2 时的情况。N=2N=2N=2 时，b[]b[]b[] 只有两种情况是 OK 的，(b0,b1)=(a0,a1)/(a1−1,a0+1)(b_0,b_1)=(a_0,a_1)/(a_1-1,a_0+1)(b0​,b1​)=(a0​,a1​)/(a1​−1,a0​+1). 特判即可。 Code #include cassert#include iostream#include iterator#include numeric#include set#include utility#include vector#define all(x) (x).begin(), (x).end()using vi = std::vectorint;using pii = std::pairint, int;int main() int n; std::cin n; std::vectorint a(n), b(n); for (auto x : a) std::cin x; for (auto x : b) std::cin x; if (std::accumulate(all(a), 0) != std::accumulate(all(b), 0)) return std::cout No , 0; if (n == 2) if (a[0] == b[0] a[1] == b[1]) std::cout Yes 0 ; else if (a[1] - 1 == b[0] a[0] + 1 == b[1]) std::cout Yes 1 1 2 ; else std::cout No ; return 0; // simulation std::vectorpii answer; auto swap = [](int i, int j) assert(0 = i i j j n); std::swap(a[i], a[j]); a[i]--, a[j]++; answer.emplace_back(i, j); ; auto prefix_incdec = [](int z, int x, int y) assert(0 = z z x x y y n); swap(x, y), swap(z, y), swap(z, x), swap(z, y); ; auto prefix_decinc = [](int z, int x, int y) assert(0 = z z x x y y n); swap(z, y), swap(z, x), swap(z, y), swap(x, y); ; auto suffix_incdec = [](int x, int y, int z) assert(0 = x x y y z z n); swap(x, y), swap(y, z), swap(x, z), swap(y, z); ; auto suffix_decinc = [](int x, int y, int z) assert(0 = x x y y z z n); swap(y, z), swap(x, z), swap(y, z), swap(x, y); ; auto mid_incdec = [](int x, int y, int z) assert(0 = x x y y z z n); swap(x, y), swap(y, z), swap(x, y), swap(x, z); ; auto mid_decinc = [](int x, int y, int z) assert(0 = x x y y z z n); swap(x, z), swap(y, z), swap(x, y), swap(y, z); ; auto call = [](int T, auto F, int x, int y, int z) assert(0 = x x y y z z n); for (int i = 0; i T; i++) F(x, y, z); ; for (int i = 0; i n; i++) if (a[i] == b[i]) continue; int j = i + 1, maxv = -1, rec = -1; for (; j n; j++) if ((a[j] b[j]) != (a[i] b[i]) abs(a[j] - b[j]) maxv) rec = j, maxv = abs(a[j] - b[j]); j = rec; if (a[i] b[i]) int dec = a[i] - b[i]; if (i + 1 == j) if (i == 0) call(dec, suffix_decinc, i, j, n - 1); else call(dec, prefix_decinc, 0, i, j); else call(dec, mid_decinc, i, j - 1, j); else int inc = b[i] - a[i]; if (i + 1 == j) if (i == 0) call(inc, suffix_incdec, i, j, n - 1); else call(inc, prefix_incdec, 0, i, j); else call(inc, mid_incdec, i, j - 1, j); if (answer.size() 31000) std::cout No ; else std::cout Yes answer.size() ; for (auto [i, j] : answer) std::cout i + 1 j + 1 ;"},{"title":"上海 2015 OI 省选","path":"/wiki/algo_contests/SHOI2015.html","content":"[SHOI2015] 自动刷题机 一个比较重要的性质：n=tn=tn=t 时可以完成的题目数量，一定不少于 n=t+1n=t+1n=t+1 时能够完成的题目数量。令 f(x)=yf(x)=yf(x)=y 表示如果自动刷题机的 n=xn=xn=x，则一共可以完成 yyy 道题，则 f(x)f(x)f(x) 单调递减。 所以，我们需要找到 f(x)=kf(x)=kf(x)=k 的 xxx 的取值区间。所以我们可以使用二分找出区间的左右端点。 Code #include algorithm#include iostream#include vectorusing i64 = long long;int main() int n, k; std::cin n k; std::vectori64 all(n); i64 max = 0; for (int i = 0; i n; i++) std::cin all[i]; max = std::max(max, all[i]); auto check = [](i64 L) int cnt = 0; i64 lines = 0; for (auto v : all) lines += v; if (lines 0) lines = 0; if (lines = L) cnt++, lines = 0; return cnt; ; // find =k, =k-1 boundary as max L i64 l, r; i64 ans_r, ans_l; l = 0, r = 1e18 + 1; while (l + 1 r) i64 mid = l + ((r - l) 1); int res = check(mid); if (res = k) l = mid; else r = mid; ans_r = l; l = 0, r = 1e18 + 1; while (l + 1 r) i64 mid = l + ((r - l) 1); int res = check(mid); if (res k) l = mid; else r = mid; ans_l = r; if (check(ans_l) k || check(ans_r) k || check(ans_r) k || check(ans_l) k) std::cout -1 ; else std::cout ans_l ans_r ; [SHOI2015] 脑洞治疗仪 区间修改？区间最大子段？这不就是线段树吗！ 我们考虑线段树怎么做：为了维护区间最大子段（最长 000 子段），我们需要维护前缀 000 的长度、后缀 000 的长度、最长的中缀 000 的长度。区间修改的话，我们还需要懒标记。 接下来，我们来考察怎么进行 fill 操作。我们首先得知 [l0,r0][l_0,r_0][l0​,r0​] 区间有多少个 111 可以用于治疗（例如说有 ttt 个），然后删掉，接着再在 [l1,r1][l_1,r_1][l1​,r1​] 找到一个位置 ppp，使得 [l1,p][l_1,p][l1​,p] 之间恰好有 ttt 个位置可以填充。找 ppp 的过程可以通过二分结合线段树的区间查询做到 O(log⁡2n)O(\\log^2 n)O(log2n). 于是，操作 0/20/20/2 的单次复杂度为 O(log⁡n)O(\\log n)O(logn)，操作 111 的单次复杂度为 O(log⁡n)O(\\log n)O(logn)，整体时间复杂度为 O(mlog⁡2n)O(m\\log^2 n)O(mlog2n). Code 代码里使用 reset = 0/1 分别标记这个线段树节点所代表的区间应该全部被设置为 0/10/10/1. #include algorithm#include cstdio#include iostreamconstexpr int N = 2e5 + 5;struct Node // for queries int prefix0; int suffix0; int segment0; // for filling int length; int count1; // label; int reset; Node() : prefix0(0), suffix0(0), segment0(0), length(0), count1(0), reset(-1) T[N 2];int n, m;void pull_up(int rt) int ls = rt 1, rs = rt 1 | 1; T[rt].length = T[ls].length + T[rs].length; T[rt].count1 = T[ls].count1 + T[rs].count1; // maintain queries T[rt].prefix0 = T[ls].prefix0; if (T[ls].prefix0 == T[ls].length) T[rt].prefix0 += T[rs].prefix0; T[rt].suffix0 = T[rs].suffix0; if (T[rs].suffix0 == T[rs].length) T[rt].suffix0 += T[ls].suffix0; T[rt].segment0 = std::max(T[ls].segment0, T[rs].segment0, T[ls].suffix0 + T[rs].prefix0);void mark_zero(int root) T[root].reset = 0; T[root].count1 = 0; T[root].prefix0 = T[root].suffix0 = T[root].segment0 = T[root].length;void mark_one(int root) T[root].reset = 1; T[root].count1 = T[root].length; T[root].prefix0 = T[root].suffix0 = T[root].segment0 = 0;void push_down(int rt) if (T[rt].reset == -1) return; int ls = rt 1, rs = rt 1 | 1; if (T[rt].reset == 0) mark_zero(ls), mark_zero(rs); else if (T[rt].reset == 1) mark_one(ls), mark_one(rs); T[rt].reset = -1;// initialize to all 1svoid build(int rt = 1, int l = 1, int r = n) if (l == r) T[rt].length = 1, T[rt].count1 = 1; T[rt].segment0 = 0, T[rt].prefix0 = 0, T[rt].suffix0 = 0; T[rt].reset = -1; return; int mid = l + ((r - l) 1); build(rt 1, l, mid); build(rt 1 | 1, mid + 1, r); pull_up(rt);// make [L, R] all 0svoid remove(int L, int R, int rt = 1, int l = 1, int r = n) if (L r or R l) return; // no overlap if (L = l and r = R) mark_zero(rt); return; int mid = l + ((r - l) 1); push_down(rt); remove(L, R, rt 1, l, mid); remove(L, R, rt 1 | 1, mid + 1, r); pull_up(rt);void set_one(int L, int R, int rt = 1, int l = 1, int r = n) if (L r or R l) return; // no overlap if (L = l and r = R) mark_one(rt); return; int mid = l + ((r - l) 1); push_down(rt); set_one(L, R, rt 1, l, mid); set_one(L, R, rt 1 | 1, mid + 1, r); pull_up(rt);int query_sum(int L, int R, int rt = 1, int l = 1, int r = n) if (L r or R l) return 0; if (L = l and r = R) return T[rt].count1; int mid = l + ((r - l) 1); push_down(rt); return query_sum(L, R, rt 1, l, mid) + query_sum(L, R, rt 1 | 1, mid + 1, r);int query_empty(int L, int R, int rt = 1, int l = 1, int r = n) if (L r or R l) return 0; if (L = l and r = R) return T[rt].length - T[rt].count1; int mid = l + ((r - l) 1); push_down(rt); return query_empty(L, R, rt 1, l, mid) + query_empty(L, R, rt 1 | 1, mid + 1, r);Node query_segment(int L, int R, int rt = 1, int l = 1, int r = n) if (L r or R l) return Node(); if (L = l and r = R) return T[rt]; int mid = l + ((r - l) 1); push_down(rt); auto left = query_segment(L, R, rt 1, l, mid); auto right = query_segment(L, R, rt 1 | 1, mid + 1, r); Node res; res.length = left.length + right.length; res.count1 = left.count1 + right.count1; res.prefix0 = left.prefix0; if (left.prefix0 == left.length) res.prefix0 += right.prefix0; res.suffix0 = right.suffix0; if (right.suffix0 == right.length) res.suffix0 += left.suffix0; res.segment0 = std::max(left.segment0, right.segment0, left.suffix0 + right.prefix0); return res;int main() std::cin n m; build(); int op, l0, r0, l1, r1; while (m--) std::cin op; if (op == 0) std::cin l0 r0; remove(l0, r0); else if (op == 1) std::cin l0 r0 l1 r1; int sum = query_sum(l0, r0); remove(l0, r0); int empty = query_empty(l1, r1); int target = std::min(empty, sum); // if (target = 0) continue; int l = l1 - 1, r = r1 + 1; while (l + 1 r) int mid = l + ((r - l) 1); if (query_empty(l1, mid) = target) l = mid; else r = mid; if (l = l1) set_one(l1, l); else std::cin l0 r0; auto seg = query_segment(l0, r0); std::cout seg.segment0 ; 这道题应该还有线段树上二分的做法，就是替换掉二分的过程。改日再研究一下~ [SHOI2015] 超能粒子炮·改 看到模数非常小就想到了卢卡斯定理，此题的模数 233323332333 还是素数，我们只需要用朴素的卢卡斯定理即可，即 下面的除号都是下取整的意思。 (nk)≡(n/pk/p)(n%pk%p)(modp) \\binom{n}{k}\\equiv\\binom{n/p}{k/p}\\binom{n\\%p}{k\\%p}\\pmod p (kn​)≡(k/pn/p​)(k%pn%p​)(modp)然而我们要求的却是一个和式 ∑i=0k(ni)(modp)\\sum_{i=0}^k \\binom{n}{i} \\pmod p∑i=0k​(in​)(modp). 我们考虑怎么拆开这个式子，一个核心的想法就是尽量往卢卡斯定理的形式上靠。 （以下的推导略去 (modp)\\pmod p(modp)） ∑i=0k(ni)=∑i=0k(n/pi/p)(n%pi%p) \\sum_{i=0}^k \\binom{n}{i}=\\sum_{i=0}^k \\binom{n/p}{i/p}\\binom{n\\%p}{i\\%p} i=0∑k​(in​)=i=0∑k​(i/pn/p​)(i%pn%p​)然后我们发现：诶！好像 i%pi\\% pi%p 的取值只有 ppp 个，而且 n%pn\\% pn%p 还是定值！所以我们考虑把 (n/pi/p)\\binom{n/p}{i/p}(i/pn/p​) 按照 i%pi\\% pi%p 进行分类： ∑i=0k(n/pi/p)(n%pi%p)=∑r=0p−1((n%pr)⋅∑i=jp+r(n/pi/p))+(n/pk/p)∑i=0k%p(n%pi) \\begin{aligned} \\sum_{i=0}^k \\binom{n/p}{i/p}\\binom{n\\%p}{i\\%p}\\\\ =\\sum_{r=0}^{p-1} \\Bigg(\\binom{n\\% p}{r}\\cdot\\sum_{i=jp+r}\\binom{n/p}{i/p}\\Bigg)+\\binom{n/p}{k/p}\\sum_{i=0}^{k\\% p}\\binom{n\\% p}{i} \\end{aligned} =​i=0∑k​(i/pn/p​)(i%pn%p​)r=0∑p−1​((rn%p​)⋅i=jp+r∑​(i/pn/p​))+(k/pn/p​)i=0∑k%p​(in%p​)​在这个式子里，我们把 kkk 个组合数分成两个部分: 一个是 [0,k/p⋅p−1][0, k/p \\cdot p-1][0,k/p⋅p−1]，这一部分我们可以完整地分成 ppp 组，每组 k/pk/pk/p 个。 我们继续考察前半部分这个和式。我们可以写成两个和式的乘积： (∑r=0p−1(n%pr))⋅(∑i=jp+r(n/pi/p)) \\Bigg(\\sum_{r=0}^{p-1} \\binom{n\\% p}{r}\\Bigg)\\cdot\\Bigg( \\sum_{i=jp+r}\\binom{n/p}{i/p} \\Bigg) (r=0∑p−1​(rn%p​))⋅(i=jp+r∑​(i/pn/p​))接着考察后半个和式 i/pi/pi/p 的取值，我们发现，其实 jjj 的取值就是 [0,k/p−1][0, k/p-1][0,k/p−1]. 另一部分则是剩余的组合数 k/p⋅p∼kk/p\\cdot p\\sim kk/p⋅p∼k，他们无法按余数分成 ppp 组，所以单独计算。 但是虽然无法按余数分组，但是他们的除以 ppp 的商是一样的，所以我们在这里按商 (n/pk/p)\\binom{n/p}{k/p}(k/pn/p​) 合并. 所以，上面这个式子可以写作： ∑i=0k(ni)=(∑r=0p−1(n%pr))⋅(∑j=0k/p−1(n/pj))+(n/pk/p)∑i=0k%p(n%pi) \\sum_{i=0}^k \\binom{n}{i}=\\Bigg(\\sum_{r=0}^{p-1} \\binom{n\\% p}{r}\\Bigg)\\cdot\\Bigg( \\sum_{j=0}^{k/p-1}\\binom{n/p}{j} \\Bigg)+\\binom{n/p}{k/p}\\sum_{i=0}^{k\\% p}\\binom{n\\% p}{i} i=0∑k​(in​)=(r=0∑p−1​(rn%p​))⋅(j=0∑k/p−1​(jn/p​))+(k/pn/p​)i=0∑k%p​(in%p​)然后我们就发现了形式上相似的地方：记 f(x,y)=∑i=0y(xi)f(x,y)=\\sum_{i=0}^y \\binom{x}{i}f(x,y)=∑i=0y​(ix​)，则有 f(n,k)=f(n%p,p−1)⋅f(n/p,k/p−1)+(n/pk/p)⋅f(n%p,k%p) f(n,k)=f(n\\% p,p-1)\\cdot f(n/p,k/p-1)+\\binom{n/p}{k/p}\\cdot f(n\\% p, k\\%p) f(n,k)=f(n%p,p−1)⋅f(n/p,k/p−1)+(k/pn/p​)⋅f(n%p,k%p)这就是 DP 递推啊！而且进一步的，f(n%p,p−1)f(n\\% p,p-1)f(n%p,p−1) 和 f(n%p,k%p)f(n\\% p, k\\%p)f(n%p,k%p) 的状态数量只有 p2p^2p2 个，(n/pk/p)\\binom{n/p}{k/p}(k/pn/p​) 可以使用卢卡斯定理计算，f(n/p,k/p−1)f(n/p,k/p-1)f(n/p,k/p−1) 则可以递归计算。 卢卡斯定理的计算过程是 n,kn,kn,k 同步 /p/p/p，因此时间复杂度是 O(log⁡n)O(\\log n)O(logn) 的。如果令 f(x,y),x≤p,y≤pf(x,y),x\\le p,y\\le pf(x,y),x≤p,y≤p 进行 O(p2)O(p^2)O(p2) 预处理计算，令计算 f(n,k)f(n,k)f(n,k) 的复杂度为 T(x)T(x)T(x) （这里 n,kn,kn,k 的变化是同步除以 ppp，因此就使用一元了），则有 T(x)=O(1)⋅T(x/p)+O(log⁡n)⋅O(1)T(x)=O(log⁡2n) T(x)=O(1)\\cdot T(x/p) + O(\\log n)\\cdot O(1)\\\\ T(x)=O(\\log^2 n) T(x)=O(1)⋅T(x/p)+O(logn)⋅O(1)T(x)=O(log2n)因此算上预处理，这道题的时间复杂度为 O(p2+Tlog⁡2n)O(p^2+T\\log^2 n)O(p2+Tlog2n). Code #include iostreamusing i64 = long long;constexpr int P = 2333;// f(n, m) = sum_i=0^m C(n, i) (mod p)int fpow(i64 b, i64 p) int res = 1; while (p) if (p 1) res = res * b % P; b = b * b % P; p = 1; return res;int C[P + 2][P + 2];int F[P + 2][P + 2];void init() for (int i = 1; i = P; ++i) C[0][i] = 0; C[0][0] = 1; for (int i = 1; i = P; ++i) for (int j = 0; j = P; ++j) C[i][j] = 0; C[i][0] = C[i][i] = 1; for (int j = 1; j i; ++j) C[i][j] = (C[i - 1][j - 1] + C[i - 1][j]) % P; // init F[][] for (int i = 0; i = P; i++) F[i][0] = 1; for (int row = 0; row = P; row++) for (int col = 1; col = P; col++) F[row][col] = (F[row][col - 1] + C[row][col]) % P; int lucas(i64 n, i64 k) if (k == 0 || n == k) return 1; if (n k) return 0; return C[n % P][k % P] * lucas(n / P, k / P) % P;int f(i64 n, i64 k) if (n = P and k = P) return F[n][k]; return (F[n % P][P - 1] * f(n / P, k / P - 1) % P + lucas(n / P, k / P) * F[n % P][k % P] % P) % P;void run() i64 n, k; std::cin n k; std::cout f(n, k) ;int main() init(); int T; std::cin T; while (T--) run(); [SHOI2015] 聚变反应炉 656565 分想法：因为 ci=0c_i=0ci​=0 时，我们总是必须取所有点，答案为 ∑di\\sum d_i∑di​，因此有 cic_ici​ 时，考虑总是贪心选择点，使得其能够减少最多的能量消耗。 看到当 c≤5c\\le 5c≤5 时，n≤2000n\\le 2000n≤2000，思考是不是可能是 O(n2)O(n^2)O(n2) 的算法。由于前 505050 分我们使用的是贪心算法，所以这次我们考虑能否 DP. 树形 DP 我们通常可以考虑将 dp[u] 设置为某个与其子树相关的状态。这里，我们令 dp[u] 表示把 uuu 子树全部激活的最小 cost. 然后我们就能发现一个问题：对于 uuu 的儿子 viv_ivi​，我们可以一部分 viv_ivi​（以及其子树）先激活，再激活 uuu，再激活剩余的 vjv_jvj​（以及其子树）. 考虑把“先于 uuu 激活的子树”、“后于 uuu 激活的子树”都视为物品，于是我们发现，这是一个 0/10/10/1 背包！ 那么背包的容量是什么呢？考虑到若选取“先于 uuu 激活的子树 vvv”这个物品，则 d[u]d[u]d[u] 可以减免 c[v]c[v]c[v] 的能量点，这一个形式就比较像背包容量。因此，我们可以令 cap[u]=min⁡(d[u],∑v∈u.sonc[v])cap[u]=\\min(d[u], \\sum\\limits_{v\\in u.son} c[v])cap[u]=min(d[u],v∈u.son∑​c[v]) 作为背包容量。那么顺理成章地，我们就令 c[v]c[v]c[v] 作为“先于 uuu 激活的子树 vvv” 的 cost，“后于 uuu 激活的子树 vvv” 的 cost 视作 000. 顺便也改一下状态：令 dp[u, c] 表示如果 uuu 从儿子节点接受了总计 ccc 点能量的辐射，那么还需要 dp[u,c] 点能量才能激活整棵子树。 然后考察每一个物品的价值，我们希望最后背包的价值最小。先考虑“先于 uuu 激活的子树 vvv”，其激活不受到 uuu 的辐射，因此其价值就是 Uv,0=min⁡c≤cap[v]dp[v,c] U_{v,0}=\\min_{c\\le cap[v]} \\texttt{dp[v,c]} Uv,0​=c≤cap[v]min​dp[v,c]对于“后于 uuu 激活的子树 vvv”而言，从 uuu 能传到 vvv 的能量，首先不超过 c[u]c[u]c[u]，其次，还要考虑 vvv 的儿子辐射给 vvv 的能量（=d[v]−cost=d[v]-cost=d[v]−cost），因此为 min⁡cost≤cap[v](c[u],d[v]−cost)\\min_{cost\\le cap[v]}(c[u], d[v]-cost)mincost≤cap[v]​(c[u],d[v]−cost)，因此价值为激活子树所需能量去掉从 uuu 传过来的能量，即 Uv,1=min⁡cost≤cap[v](dp[v,cost]-min⁡(c[u],d[v]-cost)) U_{v,1}=\\min_{\\texttt{cost}\\le \\texttt{cap[v]}}\\Big(\\texttt{dp[v,cost]-\\(\\min(\\)c[u],d[v]-cost\\()\\)}\\Big) Uv,1​=cost≤cap[v]min​(dp[v,cost]-min(c[u],d[v]-cost))然后就是简单的 0/10/10/1 背包问题了。后 505050 分的时间复杂度为 O(cn2)O(cn^2)O(cn2). Code #include algorithm#include cassert#include iostream#include numeric#include queue#include set#include utility#include vectorusing vi = std::vectorint;using vvi = std::vectorvi;using pii = std::pairint, int;int n;void case0(vi d, vi c) assert(*std::ranges::max_element(c) == 0); std::cout std::accumulate(d.begin(), d.end(), 0) ;void case1(vi d, vi c, vvi G) vi deg(d.size(), 0); for (int u = 1; u = n; u++) deg[u] = G[u].size(); std::setpii, std::greaterpii S; std::queueint Q; for (int u = 1; u = n; u++) S.insert(deg[u] * c[u], u); int ans = 0; vi vis(n + 1, false); while (!S.empty()) auto [reduced, t] = *S.begin(); S.erase(S.begin()); Q.push(t); ans += d[t]; d[t] = 0; while (!Q.empty()) int u = Q.front(); Q.pop(); if (vis[u]) continue; vis[u] = true; for (auto v : G[u]) if (d[v] = 0) continue; d[v] -= c[u]; S.erase(deg[v] * c[v], v); deg[v]--; S.insert(deg[v] * c[v], v); if (d[v] = 0) Q.push(v); std::cout ans ;constexpr int inf = 1e9;constexpr int maxc = 1e4 + 5;void case2(vi d, vi c, vvi G) vvi f(n + 1, vi(maxc, inf)); vi cap(n + 1, 0); auto dfs = [](auto F, int u, int fa) - void f[u][0] = d[u]; int totcap = 0; for (int v : G[u]) if (v == fa) continue; totcap += c[v]; F(F, v, u); cap[u] = std::min(d[u], totcap); for (int v : G[u]) if (v == fa) continue; int up = inf, down = inf; // up: u - fa, down: fa - u for (int i = 0; i = cap[v]; i++) up = std::min(up, f[v][i]); down = std::min(down, f[v][i] - std::min(c[u], d[v] - i)); vi tmp(maxc, inf); for (int i = 0; i = cap[u]; i++) if (f[u][i] == inf) continue; tmp[i] = std::min(tmp[i], f[u][i] + down); int next_cap = std::min(cap[u], i + c[v]); tmp[next_cap] = std::min(tmp[next_cap], f[u][i] + up - std::min(c[v], d[u] - i)); for (int i = 0; i = cap[u]; i++) f[u][i] = tmp[i]; ; dfs(dfs, 1, 0); auto ans = *std::ranges::min_element(f[1]); std::cout ans ;int main() std::cin n; vi d(n + 1, 0), c(n + 1, 0); vvi G(n + 1); for (int i = 1; i = n; i++) std::cin d[i]; for (int i = 1; i = n; i++) std::cin c[i]; for (int i = 1; i n; i++) int u, v; std::cin u v; G[u].push_back(v); G[v].push_back(u); if (*std::ranges::max_element(c) == 0) case0(d, c); else if (*std::ranges::max_element(c) == 1) case1(d, c, G); else case2(d, c, G); [SHOI2015] 激光发生器 计算几何题，但是细节有点多…… 因为只要反射十次，而且只有 100100100 面镜子，所以我们可以直接模拟光线轨迹。 每次模拟中，我们计算当前射线与每一面镜子的交点（要保证在线段上），那么距离射线起点最近的就是光线的反射点。 然后取出镜子的法向量，注意要和光线在镜子的同一侧（可以使用点积判断）。计算法向量和入射光线的夹角，乘上 λ\\lambdaλ 就是反射角，那么就直接旋转法向量即可。当然这里要判断一下应该逆时针旋转还是顺时针旋转。 还有要注意的点是，计算夹角时要考虑浮点数误差，即先对 cos⁡\\coscos 的值取 clamp(-1, 1) 然后再 std::acos() 比较稳妥。 Code #include algorithm#include cassert#include cmath#include iostream#include vectorconstexpr int N = 110;constexpr double EPS = 1e-9;struct pvec double x, y; pvec operator+(const pvec other) const return x + other.x, y + other.y; pvec operator-(const pvec other) const return x - other.x, y - other.y; pvec operator*(double t) const return x * t, y * t; ;struct segment pvec s, d, e; double lambda;;int n;segment seg[N], current;int vis[N];std::vectorint order;//! methods// -1 if a b, 0 if a == b, 1 if a bint sign(double a, double b);double cross(const pvec , const pvec );double dot(const pvec , const pvec );double dist(const pvec , const pvec );double angle(const pvec , const pvec );pvec normalize(const pvec );pvec rotate_anticlock(const pvec , const double );bool do_intersect(const segment , const segment );bool on_segment(const pvec , const segment );// assuming all lines, does not check parallelpvec intersect(const segment , const segment );int main() std::cin current.s.x current.s.y current.d.x current.d.y; std::cin n; for (int i = 1; i = n; i++) double a, b; std::cin seg[i].s.x seg[i].s.y seg[i].e.x seg[i].e.y a b; seg[i].lambda = a / b; seg[i].d.x = seg[i].e.x - seg[i].s.x; seg[i].d.y = seg[i].e.y - seg[i].s.y; // iteration std::vectorstd::pairpvec, int pts; for (int _ = 1; _ = 10; _++) pts.clear(); for (int i = 1; i = n; i++) if (sign(cross(seg[i].d, current.d), 0) == 0) continue; // parallel auto res = intersect(current, seg[i]); if (do_intersect(current, seg[i])) pts.push_back(res, i); if (pts.empty()) break; std::sort(pts.begin(), pts.end(), [](const auto a, const auto b) return dist(a.first, current.s) dist(b.first, current.s); ); int idx = pts[0].second; order.push_back(idx), vis[idx] = true; pvec res = pts[0].first; pvec input_d = normalize(current.d); pvec reverse_d = -input_d.x, -input_d.y; // reverse direction pvec mirror_base = normalize(seg[idx].d); pvec normal_d = mirror_base.y, -mirror_base.x; // rotate 90 degrees if (dot(input_d, normal_d) 0) normal_d = normal_d * (-1); // 同侧 double cosA = dot(reverse_d, normal_d); assert(sign(cosA, -1) = 0 sign(cosA, 1) = 0); // cosA should be in [-1, 1] double alpha = std::acos(std::max(-1.0, std::min(1.0, cosA))); double beta = seg[idx].lambda * alpha; // angle of reflection pvec new_d; if (cross(normal_d, reverse_d) 0) new_d = rotate_anticlock(normal_d, beta); else new_d = rotate_anticlock(normal_d, -beta); res = res + new_d * 1e-5; // move a bit forward to avoid numerical issues current.s = res; current.d = new_d; current.e = current.s.x + current.d.x, current.s.y + current.d.y; if (order.empty()) std::cout NONE ; else for (auto v : order) std::cout v ; std::cout ; int sign(double a, double b) if (a b - EPS) return -1; if (a b + EPS) return 1; return 0;double cross(const pvec a, const pvec b) return a.x * b.y - a.y * b.x; double dot(const pvec a, const pvec b) return a.x * b.x + a.y * b.y; double dist(const pvec a, const pvec b) return std::sqrt((a.x - b.x) * (a.x - b.x) + (a.y - b.y) * (a.y - b.y)); double angle(const pvec a, const pvec b) double d = dot(a, b); double m = std::sqrt(dot(a, a) * dot(b, b)); return std::acos(d / m);pvec normalize(const pvec v) double len = std::sqrt(dot(v, v)); return v.x / len, v.y / len;pvec rotate_anticlock(const pvec v, const double ang) double cosa = std::cos(ang); double sina = std::sin(ang); return v.x * cosa - v.y * sina, v.x * sina + v.y * cosa;bool on_segment(const pvec p, const segment seg) pvec v1 = seg.d; pvec v2 = p.x - seg.s.x, p.y - seg.s.y; pvec v3 = p.x - seg.e.x, p.y - seg.e.y; return sign(cross(v1, v2), 0) == 0 sign(dot(v2, v3), 0) = 0;bool do_intersect(const segment lazer, const segment seg) pvec pt = intersect(lazer, seg); pvec dvec = pt.x - lazer.s.x, pt.y - lazer.s.y; return on_segment(pt, seg) sign(dot(dvec, lazer.d), 0) = 0;pvec intersect(const segment a, const segment b) double div = cross(b.d, a.d); pvec dif = a.s.x - b.s.x, a.s.y - b.s.y; double t = cross(dif, b.d) / div; return a.s.x + a.d.x * t, a.s.y + a.d.y * t; [SHOI2015] 零件组装机 排除掉不连通、自环、重边的情况后，对于一张连通图 GGG，拿出和 000 相邻的节点 {v}\\{v\\}{v}，考察一下 sizesizesize 可能的取值。根据题意我们有 size≤⌊n2⌋size\\le \\lfloor \\frac{n}{2} \\rfloorsize≤⌊2n​⌋，这是题目规定 由于和 000 邻接，所以对于 vi≥size∧vi≡0(modsize)v_i\\ge size \\land v_i\\equiv 0\\pmod {size}vi​≥size∧vi​≡0(modsize) 的节点来说，都应该和 000 邻接。 那么，只要我们找到了这样的 sizesizesize 之后，就可以把这两部分之间的边全部断开，形成两张导出子图，再递归判断即可。 于是我们的任务变成了，怎么找到这样的 sizesizesize. 首先可以想到，sizesizesize 应该至多是 ≥size\\ge size≥size 且与 000 邻接的 viv_ivi​ 的最大公约数。例如，G[0]={1,2,4,6,8}G[0]=\\{1,2,4,6,8\\}G[0]={1,2,4,6,8}，那么 size≤4size \\le 4size≤4，如果 size=4size=4size=4，则 4,6,8=0(mod4)4,6,8=0\\pmod 44,6,8=0(mod4) 而这显然不对，模数应该是 222 才能让这 333 个数和 000 连边，于是 (4,6,8)=2(4,6,8)=2(4,6,8)=2. 所以为了让 4=6=8=0(modp)4=6=8=0 \\pmod p4=6=8=0(modp)，那么必须有 p∣(4,6,8)p|(4,6,8)p∣(4,6,8). 那么 sizesizesize 可能是 ppp 的约数吗？我们可以断言不可能，因为如果 sizepsize\\lt psizep 的话，那么 4+size64+size\\lt 64+size6 也应该和 000 连边，但是并没有，所以我们只需要检验 size=p=2size=p=2size=p=2 的情况，也就是 v[i]=suffix_gcd[i]v[i]=\\texttt{suffix\\_gcd}[i]v[i]=suffix_gcd[i]，然后 O(nlog⁡n)O(n\\log n)O(nlogn) 检查是否正确连边、以及删去边，这一点可以用 std::vectorstd::setint 进行维护。总时间复杂度为 O(nlog⁡2n)O(n\\log^2 n)O(nlog2n) Code #include iostream#include numeric#include set#include vectorconstexpr int MAXN = 100005;using vi = std::vectorint;using si = std::setint;struct UnionFind vi fa, size; UnionFind(int n) : fa(n), size(n, 1) for (int i = 0; i n; ++i) fa[i] = i; int root(int u) return u == fa[u] ? u : fa[u] = root(fa[u]); bool same(int u, int v) return root(u) == root(v); void merge(int u, int v) int fu = root(u), fv = root(v); if (fu == fv) return; if (size[fu] size[fv]) std::swap(fu, fv); fa[fv] = fu; size[fu] += size[fv]; bool check_connected() bool ok = true; for (int i = 1; i fa.size(); ++i) if (!same(i, 0)) ok = false; break; return ok; ;bool dfs(std::vectorsi G, int L, int R) if (L == R) return true; int length = R - L + 1; int max_size = length / 2; int begin = L; vi nodes; for (auto v : G[begin]) if (v = L v = R) nodes.push_back(v - L); if (nodes.empty()) return false; int size = nodes.size(); vi suffixgcd(size); suffixgcd[size - 1] = nodes[size - 1]; for (int i = size - 2; i = 0; i--) suffixgcd[i] = std::gcd(suffixgcd[i + 1], nodes[i]); int c_size = -1; for (int i = size - 1; i = 0; i--) if (suffixgcd[i] == nodes[i] nodes[i] = max_size) c_size = nodes[i]; break; if (c_size 1) return false; // remove edges for (int u = L + c_size; u = R; u++) if (!G[u].contains(L + (u - L) % c_size)) return false; // no such edge G[u].erase(L + (u - L) % c_size); G[L + (u - L) % c_size].erase(u); for (int u = L; u L + c_size; u++) if (G[u].empty()) continue; if (*G[u].rbegin() = L + c_size) return false; for (int u = L + c_size; u = R; u++) if (G[u].empty()) continue; if (*G[u].begin() L + c_size) return false; return dfs(G, L, L + c_size - 1) dfs(G, L + c_size, R);void run() int n, m; std::cin n m; UnionFind uf(n); std::vectorsi G(n); bool is_valid = true; for (int i = 0, u, v; i m; i++) std::cin u v; if (u == v || G[u].contains(v)) is_valid = false; G[u].insert(v); G[v].insert(u); uf.merge(u, v); is_valid = uf.check_connected(); if (!is_valid) return void(std::cout NO ); else std::cout (dfs(G, 0, n - 1) ? YES : NO );int main() std::cin.tie(nullptr)-sync_with_stdio(false); int T; std::cin T; while (T--) run();"},{"title":"[2/8] Codeforces Round 1025 (Div. 2)","path":"/wiki/algo_contests/cf2109.html","content":"A. It’s Time to Duel 不合法的就两个条件，满足任何一个即不合法： 总和超过 n−1n-1n−1，因为 n−1n-1n−1 场比赛最多 n−1n-1n−1 个胜者 连续两个 000。这是因为他们之间必有一场比赛，因此必有一个胜者 Code #include headers/io/iov2.hpp#include numeric#include vectorIO::IO io;void run() int n = io.scanint(); std::vectorint s = io.scanstd::vectorint(n); if (std::accumulate(s.begin(), s.end(), 0) = n) return io.println(YES); // consecutive 0s for (int i = 0; i n - 1; i++) if (s[i] == 0 s[i + 1] == 0) return io.println(YES); io.println(NO);int main() int T = io.scanint(); while (T--) run(); B. Slice to Survival 如果换个先手，让 Fouad 先移动，那么他一定会移动到中心的位置，Mouf 每次切只能切掉一半。这时的总次数就是 ⌈log⁡2n⌉×⌈log⁡2m⌉\\lceil \\log_2 n\\rceil \\times \\lceil \\log_2 m\\rceil⌈log2​n⌉×⌈log2​m⌉. 但是现在是 Mouf 先手，所以我们考虑把第一次的先手提出来单独计算，于是剩下的就和上面一样了。总次数 1+min⁡{⌈log⁡2n⌉+⌈log⁡2min⁡(b,m−b+1)⌉,⌈log⁡2min⁡(a,n−a+1)⌉+⌈log⁡2m⌉} \\gdef\\clog#1{\\lceil\\log_2 #1\\rceil} 1+\\min\\Bigg\\{ \\clog{n}+\\clog{\\min(b,m-b+1)}, \\clog{\\min(a,n-a+1)}+\\clog{m} \\Bigg\\} 1+min{⌈log2​n⌉+⌈log2​min(b,m−b+1)⌉,⌈log2​min(a,n−a+1)⌉+⌈log2​m⌉} Code #include algorithm#include headers/io/iov2.hppIO::IO io;using i64 = long long;void run() i64 n, m, a, b; io.read(n, m, a, b); auto clog2 = [](i64 x) return x = 1 ? 0 : 64 - __builtin_clzll(x - 1); ; io.println(1 + std::min(clog2(n) + clog2(std::min(b, m - b + 1)), clog2(std::min(a, n - a + 1)) + clog2(m)));int main() int T = io.scanint(); while (T--) run();#ifndef ONLINE_JUDGE io.println(==========);#endif return 0; C1. Hacking Numbers (Easy) 想法是快速归约到一个确定的数字，然后花一步到达 target. 那么我们最多用 666 完成归约这一步骤。想到用 digit 归约：因为题目 unknown number 最大不超过 10910^9109，因此数位和最大为 818181 (对应的数为 999 个 999)，再进行一次 digit 运算则数位和最大为 161616 (对应的数为 797979)。 然后就只剩四步归约到某个确定的数上。考虑二进制（直觉说 log⁡216=4\\log_2 16=4log2​16=4），我们依次减去 20,21,22,232^0,2^1,2^2,2^320,21,22,23，于是无论如何，xxx 都会被减成 111，这个数就确定了。这样对于每个数都可以通过这 777 完成。 Code #include iostreamusing i64 = long long;int digit() std::cout digit std::endl; int d; std::cin d; return d;int add(i64 x) std::cout add x std::endl; int d; std::cin d; return d;int mul(i64 x) std::cout mul x std::endl; int d; std::cin d; return d;int div(i64 x) std::cout div x std::endl; int d; std::cin d; return d;void finish() std::cout ! std::endl; int d; std::cin d;void run() i64 target; std::cin target; digit(), digit(); for (int i = 3; i = 0; i--) add(-(1 i)); add(target - 1); finish();int main() int T = 1; std::cin T; while (T--) run(); C2. Hacking Numbers (Medium) 想法依然是快速归约到一个数字。上一题我们用了两次 digit，这一次，我们考虑先 ×9\\times 9×9，这样其数位和一定是 999 的倍数，而且最多 101010 位数，因此数位和还一定 ≤90\\le 90≤90，于是，再做一次数位和，我们就一定可以得到 999。然后再花一步得到结果即可。 D. D/D/D 想到了大致做法但是小细节想错了 orz 首先要考虑到一件事：如果我们可以用 SSS 步到达点 iii，那么我们也可以用 S+2k,k∈NS+2k,k\\in\\NS+2k,k∈N 步到达点 iii，方法是选一条边 (u,v)(u,v)(u,v) 来回走 u→v→u…u\\to v\\to u \\dotsu→v→u…. 因此我们只需要维护两个东西，一个是“通过最少的奇数步到达点 iii” dp[i][1]dp[i][1]dp[i][1]，另一个是“通过最少的偶数步到达点 iii” dp[i][0]dp[i][0]dp[i][0]. 因为只关心最少，我们直接 BFS，同时注意转移 dp[u][0]=min⁡(u,v)∈E(dp[v][1]+1)dp[u][1]=min⁡(u,v)∈E(dp[v][0]+1) dp[u][0]=\\min_{(u,v)\\in E} (dp[v][1]+1)\\\\ dp[u][1]=\\min_{(u,v)\\in E} (dp[v][0]+1) dp[u][0]=(u,v)∈Emin​(dp[v][1]+1)dp[u][1]=(u,v)∈Emin​(dp[v][0]+1) Code #include array#include headers/io/iov2.hpp#include queue#include utility#include vectorIO::IO io;using i64 = long long;void run() auto [n, m, l] = io.scanint, int, int(); std::vectori64 a = io.scandecltype(a)(l); i64 max_even = 0, max_odd = 0, sum = 0; i64 min_even = 1e18, min_odd = 1e18; for (auto i : a) sum += i; if (i % 2 == 0) min_even = std::min(min_even, i); else min_odd = std::min(min_odd, i); max_even = (sum % 2 == 0 ? sum : sum - min_odd); max_odd = (sum % 2 == 1 ? sum : sum - min_odd); std::vectorstd::vectorint G(n); for (int i = 0; i m; i++) auto [u, v] = io.scanint, int(); u--, v--; G[u].push_back(v); G[v].push_back(u); // BFS tree std::vectorstd::arrayi64, 2 dp(n, static_castint(1e18), static_castint(1e18)); std::queuestd::pairint, i64 q; q.push(0, 0); dp[0][0] = 0; // start with even while (!q.empty()) auto [u, d] = q.front(); q.pop(); i64 parity = d % 2; // 0 for even, 1 for odd for (auto v : G[u]) if (dp.at(v).at(!parity) dp.at(u).at(parity) + 1) dp.at(v).at(!parity) = dp.at(u).at(parity) + 1; q.push(v, d + 1); io.set_delim(); for (int i = 0; i n; i++) if (max_even = dp.at(i).at(0) || max_odd = dp.at(i).at(1)) io.print(1); else io.print(0); io.println();int main() int T = io.scanint(); while (T--) run();#ifndef ONLINE_JUDGE io.println(==========);#endif return 0;"},{"title":"[6/6] CodeForces Round 1026 (Div. 2)","path":"/wiki/algo_contests/cf2110.html","content":"这次写了四道题，E 题有思路但是不会写，再接再厉吧 A. Fashionable Array 观察到 nnn 非常小，只有 505050. 因此我们可以直接对 A[]A[]A[] 排序后，用 O(n2)O(n^2)O(n2) 暴力枚举 min⁡,max⁡\\min,\\maxmin,max 即可。唯一值得注意的是，min⁡,max⁡\\min,\\maxmin,max 可以是同一个数。 Code #include algorithm#include headers/io/io.hpp#include vectorIO::IO io;void run() int n = io.scanint(); std::vectorint mp(n); io.read(mp); std::ranges::sort(mp); int ans = 1e9; for (int i = 0; i n; i++) for (int j = i; j n; j++) if ((mp[i] + mp[j]) % 2 != 0) continue; ans = std::min(ans, n - (j - i + 1)); io.println(ans);int main() int T = io.scanint(); while (T--) run(); B. Down with Brackets 因为需要且必须删除一个左括号、一个右括号，考虑两种情况： 删的右括号在左括号前面 我们可以证明这个情况是不行的。由于原串已经是合法的括号序了，令左括号为 ci=1c_i=1ci​=1、右括号为 ci=−1c_i=-1ci​=−1，则对于每一个位置都有 ∀i,f(i)=∑1≤j≤icj≥0 \\forall i, f(i)=\\sum_{1\\le j\\le i} c_j \\ge 0 ∀i,f(i)=1≤j≤i∑​cj​≥0那么，如果先删右括号，这个和式必然不会减小。比如说删除了 iii 位置的 ')' 和 jjj 位置的 '(' 且有 iji\\lt jij，那么 f(k),kif(k),k\\lt if(k),ki 都不变，f(k),ikjf(k),i\\lt k\\lt jf(k),ikj 会变大，f(k),kjf(k),k\\gt jf(k),kj 不变。所以这个串必然还是合法的括号序 删的左括号在右括号前面 对于这种情况的话，我们发现，如果某个位置上 f(i)=0f(i)=0f(i)=0，那么删掉它（或者它之前的一个 '('）就会让括号序不合法 Code #include headers/io/io.hpp#include stringIO::IO io;void run() std::string s = io.scanstd::string(); int n = s.length(); std::vectorint pf(n + 1); pf[0] = 0; for (int i = 1; i = n; i++) if (s[i - 1] == () pf[i] = pf[i - 1] + 1; else pf[i] = pf[i - 1] - 1; if(in pf[i] == 0) io.println(YES); return; io.println(NO);int main() int T = io.scanint(); while (T--) run(); C. Racing 合法性比较容易想到，就是用 [li,ri][l_i,r_i][li​,ri​] 维护走完 did_idi​ 后可能的高度，判断和规定的区间是否有交集。没有则不合法，否则一定合法。 对于构造答案，我们从任意一个结束时的合法值出发，然后倒着看 did_idi​。如果符合要求的区间高度，则下降；否则不下降。 Code #include headers/io/io.hpp#include utilityusing pii = std::pairint, int;IO::IO io;void run() int n = io.scanint(); std::vectorint d(n); std::vectorpii a(n); io.read(d, a); std::vectorpii inter(n + 1, 0, 0); for (int i = 1; i = n; i++) if (d[i - 1] != -1) inter[i].first = inter[i - 1].first + d[i - 1]; inter[i].second = inter[i - 1].second + d[i - 1]; else inter[i].first = inter[i - 1].first; inter[i].second = inter[i - 1].second + 1; inter[i].first = std::max(inter[i].first, a[i - 1].first); inter[i].second = std::min(inter[i].second, a[i - 1].second); if (inter[i].first inter[i].second) io.println(-1); return; // possible int H = inter[n].first; for (int i = n; i 0; i--) if (d[i - 1] != -1) H -= d[i - 1]; else if (H - 1 = inter[i - 1].first H - 1 = inter[i - 1].second) H -= 1, d[i - 1] = 1; else d[i - 1] = 0; for (auto i : d) io.print(i, ); io.println();int main() int T = io.scanint(); while (T--) run(); D. Fewer Battery 考虑任意一条路径，我们发现如果走整条路径的话，终点时手上的电池数应该等于路径上的最大边权（当然前提要保证有足够多的电池可以走过这些边） 所以我们可以使用二分答案，过滤 w≥midw\\ge \\texttt{mid}w≥mid 的边，然后检查剩下的边是否可以成功到达终点。 Code #include headers/io/iov2.hpp#include algorithm#include utility#include vectorusing i64 = long long;using pii = std::pairint, i64;constexpr i64 V = -1e10;IO::IO io; void run() auto [n, m] = io.scanint, int(); std::vectori64 b(n); io.read(b); std::vectorstd::vectorpii adj(n); std::vectori64 ws; for (int i = 0; i m; i++) auto [u, v, w] = io.scanint, int, i64(); u--, v--; adj[u].emplace_back(v, w); ws.push_back(w); std::vectori64 dp(n, V); std::ranges::sort(ws); ws.erase(std::unique(ws.begin(), ws.end()), ws.end()); i64 l = -1, r = ws.size(); auto ck = [](i64 mid) - bool std::ranges::fill(dp, V); dp[0] = b[0]; for (int u = 0; u n; u++) if (dp[u] == V) continue; for (auto [v, w] : adj[u]) if (w mid) continue; if (dp[u] w) continue; dp[v] = std::max(dp[v], dp[u] + b[v]); return dp[n - 1] = 0; ; while (l + 1 r) i64 mid = l + ((r - l) 1); if (ck(ws[mid])) r = mid; else l = mid; io.println(r == ws.size() ? -1 : ws[r]); int main() int T = io.scanint(); while (T--) run(); E. Melody 考虑左侧一列点位为 volume，右侧一列点为 pitch，条件相当于要求任意相邻两项是 v 不同、p 不同这样交错下去。 所以按上面这样建图的话，这个问题就是二分图上找欧拉路径 Code #include algorithm#include headers/io/iov2.hpp#include map#include ranges#include utility#include vector#include rangesusing i64 = long long;using pii = std::pairint, int;IO::IO io;void run() int n = io.scanint(); auto vp = io.scanstd::vectorpii(n); std::vectorint vs, ps; for (auto [v, p] : vp) vs.push_back(v); ps.push_back(p); std::ranges::sort(vs), std::ranges::sort(ps); vs.erase(std::unique(vs.begin(), vs.end()), vs.end()); ps.erase(std::unique(ps.begin(), ps.end()), ps.end()); int numv = vs.size(), nump = ps.size(); int num = numv + nump; std::vectorstd::vectorpii G(num); std::vectorint deg(num, 0); std::mappii, int index; for (int i = 0; i n; i++) auto [v, p] = vp[i]; v = std::lower_bound(vs.begin(), vs.end(), v) - vs.begin(); p = std::lower_bound(ps.begin(), ps.end(), p) - ps.begin() + numv; deg[v]++, deg[p]++; G[v].push_back(p, i); G[p].push_back(v, i); index[v, p] = i; index[p, v] = i; std::vectorint used(n, 0); std::vectorint ans; std::vectorint cur(num, 0); auto dfs = [](auto F, int u) - void while(cur.at(u) G.at(u).size()) auto [v, id] = G[u][cur[u]]; cur[u]++; if (used[id]) continue; used[id] = 1; F(F, v); ans.push_back(u); ; int root = 0, cnt = 0; for (int i = 0; i num; i++) if (deg[i] % 2 == 1) cnt++, root = i; dfs(dfs, root); if (ans.size() != n + 1 || cnt 2) io.println(NO); return; auto pt = ans | std::views::adjacent_transform2([](int a, int b) return index[a, b] + 1; ); io.println(YES); std::ranges::for_each(pt, [](int x) io.print(x), io.print( ); ); io.println();int main() int T = io.scanint(); while (T--) run(); F. Faculty 最没有注意力的一集…… 我们需要观察到以下几点： min⁡(x,y)≤f(x,y)≤max⁡(x,y),x≠y\\min(x,y)\\le f(x,y)\\le \\max(x,y), x e ymin(x,y)≤f(x,y)≤max(x,y),x=y 这个结论的证明比较简单。不妨设 xyx\\lt yxy，则令 y=kx+r,k≥1∧0≤rxy=kx+r,k\\ge 1 \\land 0\\le r\\lt xy=kx+r,k≥1∧0≤rx. 那么 x≤f(x,y)=x+r≤kx+r=y x\\le f(x,y)=x+r\\le kx+r=y x≤f(x,y)=x+r≤kx+r=y故得证 考虑 xyzx\\lt y\\lt zxyz，则 f(x,y)≤f(y,z)f(x,y)\\le f(y,z)f(x,y)≤f(y,z) 由 (1) 可证，f(x,y)≤max⁡(x,y)=y=min⁡(y,z)≤f(y,z)f(x,y)\\le \\max(x,y)=y=\\min(y,z)\\le f(y,z)f(x,y)≤max(x,y)=y=min(y,z)≤f(y,z) 这个结论也告诉我们，对于任意一个数组 a[1…n]a[1\\dots n]a[1…n]，实际上只有 nnn 个值需要检查：即 f(a1,amax),f(a2,amax)…,f(an,amax)f(a_1,a_{max}),f(a_2,a_{max})\\dots, f(a_n,a_{max})f(a1​,amax​),f(a2​,amax​)…,f(an​,amax​) 若 xy2xx\\lt y\\lt 2xxy2x，则 f(x,y)=yf(x,y)=yf(x,y)=y 也可以从 (1) 证明。此时 y=kx+r ⟹ k=1y=kx+r\\implies k=1y=kx+r⟹k=1，故 f(x,y)=x+r=yf(x,y)=x+r=yf(x,y)=x+r=y. 有了这几点后我们就可以利用势能分析法了. 设新加入的数为 aia_iai​，a1:i−1a_{1:i-1}a1:i−1​ 的最大值为 amaxa_{max}amax​ 如果 ai≤amaxa_i\\le a_{max}ai​≤amax​，那么根据 (2)，我们只需要考虑 f(ai,amax)f(a_i,a_{max})f(ai​,amax​) 会不会成为答案即可。 如果 amaxai2amaxa_{max}\\lt a_i\\lt 2a_{max}amax​ai​2amax​，那么根据 (3)，我们只需要考虑 f(ai,amax)=aif(a_i,a_{max})=a_if(ai​,amax​)=ai​ 会不会成为答案即可。 否则若 ai≥2amaxa_i\\ge 2a_{max}ai​≥2amax​，那么我们就遍历数组暴力求解 1/2 两步都是 O(1)O(1)O(1) 的，对于 (3)，由于每一次 amaxa_{max}amax​ 都至少翻倍，因此最多执行 O(log⁡V)O(\\log V)O(logV) 次第三步，因此这样的时间复杂度是 O(nlog⁡V)O(n\\log V)O(nlogV) Code #include headers/io/iov2.hppIO::IO io;void run() int n = io.scanint(); std::vectorint a = io.scanstd::vectorint(n); auto F = [](int x, int y) return x % y + y % x; ; int max = a[0]; int ans = 0; for (int i = 0; i n; i++) ans = std::max(ans, F(max, a[i])); if (max a[i] a[i] 2 * max) max = a[i]; ans = std::max(ans, F(max, a[i])); else if (a[i] = 2 * max) max = a[i]; for (int j = 0; j = i; j++) ans = std::max(ans, F(a[i], a[j])); io.print(ans); io.println();int main() int T = io.scanint(); while (T--) run();"},{"title":"Codeforces Round 2124 (Div. 1+2)","path":"/wiki/algo_contests/codeforces-2124.html","content":"Codeforces Round 2124 (Div. 1+2) 可惜，感觉很多时候时间在找思路上面和证明思路上面，找思路还是有点慢了。 A. Deranged Deletions 我们只需要找到一个相邻的逆序对即可，有则可以把所有其他数都删完。若没有这样的逆序对，则说明原序列里所有数已经是递增的了，此时不管怎么删，都不会改变这些数的相对顺序，因此无解。 #include iostream#include vectorvoid run() int n; std::cin n; std::vectorint a(n); for (int i = 0; i n; ++i) std::cin a[i]; for (int i = 0; i n; i++) for (int j = i + 1; j n; j++) if (a[i] a[j]) std::cout YES 2 ; std::cout a[i] a[j] ; return; std::cout NO ;int main(int argc, char *argv[]) int T; std::cin T; while (T--) run(); return 0; B. Minimise Sum 首先，我们可以又一个大致的想法：把 000 尽可能放前面，这样后面的 prefix min 就都是 000，大概率能更小一点。 所以，我们贪心地考虑前 333 个位置。如果 a1a2a_1\\gt a_2a1​a2​，则令 (i,j)=(1,2)(i,j)=(1,2)(i,j)=(1,2)，总和为 a1+a2a_1+a_2a1​+a2​；若 a1a2a_1\\lt a_2a1​a2​，则令 (i,j)=(2,3)(i,j)=(2,3)(i,j)=(2,3)，总和为 a1+a1a_1+a_1a1​+a1​，于是此时的总和最小可以达到 a1+min⁡(a1,a2) a_1+\\min(a_1,a_2) a1​+min(a1​,a2​)而 S≥a1+min⁡(a1,a2)S\\ge a_1+\\min(a_1,a_2)S≥a1​+min(a1​,a2​)，所以这就是最小。 C. Subset Multiplication D. Make a Palindrome E. Make it Zero F1. Appending Permutations (Easy Version) F2. Appending Permutations (Hard Version) G. Maximise Sum H. Longest Good Subsequence I. Lexicographic Partition"},{"title":"IOI 2024","path":"/wiki/algo_contests/ioi-2024.html","content":"象形文字序列 首先需要观察到一个性质： UCS 的长度 令字符集合 SSS，对于某个字符 s∈Ss\\in Ss∈S，其在 AAA 中出现 CA(s)C_A(s)CA​(s) 次，在 BBB 中出现 CB(s)C_B(s)CB​(s) 次，则 UCS 的长度必须为 ∑s∈Smin⁡(CA(s),CB(s)) \\sum_{s\\in S} \\min(C_A(s), C_B(s)) s∈S∑​min(CA​(s),CB​(s))【简要证明】不妨 CA(s)≤CB(s)C_A(s)\\le C_B(s)CA​(s)≤CB​(s)，如果 UCS 里 sss 只出现了 CA(s)−1C_A(s)-1CA​(s)−1 次，那么由于 ss…s⏟CA(s)\\underbrace{ss\\dots s}_{C_A(s)}CA​(s)ss…s​​ 是 A,BA,BA,B 共同的子串，但是并不是 UCS 的子串，这与 UCS 的定义矛盾。因此 UCS 的长度其实是可以确定的。 那么，既然我们知道了 UCS 的字符构成，我们开始思考怎么去从给定的字符中构造 UCS. 由于字符串长度较长，所以应该是 O(n)O(n)O(n) 或者 O(nlog⁡n)O(n\\log n)O(nlogn) 的构造。 如果对于某个字符 s∈Ss\\in Ss∈S 且 CA(s)≤CB(s)C_A(s)\\le C_B(s)CA​(s)≤CB​(s)，就说明 UCS 里出现的所有 sss 刚好和 AAA 全部匹配上，把 sss 在 AAA 里所有出现的位置记为 sss-critical-in-AAA. 类似地有 sss-critical-in-BBB. 把 sss 记为 critical char of A/BA/BA/B，sss 在 A,BA,BA,B 里面的下标记为 critical position. 尝试一下“贪心构造再检查”的策略，那就是考虑怎么把 critical char of A,BA,BA,B 放入 UCS. 同时我们要考虑到 critical char 之间的顺序：例如样例一，AAA 的 critical char 为 0,1,0,20,1,0,20,1,0,2，那么 UCS 里就不能是 2,0,1,02,0,1,02,0,1,0（不然的话 222-critical-in-AAA 就无法匹配了）。 由此我们得到了一个贪心的重要依据：字符串 A,BA,BA,B 里的 critical char 必须按照这个 char 在 A/BA/BA/B 内的顺序进行排列，也就是类似于双指针排序的过程（如果 s1s_1s1​ 在 AAA 字符串里排在 s2s_2s2​ 前面，那么 s1s_1s1​ 在 UCS 里也必须排在 s2s_2s2​ 前面）。 所以，我们可以用双指针指向 A,BA,BA,B’s critical positions of sss，每次判断该放 critical char of BBB 还是 of AAA. 然后，我们考虑如何判断。假设已经有了一段 UCS，分别匹配了前缀 A[1,i],B[1,j]A[1,i],B[1,j]A[1,i],B[1,j]，当前的 critical position of A,BA,BA,B 分别为 kA,kBk_A,k_BkA​,kB​. 如果 A[kA]A[k_A]A[kA​] 上的字符可以放入 UCS，那么： B[j,kB−1]B[j,k_B-1]B[j,kB​−1] 这一段子串里，应该有一个字符等于 A[kA]A[k_A]A[kA​]，这样才能匹配上并且 kBk_BkB​ 这个字符不会被跳过（被跳过就无法放入 UCS 了） 放入 A[kA]A[k_A]A[kA​] 后，UCS 匹配的前缀是 A[1,kA]A[1,k_A]A[1,kA​]。为了让 B[kB]B[k_B]B[kB​] 也能够完成匹配，在 A[kA+1,end]A[k_A+1, \\texttt{end}]A[kA​+1,end] 这段后缀里，应该有足够多的字符让 BBB’s remaining critical chars 匹配。 对 B[kB]B[k_B]B[kB​] 也是同理。 如果都不能放，那么 UCS 无解。如果都可以放，那么也就是说，A,BA,BA,B 之间有两个子序列，一个子序列在这个位置是 A[kA]A[k_A]A[kA​] 另一个却是 B[kB]B[k_B]B[kB​]（这两个字符不一样），而且长度还都是一样的，这样的情况下，这两个子序列不可能同时是 UCS 的子序列，所以也无解。 构造出 UCS 后，我们再来检查构造出来的 UCS 是否合法。对 i∈[1,n]i\\in [1,n]i∈[1,n]，我们处理出对应的 min⁡j\\min jminj 使得 A[1,i]A[1,i]A[1,i] 可以匹配 B[1,j]B[1,j]B[1,j] 而无法匹配 B[1,j−1]B[1,j-1]B[1,j−1]. (prepare()) Code #include algorithm#include iostream#include utility#include vectorusing vi = std::vectorint;constexpr int V = 2e5 + 5;struct Sequence int length; int pos; vi first_of; vi next_same; vi count_same; vi data; Sequence(vi T) : dataT length = T.size(), pos = 0; first_of.assign(V, length); next_same.assign(length + 1, length); count_same.assign(length + 1, 0); for (int i = length - 1; i = 0; i--) next_same[i] = first_of[T[i]]; first_of[T[i]] = i; count_same[i] = count_same[next_same[i]] + 1; int next(int ch) const return first_of[ch]; int remain(int ch) const int p = first_of[ch]; return p length ? count_same[p] : 0; void step() first_of[data[pos]] = next_same[pos]; pos++; void move_to(int new_pos) while (pos new_pos) step(); void match(int ch) move_to(first_of[ch] + 1); ;vi calculate_ucs(vi A, vi B, vi pickA, vi pickB) int n = A.size(), m = B.size(); vi cntA(V, 0), cntB(V, 0); for (int x : A) cntA[x]++; for (int x : B) cntB[x]++; vi partA, partB; for (int i = 0; i n; i++) if (cntA[A[i]] = cntB[A[i]]) partA.push_back(i); for (int i = 0; i m; i++) if (cntB[B[i]] cntA[B[i]]) partB.push_back(i); partA.push_back(n), partB.push_back(m); Sequence seqA(A), seqB(B); Sequence skipA(A), skipB(B); auto pA = partA.begin(), pB = partB.begin(); skipA.move_to(*pA), skipB.move_to(*pB); vi candidate; while (*pA != n or *pB != m) bool can_putA = true, can_putB = true; if (*pA != n) // can we fill A[i]? can_putA = seqB.remain(A[*pA]) skipB.remain(A[*pA]); if (*pB != m) can_putA = skipA.remain(B[*pB]) = skipB.remain(B[*pB]); else can_putA = false; if (*pB != m) can_putB = seqA.remain(B[*pB]) skipA.remain(B[*pB]); if (*pA != n) can_putB = skipB.remain(A[*pA]) = skipA.remain(A[*pA]); else can_putB = false; std::cerr pA: *pA , pB: *pB , can_putA: can_putA , can_putB: can_putB ; if (can_putA == can_putB) return -1; else if (can_putA) int cha = A[*pA]; candidate.push_back(cha); seqB.match(cha); std::swap(seqA, skipA); seqA.step(); pA++; skipA.move_to(*pA); else int chb = B[*pB]; candidate.push_back(chb); seqA.match(chb); std::swap(seqB, skipB); seqB.step(); pB++; skipB.move_to(*pB); pickA.push_back(seqA.pos - 1); pickB.push_back(seqB.pos - 1); return candidate;vi prepare(vi A, vi B) int n = A.size(), m = B.size(); std::vectorvi appear(V); for (int i = 0; i m; i++) appear[B[i]].push_back(i); for (auto v : appear) v.push_back(m); vi last(V, -1); std::vectorstd::pairint, int stack; stack.push_back(-1, -1); vi match(n, -1); for (int i = 0; i n; i++) int L = last[A[i]]; int where = std::lower_bound(stack.begin(), stack.end(), std::make_pair(L, -1))-second; if (where != m) where = *std::upper_bound(appear[A[i]].begin(), appear[A[i]].end(), where); match[i] = where; while (!stack.empty() stack.back().second = where) stack.pop_back(); stack.push_back(i, where); last[A[i]] = i; return match;bool check(vi A, vi B, vi c, vi posA, vi posB) int n = A.size(), m = B.size(), t = c.size(); vi matchA = prepare(A, B); vi atA(n, -1), prev_atA(n + 1, -1); for (int i = 0; i t; i++) atA[posA[i]] = i; prev_atA[posA[i] + 1] = i; for (int i = 1; i = n; i++) if (prev_atA[i] == -1) prev_atA[i] = prev_atA[i - 1]; for (int i = 0; i n; i++) if (atA[i] != -1) continue; int index = prev_atA[i]; if (index != -1 matchA[i] = posB[index]) return false; return true;vi ucs(vi A, vi B) vi posa, posb; auto ans = calculate_ucs(A, B, posa, posb); if (ans.size() == 1 ans[0] == -1) return -1; if (!check(A, B, ans, posa, posb)) return -1; if (!check(B, A, ans, posb, posa)) return -1; return ans;int main() int n, m; std::cin n m; vi A(n), B(m); for (int x : A) std::cin x; for (int x : B) std::cin x; vi result = ucs(A, B); std::cout result.size() ; for (auto x : result) std::cout x ; std::cout ;"},{"title":"牛客练习赛 139","path":"/wiki/algo_contests/nowcoder-practice-139.html","content":"A. B/C. 注意到题目描述里是从第一列的给定位置走到第 mmm 列的给定位置，并且我们往右走是无法回头的。 所以这个提醒我们可以按列进行考虑。 D. 树到云端 因为通过 val[]{val}[]val[] 计算出来的 T[]T[]T[] 数组是已知的，而 val[]{val}[]val[] 是未知的，这就相当于我们在解方程，于是就可以想到消元（其实就是作差）。考虑以 111 为根，考虑树边 u→vu\\to vu→v 其中 dep[u]dep[v]\\texttt{dep}[u]\\texttt{dep}[v]dep[u]dep[v]，则有 T[u]−T[v]=∑i∈subtree(v)val[i]−∑i∉subtree(v)val[i]=(2×∑i∈subtree(v)val[i])−S \\begin{aligned} T[u]-T[v]=\\sum_{i\\in \\text{subtree(v)}}val[i]-\\sum_{i otin\\text{subtree(v)}}val[i]\\\\ =\\Big(2\\times\\sum_{i\\in\\text{subtree(v)}}val[i]\\Big)-S \\end{aligned} T[u]−T[v]​=i∈subtree(v)∑​val[i]−i∈/subtree(v)∑​val[i]=(2×i∈subtree(v)∑​val[i])−S​这里 S=∑ival[i]S=\\sum_i val[i]S=∑i​val[i]. 我们再把所有边加起来： 这一步我做的时候没有想到…… -.- ∑(u→v)∈Edep[u]dep[v]T[u]−T[v]=−(n−1)S+2(∑v≠1∑i∈subtree(v)val[i]) \\begin{aligned} \\sum_{(u\\to v)\\in E}^{\\texttt{dep}[u]\\texttt{dep}[v]}T[u]-T[v] =-(n-1)S+2\\Bigg( \\sum_{v e 1}\\sum_{i\\in\\text{subtree(v)}}val[i] \\Bigg) \\end{aligned} (u→v)∈E∑dep[u]dep[v]​T[u]−T[v]​=−(n−1)S+2(v=1∑​i∈subtree(v)∑​val[i])​然后我们注意看括号里的和式，我们换一个角度考察。现在的和式是“对于每一个 vvv，统计其子树内的 val[]val[]val[] 的和”。我们把视角放回 vvv 何时可以被某个 subtree(u)\\text{subtree(u)}subtree(u) 统计到，我们发现当且仅当 uuu 是 vvv 的祖先时可以，而 vvv 有多少的祖先呢？一共 dep[v]\\texttt{dep[\\(v\\)]}dep[v] 个（这里令 dep[root]=0\\texttt{dep[root]}=0dep[root]=0，而且要注意到 subtree(u)\\text{subtree}(u)subtree(u) 要求 u≠rootu e\\texttt{root}u=root)，于是这个和式可以进一步改写为 =−(n−1)S+2(∑v≠1(val[v]×dep[v])) =-(n-1)S+2\\Bigg( \\sum_{v e 1}(\\texttt{val[\\(v\\)]}\\times \\texttt{dep[\\(v\\)]}) \\Bigg) =−(n−1)S+2(v=1∑​(val[v]×dep[v]))刚好这个和式就等于 T[1]T[1]T[1]，于是： ∑(u→v)∈ET[u]−T[v]=−(n−1)S+2T[1]S=2T[1]−∑(u→v)∈ET[u]−T[v]n−1 \\sum_{(u\\to v)\\in E}T[u]-T[v]=-(n-1)S+2T[1]\\\\ S=\\frac{2T[1]-\\sum_{(u\\to v)\\in E}T[u]-T[v]}{n-1} (u→v)∈E∑​T[u]−T[v]=−(n−1)S+2T[1]S=n−12T[1]−∑(u→v)∈E​T[u]−T[v]​所以我们也可以求出子树 vvv 的 val[]val[]val[] 和了： ∑i∈subtree(v)val[i]=S+T[u]−T[v]2 \\sum_{i\\in\\text{subtree(v)}}val[i]=\\frac{S+T[u]-T[v]}{2} i∈subtree(v)∑​val[i]=2S+T[u]−T[v]​考虑节点 uuu，那么其 val[u]val[u]val[u] 值就是其子树和减去所有儿子的子树和 val[u]=∑i∈subtree(u)val[i]−∑v∈sonu∑i∈subtree(v)val[i] val[u]=\\sum_{i\\in\\text{subtree(u)}}val[i]-\\sum_{v\\in son_u}\\sum_{i\\in\\text{subtree(v)}}val[i] val[u]=i∈subtree(u)∑​val[i]−v∈sonu​∑​i∈subtree(v)∑​val[i]对 root=1root=1root=1 特殊考虑一下。 Code #include iostream#include vectorusing i64 = long long;using vi = std::vectori64;using vvi = std::vectorvi;using tree = std::vectorstd::vectorint;int main() int n; std::cin n; tree G(n + 1); for (int i = 1, u, v; i n; i++) std::cin u v; G.at(u).push_back(v); G.at(v).push_back(u); vi T(n + 1, 0); for (int i = 1; i = n; i++) std::cin T.at(i); vi val(n + 1, 0), subtree(n + 1, 0); i64 delta = 0; auto dfs = [](auto self, int u, int fa) - void for (auto v : G.at(u)) if (v == fa) continue; delta += T.at(u) - T.at(v); self(self, v, u); ; dfs(dfs, 1, 1); i64 sumval = (2 * T.at(1) - delta) / (n - 1); auto dfs2 = [](auto self, int u, int fa) - void for (auto v : G.at(u)) if (v == fa) continue; self(self, v, u); subtree.at(u) += subtree.at(v); if (u != 1) val.at(u) = (T.at(fa) - T.at(u) + sumval) / 2 - subtree.at(u); else val.at(u) = sumval - subtree.at(u); subtree.at(u) += val.at(u); ; dfs2(dfs2, 1, 1); for (int i = 1; i = n; i++) std::cout val.at(i) [i == n]; F. 信条 首先，廻文串是回文串，我们先用马拉车 O(n)O(n)O(n) 计算出回文串，然后再在回文串的基础上判断廻文串。 除去长度为 111 的廻文串，因为廻文串满足 ww′ww′wwwwww′ww′ 的 pattern，所以长度必须为偶数，因此，在 augmented string A[]A[]A[] 里，廻文串的中心必须是 padding char (#) 考虑第 iii 个位置 A[i]=‘#’A[i]=\\texttt{`\\#}A[i]=‘#’，以其为中心的最大回文串长度为 p[i]p[i]p[i]，如下图所示，我们希望知道它是多少个廻文串的中心。 廻文串 我们关注右侧的黄色部分，注意到其实 jjj 也是一个回文中心，我们可以得出 jjj 需要满足的条件： jjj 为中心的最大回文串至少需要包住 iii 考虑以 A[i…j]A[i\\dots j]A[i…j] 为左半段的回文串，其右端点不能超过 iii 的回文半径（下图浅蓝色红色部分），即 i+1≤j≤i+pi2i+1\\le j\\le i+\\frac{p_i}{2}i+1≤j≤i+2pi​​ 我们考虑对于 iii 怎么维护满足条件的 jjj。一个想法就是，如果让某个数据结构满足 T[j]=1T[j]=1T[j]=1 表示对于 iii，jjj 满足条件，那么我只需要求和 T[i+1]+…T[i+pi2]T[i+1]+\\dots T[i+\\frac{p_i}{2}]T[i+1]+…T[i+2pi​​] 即可。那么该怎么表示 ∑i+1≤j≤i+pi2j−p[j]≤iT[j] \\sum_{i+1\\le j\\le i+\\frac{p_i}{2}}^{j-p[j]\\le i} T[j] i+1≤j≤i+2pi​​∑j−p[j]≤i​T[j]我们考虑把 jjj 挂载到 pos=j−p[j]pos=j-p[j]pos=j−p[j] 上，这样我们顺序处理的时候，如果经过 pospospos，就表明 jjj 的回文中心的字符串可以到达 pospospos 这个位置，那么对于 i≥posi\\ge posi≥pos 的 iii 来说，j−p[j]≤ij-p[j]\\le ij−p[j]≤i 就自动满足了。然后我们挂载的时候，把 T[j]T[j]T[j] 设置为 111，这样，对于位置 iii 他就可以通过查询 ∑i+1≤j≤i+pi2T[j]\\sum_{i+1\\le j\\le i+\\frac{p_i}{2}} T[j]∑i+1≤j≤i+2pi​​​T[j] 找到对 iii 来说所有满足要求的 jjj。 j 的选择 再来看第二问，这是一个典型的贪心问题。对于廻文中心在 A[i]A[i]A[i] 的字符串，我们只需要考虑最长的廻文子串即可。这样一共有 O(n)O(n)O(n) 条线段。我们按左端点排序，维护一个“已经被覆盖的区间 [l,r][l,r][l,r]”，然后顺序遍历所有线条，我们下一条线段取“左端点在 [l,r][l,r][l,r] 里、右端点最大”的线段。时间复杂度 O(nlog⁡n)O(n\\log n)O(nlogn). 取最长的廻文子串需要找到对于 iii 来说 [i+1,i+pi2][i+1,i+\\frac{p_i}{2}][i+1,i+2pi​​] 中最远的那个 111. 这一点可以用线段树完成（如果为 111，maxpos 设置为 pospospos，否则为 −1-1−1，查询区间的时候查找区间内的 maxpos）时间复杂度也为 O(nlog⁡n)O(n\\log n)O(nlogn) Code #include algorithm#include cassert#include iostream#include string#include utility#include vectorusing pii = std::pairint, int;class SegTree std::vectorint tree; std::vectorint maxpos; int n; void add(int p, int l, int r, int pos, int val) if (l == r) tree[p] += val; maxpos[p] = pos; return; int mid = l + ((r - l) 1); if (pos = mid) add(p * 2, l, mid, pos, val); else add(p * 2 + 1, mid + 1, r, pos, val); tree[p] = tree[p * 2] + tree[p * 2 + 1]; maxpos[p] = std::max(maxpos[p * 2], maxpos[p * 2 + 1]); int sum(int p, int l, int r, int ql, int qr) const if (ql r || qr l) return 0; if (ql = l r = qr) return tree[p]; int mid = l + ((r - l) 1); return sum(p * 2, l, mid, ql, qr) + sum(p * 2 + 1, mid + 1, r, ql, qr); int mr(int p, int l, int r, int ql, int qr) if (ql r || qr l) return -1; if (ql = l r = qr) return maxpos[p]; int mid = l + ((r - l) 1); return std::max(mr(p * 2, l, mid, ql, qr), mr(p * 2 + 1, mid + 1, r, ql, qr)); public: SegTree(int n_) : tree(5 * n_, 0), nn_, maxpos(5 * n_, -1) void add(int pos, int val) add(1, 0, n - 1, pos, val); int sum(int ql, int qr) const return ql = qr ? sum(1, 0, n - 1, ql, qr) : 0; int maxr(int pos, int l, int r) if (l = r) return pos; else return mr(1, 0, n - 1, l, r); int operator[](int pos) const assert(pos = 0 pos n); return sum(pos, pos); ;int main() std::string s; std::cin s; std::string aug = #; for (char c : s) aug += c; aug += #; std::vectorint maxlen; std::vectorstd::vectorint lbound(aug.size() + 1); int l = 0, r = -1; for (int i = 0, lr = aug.size(); i lr; i++) int tmp = (i r ? 0 : std::min(maxlen[l + r - i], r - i)); while (i - tmp = 0 i + tmp lr aug[i - tmp] == aug[i + tmp]) ++tmp; tmp--; maxlen.push_back(tmp); if (i + tmp r) l = i - tmp; r = i + tmp; if (i % 2 == 0) lbound.at(i - tmp).push_back(i); long long ans = 0; SegTree st(aug.size() + 1); std::vectorpii str; // L, R for (int i = 0; i aug.size(); i++) for (auto e : lbound.at(i)) assert(e % 2 == 0); st.add(e, 1); if (i % 2 == 0) int v = st.sum(i + 1, i + maxlen[i] / 2); ans += v; int len = st.maxr(i, i + 1, i + maxlen[i] / 2); if (len i) str.push_back((i + 1 - (len - i) * 2) / 2, +(i - 1 + (len - i) * 2) / 2); else str.push_back(i / 2, i / 2); std::sort(str.begin(), str.end(), [](const pii a, const pii b) return a.first b.first || (a.first == b.first a.second b.second); ); int cnt = 0, R = -1; for (int i = 0; i str.size();) int tr = -1, j = i; while (j str.size() str.at(j).first = R) tr = std::max(tr, str[j].second); j++; tr = std::max(tr, str[j].second); if (j str.size()) cnt++, R = tr; i = j + 1; std::cout ans + s.size() cnt ;"},{"title":"北京大学 2024 年《数据结构与算法A（实验班）》期末考试","path":"/wiki/algo_contests/pku-2024-ds-and-algo-A-final.html","content":"D. MST 算法流程 先对 “(边权, ID)” 进行排序（从小到大） 初始化…… 并查集，两颗线段树（一棵维护从左向右的字符串哈希值，另一棵维护从右向左的字符串哈希值） 给并查集上的每一个连通块分配一个随机数（nnn 个，初始时并查集都不连通） 初始化 vector，记录一下每一个连通块内的所有点 遍历排序过的边…… (w,id)(w,id)(w,id) 首先，计算一下 ididid 对应的边集，(1,id−1),(2,id−2),…,(id−12,id−id−12)(1,id-1), (2,id-2), \\dots, (\\frac{id-1}{2}, id-\\frac{id-1}{2})(1,id−1),(2,id−2),…,(2id−1​,id−2id−1​) 从 l=id−12,r=id−id−12l=\\frac{id-1}{2},r=id-\\frac{id-1}{2}l=2id−1​,r=id−2id−1​ 开始向外二分查找下一条要连接的边 (l−M,r+M)(l-M, r+M)(l−M,r+M) 在并查集上连接这一条边对应的两个点 l−M,r+Ml-M,r+Ml−M,r+M， 同时维护 vector（更新同一个连通块内的点，这里需要用启发式合并）。 维护 vector 的同时，在线段树上同步修改对应点的值（修改成新连通块的值），即同步维护字符串的哈希值。 每合并两个点，就把边权加入答案 最后输出答案 正确性证明 考虑根据 Kruskal 算法的思路，我们总是尝试从边权最小的边 e=(u,v)e=(u,v)e=(u,v) 开始尝试加入 MST，如果 (u,v)(u,v)(u,v) 在并查集里不连通，那么就说明这条边可以加入 MST. 现在的话，边都是以 ai+ja_{i+j}ai+j​ 的形式给出，例如对于 aka_kak​，它所代表的边为 (1,k−1),(2,k−2),…(1,k-1),(2,k-2),\\dots(1,k−1),(2,k−2),…。 如果我们给并查集里的每一个连通块分配一个字母，那么考虑并查集里的两个点 i,ji,ji,j 且我们正在考虑 aka_kak​ 满足 k=i+jk=i+jk=i+j：那么我们可以发现的一点是，如果 i,ji,ji,j 已经连通，那么他们的字母应该是相同的，否则就不相同。如果字母相同，我们就不需要在 (i,j)(i,j)(i,j) 之间连边，因为他们已经在同一个连通块里（根据 Kruskal 算法，加入 (i,j)(i,j)(i,j) 这条边会产生一个环）；否则我们就可以加入这条边，在并查集里把他们连起来。 然后我们就可以发现一件事：如果对每一条 aka_kak​ 对应的边 (i,j)(i,j)(i,j) 来说，都不需要向 MST 里添加这条边，这意味着 i,ji,ji,j 对应的值相等；而 i+j=ki+j=ki+j=k，因此总是有 val[i]=val[k−i]val[i]=val[k-i]val[i]=val[k−i]，也就是说 aka_kak​ 所对应的点 1…k−11\\dots k-11…k−1 是回文串！ 这意味着我们可以通过不断判断某一段前后缀是否回文，来看这一段前后缀是不是已经在并查集（也即 MST）上连接完毕。我们可以用二分快速进行查找和判断。 时间复杂度分析 根据 MST 的性质，MST 是一棵树，最多 n−1n-1n−1 条边，而因为每一次二分必将连接一条边，因此“二分枚举待连接的边”这个操作最多进行 n−1n-1n−1 次，即 O(n)O(n)O(n) 次。每一次二分最多在包含 nnn 条边的集合内搜索，因此二分次数是 O(nlog⁡n)O(n\\log n)O(nlogn) 的。每一次二分都需要在线段树上进行区间查询，而单次区间查询是 O(log⁡n)O(\\log n)O(logn) 的，所有二分部分的时间复杂度是 O(nlog⁡2n)O(n\\log^2 n)O(nlog2n) 接着考虑启发式合并部分的复杂度。由于每一次都将小的集合添加到大的集合里，因此每一次合并，被添加的元素所在的集合大小都会翻倍，由于最多有 nnn 个点，因此最坏情况下一个元素会被添加 log⁡n\\log nlogn 次，因此启发式合并一共会产生 O(nlog⁡n)O(n\\log n)O(nlogn) 次添加元素操作。 但是在每次添加元素的时候，我们还要维护线段树，对单点修改、区间查询线段树而言，修改一次的复杂度是 O(log⁡n)O(\\log n)O(logn)，因此启发式合并以及维护线段树的总体复杂度就是 O(nlog⁡2n)O(n\\log^2 n)O(nlog2n) 因此总体时间复杂度为 O(nlog⁡2n)O(n\\log^2n)O(nlog2n) Code #include algorithm#include cassert#include functional#include iostream#include numeric#include random#include utility#include vectorusing u64 = unsigned long long;constexpr u64 P = 4816069;std::mt19937_64 rng(std::random_device());std::vectoru64 base, rd;struct ModTree struct Node int l, r; u64 fhash, bhash; ; std::vectorNode tree; int n; Node update(Node l, Node r) Node res; res.l = l.l, res.r = r.r; res.fhash = l.fhash * base[r.r - r.l + 1] + r.fhash; res.bhash = r.bhash * base[l.r - l.l + 1] + l.bhash; return res; void init(int n) tree.assign(n * 4, Node()); this-n = n; void build(std::vectoru64 vec, int p, int l, int r) tree[p].l = l, tree[p].r = r; if (l == r) tree[p].fhash = tree[p].bhash = vec[l]; return; int mid = (l + r) 1; build(vec, p 1, l, mid); build(vec, p 1 | 1, mid + 1, r); tree[p] = update(tree[p 1], tree[p 1 | 1]); void modify(int p, int pos, u64 val) if (tree[p].l == tree[p].r) tree[p].fhash = tree[p].bhash = val; return; int mid = (tree[p].l + tree[p].r) 1; if (pos = mid) modify(p 1, pos, val); else modify(p 1 | 1, pos, val); tree[p] = update(tree[p 1], tree[p 1 | 1]); Node query(int p, int l, int r) if (l = tree[p].l tree[p].r = r) return tree[p]; int mid = (tree[p].l + tree[p].r) 1; if (r = mid) return query(p 1, l, r); else if (l mid) return query(p 1 | 1, l, r); Node res = update(query(p 1, l, mid), query(p 1 | 1, mid + 1, r)); return res; ;int main() std::ios::sync_with_stdio(false); std::cin.tie(nullptr); std::cout.tie(nullptr); int n; std::cin n; [] base.resize(n + 1), rd.resize(n + 1); base[0] = 1; for (int i = 1; i = n; i++) base[i] = base[i - 1] * P, rd[i] = rng(); (); std::vectorstd::pairu64, int vec; std::vectorstd::vectorint nodes(n + 1); for (int i = 3; i n * 2; i++) u64 x; std::cin x; vec.emplace_back(x, i); std::vectorint fa(n + 1, 0); std::iota(fa.begin(), fa.end(), 0); std::functionint(int) find = [](int x) return fa[x] == x ? x : fa[x] = find(fa[x]); ; ModTree tree; tree.init(n); tree.build(rd, 1, 1, n); for (int i = 1; i = n; i++) nodes[i].push_back(i); auto unite = [](int u, int v) u = find(u), v = find(v); if (u == v) return; if (nodes[u].size() nodes[v].size()) std::swap(u, v); fa[u] = v; for (int i : nodes[u]) nodes[v].emplace_back(i); rd[i] = rd[v]; tree.modify(1, i, rd[i]); nodes[u].clear(); ; std::sort(vec.begin(), vec.end()); long long ans = 0; for (auto [E, id] : vec) int l = (id - 1) / 2, r = id - l; int size = std::min(l, n - r + 1); int L = l - size + 1, R = r + size - 1; while (r = R) // std::cerr l r L R ; // std::cerr tree.query(1, L, l).fhash tree.query(1, r, R).bhash ; // for (int i = 1; i = n; i++) std::cerr i : rd[i] ; if (tree.query(1, L, l).fhash == tree.query(1, r, R).bhash) break; int lb = 0, ub = R - r; while (lb = ub) int mid = (lb + ub) 1; if (tree.query(1, l - mid, l).fhash != tree.query(1, r, r + mid).bhash) ub = mid - 1; else lb = mid + 1; l -= lb, r += lb; unite(l, r); ans += E; std::cout ans ; return 0;"},{"title":"CCPC 2024 广州","path":"/wiki/algo_contests/ucup038-guangzhou.html","content":"B. Add One 3 有两个 sub task: 如何确定 [l,r][l, r][l,r] 能否成为唯一的 MSS 最少需要几步 判断问题 先来回答第一个问题。因为我们只能对某个数 +1+1+1，所以对于一段区间来说，其和只能增大不能减少。考虑和 [l,r][l,r][l,r] 邻接的前缀和后缀（即 [i,l−1][i,l-1][i,l−1] 和 [r+1,j][r+1,j][r+1,j] 这两类区间），如果这两类区间的和 ≥0\\ge 0≥0，那么我们完全可以把 [l,r][l,r][l,r] 接上这个 subrange，这样 ∑[i,r]≥∑[l,r]\\sum [i,r]\\ge\\sum [l,r]∑[i,r]≥∑[l,r] 或者 ∑[l,j]≥∑[l,r]\\sum [l,j]\\ge \\sum [l,r]∑[l,j]≥∑[l,r]，这就意味着 [l,r][l,r][l,r] 永远不可能单独成为 MSS. 方案数 接下来处理最少需要几步。因为整个段需要是唯一的 MSS： 如果 [l,r][l,r][l,r] 的某个前缀和小于等于零，即 ∃k,∑i=lkai≤0\\exists k,\\sum_{i=l}^k a_i\\le 0∃k,∑i=lk​ai​≤0，那么我们完全可以扔掉这个前缀，剩下的部分 [k+1,r][k+1,r][k+1,r] 可以组成 sum 更大的 MSS。这就意味着所有前缀都必须 0\\gt 00 类似的，[l,r][l,r][l,r] 的所有后缀也都必须是 0\\gt 00. 同时，考虑不在 [l,r][l,r][l,r] 区间的 MSS，设最大的 MSS 为 MMM。如果存在这样的 MSS（不在 [l,r][l,r][l,r] 里而其和仍为 MMM），那么 [l,r][l,r][l,r] 至少需要达到 M+1M+1M+1. 所以，我们找两个下标 p1p2p_1\\lt p_2p1​p2​ 使得 [l,p1][l,p_1][l,p1​] 这个前缀与 [p2,r][p_2,r][p2​,r] 这个后缀都是负数（也可以是只有负数前缀而没有后缀，或者只有后缀没有前缀） 一个疑惑点是：难道没有可能前缀 [l,p1][l,p_1][l,p1​] 和后缀 [p2,r][p_2,r][p2​,r] 有重叠吗？这种情况下，显然只可能是 [p1,p2][p_1,p_2][p1​,p2​] 为负数，且绝对值比较大，而 [l,p1][l,p_1][l,p1​] 可正可负。这时，我们可以把这类情况归类到无负前缀或者前后缀均负的分类里。 所以，我们找到负数绝对值最大的前缀与后缀，先将其 +1+1+1 填成 000 后，还需要再 +1+1+1 填成 111，也就是说要 max⁡p1,p2∈[l,r]−∑i=lp1ai−∑i=p2rai+C \\max_{p_1,p_2\\in [l,r]} -\\sum_{i=l}^{p_1} a_i -\\sum_{i=p_2}^{r} a_i+C p1​,p2​∈[l,r]max​−i=l∑p1​​ai​−i=p2​∑r​ai​+C 为什么只需要找绝对值最大的前缀 p1p_1p1​ 呢？因为就算还有 jp1j\\lt p_1jp1​ 它的前缀是负数 x=∑[l,j]∑[l,p1]x=\\sum [l,j]\\lt \\sum[l,p_1]x=∑[l,j]∑[l,p1​]，我们可以先在 ∑[l,j]\\sum [l,j]∑[l,j] 里加上 xxx，然后再把剩下的 +1+1+1 加到 [l,p1][l,p_1][l,p1​] 上。 这里的 +C+C+C 是这样算的：如果有非负的前缀与非负后缀，则 +2+2+2；若只有其一，则只 +1+1+1。 然后一个变形是，把这里代表前后缀的 ∑\\sum∑ 换成代表 [l,r][l,r][l,r] 内最大子段和的形式： max⁡p1,p2(−∑i=lrai+∑i=p1+1p2−1ai+C) \\max_{p_1,p_2}\\Big( -\\sum_{i=l}^r a_i + \\sum_{i=p_1+1}^{p_2-1} a_i + C\\Big) p1​,p2​max​(−i=l∑r​ai​+i=p1​+1∑p2​−1​ai​+C)对于 MSS 不在 [l,r][l,r][l,r] 的情况来说，我们要把 [l,r][l,r][l,r] 补到 M+1M+1M+1，所以次数为 M+1−∑i=lrai\\boxed{M+1-\\sum_{i=l}^r a_i}M+1−i=l∑r​ai​​ 所以，总结一下就是： 当没有非负前后缀时，就只用考虑 MSS 在 [l,r][l,r][l,r] 外的情况 M+1−∑i=lraiM+1-\\sum_{i=l}^r a_iM+1−∑i=lr​ai​ 当只有非负前缀的时候，就需要考虑 MSS 在 [l,r][l,r][l,r] 外 M+1−∑i=lraiM+1-\\sum_{i=l}^r a_iM+1−∑i=lr​ai​ 把自己的非负后缀都填到 0\\gt 00，次数为 −∑[p2,r]+1-\\sum [p_2,r]+1−∑[p2​,r]+1 当只有非负前缀时是类似的 当有非负前后缀时，四种情况都要考虑。 可以使用线段树维护区间的 MSS、最负后缀、最负前缀，时间复杂度 O(nlog⁡n)O(n\\log n)O(nlogn). Code 我的代码里实现方式是不分类讨论，直接对四种情况取 max⁡\\maxmax. 可以这样做的原因是因为，四种式子分别对应满足各自情况时需要的最少次数，那么要满足所有情况，就得取其中最大的次数。 例如，如果 [l,r][l,r][l,r] 之间没有非负前后缀，这就说明对于“无非负前缀”、“无非负后缀”这两个判定条件我只需要花 000 步，但是又有 MSS 不在 [l,r][l,r][l,r] 里，所以需要把 x0x\\gt 0x0 步把 [l,r][l,r][l,r] 补到 M+1M+1M+1，所以最终需要 xxx 步。 #include algorithm#include cassert#include iostream#include vectorusing ll = long long;using vi = std::vectorint;constexpr ll inf = 1e18;struct Node ll sum0; ll max_psum-inf; ll max_ssum-inf; ll min_psuminf; ll min_ssuminf; ll max_inseg_sum-inf; int l, r, segl, segr, suf, prf; void set(ll x, int pos) sum = x; max_psum = x; max_ssum = x; max_inseg_sum = x; min_ssum = x; min_psum = x; ;void run() int n, q; std::cin n q; vi a(n + 1); for (int i = 1; i = n; i++) std::cin a[i]; std::vectorNode T(6 * n); auto up = [](Node l, Node r) Node t; t.sum = l.sum + r.sum; t.max_psum = std::max(l.max_psum, l.sum + r.max_psum); t.max_ssum = std::max(r.max_ssum, r.sum + l.max_ssum); t.max_inseg_sum = std::max(l.max_inseg_sum, r.max_inseg_sum, l.max_ssum + r.max_psum); t.min_psum = std::min(l.min_psum, l.sum + r.min_psum); t.min_ssum = std::min(r.min_ssum, r.sum + l.min_ssum); return t; ; auto build = [](auto F, int p, int l, int r) - void if (l == r) T[p].set(a[l], l); return; int mid = l + ((r - l) 1); F(F, 2 * p, l, mid), F(F, 2 * p + 1, mid + 1, r); T[p] = up(T[p * 2], T[p * 2 + 1]); ; build(build, 1, 1, n); auto query = [](auto F, int p, int l, int r, int ql, int qr, bool debug = false) - Node if (qr ql) return Node(); // empty range if (ql = l r = qr) return T[p]; int mid = l + ((r - l) 1); Node res; if (qr = mid) res = F(F, 2 * p, l, mid, ql, qr, debug); else if (ql mid) res = F(F, 2 * p + 1, mid + 1, r, ql, qr, debug); else Node left = F(F, 2 * p, l, mid, ql, mid, debug); Node right = F(F, 2 * p + 1, mid + 1, r, mid + 1, qr, debug); res = up(left, right); return res; ; auto q1 = [](int L) if (L == 1) return true; else Node t = query(query, 1, 1, n, 1, L - 1); return t.max_ssum 0 /* max suffix sum of [1, l-1] 0 */; ; auto q2 = [](int R) if (R == n) return true; else Node t = query(query, 1, 1, n, R + 1, n); return t.max_psum 0 /* max prefix sum of [r+1, n] 0 */; ; Node maxx = query(query, 1, 1, n, 1, n); // std::cerr global max subarray sum= maxx.max_inseg_sum ; while (q--) int ql, qr; std::cin ql qr; bool b1 = q1(ql), b2 = q2(qr); if (!b1 || !b2) std::cout -1 ; continue; Node t = query(query, 1, 1, n, ql, qr); auto mid = query(query, 1, 1, n, ql + 1, qr - 1); Node lf = query(query, 1, 1, n, 1, ql - 1); Node rf = query(query, 1, 1, n, qr + 1, n); ll outside = std::max(lf.max_inseg_sum, rf.max_inseg_sum, 0ll); if (ql == qr) std::cout std::max(0ll, outside - a[ql] + 1) ; continue; ll ans = std::max(0ll, mid.max_inseg_sum) - t.sum + 2; // mss in (l, r) ans = std::max(ans, 1 - t.min_psum, 1 - t.min_ssum, outside - t.sum + 1); // no prefix = 0, no suffix = 0, mss outside [l,r] std::cout std::max(0ll, ans) ; int main() int T; std::cin T; while (T--) run(); C. Iridescent Universe 考虑图，如果一个点出发的所有边都有相同的 target color，那么我们可以先随便染色其他边，最后再染色这个点，那么我们就不需要理睬这个点的 indicent edge 之前是什么颜色的。 用第一个样例来解释，我们不管之前到底是怎么染色的，只要最后一次染色是 222 号点染色 222 号颜色，那么最后的图里，222 出发的所有边一定都是 222 号颜色。 所以我们可以拓扑排序：每次染色点，其 incident edges 都有相同的 target color，然后删边。最后如果还有边留下来，那么我们检查他们的 target color 和 initial color 匹配即可。 Code 我这里使用 mapint, int 记录每个点的边的颜色信息。时间复杂度是 O(nlog⁡n)O(n\\log n)O(nlogn). #include algorithm#include iostream#include map#include queue#include utility#include vectorusing vi = std::vectorint;constexpr int N = 2e5 + 5;struct edge int uv, c, tc; int colored; E[N];vi G[N];std::mapint, int C[N];int vis[N];int main() int n, m, k; std::cin n m k; for (int i = 0, u, v, c, t; i m; i++) std::cin u v c t; E[i] = u ^ v, c, t, false; G[u].push_back(i), G[v].push_back(i); C[u][t]++, C[v][t]++; std::queueint q; std::vectorstd::pairint, int ans; for (int i = 1; i = n; i++) if (C[i].size() == 1) q.push(i), vis[i] = true; int cnt = 0; while (!q.empty()) int u = q.front(); ans.push_back(u, C[u].begin()-first); for (auto eid : G[u]) E[eid].colored = true; cnt++; q.pop(); for (int eid : G[u]) int v = E[eid].uv ^ u; if (vis[v]) continue; C[v][E[eid].tc]--; if (C[v][E[eid].tc] == 0) C[v].erase(E[eid].tc); if (C[v].size() == 1) q.push(v); vis[v] = true; if (cnt != n) for (int eid = 0; eid m; eid++) if (E[eid].colored) continue; if (E[eid].c != E[eid].tc) std::cout -1 ; return 0; std::reverse(ans.begin(), ans.end()); std::cout ans.size() ; for (auto [u, c] : ans) std::cout u c ; E. Omniscient Artist 矩形覆盖数点会联想到扫描线：按 xxx 递增扫描矩形，同时用数据结构维护 yyy 轴找到符合条件的点。所以，我们把矩形的左右两边加入扫描线，左侧边 +1+1+1 表示从这个 xxx 坐标开始 [y1,y2][y_1,y_2][y1​,y2​] 之间的点会多出现 111；右侧边 −1-1−1. 那么我们“维护 yyy 轴”，想要维护的是什么呢？其实是 map[x] = y，意义为有 yyy 个点出现 xxx 次。这样，我们就可以遍历 cmcmcm，快速加和点数。 我们怎么维护这个东西呢？线段树并不好做，这个东西维护起来很怪，所以我们使用分块. 块上维护区间加的 tag（注意查询 cmcmcm 的时候也要考虑这个 tag），和一个 unordered_map（其实建议用数组而不是 unordered_map） 但是如果直接查询 cmcmcm 的话，时间复杂度是错的，因为枚举 cmcmcm 需要 O(n/m)O(n/m)O(n/m)，还需要枚举第几块 O(n)O(\\sqrt n)O(n​)，总共 nnn 轮，时间复杂度是 O(n2nm)O(\\frac{n^2\\sqrt n}{m})O(mn2n​​) 可能变成 O(n2)O(n^2)O(n2). min⁡,max⁡\\min,\\maxmin,max 优化上下界 我们给每一个块额外维护 min⁡,max⁡\\min,\\maxmin,max 分别表示最少出现几次、最多出现几次，然后查询时枚举块，ccc 的范围由 min⁡,max⁡\\min,\\maxmin,max 决定。这样，单轮查询的时间复杂度就从 O(nnm)O(\\frac{n\\sqrt n}{m})O(mnn​​) 降为 O(nm)O(\\frac{n}{m})O(mn​) 为什么这样子做会降低复杂度呢？我们考察每一次区间操作对于区间 max⁡i−min⁡i\\max_i-\\min_imaxi​−mini​ 的影响。每一次区间操作会横跨 xxx 个完整的区间，以及最多 222 个散块。 如果对于整个块都 +1/−1+1/-1+1/−1 的话，其 max⁡−min⁡\\max-\\minmax−min 不变，因为两者会同步变化。对于散块而言，这个散块所属的整块，其 max⁡−min⁡\\max-\\minmax−min 最多 +1/−1+1/-1+1/−1。 因此，每一次区间操作使得 ∑imax⁡i−min⁡i\\sum_{i} \\max_i-\\min_i∑i​maxi​−mini​ 最多增加 222，故 nnn 次区间操作使得这个和式 ≤2n\\le 2n≤2n，即 O(n)O(n)O(n). Code 一个实现上的细节：我第一版代码是对 xxx 坐标 sort 之后，进行扫描线，先更新点集后，选择用 x - prevX 计算宽（和计算矩形的面积那样） 但是这个问题就在于，如果是先加入线段再统计点数，那么刚加进来的线段覆盖的点 (xi,yi)(x_i,y_i)(xi​,yi​) 会有 p+1p+1p+1 次 occurrance，而在其左侧 yyy 坐标相同的点却只出现了 ppp 次。 错误代码 prvX = scan[0].x-1;for (int i = 0, j; i scan.size();) // 统计答案 int x = scan[i].x; int len = x - prvX; j = i; while (j scan.size() scan[j].x == scan[i].x) add(scan[j].lb, scan[j].ub, scan[j].exit); j++; for (int b = 1; b = blocks; b++) for (int c = std::max(1, (min[b] + m - 1) / m); c * m = max[b]; c++) if (c * m block_add[b]) continue; i64 cnt = cntpoint[b][c * m - block_add[b]]; ans[c] += cnt * len; prvX = x; i = j; 所以，一个代码难度更小的做法是，直接让 xxx 从 111 到 nnn 递增，且只处理横座标为 xxx 的线段，在分块上维护。维护完后统计点数。这样，查询的时间复杂度是 O(n2m)O(\\frac{n^2}{m})O(mn2​)，也不会 TLE. #include algorithm#include cassert#include cmath#include iostream#include vectorconstexpr int N = 3e5 + 5;constexpr int B = 600;using i64 = long long;struct Rec int l, r, t, b; r[N];struct Seg int x, ub, lb, exit, id;;int n, m;std::vectorSeg scan[N];int blocksize, blocks;int bid[N], bl[B], br[B];int cnty[N], prvX-1, block_add[B], max[B], min[B];int cntpoint[B][N];i64 ans[B];void rebuild(int l, int r, int w) assert(bid[l] == bid[r]); int id = bid[l]; for (int i = bl[id]; i = br[id]; i++) cntpoint[id][cnty[i]]--; max[id] = 0, min[id] = N; for (int i = bl[id]; i = br[id]; i++) cnty[i] += block_add[id]; if (l = i i = r) cnty[i] += w; cntpoint[id][cnty[i]]++; max[id] = std::max(max[id], cnty[i]); min[id] = std::min(min[id], cnty[i]); block_add[id] = 0;void add(int l, int r, int w) if (bid[l] == bid[r]) rebuild(l, r, w); else rebuild(l, br[bid[l]], w); for (int i = bid[l] + 1; i = bid[r] - 1; i++) block_add[i] += w, max[i] += w, min[i] += w; rebuild(bl[bid[r]], r, w); void debug() for (int b = 1; b = blocks; b++) std::cerr Block b : ; for (int i = bl[b]; i = br[b]; i++) std::cerr \\tPos i = cnty[i] + block_add[b] ; for (int cnt = 0; cnt = max[b]; cnt++) if (cntpoint[b][cnt] == 0) continue; std::cerr \\tCount cnt + block_add[b] : cntpoint[b][cnt] points ; int main() std::cin.tie(0)-sync_with_stdio(0); std::cin n m; for (int i = 1; i = n; i++) std::cin r[i].l r[i].r r[i].b r[i].t; r[i].t--; scan[r[i].l].push_back(r[i].l, r[i].t, r[i].b, 1, i); // scan.push_back(r[i].r - 1, r[i].t, r[i].b, 0, i); scan[r[i].r].push_back(r[i].r, r[i].t, r[i].b, -1, i); // blocks blocksize = (int)std::sqrt(n); for (int i = 1; i = n; i++) bid[i] = (i - 1) / blocksize + 1; for (int i = 1; i = bid[n]; i++) bl[i] = (i - 1) * blocksize + 1; br[i] = i * blocksize; br[bid[n]] = n, blocks = bid[n]; for (int b = 1; b = blocks; b++) cntpoint[b][0] = br[b] - bl[b] + 1; max[b] = 0, min[b] = 0; for (int i = 1; i = n; i++) for (auto [x, ub, lb, v, id] : scan[i]) add(lb, ub, v); for (int b = 1; b = blocks; b++) for (int c = std::max(1, (min[b] + m - 1) / m); c * m = std::min(n, max[b]); c++) if (c * m block_add[b]) continue; ans[c] += (i64)cntpoint[b][c * m - block_add[b]]; for (int c = 1; c * m = n; c++) std::cout ans[c] ; F. Witnessing the Miracle 这个题本质上是两个序列之间进行匹配，即考虑 sis_isi​ 最终状态下能否和 tjt_jtj​ 进行匹配。 不过，由于题目有“移除 kkk 个磁铁”的设定，实际上，对于某一个 sis_isi​，假设其左边激活 ddd 个磁铁，那么其在 ttt 序列里对应的位置是可以唯一确定的：j=i+d−(k−d)j=i+d-(k-d)j=i+d−(k−d). 我们令 dp 状态为 dp[i,d]dp[i,d]dp[i,d] 表示在 s[1,i−1]s[1,i-1]s[1,i−1] 中间激活 ddd 个磁铁的方案数量. 那么我们就考虑怎么从 dp[i−1]dp[i-1]dp[i−1] 转移到 dp[i]dp[i]dp[i] 上. 考虑 sis_isi​ 和 tjt_jtj​ 各自可以填什么数字： 如果 si=0,tj=0s_i=0,t_j=0si​=0,tj​=0，可行。 都没有磁铁的位置显然可以互相匹配，所以 dp[i, d] += dp[i-1, d] 如果 si=0,tj=1s_i=0, t_j=1si​=0,tj​=1，不可行 原来没有磁铁不可能凭空出现磁铁（就算有，那也是从 sss 的其他地方跑过来的），所以不更新 dp 如果 si=1,tj=1s_i=1,t_j=1si​=1,tj​=1，可行 有磁铁的位置匹配有磁铁的位置，说明这块磁铁没有被激活，dp[i, d] += dp[i-1, d] 如果 si=1,tj=0s_i=1,t_j=0si​=1,tj​=0，可行 有磁铁的位置最终匹配到没有磁铁的位置，说明这块磁铁被激活了，dp[i, d+1] += dp[i-1, d] 这个 dp 乍一看比较难懂。实际上真的比较难懂。我建议还是按 dp[i,j]dp[i,j]dp[i,j] 的思路来看 最后的答案即为 dp[n, k]. G. Addition, Multiplication with a Sugar 首先，肯定先把开头的一连串 111 和结尾的一连串 111 拿走，他们一定是加起来的。 然后考虑中间的一段，先看成 x1:≠11×ax2:≠11×b… \\boxed{x_1: e 1}\\boxed{1\\times a}\\boxed{x_2: e 1}\\boxed{1\\times b}\\dots x1​:=1​1×a​x2​:=1​1×b​…如果切开更优，则有 ∑xi+n∏xin+1∏(xi−1) \\begin{aligned} \\sum x_i+n\\gt \\prod x_i\\\\ n+1\\gt \\prod (x_i-1) \\end{aligned} ∑xi​+nn+1​∏xi​∏(xi​−1)​ M. Under the Epilogue 我们先来考察题目的性质：因为对于某个点集 SSS，我们希望能找到一个点 uuu，使得其可以经过 SSS 内的每个点，最后回到 uuu。我们可以证明，这样的 SSS 一定是一个强连通分量。 这是因为，考虑 SSS 内的任意两个点 a,ba,ba,b，因为 u→uu\\to uu→u 的路径上必定会有下面两种情况中的一个： u→a→b→uu\\to a\\to b\\to uu→a→b→u，这是就有 a→ba\\to ba→b 的路径了 u→b→a→uu\\to b\\to a\\to uu→b→a→u，此时，我们可以让 a→u→ba\\to u\\to ba→u→b 所以，SSS 一定是强连通分量，而且是导出子图。因此，我们的任务就是：给定边集，求出强连通导出子图的数量。考虑到 n≤50n\\le 50n≤50，开始往 dp 的方向上想。如果用 dp[...] 表示最终答案 SSS 的数量，该怎么设计状态呢？ 到目前为止，我们只利用了 SSS 的性质（从题目定义出发推出的），还没有利用 [li,ri][l_i,r_i][li​,ri​] 是连续区间这个性质. 先从简单例子入手思考一下： 首先，只有一个点显然是 SCC. 接着考虑两个点的情况，一定是 a→b,b→aa\\to b, b\\to aa→b,b→a 都有边才行. 接着考虑三个点的情况，我们假定 abca\\lt b\\lt cabc，首先，绝对不可能出现导出子图里三个点出度均为 111 的情况，即 a→b→c→aa\\to b\\to c\\to aa→b→c→a. 这是因为如果 ccc 可以到 aaa，由于 [lc,rc][l_c,r_c][lc​,rc​] 是连续的，所以 c→bc\\to bc→b 这条边一定存在，因此，任意的三个点里，一定存在两个点，他们组成的点集 S2S_2S2​ 也是满足条件的 SSS. 所以，所有的 S:∣S∣=3S:|S|=3S:∣S∣=3 可以看成是 S:∣S∣=2S:|S|=2S:∣S∣=2 的 S2[i]={ a,b },abS_2[i] = \\set{a,b},a\\lt bS2​[i]={a,b},ab 再加上一个点 ccc，而且这个点 c∉[a,b]c otin [a,b]c∈/[a,b]（证明和上一段类似，也是利用 [li,ri][l_i,r_i][li​,ri​] 的连续性）. 所以，ccc 和 { a,b }\\set{a,b}{a,b} 之间必有连边，即 max⁡(ra,rb)≥c\\max(r_a,r_b)\\ge cmax(ra​,rb​)≥c（a/ba/ba/b 向 ccc 连一条边）并且 lc≤bl_c\\le blc​≤b（ccc 向 a/ba/ba/b 连一条边，lcl_clc​ 至少要比 bbb 靠左）. 这个结论可以推广一下，考虑任意两个 vertex set S1,S2S_1, S_2S1​,S2​ 合并的判定条件： min⁡i∈S2ai≤max⁡i∈S1bi\\min_{i\\in S_2}a_i\\le \\max_{i\\in S_1}b_ii∈S2​min​ai​≤i∈S1​max​bi​ 也就是两个连通块之间可以互相一步到达。 但是如果单纯是这个条件的话，还是比较难统计. 我们这里作出的一个等价限制是：S=∪i[xi,yi]S=\\cup_i [x_i,y_i]S=∪i​[xi​,yi​] 其中 lyi≤yi−1l_{y_i}\\le y_{i-1}lyi​​≤yi−1​. 这是因为，如果 uuu 要能走回 uuu 且 SSS 里有比 uuu 小的元素，那么无论如何 uuu 都应该可以走到某个 vuv\\lt uvu 的位置上，就可以让 yi−1=v,yi=uy_{i-1}=v, y_i=uyi−1​=v,yi​=u."},{"title":"计算几何：双向连接边表 DCEL","path":"/wiki/algo/DCEL.html","content":"Doubly-Connected Edge List 半边 Half Edge Half Edge"},{"title":"Ascend C 介绍与 NPU 芯片","path":"/wiki/ascendc/intro.html","content":"d0144f89de14a1fc384914230d36d0ec0054caf00183a222885cc88f31848a18aab140cd588bb1a31357d2dfedf6c8adfb592b49da5961aaa495123a3ccb3fa9a9f6c36e1bc55e6ff161822b769668a2076f5cfab45f196e1c53f0376e4956630c8a0923bfd91ca220c8d6a51d78be71e5b15538793255c1fcf3fbc64b80ef22508f3168feccbdaffac7faff9ec41aa90bd14105244569a56fb953d126552fc91d226fb4aa73c720ffee5e27a6e6c44331325d651b1f74c98b14d272388278d75502dfd76dee11cf4ae7c17bae192f36d0fc6097e31014e778d3ce734f793cc91d6a0cd8deee525e0a2b5df1feb19690d6cb0ed574e528834c7497615774b37a7d6a622e4a391fda0f6d046ee84fabcc6866a2fa790d0da49f405d25262fe0b227284612f2bbedafb19c35fddce7dbee9ea231f1128845e2cb4d3acb14a798c9445debfe7149b4028652944b99b85e6edd553e3657d323986791286e06611026a0b53564e9d42cb8d5930b665780169dd1f70bcc60ea6a108e7508f6b4bb904766b050f2d77edb2d92da12da5e5c4e226216b6aebe1366030bb436121c7a9f88e091b50f1553e5c3fbf3e08989b7c17a3a39de4e90112e198843ee98d7250d6cd7aa6775e73d8e3f2c10e535f76a20fb37d456d87f6666f252b1711bb852ba8ebdb2569e786dc13560eadb4ae4c42e8b5d14abef39d4ba6c5316bef5bce30910aa0dbe3bd454a7fdf5dbd7c47c034aa4008e8976343eca32e87ba156dc597cb588f4606b79ed83933468023f298250221b45caa3fbc371929526c7172ba395c9ece27b8ece80706195af6c0e7022c6f17e2b0cdd6b68406ce32e43d5bd7bc28fba6d76fe865bc8d0418149ca493a51097a7de299e67e71170344738fcfd519ce277e2a286cff0c58e2a44ea50dddf92fa061b6360d6804ef591820ebe7ead7532e594b1b2328f6deb4d87aa44f3b2c206b04e743f4062a0f3e97c1b4864b8c6d7906763512c3f64396b213ab89caf45d38c0f50f1f5f93fd38816ec6bebbca3364766f2a26cda6379849f8a480114accbaeb749a9dd5b9f6cbee7c31fcb51ff6fcf80c879e9eaa5f05c522fbc29d55095152d5c8e5f7745956c602d18cc1637d57c82ea950aad8409b557346ad1245f228a4492cdfd9274376eadf8dc24f39ecd4594177677dd558ea8a857c7beb585e8d2d780bb29be3591827a4768e7f03b285aa795a4f294b5af5c6474303a17193a9be731f2d6453374ecc65ce9bbeb3cb7eccac9708994ea7be1632ecf6be3094 Password is needed."},{"title":"KMP 算法","path":"/wiki/algo/KMP.html","content":"KMP 算法 核心是最长公共前后缀."},{"title":"博弈论：Minimax 与 Alpha-Beta 剪枝","path":"/wiki/algo/alpha-beta-minimax.html","content":"Minimax 博弈游戏可以简化成这样的局面：第 iii 轮我方行动，目的是最大化得分；下一轮对手行动，目的是最小化我方得分；再下一轮又是我方行动，目的是最大化得分……如此往复。 Minimax 搜索优化：Alpha-Beta 剪枝 记节点分数为 xxx，我们给每一个节点维护两个值 α,β\\alpha,\\betaα,β 满足 α≤x≤β\\alpha\\le x\\le\\betaα≤x≤β. 算法流程大致如下： 如果是我方行动"},{"title":"NP 理论：近似算法","path":"/wiki/algo/approx-algo.html","content":"近似算法 近似算法的目的在于：对 NP 难问题设计多项式时间算法，保证解的质量在一定比例内（近似比）"},{"title":"Boruvka 算法：特殊限制下的最小生成树算法","path":"/wiki/algo/boruvka.html","content":"Boruvka 最小生成树算法 Boruvka 在思想上算是 Kruskal 和 Prim 算法的结合，在 某个点出发的边的边权可以放在一起考虑 边权具有特殊性质 时具有较大优势。 算法流程 和 Kruskal 一样，我们维护若干个连通块。我们定义，连通块 cic_ici​ 的最小边表示这个连通块和其他连通块之间的边里最小的边，即 min⁡w(e){e:e=(u,v);u∈ci∧v∈cj∧i≠j}\\min_{w(e)}\\{ e:e=(u,v);u\\in c_i\\land v\\in c_j\\land i e j \\}minw(e)​{e:e=(u,v);u∈ci​∧v∈cj​∧i=j} 初始时，每一个点 vvv 都分配一个连通块 cvc_vcv​。 计算每一个点属于哪一个连通块，把这个连通块的最小边设为 None 遍历每一条边 e=(u,v)e=(u,v)e=(u,v)，如果 u,vu,vu,v 不在同一个连通块内，用 w(e)w(e)w(e) 更新这两个连通块 cu,cvc_u,c_vcu​,cv​ 的最小边 如果所有连通块的最小边都是 None，则结束；否则，将每个连通块的最小边加入答案，继续从 111 循环"},{"title":"无/有源汇 上下界 可行/最大/最小流","path":"/wiki/algo/bounded-flow.html","content":"无源汇 上下界可行流 每条边都存在下界 b(u,v),c(u,v)b(u,v),c(u,v)b(u,v),c(u,v) 分别表示这条边的流量至少、至多为多少。 我们先直接假设每条边已经流了 b(u,v)b(u,v)b(u,v) 的流量，设为初始流量 然后构造新图 HHH，其中的每一条边 eH(u,v)e_H(u,v)eH​(u,v) 满足其容量为 c(u,v)−b(u,v)c(u,v)-b(u,v)c(u,v)−b(u,v) 然后对 HHH 中的节点 iii 进行调整，假设 HHH 中两个额外的点 S,TS,TS,T 分别作为 HHH 中的源汇点 如果初始流量中 iii 的收支平衡，则不用添加边 如果 iii 的入流多于出流，差值为 ddd，则 SSS 向 iii 连边，容量为 ddd 如果 iii 的出流多于入流，差值为 ddd，则 iii 向 TTT 连边，容量为 ddd 然后以 SSS 为源点，TTT 为汇点跑最大流。 如果 SSS 出发的边都满流，则存在可行流；否则不存在 正确性证明 有源汇 上下界可行流 设源点为 SSS，汇点为 TTT，则我们连 T→ST\\to ST→S 的边，其下界为 000，上界为 ∞\\infin∞。于是问题转化为无源汇上下界可行流。 此时若有解，S→TS\\to TS→T 的可行流的流量就等于 T→ST\\to ST→S 的附加边的流量。 上下界最大流 上下界最小流"},{"title":"计算几何：圆","path":"/wiki/algo/circles.html","content":"三点共圆 三点共圆问题 已知三个点的坐标 p1(x1,y1),p2(x2,y2),p3(x3,y3)p_1(x_1,y_1), p_2(x_2,y_2), p_3(x_3,y_3)p1​(x1​,y1​),p2​(x2​,y2​),p3​(x3​,y3​)，求这三个点形成的圆 CCC 的中心 ccc、半径 rrr. 我们首先把三点共线的情况排除掉，因为这种情况下必定不可能共圆。 接着，我们首先求出 p1p2p_1p_2p1​p2​ 和 p2p3p_2p_3p2​p3​ 的中垂线 l1,l2l_1,l_2l1​,l2​，计算其交点，则这个交点必为圆心 ccc. 于是半径 rrr 也很好求了. 三点共圆 (C++) void none() 圆的公切线"},{"title":"排列组合（一）","path":"/wiki/algo/combination.html","content":"排列组合加速技巧 C(n, a) P(n, a)，其中 a 较小时 可以在 O(a)O(a)O(a) 的时间内计算单个值。 mint res;for (int i = 1; i = res; i++)"},{"title":"计算几何：凸包","path":"/wiki/algo/convex-hull.html","content":"求解凸包"},{"title":"算法设计：计数模型","path":"/wiki/algo/counting-techniques.html","content":"计数模型 计数模型 算法竞赛里的计数问题通常有几种类别： 给定区间，求这个区间里合法元素的个数"},{"title":"斜率优化 DP","path":"/wiki/algo/dp-convex-opt.html","content":"斜率优化 DP dp[i]=max⁡j:conditiondp[j]+f(i)×f(j) dp[i] = \\max_{j:\\text{condition}} dp[j] + f(i)\\times f(j) dp[i]=j:conditionmax​dp[j]+f(i)×f(j)维护 condition 的技巧 我们可以用 例题 Luogu P5504 首先我们需要想到的一点是：如果取的是 [l,r][l,r][l,r] 的贝壳，那么选择的 s0=sizel=sizers_0=size_l=size_rs0​=sizel​=sizer​ . 如果不这样做，考虑选取的是 [l,r][l,r][l,r] 而 lkr,sizek=sizerl\\lt k\\lt r, size_k=size_rlkr,sizek​=sizer​，那么，我们完全可以把这一段拆成 [l,k−1],[k,r][l,k-1],[k,r][l,k−1],[k,r] 两段，答案肯定更优。 然后，我们考虑 dp[]dp[]dp[] 式子，令 dp[]dp[]dp[] 就是我们想要的最大柠檬数，把它想象成一个总是从前缀转移的 dp，可以列出 c=sizeidpi=max⁡j≤i∧sizej=c(dpj+c×(sumc,i−sumc,j+1)2) c=size_i\\\\ dp_i=\\max_{j\\le i\\land size_j=c}\\Bigg( dp_j + c\\times (sum_{c,i}-sum_{c,j}+1)^2 \\Bigg) c=sizei​dpi​=j≤i∧sizej​=cmax​(dpj​+c×(sumc,i​−sumc,j​+1)2) 其中 sumc,isum_{c,i}sumc,i​ 表示 1∼i1\\sim i1∼i 里 size 为 ccc 的贝壳数量。"},{"title":"网络流：EK 算法","path":"/wiki/algo/edmonds-karp.html","content":"EK 算法 EK 算法在 Residual Graph 里找增广路的时候，使用 BFS 算法求解出的增广路一定是 shortest (in terms of fewest edges). 算法证明 Distance Lemma 令 EF 算法第 iii 次在 GfG_fGf​ 上找到的增广路为 fif_ifi​，并且这些 fif_ifi​ 是最短的（经过最少的边）。记 GiG_{i}Gi​ 为 fif_ifi​ 对应的 residual graph，di(u,v)d_i(u,v)di​(u,v) 为 GiG_{i}Gi​ 上两点之间的最短距离（最小边数），那么有 di+1(s,v)≥di(s,v) \\boxed{d_{i+1}(s,v)\\ge d_i(s,v)} di+1​(s,v)≥di​(s,v)​ 证明 令 s,vs,vs,v 最短路径上的点按 distance 递增排列。我们用数学归纳法证明。 当 di+1(s,v)=0d_{i+1}(s,v)=0di+1​(s,v)=0 时，说明 s=vs=vs=v 两者是同一个点，因此在 fif_ifi​ 对应的图里，di(s,v)=0≤di+1(s,v)d_i(s,v)=0\\le d_{i+1}(s,v)di​(s,v)=0≤di+1​(s,v). 考虑任意长度 L0L\\gt 0L0，假设引理对 ∀v,di+1(s,v)L\\forall v, d_{i+1}(s,v)\\lt L∀v,di+1​(s,v)L 成立，考察 ∀v,di+1(s,v)=L\\forall v,d_{i+1}(s,v)=L∀v,di+1​(s,v)=L： 在 residual graph Gi+1G_{i+1}Gi+1​ 上找到 s,vs,vs,v 的最短路，令 xxx 为 vvv 的上一个节点，那么有 di+1(s,x)=L−1d_{i+1}(s,x)=L-1di+1​(s,x)=L−1 所以根据假设 di(s,x)≤L−1d_{i}(s,x)\\le L-1di​(s,x)≤L−1，我们再根据这个信息，推理 di(s,v)d_i(s,v)di​(s,v)。在 GiG_iGi​ 上有两种情况 GiG_iGi​ 中存在 (x,v)(x,v)(x,v) 这条边 这种情况下，我们只需要走 s→x→vs\\to x\\to vs→x→v，就一定可以保证 di(s,v)≤Ld_i(s,v)\\le Ldi​(s,v)≤L，所以 di(s,v)≤di+1(s,v)d_i(s,v)\\le d_{i+1}(s,v)di​(s,v)≤di+1​(s,v) GiG_iGi​ 中不存在 (x,v)(x,v)(x,v) 这条边 如果 GiG_iGi​ 不存在这条边，但 Gi+1G_{i+1}Gi+1​ 存在这条边，这就说明 (v,x)∈Gi(v,x)\\in G_i(v,x)∈Gi​ EK 算法找到了一条增广路，s→v→x→ts\\to v\\to x\\to ts→v→x→t 此时，由于 EF 算法找到的总是最短路，而 di(s,x)≤L−1d_i(s,x)\\le L-1di​(s,x)≤L−1 且经过 (v,x)(v,x)(v,x)，因此我们可以推导出 di(s,v)=di(s,x)−1≤L−2 d_i(s,v)=d_i(s,x)-1\\le L-2 di​(s,v)=di​(s,x)−1≤L−2所以 di(s,v)≤di+1(s,v)d_i(s,v)\\le d_{i+1}(s,v)di​(s,v)≤di+1​(s,v) 便自动成立了 Critical Edge Lemma"},{"title":"网络流：Ford-Fulkerson 增广路算法","path":"/wiki/algo/ford-fulkerson.html","content":"Ford Fulkerson 算法 对于边 (u,v)(u,v)(u,v)，我们定义 Residual Capacity cf(u,v)=c(u,v)−f(u,v)c_f(u,v)=c(u,v)-f(u,v)cf​(u,v)=c(u,v)−f(u,v)。把所有剩余容量 0\\gt 00 的边构成的子图定义为 Residual Graph GfG_fGf​。 Residual Graph 能够 work 的核心在于对 Backward Edge 的理解。Forward Edge 上的增广和 Backward Edge 上的增广可以抵消。 退流 Ford-Fulkerson 增广算法的时间复杂度是 O(nmf)O(nmf)O(nmf) 的，受容量最大的边的影响。 正确性证明"},{"title":"贪心算法","path":"/wiki/algo/greedy.html","content":"如何证明贪心算法的正确性？ 证明最佳的 solution 可以通过贪心算法在不增加 cost 的情况下求出来 证明每一步选择时，贪心算法的答案都不劣于其他算法，或者都是最优的 贪心模型 任务规划"},{"title":"动态规划例题 (1)","path":"/wiki/algo/dp-design.html","content":"动态规划例题 不能很清晰地分类……就全丢到这里了…… Codeforces 2107 F1 TP LinkSubmission我们考虑 apa_pap​，我们可以这样做：花费 i−pi-pi−p 把 apa_pap​ 换到自己前面花费 apa_pap​ 超车再花费 111 把 apa_pap​ 换到自己面前再花费 apa_pap​ 超车……于是我们可以利用 apa_pap​ 超车一个区间 ([l,r],l≤p≤r[l,r],l\\le p\\le r[l,r],l≤p≤r) 的车手，花费为（假设当前正在 rrr 的身后）(r−l+1)⋅ap超车费用+r−l把 ap 从身后换到身前+r−p把 ap 从原来的位置换到自己身前\\begin{array}{rlll}(r-l+1)\\cdot a_p 超车费用\\\\+r-l 把\\ a_p\\ 从身后换到身前\\\\+r-p 把\\ a_p\\ 从原来的位置换到自己身前\\end{array}(r−l+1)⋅ap​+r−l+r−p​超车费用把 ap​ 从身后换到身前把 ap​ 从原来的位置换到自己身前​当我们从 rrr 向 lll 扫描的时候，此时我们枚举的 ppp 递减，因此 r−pr-pr−p 递增，要使这个式子最小，apa_pap​ 必须为 [l,r][l,r][l,r] 内最小值（且最靠右），才有可能最小化这个式子。解决完这个区间之后，我们发现，整个 [1,n][1,n][1,n] 可以切分成多个这样的子结构（每个小区间里选出自己的 apa_pap​）。差不多就类似于走进另一个区间发现在另一个区间用另一个数当 apa_pap​ 更划算。现在我们来定义状态。设 dp[i]dp[i]dp[i] 表示从第 nnn 个人后面走到第 iii 个人后面、第 i+1i+1i+1 个人前面时所需要的最小费用。那么 dp[0]dp[0]dp[0] 就是我们需要的答案，初始化 dp[n]=0dp[n]=0dp[n]=0.随后，我们从后向前枚举 iii（现在在第 iii 个人后面），并且枚举 jjj，表明我们要从 iii 走到 jjj 位置，即 dp[i]→dp[j]dp[i]\\to dp[j]dp[i]→dp[j].根据上文的分析，我们需要知道 a[j…i]a[j\\dots i]a[j…i] 的最小值 a[p]a[p]a[p]（有多个的话取最右的，这个可以在枚举 jjj 时一起维护）dp[j−1]←min⁡dp[i]+a[p]×(i−j+1)⏟超车费用+i−p⏟第一次换到身前+i−j⏟换到身前(j≤p≤i)dp[j-1]\\underset{\\min}{\\gets} dp[i]+\\underbrace{a[p]\\times(i-j+1)}_{超车费用}+\\underbrace{i-p}_{第一次换到身前}+\\underbrace{i-j}_{换到身前} (j\\le p\\le i)dp[j−1]min←​dp[i]+超车费用a[p]×(i−j+1)​​+第一次换到身前i−p​​+换到身前i−j​​(j≤p≤i)因为 a[p]a[p]a[p] 考虑了 a[j]a[j]a[j]，所以 jjj 位置也会被超车，因此更新的是 dp[j−1]dp[j-1]dp[j−1]"},{"title":"图论、网络流：最小割树 (Gomory-Hu Tree)","path":"/wiki/algo/gomory-hu-tree.html","content":"Gomory-Hu Tree 以下分析约定： 符号 含义 valSval_SvalS​ 令 SSS 是边集，那么 c(S)c(S)c(S) 就是其边权和 cutu,v={U,V−U}cut_{u,v}=\\{U,V-U\\}cutu,v​={U,V−U} 分割 u,vu,vu,v 的最小割，其中 u∈U,v∈V−Uu\\in U, v\\in V-Uu∈U,v∈V−U edgeUedge_UedgeU​ 对于一个割 U,V−UU,V-UU,V−U，其为割下的所有边，即 {(u,v):u∈U,v∈V−U}\\{(u,v):u\\in U,v\\in V-U\\}{(u,v):u∈U,v∈V−U} mincutu,vmincut_{u,v}mincutu,v​ (u,v)(u,v)(u,v) 的最小割（权值最小） minvalu,vminval_{u,v}minvalu,v​ =val(mincut(u,v))=val(mincut(u,v))=val(mincut(u,v)) 最小割树 T=(V,ET)T=(V,E_T)T=(V,ET​) 是这样一种树，对于所有的边 (s,t)∈ET(s,t)\\in E_T(s,t)∈ET​，从树上去掉这两条边之后剩下的两个连通块 S,TS,TS,T，恰好就是 s,ts,ts,t 的最小割 mincuts,tmincut_{s,t}mincuts,t​ 代码实现 Code // pass 例题"},{"title":"区间 DP","path":"/wiki/algo/interval-dp.html","content":"区间 DP 常见建模技巧 将区间左右端点显式表现在 dp 状态定义里 例如说 dp[l][r]dp[l][r]dp[l][r] 表示区间 [l,r][l,r][l,r] 内的某某状态，且通常需要小区间拼接成大区间。为了保证正确性，这种转移通常先枚举区间长度，然后再枚举左右端点。 dp[l,r]←F( [l,a1],[a1,a2],…[am,r] ),l≤a1≤a2⋯≤am≤r dp[l,r]\\gets F\\Big(\\ [l,a_1],[a_1,a_2],\\dots[a_m,r] \\ \\Big),l\\le a_1\\le a_2\\dots\\le a_m\\le r dp[l,r]←F( [l,a1​],[a1​,a2​],…[am​,r] ),l≤a1​≤a2​⋯≤am​≤r有的时候，也会省略掉一个端点，只保留 lll (or rrr)。这种形式的 DP 通常是区间的特例，即 dp[i]dp[i]dp[i] 代表 [i,n][i,n][i,n] 后缀或者 [1,i][1,i][1,i] 前缀。状态转移差不多就是 dp[i]←dp[j]+f( [i,j) ) dp[i]\\gets dp[j]+f\\Big(\\ [i,j)\\ \\Big) dp[i]←dp[j]+f( [i,j) )"},{"title":"Manacher","path":"/wiki/algo/manacher.html","content":"Manacher 算法 Manacher 推广 如果我们的 pattern 拥有如下的一些性质，那么我们就可以利用 Manacher 进行加速： 具有类似回文的对称性。如果维护的回文 Box 为 [l,r][l,r][l,r]，那么这种对称性使得 R[i]R[i]R[i] 至少 ≥R[l+r−i]\\ge R[l+r-i]≥R[l+r−i]. 外推性：如果 s[l…r]s[l\\dots r]s[l…r] 满足性质，那么 s[l+1…r−1]s[l+1\\dots r-1]s[l+1…r−1] 也应该满足性质 例题 P3501 [POI 2010] ANT-Antisymmetry 题目所描述的 pattern 符合外推性：一个合法的 pattern 必须有 s[0]≠s[−1]s[0] e s[-1]s[0]=s[−1], 去掉之后的子串也必然满足反对称. 而且也具有对称性。于是可以使用 Manacher 算法，而且反对称的串长必为偶数，我们在数字中间 pad 字符，这样就可以向 Manacher 那样了。时间复杂度 O(n)O(n)O(n) Code #include iostream#include string#include vectorint main() int n; std::cin n; std::string s; std::cin s; std::string T = .; for (auto c : s) T += c, T += .; int L = T.length(); std::vectorint R(L + 1, 0); auto check = [](int p1, int p2) if (T[p1] == . T[p2] == .) return true; else if (T[p1] == 1 T[p2] == 0) return true; else if (T[p1] == 0 T[p2] == 1) return true; else return false; ; int C = 0, r = 0; long long ans = 0; for (int i = 0; i L; i += 2) int reflect = 2 * C - i; int k; if (i = C + r) k = std::min(R[reflect], C + r - i); else k = 0; while (i - k = 0 i + k L check(i - k, i + k)) k++; R[i] = k - 1; if (i + R[i] C + r) C = i; r = R[i]; ans += R[i] / 2; std::cout ans std::endl;"},{"title":"网络流模型","path":"/wiki/algo/network-flow-models.html","content":"二分图匹配模型"},{"title":"网络流：最大流、最小割","path":"/wiki/algo/network-flow.html","content":"Flow Network 网络流图 G=(V,E,c)G=(V,E,c)G=(V,E,c) 是一张有向图，其中每一条有向边 e=(u,v)e=(u,v)e=(u,v) 有容量 (capacity) c(u,v)≥0c(u,v)\\ge 0c(u,v)≥0. 除此之外，GGG 中还有两个特殊节点 source sss 和 sink ttt. Flow 在此基础上，我们定义流 (Flow). GGG 上的流 fff 给每一条边 e=(u,v)e=(u,v)e=(u,v) 都赋上一个实数 f(u,v)f(u,v)f(u,v) 且满足： 每一条边的流量都不会超过其容量 capacity.f(u,v)≤c(u,v)f(u,v)\\le c(u,v)f(u,v)≤c(u,v) 除了源点与汇点，其余每一点都满足：流入的流量和流出的流量相等。∀v∈V−{s,t},∑(x,v)∈Ef(x,v)=∑(v,y)∈Ef(v,y)\\forall v\\in V-\\{s,t\\}, \\sum_{(x,v)\\in E} f(x,v)=\\sum_{(v,y)\\in E} f(v,y)∀v∈V−{s,t},(x,v)∈E∑​f(x,v)=(v,y)∈E∑​f(v,y) 最大流求解算法 Ford-Fulkerson 算法 Cut 什么是割？ 图的一个“割” (Cut) 是指将图分成两个点集 A,BA,BA,B 且源点 s∈As\\in As∈A，汇点 t∈Bt\\in Bt∈B. 定义 Capacity of Cut cap(A,B)=∑e out of Ac(e)cap(A,B)=\\sum_{e\\text{ out of }A}c(e)cap(A,B)=∑e out of A​c(e) Flow Value Lemma 令 fff 为 GGG 上任意的流，(A,B)(A,B)(A,B) 为 GGG 上任意的割（s∈A,t∈Bs\\in A,t\\in Bs∈A,t∈B），则必有 value(f)=∑e out of Af(e)−∑e into Af(e) \\text{value}(f)=\\sum_{e \\text{ out of }A}f(e)-\\sum_{e\\text{ into }A} f(e) value(f)=e out of A∑​f(e)−e into A∑​f(e) 证明 考虑 AAA 中的每一个节点，除了源点 sss 以外，其余所有点都满足 outflow(v)=inflow(v)\\text{outflow}(v)=\\text{inflow}(v)outflow(v)=inflow(v)，而 sss 的 inflow(s)=0\\text{inflow}(s)=0inflow(s)=0，所以 value(f)=∑outflow(s)=∑v∈Aoutflow(v)−inflow(v) \\mathrm{value}(f)=\\sum \\mathrm{outflow}(s)=\\sum_{v\\in A} \\mathrm{outflow}(v)-\\mathrm{inflow}(v) value(f)=∑outflow(s)=v∈A∑​outflow(v)−inflow(v)我们再来考察 ∑v∈Aoutflow(v)\\sum_{v\\in A}\\mathrm{outflow}(v)∑v∈A​outflow(v)，检查所有边，可得 ∑v∈Aoutflow(v)=∑e inside Af(e)+∑e out of Af(e) \\sum_{v\\in A}\\mathrm{outflow}(v)=\\sum_{e\\text{ inside }A}f(e)+\\sum_{e\\text{ out of }A}f(e) v∈A∑​outflow(v)=e inside A∑​f(e)+e out of A∑​f(e)同理对 inflow 有 ∑v∈Ainflow(v)=∑e inside Af(e)+∑e into Af(e) \\sum_{v\\in A}\\mathrm{inflow}(v)=\\sum_{e\\text{ inside }A}f(e)+\\sum_{e\\text{ into }A}f(e) v∈A∑​inflow(v)=e inside A∑​f(e)+e into A∑​f(e)两式相减可得 value(f)=∑e out of Af(e)−∑e into Af(e) \\mathrm{value}(f)=\\sum_{e\\text{ out of }A}f(e)-\\sum_{e\\text{ into }A}f(e) value(f)=e out of A∑​f(e)−e into A∑​f(e) 由此也可以推得几个推论 Corollary 1 value(f)≤cap(A,B) \\mathrm{value}(f)\\le \\mathrm{cap}(A,B) value(f)≤cap(A,B) 证明 value(f)=∑e out of Af(e)−∑e into Af(e)≤∑e out of Af(e)≤∑e out of Acap(e)=cap(A,B) \\begin{aligned} \\mathrm{value}(f)=\\sum_{e\\text{ out of }A} f(e)-\\sum_{e\\text{ into }A} f(e)\\\\ \\le \\sum_{e\\text{ out of }A} f(e)\\\\ \\le\\sum_{e\\text{ out of }A} \\mathrm{cap}(e)\\\\ =\\mathrm{cap}(A,B) \\end{aligned} value(f)​=e out of A∑​f(e)−e into A∑​f(e)≤e out of A∑​f(e)≤e out of A∑​cap(e)=cap(A,B)​ Theorem 3 令 fff 为图上的流且使得 GfG_fGf​ 不存在增广路，那么存在一种 cut (A,B)(A,B)(A,B) 使得 value(f)=cap(A,B)\\mathrm{value}(f)=cap(A,B)value(f)=cap(A,B). 证明 既然 GfG_fGf​ 上已经不存在增广路，那么 GfG_fGf​ 天然的可以被划分为两个集合 A,BA,BA,B，其中 A={ v:s→v },B=V−AA=\\set{v:s\\to v},B=V-AA={v:s→v},B=V−A 这也就是说，原图 GGG 中，AAA 到 BBB 的有向边的 residual capacity 均为 000，根据 Flow Value Lemma，cut(A,B)\\mathrm{cut}(A,B)cut(A,B) 就是一种符合条件的割。 最大流最小割定理 Max Flow=Min Cut \\text{Max Flow}=\\text{Min Cut} Max Flow=Min Cut"},{"title":"【博弈论】Nim 游戏","path":"/wiki/algo/nim-game.html","content":"有向图游戏（博弈图） 博弈图是一张有向图，每一个节点表示游戏的状态（例如每个堆里石子的个数），有向边表示行动（取石子导致了状态的变化）。根据定义，博弈图是有向无环图 Nim Game Graph Nim 定理"},{"title":"经典 NP-Complete 问题与证明","path":"/wiki/algo/npc-problems.html","content":"SAT 形式：AND of OR clauses, Conjunctive Normal Form. 一个 SAT 是多个 clause 取 AND 的结果，每一个 clause 是多个变量取 OR 的结果。 (x1∨¬x2)∧(¬x1∨x3∨x4)∧(x2∨¬x3​) (x_1\\lor \\lnot x_2)\\land (\\lnot x_1\\lor x_3\\lor x_4)\\land (x_2\\lor \\lnot x_3​) (x1​∨¬x2​)∧(¬x1​∨x3​∨x4​)∧(x2​∨¬x3​​) from SAT to 3SAT 3SAT: 在 SAT 的基础上，满足每一个 clause 只包含三个变量。 Clique 团 Clique Problem 是指: 给定一张图 $G=(V,E)$ 和一个整数 $k$，检查是否存在 $|V'|=k$ 的 clique. 证明 首先，clique problem 是 NP 问题。这个比较好证明。 其次，我们尝试把 3SAT 归约到 Clique. 对于每一个 clause ci=x1∨x2∨x3c_i=x_1\\lor x_2\\lor x_3ci​=x1​∨x2​∨x3​，建立三个节点 ni,1,ni,2,ni,3n_{i,1},n_{i,2},n_{i,3}ni,1​,ni,2​,ni,3​. 对于图中不属于同一个 clause 的两个节点 xi,xjx_i, x_jxi​,xj​，只要 xi≠¬xjx_i e \\lnot x_jxi​=¬xj​，就建立一条边。 我们令 k=mk=mk=m，检查图里是否存在大小为 kkk 的 clique. Subset Sum 给定 nnn 个元素 {a1,a2,…an}\\{ a_1,a_2,\\dots a_n \\}{a1​,a2​,…an​} 和一个数 TTT，是否存在能从这 nnn 个元素里找到一个子集，使得其和为 TTT？ 证明 我们证明 3SAT∝pSubset Sum\\text{3SAT} \\propto_p \\text{Subset Sum}3SAT∝p​Subset Sum 考虑 3SAT 有 nnn 个变量和 mmm 个 clause，对于每一个 3SAT 变量 xix_ixi​，在 subset sum 里创建两个变量 ti,fit_i,f_iti​,fi​ 我们令 set 里的变量均有 n+mn+mn+m 位，前 nnn 位记为变量部分，后 mmm 位记为子句部分。 tit_iti​ 变量部分第 iii 位设置为 111，子句部分若 clausej\\text{clause}_jclausej​ 包含 xix_ixi​ 则子句部分的第 jjj 位设置为 111 fif_ifi​ 变量部分第 iii 位设置为 111，子句部分若 clausej\\text{clause}_jclausej​ 包含 ¬xi\\lnot x_i¬xi​ 则子句部分的第 jjj 位设置为 111 同时，对每一个子句 clausei\\text{clause}_iclausei​，创建变量 cic_ici​，其变量部分为全 000，子句部分仅第 iii 位为 111. 考虑如何构造 TTT，令 TTT 的变量部分的每一位都是 111，子句部分的每一位都是 333. 3SAT ⟹ \\implies⟹ Subset Sum 如果 3SAT 存在一种合法的方案 SSS，对于 xi∈Sx_i\\in Sxi​∈S，如果 xi=truex_i=\\texttt{true}xi​=true，则往 subset 里添加 tit_iti​，否则添加 fif_ifi​. 又因为对每一个子句而言，至少有一个 xix_ixi​ 或者 ¬xi\\lnot x_i¬xi​ 为真，因此最多选两个 cjc_jcj​ 一定可以让 TTT 子句部分的第 jjj 位为 333. 3SAT ⟸ \\impliedby⟸ Subset Sum 考虑某个子集的元素： 如果包含 tit_iti​，则令 xi=truex_i=\\texttt{true}xi​=true 如果包含 fif_ifi​，则令 xi=falsex_i=\\texttt{false}xi​=false 因此对于每一个 clausej\\text{clause}_jclausej​ 而言，因为 cjc_jcj​ 最多被选 222 次，而 TTT 对应位置为 333，所有至少有一个 xi∈clausej=truex_i\\in \\text{clause}_j=\\texttt{true}xi​∈clausej​=true，即 clause 为真，从而 3SAT 满足。 Equal Sum Partition 给定数集 {a1,a2,…,an}\\{a_1,a_2,\\dots,a_n\\}{a1​,a2​,…,an​}，能否选出子集，使得子集的和恰好为总和的一半？ 证明 我们证明 Subset Sum∝pEqual Sum Partition\\text{Subset Sum}\\propto_p \\text{Equal Sum Partition}Subset Sum∝p​Equal Sum Partition 令 s=∑ais=\\sum a_is=∑ai​， 如果 t=s2t=\\frac s2t=2s​，那么问题不变 如果 ts2t\\gt \\frac s2t2s​，那么添加一个数 an+1=2t−sa_{n+1}=2t-san+1​=2t−s 否则 ts2t\\lt \\frac s2t2s​，那么添加一个数 an+1=s−2ta_{n+1}=s-2tan+1​=s−2t General Knapsack 背包问题 存在 nnn 个物品，每一个都有重量 wiw_iwi​ 和价值 viv_ivi​。给出重量限制 WWW 和价值目标 VVV，能否选出一些物品 SSS，使得 ∑i∈Swi≤W\\sum_{i\\in S} w_i\\le W∑i∈S​wi​≤W 并且 ∑i∈Svi≥V\\sum_{i\\in S} v_i\\ge V∑i∈S​vi​≥V. 证明 思路：我们证明 Subset Sum∝pKnapsack\\text{Subset Sum}\\propto_p \\text{Knapsack}Subset Sum∝p​Knapsack 【归约】令物品 wi=vi=aiw_i=v_i=a_iwi​=vi​=ai​，且 W=V=TW=V=TW=V=T. Hamiltonian Path 哈密顿路径 有向图下的哈密顿路径 证明 我们证明 3SAT∝pH-Cycle\\text{3SAT}\\propto_p \\text{H-Cycle}3SAT∝p​H-Cycle 【归约】 令 3SAT 有 nnn 个变量和 mmm 个子句。对于一个变量 xix_ixi​： 让其对应一行节点 rowirow_irowi​，包含 3m+33m+33m+3 个节点，这一行的相邻节点之间连双向边 在这一行节点中，从第二个节点开始，每三个节点代表一个 clause cjc_jcj​，颜色顺序为黄、绿、绿 额外有一个黄色节点，分别指向这一行的开头结尾两个节点 规定 xi=truex_i=\\texttt{true}xi​=true 则往左走，否则往右走 一行的开头结尾两个节点又分别指向 xi+1x_{i+1}xi+1​ 的额外黄色节点 对应 $x_i$ 对于每一个子句 cjc_jcj​，找到其所包含的三个变量的行 rowirow_irowi​ 中，对应 cjc_jcj​ 的两个绿色节点 rowi,1,rowi,2row_{i,1},row_{i,2}rowi,1​,rowi,2​，分别连不同方向的有向边。 如果是 xix_ixi​，则连边方向为：靠左的绿色节点 对应 $c_j$ 3SAT ⟹ \\implies⟹ H-Path 如果一个合法的 3SAT 方案存在 最长路径 旅行商问题"},{"title":"NP 理论初探","path":"/wiki/algo/np-complete.html","content":"P 与 NP P: 存在多项式算法，可以解出一个 solution NP: 存在多项式算法，给定 solution 可以判定输入是否合法 NP-Complete: 所有 NP 问题都可以归约到 AAA，且 AAA 是 NP 问题，则 AAA 是 NP-Complete 问题 NP-Hard Polynomial-Time Reduce B≤pAB \\le_p AB≤p​A 或者 B→AB\\to AB→A，表示存在一个多项式算法 fff： 将 BBB 问题的输入 xxx 转化为 AAA 问题的输入 f(x)f(x)f(x)； xxx 是 BBB 问题的一组合法解，当且仅当 f(x)f(x)f(x) 是 AAA 问题的一组合法解。 NP 问题判定定理 111 若 B→AB\\to AB→A，且 AAA 是 P 问题，则 BBB 也是 P 问题。 【证明】 因为 AAA 问题内多项式时间 O(f(x))O(f(x))O(f(x)) 内可解，而又存在多项式算法 O(g(x))O(g(x))O(g(x)) 可以转化输入，则可以在 O(f(x)+g(x))O(f(x)+g(x))O(f(x)+g(x)) 的时间内解决 BBB. □\\square□ NP-Hard 优化问题 (Optimization Problem) NP Problem 是在寻找可行解，而其对应的优化问题则是在找最优解。 如果某个优化问题对应的判定问题是 NP Complete 的，则这个优化问题为 NP Hard 的。 考虑判定问题 XXX 和对应的优化问题 YYY，如果 XXX 是 NP Complete 问题 我们可以在多项式时间内解决 YYY 则我们可以在多项式时间内解决 XXX，从而 P=NPP=NPP=NP，那么 YYY 就是 NP-Hard 的。"},{"title":"有约束的数字满足性问题","path":"/wiki/algo/number-constraint-model.html","content":"题面描述 这类题型有几个比较明显的特征： 通常询问的是 ≤n\\le n≤n 内满足某个条件的数有多少个 通常数据范围很大，如 n≤1018n\\le 10^{18}n≤1018 解法一：素因子分解法 这一种方法的视角下，条件通常可以在素因子分解后，转化成指数上的约束，大大减少了可能的数得到范围。 【例】Number Reduction 考虑一个数 xxx，如果 xxx 的十进制表示中含有 kkk (2≤k≤92\\le k\\le 92≤k≤9) 且 k∣xk|xk∣x，则将 x←xkx\\gets \\frac{x}{k}x←kx​. 如果 xxx 可以经过以上任意次操作变成 111，则 xxx 是 Good 的。给定一个整数 n≤1018n\\le 10^{18}n≤1018，问有多少个数 ≤n\\le n≤n 是 Good 的？ 根据题面，显然我们每次只能除以 2∼92\\sim 92∼9，既然最后可以变成 111，这就说明 xxx 只能含有因子 2,3,5,72,3,5,72,3,5,7，即 x=2a3b5c7d x=2^a3^b5^c7^d x=2a3b5c7d那么 ≤1018\\le 10^{18}≤1018 有多少数满足这样的形式呢？答案是 log⁡2(1e18)×log⁡3(1e18)×log⁡5(1e18)×log⁡7(1e18)≈1.2×106\\log_2(1e18)\\times\\log_3(1e18)\\times\\log_5(1e18)\\times\\log_7(1e18)\\approx 1.2\\times 10^6log2​(1e18)×log3​(1e18)×log5​(1e18)×log7​(1e18)≈1.2×106. 可以看到量级最大大概只有 10610^6106. 确定了数不多后，我们考虑把所有这样的数都提取出来，然后检查数位和整除的条件. 既然最终可以变成 111，这样一个变化的过程即 a0=1→×m0a1→×m1a2→×m2…→×mkak+1 a_0=1\\underset{\\times m_0}{\\to}a_1\\underset{\\times m_1}{\\to}a_2\\underset{\\times m_2}{\\to}\\dots\\underset{\\times m_k}{\\to}a_{k+1} a0​=1×m0​→​a1​×m1​→​a2​×m2​→​…×mk​→​ak+1​这里 mi∈[2,9]m_i\\in [2,9]mi​∈[2,9]，所以其实相当于在有向无环图，以 111 为起点能到达的所有点。我们只需要对每一个 x=2a3b5c7dx=2^a3^b5^c7^dx=2a3b5c7d，枚举数位并判断整除，然后在图上添加有向边，最后从 111 开始跑 DFS 即可。 【时间复杂度】枚举 2a3b5c7d2^a3^b5^c7^d2a3b5c7d 需要 O(log⁡4n)O(\\log^4 n)O(log4n) 的时间，再算上枚举数字和其数位，需要 O(log⁡5n)O(\\log^5 n)O(log5n). Code #include algorithm#include cmath#include iostream#include unordered_map#include vectorusing i64 = long long;using vi = std::vectorint;constexpr int N = 1e7 + 5;vi G[N];i64 n;std::vectori64 v;std::unordered_mapi64, int mp;int mark[10];i64 get_num(i64 a, i64 b, i64 c, i64 d) return std::pow(2ll, a) * std::pow(3ll, b) * std::pow(5ll, c) * std::pow(7ll, d);int main() std::cin n; for (i64 a = 1; a = n; a *= 2) for (i64 b = 1; b = n; b *= 3) for (i64 c = 1; c = n; c *= 5) for (i64 d = 1; d = n; d *= 7) i64 x = a * b * c * d; if (x = n) v.push_back(x); for (int i = 0; i v.size(); i++) mp[v[i]] = i; for (int i = 0; i 10; i++) mark[i] = -1; for (int i = 0; i v.size(); i++) i64 x = v[i]; while (x 0) mark[x % 10] = i; x /= 10; for (int j = 2; j = 9; j++) if (mark[j] != i || v[i] % j != 0 || !mp.count(v[i] / j)) continue; G[mp[v[i] / j]].push_back(mp[v[i]]); int ans = 0; vi vis(v.size(), false); auto dfs = [](auto F, int u) - void vis[u] = true; ans++; for (int v : G[u]) if (!vis[v]) F(F, v); ; dfs(dfs, mp[1]); std::cout ans std::endl; 解法二：数位 DP 算是数数字的正统方法。记忆化搜索的写法比迭代的写法更简单易懂。"},{"title":"回文树","path":"/wiki/algo/palindromic-tree.html","content":"回文树 回文树基于三个重要的观察： 代码实现 回文树的构建 回文树依赖若干个数据结构 树上的每一个节点实际上代表了一个以 iii 为结尾的最长回文串（从根到 s[i]s[i]s[i]） 对于树上的实边 next[] 指针，next[i][c] = j 说明在以 iii 为结尾的最长回文串的两边各添加字符 c（其实也就是 s[j]s[j]s[j]）之后，就变成了以 jjj 为结尾的最长回文串。 对于树上的虚边 fail[] 指针，它实际上维护的是以 iii 为结尾的次长回文串。如果 fail[i] = j，则次长的回文串是 node[j]，其中 node[j] 表示树上节点 jjj 代表的最长回文串 没错，也就是说此时以 iii 为结尾的次长回文串和以 jjj 为结尾的最长回文串是一样的。但是我们又必须以 iii 为结尾，所以我们只需要知道其长度信息即可。 要注意的是，节点建模的是“回文串”而不是“以 iii 为结尾的最长回文串”，因为以 iii 为结尾可能有很多回文串，我们就是要通过 fail 指针快速查找以 iii 为结尾的回文串的长度，所以回文串以 iii 结尾还是 jjj 结尾（对于长度这个信息而言）无关紧要。 我们先来定义数据结构 using indexing = int;constexpr int N = 5e5 + 5;constexpr int E = 26;struct Node std::arrayindexing, E next; // 实边 indexing fail0; // 虚边 fail 指针 int len0; // 这个节点对应的回文串 的长度 int num0; // 多少回文串以 节点i代表的最长回文串最末尾的字符 为结尾 int count0; // 这个节点对应的回文串 的数量 void init(int len) this-len = len; this-count = 0; fail = 0; next.fill(0); ;std::arrayNode, N T;std::arrayint, N S;indexing last = 0, pnode = -1, strend = -1;// 构造一个新节点，放在末尾indexing construct(int len) T.at(++pnode).init(len); return pnode;// 初始化，添加偶根和奇根节点// 在最开头插入一个不可能出现的字符，减少后面的特判void init() // 0: 偶根，1: 奇根 construct(0), construct(-1); T[0].fail = 1; S[++strend] = -1; last = 0; 跳 fail 指针 然后我们先来看如何跳 fail 指针。跳 fail 指针的核心在于，对于当前字符 S[i]S[i]S[i] 找到一个位置 jjj 使得 S[i]=S[j]S[i]=S[j]S[i]=S[j]。 如果指针当前指向的 vvv、其代表的回文串为 p(v)p(v)p(v)，则 j=i−p(v).len−1j=i-p(v).\\texttt{len}-1j=i−p(v).len−1。如果无法匹配，我们就跳 fail 指针 j←j.failj\\gets j.\\texttt{fail}j←j.fail，即我在满足 S[j…i−1]S[j\\dots i-1]S[j…i−1] 是回文串的条件下缩小这个后缀回文串的长度，然后判断 iii 能组成的后缀回文串的最大长度。 // 返回 pos 使得// T[pos].len 最大，且 S[strend - T[pos].len - 1] ~ S[strend] 构成回文串indexing match(indexing pos) while (S[strend] != S[strend - T[pos].len - 1]) pos = T[pos].fail; return pos; 在字符串末尾插入字符 然后我们执行插入字符操作。我们需要做两件事： 维护 next[] 指针（实边） 维护 fail 指针（虚边） 对于实边而言，我们找到一个第一个 pos 使得 S[i-T[pos].len-1] ~ S[i] 构成回文串，那么根据定义，iii 应该成为 pos 的儿子节点，边权为 S[i]. 对于虚边而言，我们需要找到下一个 jjj 使得 j≠posS[j…i] is palindrome. j e pos \\\\ S[j\\dots i] \\text{ is palindrome.} j=posS[j…i] is palindrome.既然 S[j…i]S[j\\dots i]S[j…i] 是回文串，那么 S[j+1…i−1]S[j+1\\dots i-1]S[j+1…i−1] 也应该是回文串，且 S[j]=S[i]S[j]=S[i]S[j]=S[i]。这不就是要找 S[i−1]S[i-1]S[i−1] 为结尾的回文串嘛！不过由于是 fail 指针，所以这里的“回文串”其实不是指最长回文串，也就是说，我们需要从 pos.fail 开始跳 fail 指针，以免用最长回文串来更新 fail. void insert(int c) S[++strend] = c; indexing fa = match(last); indexing son = T[fa].next[c]; if (!son) son = construct(T[fa].len + 2); T[son].fail = T[match(T[fa].fail)].next[c]; T[fa].next[c] = son; T[son].num = T[T[son].fail].num + 1; // 注意这里必须先维护 fail 再更新子节点 // 不然可能出现当 fa 为偶根和奇根的时候 T[son].fail = son last = son; T[son].count++; 在字符串的开头插入字符 在末尾插入比较好理解，考虑当前在维护第 iii 个字符，last 刚好可以代表以 S[i−1]S[i-1]S[i−1] 为结尾的最长回文串。那如果需要在字符串开头插入字符呢？ 类似的，我们想，是不是需要用 last_front 表示以 S[0]S[0]S[0] 为开头的最长回文串，然后跳 fail 呢？但是我们的节点维护的都是以某个字符为结尾的回文串，应该怎么转化呢？ 这里，我们就需要以“节点对应的是回文串”视角来看待 last 和 last_front 指针了（而非“节点对应的是以 i−1i-1i−1 为结尾的回文串”）。last_front 指针保存的回文串，是从 S.front() 为开头的最长回文串。 last_front 指针 我们考虑对 last_front 跳 fail 指针，得到的是什么。根据跳 fail 指针的定义，我们会有 last_front 的跳 fail 考虑 last_front 对应回文串的回文性，于是： 利用回文性和 fail 指针的长度信息 于是我们就可以使用和“在末尾插入字符”同样的思路，维护“在开头插入字符”的操作。 线性时间复杂度证明 证明线性复杂度，我们考虑节点在 fail 树上的深度。"},{"title":"Prufer 序列","path":"/wiki/algo/prufer-seq.html","content":""},{"title":"网络流：预流推进算法","path":"/wiki/algo/push-relabel.html","content":"代码参考 template typename Tclass FlowGraph public: struct Edge std::size_t to; T cap; // flow, capacity ; std::vectorint dist; std::vectorstd::size_t cur; std::vectorstd::vectorstd::size_t adj; std::vectorEdge edges; std::size_t s, t; std::size_t vtot, etot; // ! ===== functionality ===== FlowGraph() : vtot(0), etot(0) void init(std::size_t s, std::size_t t, std::size_t vtot) this-s = s, this-t = t, this-vtot = vtot; adj.resize(vtot), dist.resize(vtot), cur.resize(vtot); void add(std::size_t u, std::size_t v, T f) adj.at(u).push_back(edges.size()); edges.emplace_back(v, f); adj.at(v).push_back(edges.size()); edges.emplace_back(u, 0); ;template typename Tclass PushRelabel : public FlowGraphT public: std::vectorT height; std::vectorT excess; std::vectorstd::size_t gap; std::vectorstd::vectorstd::size_t bucket; T level0; static constexpr T inf = std::numeric_limitsT::max(); bool push(std::size_t u) bool init = u == this-s; for (auto e : this-adj.at(u)) auto [v, cap] = this-edges.at(e); if (cap == 0 or this-height.at(v) == inf) continue; if (!init and this-height.at(u) != this-height.at(v) + 1) continue; T k = init ? cap : std::min(cap, this-excess.at(u)); if (v != this-s and v != this-t and this-excess.at(v) == 0) this-bucket.at(this-height.at(v)).push_back(v); this-level = std::max(this-level, this-height.at(v)); // push this-excess.at(u) -= k; this-excess.at(v) += k; this-edges.at(e).cap -= k; this-edges.at(e ^ 1).cap += k; if (this-excess.at(u) == 0) return false; // finish pushing return true; void relabel(std::size_t u) this-height.at(u) = inf; for (auto e : this-adj.at(u)) auto [v, cap] = this-edges.at(e); if (cap 0) this-height.at(u) = std::min(this-height.at(u), this-height.at(v)); this-height.at(u)++; if (this-height.at(u) static_castT(this-vtot)) this-bucket.at(this-height.at(u)).push_back(u); level = std::max(level, this-height.at(u)); ++this-gap.at(this-height.at(u)); bool bfs_init() this-height.assign(this-vtot, inf); std::queuestd::size_t q; q.push(this-t); this-height.at(this-t) = 0; while (!q.empty()) auto u = q.front(); q.pop(); for (auto e : this-adj.at(u)) auto [v, cap] = this-edges.at(e); auto [rv, rcap] = this-edges.at(e ^ 1); if (rcap 0 and this-height.at(v) this-height.at(u) + 1) this-height.at(v) = this-height.at(u) + 1; q.push(v); return this-height.at(this-s) != inf; std::size_t select() while (this-level -1 and this-bucket.at(this-level).size() == 0) this-level--; return this-level == -1 ? 114514 : this-bucket.at(this-level).back(); public: void init(std::size_t s, std::size_t t, std::size_t n) FlowGraphT::init(s, t, n); this-height.assign(n, inf); this-excess.assign(n, 0); this-gap.assign(n + 1, 0); this-bucket.assign(n + 1, ); this-level = 0; T max_flow() if (not this-bfs_init()) return 0; this-gap.assign(this-vtot, 0); for (std::size_t i = 0; i this-vtot; i++) if (this-height.at(i) != inf) this-gap.at(this-height.at(i))++; this-height.at(this-s) = this-vtot; this-push(this-s); for (std::size_t u = select(); u != 114514; u = select()) this-bucket.at(this-level).pop_back(); if (this-push(u)) if (not --this-gap.at(this-height.at(u))) for (std::size_t i = 0; i this-vtot; i++) if (i == this-s) continue; if (this-height.at(i) = static_castT(this-vtot + 1)) continue; if (this-height.at(i) = this-height.at(u)) continue; this-height.at(i) = static_castT(this-vtot + 1); this-relabel(u); return this-excess.at(this-t); ;"},{"title":"线段树分治","path":"/wiki/algo/segtree-decomp.html","content":"线段树分治"},{"title":"数列模型","path":"/wiki/algo/seq-model.html","content":"数列变换模型 数列变换模型 有 A,BA,BA,B 两个数列，每次操作可以对 AAA 数列进行操作，求问能否通过操作使得 A=BA=BA=B？ 解题思路 转化成 ai←ai−1,aj←aj+1a_i\\gets a_i-1, a_j\\gets a_j+1ai​←ai​−1,aj​←aj​+1 的模型。"},{"title":"Sum over Subset DP","path":"/wiki/algo/sosdp.html","content":"Intro 若 xxx 有 kkk 个 bits 为 000，则 xxx 会被 2k2^k2k 个 mask 访问."},{"title":"三角剖分与 Voronoi 图","path":"/wiki/algo/triangulation.html","content":"Delauney 三角剖分 双向链接边表 DCEL"},{"title":"使用 Dify 的“节点”完成数据预处理","path":"/wiki/dify/custom-data-preprocess.html","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"安装与部署 Dify","path":"/wiki/dify/install-n-use.html","content":"下载 Dify 的 docker compose 文件 git clone 启动 docker 确保 docker 可以共享文件夹 在 docker desktop - settings - resource share 里查看 folder 是否存在。 进入本地部署的 Dify 使用 ip a 查看 docker0 对应的 IP 地址（inet），然后用这个 IP 进入，而不是 localhost"},{"title":"SVD","path":"/wiki/linear-algebra/SVD.html","content":"SVD 分解"},{"title":"CAPM 资本资产定价模型","path":"/wiki/fina/CAPM.html","content":"公式 E[Rp]=Rf+βp(RM−Rf) \\mathbb E[R_{p}]=R_f+\\beta_{p}(R_M-R_f) E[Rp​]=Rf​+βp​(RM​−Rf​)市场风险溢价 例题"},{"title":"IRR","path":"/wiki/fina/IRR.html","content":"Definition The IRR of the project is the single annual discount rate at which the NPV of the project is equal to zero. 公式 NPV=C0+∑i=1m(11+IRR)iCi=0 NPV=C_0+\\sum_{i=1}^{m} \\Big(\\frac{1}{1+IRR}\\Big)^i C_i=0 NPV=C0​+i=1∑m​(1+IRR1​)iCi​=0 IRR Rule 定义 Minimum required return 计算 IRRIRRIRR，与 required return 进行比较 问题 还需要将 Interest Rate 纳入考量 解决办法 先算出两个 project 的 NPV 相等时的利率 RRR，然后根据现在的利率，判断选择那个 project. Amortization Schedule monthly: IRR12\\frac{IRR}{12}12IRR​"},{"title":"Bonds","path":"/wiki/fina/bonds.html","content":"Bonds 债券 不拥有 Ownership 不能投票 无论是否盈利，盈利多少，企业都必须支付本息；否则视为破产 有法律义务支付本息 企业先支付本息，再支付分红 由于支付利息视作企业运营的开支，因此可以抵扣税款 Terms Maturity Date Face Value (Par Value) FFF Coupon Payment CCC Variations Zero-Coupon Bonds: 无利息 Bond Valuation NPV Approach Yield to Maturity (YTM) YTM 使得债券 NPV 为 000 时的 discount rate 假设一年付 mmm 次，那么每次付的比率是 YTMm\\frac{YTM}{m}mYTM​；假设 nnn 年 −P0+C×1−(1+YTM/m)−nmYTM/m+F×(1+YTM/m)−nm=0 -P_0+C\\times\\frac{1-(1+YTM/m)^{-nm}}{YTM/m}+F\\times\\Big( 1+YTM/m \\Big)^{-nm}=0 −P0​+C×YTM/m1−(1+YTM/m)−nm​+F×(1+YTM/m)−nm=0 The investors are getting an annual rate of return equal to the return they require on the investment The YTM can be obtained ONLY IF we hold the bond until maturity Risk of Investment 债券投资的风险 利率风险：市场利率上升导致债券价格下跌。 信用风险：发行人违约可能性（如公司破产）。 流动性风险：债券难以快速变现。 通胀风险：通胀削弱固定收益的实际购买力。"},{"title":"Capital Investment Decision","path":"/wiki/fina/capital-investment-decision-01.html","content":"Incremental Cash Flow=Operating Cash Flow−Incremental Cash Flow on Capital Spending−Incremental Cash Flow on Change in Net Working Capital \\begin{aligned} \\text{Incremental Cash Flow}\\\\ \\quad =\\text{Operating Cash Flow}\\\\ \\quad -\\text{Incremental Cash Flow on Capital Spending}\\\\ \\quad -\\text{Incremental Cash Flow on Change in Net Working Capital} \\end{aligned} ​Incremental Cash Flow=Operating Cash Flow−Incremental Cash Flow on Capital Spending−Incremental Cash Flow on Change in Net Working Capital​ EBIT approach 先计算 EBIT Tax Shield approach OCF=(PQ−FC−VC)(1−Tc)+Dep⋅Tc OCF=(PQ-FC-VC)(1-T_c)+Dep\\cdot T_c OCF=(PQ−FC−VC)(1−Tc​)+Dep⋅Tc​ 例题 Opportunity Cost 相关 Parker Stone, Inc. is considering building a new manufacturing plant in South Park to produce garden tools. The company purchased land six years ago for $2.8\\$2.8$2.8 million with the intention of using it as a warehouse and distribution site. However, the company later decided to lease these facilities from a competitor instead. If sold today, the land could generate $3.2\\$3.2$3.2 million in net proceeds. The company now plans to build the new manufacturing plant on this land, which will cost $14.3\\$14.3$14.3 million to construct. Additionally, the site requires $825,000\\$825,000$825,000 in grading expenses to prepare it for construction. Question: What is the appropriate cash flow amount to use as the initial investment in fixed assets when evaluating this project? Explain your reasoning."},{"title":"Capital Structure 资产结构","path":"/wiki/fina/capital-structure.html","content":"Handout10: Key Take-Away 企业现值：无负债 V=EV=EV=E；有负债 V=E+DV=E+DV=E+D Cost of Equity Cost of Debt MM Proportion 1 在无税收、无破产成本的情况下，有 VU=VLV_U=V_LVU​=VL​. 这是因为无税收无破产成本的情况下，所有的 EBIT 只在企业、股权所有者、债权所有者之间流通。 MM Proportion 2: 股权、债权、资产对风险的敏感程度的关系为 DVβD+EVβE=βA\\frac{D}{V}\\beta_D+\\frac{E}{V}\\beta_E=\\beta_AVD​βD​+VE​βE​=βA​ 股权、债权、资产的期望回报率 (Expected Return) 为 DVE[RD]+EVE[RE]=E[RA]\\frac{D}{V}\\mathbb E[R_D]+\\frac{E}{V}\\mathbb E[R_E]=\\mathbb E[R_A]VD​E[RD​]+VE​E[RE​]=E[RA​] 改变股权债权结构 不影响股价 平衡点：ENE=DND\\frac{E}{N_E}=\\frac{D}{N_D}NE​E​=ND​D​，即股权价格等于债权价格。 Handout11: Key Take-Away Without Tax and Backruptcy Costs 企业可以通过 发行股票 issue Equity 举债 debt, bonds, bank loan 进行融资。 Value of Firm=Value of Equity+Value of Debt \\text{Value of Firm}=\\text{Value of Equity}+\\text{Value of Debt} Value of Firm=Value of Equity+Value of Debt MM Proportion I 在无税收、无破产成本的情况下，公司价值 VVV 不受资本结构影响，即无杠杆公司的价值等于有杠杆的公司 VU=VL=OCF V_U=V_L=OCF VU​=VL​=OCF With Tax and Bankruptcy Costs MM Proportion I 在存在企业所得税的情况下，公司价值（VLV_LVL​​）随财务杠杆增加而提升 ，主要因利息税盾（Interest Tax Shield）的税收优惠效应。 VL=VU+D×Tc V_L=V_U+D\\times T_c VL​=VU​+D×Tc​ MM Proportion II 在有税环境下，股权成本（RER_ERE​​）仍随杠杆增加而上升 ，但公式需调整以反映税盾效应： RE​=RU+(RU​−RD​)×ED​×(1−Tc​) R_E​=R_U+(R_U​−R_D​)\\times E_D​\\times (1−T_c​) RE​​=RU​+(RU​​−RD​​)×ED​​×(1−Tc​​)税收降低了债务的实际成本（因利息税盾），但股权风险和成本仍随杠杆上升而增加。"},{"title":"Investment Decision Rule","path":"/wiki/fina/invest-decision-rule.html","content":"Investment Decision Rule … based on Returns 就是看最后拿到的钱 RewardRewardReward 是不是初始投资 InvestInvestInvest 多就行， … based on NPV NPV定义​ 净现值（Net Present Value, NPV）是评估投资项目价值的核心指标，计算方式为项目所有现金流（含初始投资）按贴现率折算后的现值总和。公式为： NPV=C0​+∑i=1TCi(1+R)iNPV=C_0​+\\sum_{i=1}^T\\frac{C_i}{(1+R)^i}NPV=C0​​+∑i=1T​(1+R)iCi​​ CtC_tCt​​: 第 ttt 期的现金流（C0C_0C0​​ 为初始成本，通常为负值）。 RRR: 贴现率（通常为金融市场可获得的回报率）。 ​决策规则​ ​NPV 0：项目收益高于金融市场回报，应接受。 ​NPV 0：项目收益低于金融市场回报，应拒绝。 ​NPV = 0：项目收益与金融市场相当，决策无差异（可结合其他因素考虑）。 ​关键原则​ ​基准比较：以金融市场回报率为基准，衡量项目是否创造额外价值。 ​现金流方向： 现金流入（收入）为正值（Ct​0）。 现金流出（成本）为负值（Ct​0）。 沉没成本忽略：过去已发生且不可逆的成本（如前期调研费用）不计入NPV，仅考虑未来现金流。 ​注意事项​ ​时间价值：现金流的时点影响现值，需准确对应贴现期数。 ​零NPV的意义：项目回报率等于贴现率（金融市场回报率），而非无收益。 总结：NPV规则通过量化项目相对于金融市场的净收益，为投资决策提供清晰标准，强调未来现金流和沉没成本的正确处理。 … based on IRR 预设项目的最少回报 (Minimum Return Required)，然后判断项目的 IRR 是否高于预期。 Internal Rate of Return (IRR) 是将单笔资金拓展到多笔资金，IRRIRRIRR 是年利率 (Annual Rate of Return)，使得整个项目周期结束后的 NPV 为零 NPV=0=C0+∑i=1T(11+IRR)iCi NPV=0=C_0+\\sum_{i=1}^T \\Big(\\frac{1}{1+IRR}\\Big)^i C_i NPV=0=C0​+i=1∑T​(1+IRR1​)iCi​ NPV or IRR 实际上，IRR 和 NPV 大致成反比关系。 Notice the role of the return from the financial sector (e.g., interest rate on bank deposit) in the NPV rule and IRR rule: in the NPV rule, it is the discount rate in the IRR rule, it is the (minimum) required return of the real investment project under consideration. conventional: 初始投资都是 cash outflow，后续所有现金流都是入账 cash inflow non-conventional: 不符合 conventional 的现金流情况 IRR Rule 的问题 当同时考虑多个项目时，先计算 xxx，使得这几个项目在 Discount Rate 为 xxx 时的 NPV 相同。 Payback Rule 考虑多久可以回本（不考虑 discount） Discounted Payback Rule 先 discount cash flow，再应用 Payback Rule Profitability Index PI=PV of future cash flowsinitial cost PI=\\frac{\\text{PV of future cash flows}}{\\text{initial cost}} PI=initial costPV of future cash flows​"},{"title":"Agency Problem 和 Market Efficiency","path":"/wiki/fina/market-efficiency.html","content":"Agency Problem 什么是 Agency Problem? 代理问题指公司管理层（代理人）与股东（委托人）之间的利益冲突。管理层可能牺牲股东利益，追求自身利益最大化。 例如，接受负净现值（NPV）项目以获取回扣。 ​​委托——代理关系​​ 股东（委托人）委托管理层（代理人）管理公司，但代理人可能以牺牲委托人利益为代价谋取私利。 Compensation Package 薪酬结构 股权激励​​：将管理层薪酬与公司股票表现挂钩，使其利益与股东一致。 例子​​：若管理层持有公司股票，接受负NPV项目会导致其持股价值下降，从而抑制此类行为。 ​​固定薪酬的局限性​​：固定工资无法激励管理层为公司价值最大化努力。 合伙制中的代理问题​​ 普通合伙​​（无限责任）：合伙人需以个人财产承担公司债务，降低冒险行为。 有限合伙​​：部分合伙人仅承担有限责任，可能增加代理问题。 例子​​：普通合伙人在面临破产风险时更谨慎，因其个人资产可能被追偿。 Efficient Market Hypothesis 有效市场假设 Technical Analysis基于股票的历史交易数据从历史交易的价格检测出规律，并总结为交易策略 Fundamental Analysis基于股票的内在价值从企业的商业运营衡量股票的价值例如 Dividend Discount Model (DDM): PV=∑iDi(1+r)iPV=\\sum_i \\frac{D_i}{(1+r)^i}PV=∑i​(1+r)iDi​​常见做法：track the performance of actively managed mutual funds, 因为……这些基金由专家管理这些专家也只能通过公开数据、公开信息来对股票进行股价和选股CAPM 模型可以用来看是否可以 outperform market Fundamental Analysis 的暗示：有的时候连专家也无法保证持续从股票获利，那么为什么要交昂贵的管理费？于是诞生了指数 (index funds)，进一步演化为 EFT (Exchange Traded Funds) 使得一群股票可以像一支股票那样进行买卖。 Weak Form Efficiency 【定义】股价已反映所有历史交易信息（如价格、成交量），Technical Analysis 无效。 Semi Strong Form Efficiency 股价已反映所有公开信息（如财报、行业新闻），Fundamental Analysis 无效。 Strong Form Efficiency 股价反映所有信息（包括内幕信息），内幕交易也无法获利。 但内幕交易违法，现实中几乎不存在 IPO IPO (Initial Public Offering) 指公司首次向公众发行股票并在证券交易所上市的过程，是私有企业转变为上市公司的关键步骤。 IPO 流程与参与者 前期准备与风险投资 (Venture Capital, VC) VC的作用​​： 资金与指导​​：VC 在 IPO 前为公司提供资金和战略支持，帮助其扩展业务、优化管理。 持股与退出​​：VC 通过持有公司股份（通常为40%以上）并在 IPO 后出售股票获利。 投资银行 (Investment Banks) 核心职责： 承销 (Underwriting)​​：投行承诺购买全部新股并转售给公众，承担发行风险。从企业购入股票的价格会低于售卖给公众的价格，从中获利。 firm commitment underwriting: 买下企业全部的股票 定价​​：确定发行价，需平衡公司融资需求与市场接受度。 组建承销团 (Syndicate)：多家投行联合承销以分散风险（如阿里巴巴 IPO 由高盛、瑞银等牵头）。 费用结构： 承销费通常为融资额的 4%∼7%4\\%\\sim 7\\%4%∼7% Under-Pricing IPO 发行价低于首日收盘价，导致投资者首日可获得超额收益。 原因： 信息不对称：投行可能刻意低估发行价以确保发行成功（如吸引长期投资者）。 市场热度：高抑价可制造“赚钱效应”，吸引更多投资者参与后续 IPO。 风险补偿：新股不确定性高，抑价作为对投资者的风险补偿。 可能带来的损失： 公司损失：抑价导致公司融资额减少 投机行为：散户可能因追逐首日涨幅盲目申购，面临破发风险"},{"title":"PV, FV, NPV","path":"/wiki/fina/pv-fv-npv.html","content":"PV, NPV Present Value: 一笔在未来会获得的钱在当下的价值 Future Value: 一笔现在的钱在未来的价值 实际上 PV 和 FV 非常简单，主要就是考虑利滚利 (Compounding of Interest)，把指数算清楚即可。 某一笔钱的 PV/FV 钱的 PV 相当于说，如果某笔 TTT 年后的钱 QQQ，且利率 rrr 保持不变，那么现在要存 PVPVPV 块钱，这样经过 TTT 年的利滚利，这 PVPVPV 块钱就变成了 QQQ 块钱。 PV×(1+r)T=Q PV\\times (1+r)^T=Q PV×(1+r)T=Q反过来，Future Value 就是，现在存的 QQQ 块钱，在 TTT 年后会变成 FVFVFV 块钱。 FV=Q×(1+r)T FV=Q\\times(1+r)^T FV=Q×(1+r)T 现金流（多笔钱）的 PV/FV 本质就是多笔钱的 FV/PV 全部换算到当前的时间点， PVaggregate=∑PViFVaggregate=∑FVi PV_{aggregate}=\\sum PV_{i}\\\\ FV_{aggregate}=\\sum FV_{i}\\\\ PVaggregate​=∑PVi​FVaggregate​=∑FVi​由于每笔钱的利滚利时间不同，因此右式的和式通常又可以写成有限项等比数列求和的形式 Annuity, Perpetuity Perpetuity 表示永久持续的恒定现金流，用 CCC 表示每年的现金流（且第一笔现金在一年后） 必须满足两个条件： The cash flows and the interest rates are constant over time, The first cash flow occurs one year from today. 那么所有这些钱的 PV 就是 PV=∑i=1∞C×(11+r)i=Cr \\begin{aligned} PV=\\sum_{i=1}^{\\infin} C\\times(\\frac{1}{1+r})^i\\\\ =\\frac{C}{r} \\end{aligned} PV​=i=1∑∞​C×(1+r1​)i=rC​​ Present Value of Annuity 与 Perpetuity 的区别在于 Annuity 有时限。假设经过 TTT 年，那么 Annuity 的 PV 就等于 PV=C(11+r)+C(11+r)2+⋯+C(11+r)T=C×1−(11+r)Tr PV=C(\\frac{1}{1+r})+C(\\frac{1}{1+r})^2+\\dots+C(\\frac{1}{1+r})^T=C\\times\\frac{1-(\\frac{1}{1+r})^T}{r} PV=C(1+r1​)+C(1+r1​)2+⋯+C(1+r1​)T=C×r1−(1+r1​)T​在一笔现金的时候我们知道，(11+r)T(\\frac{1}{1+r})^T(1+r1​)T 就是 Present Value Factor，所以也可以直接代入写成 PV=1−Present Value Factor(T)rC PV=\\frac{1-\\text{Present Value Factor}(T)}{r}C PV=r1−Present Value Factor(T)​C Future Value of Annuity 如果以第 TTT 年的价值作为基准，把每一笔钱的 FV 都加起来，就能得到 FV=(1+r)T−1rC=Future Value Factor(T)−1rC FV=\\frac{(1+r)^T-1}{r}C=\\frac{\\text{Future Value Factor}(T)-1}{r}C FV=r(1+r)T−1​C=rFuture Value Factor(T)−1​C Effects of Inflation 由于通胀 (Inflation) 的存在，尽管手上的钞票数量变多了，但这并不意味着购买力 (Purchasing Power) 提升。 Purchasing Power the quantity of goods and services that we can buy with our money. … on Nominal/Real Interest Rate Fisher’s Equation Nominal IR RRR: interest rate in terms of money Real IR rrr: interest rate in terms of purchasing power 我们用 hhh 表示物价的变化，即通胀率 (Inflation Rate)，则可以得出他们之间的关系 (Fisher Equation) (1+r)(1+h)=(1+R) (1+r)(1+h)=(1+R) (1+r)(1+h)=(1+R) 证明 考虑一开始的钱 QQQ，一开始的物价 PPP，则今年的购买力为 QP\\frac{Q}{P}PQ​，明年的购买力（即经过一年的通胀）为 Q(1+R)P(1+h)\\frac{Q(1+R)}{P(1+h)}P(1+h)Q(1+R)​ 根据 Real Interest Rate 的定义，我们有 Purchase Poweri+1−Purchase PoweriPurchase Poweri=Real IRQ(1+R)P(1+h)QP=1+r(1+r)(1+h)=1+R \\begin{aligned} \\frac{\\text{Purchase Power}_{i+1}-\\text{Purchase Power}_i}{\\text{Purchase Power}_i}=\\text{Real IR}\\\\ \\frac{\\frac{Q(1+R)}{P(1+h)}}{\\frac{Q}{P}}=1+r\\\\ (1+r)(1+h)=1+R \\end{aligned} Purchase Poweri​Purchase Poweri+1​−Purchase Poweri​​PQ​P(1+h)Q(1+R)​​(1+r)(1+h)​=Real IR=1+r=1+R​ 由于这些值都很小，所以我们通常直接近似为 r≊R−hr\\approxeq R-hr≊R−h … on PV NPV Inflation 并不影响 PV 和 NPV。但必须 discount nominal cash at a nominal rate 或者 discount real cash at a real rate 证明 考虑 inflation rate 为 hhh，nominal interest rate 为 RRR，考虑 nnn 年后的一笔钱 CCC (nominal)，那么用 Nominal Interest Rate 算的话 PVnominal=C(1+R)n PV_{nominal}=\\frac{C}{(1+R)^n} PVnominal​=(1+R)nC​用购买力计算的话，nnn 年后的购买力为 C(1+h)n\\frac{C}{(1+h)^n}(1+h)nC​，因此 discount at a real rate 的话，即为 PVreal=C(1+h)n(1+r)n PV_{real}=\\frac{\\frac{C}{(1+h)^n}}{(1+r)^n} PVreal​=(1+r)n(1+h)nC​​代入 Fisher’s Equation 1+R=(1+h)(1+r)1+R=(1+h)(1+r)1+R=(1+h)(1+r) 可得 PVreal=PVnominal PV_{real}=PV_{nominal} PVreal​=PVnominal​因此其实并不影响 Present Value。对于 Net PV，由于基准年的金额有 Nominal=RealNominal=RealNominal=Real，因此也不影响 NPV"},{"title":"Risk of Return","path":"/wiki/fina/risk-and-return.html","content":"Risk of Return 现实世界中，未来的 Return 并非确定的，而是一个概率分布。 Probability 我们可以计算 Expected Return E[R]=∑P(r)⋅r=4.30% \\mathbb E[R]=\\sum P(r)\\cdot r=4.30\\% E[R]=∑P(r)⋅r=4.30%进一步的，可以计算其方差： Var(R)= Var(R)= Var(R)=我们可以把 return 的方差视为 volatility，方差越大，股价越不稳定。 Risk Free Risk Free 的意思就是方差为 000，通常只有国债才能做到。 Portfolio Portfolio 就是 a basket of assets，每一个 asset 都有一定的比重 Risk Systematic 经济体内的每一家企业都会遇到的风险（例如政治稳定、税收等等） Unsystematic 这类风险只会影响个别企业（例如舆论） Risk Diversification"},{"title":"Valuation of Stocks","path":"/wiki/fina/valuation-of-stocks.html","content":"Stock 股票 拥有对企业的所有权 Ownership 可以投票 以分红的形式分享利益 没有法律义务支付一定数额的分红 企业先付 bonds 产生的利息，再支付分红 支付的分红不能用于抵扣税款 Dividend Discount Model (DDM 模型) stock 会产生分红现金流， PV of Dividend Stream=∑i=1+∞Di(1+R)i \\text{PV of Dividend Stream}=\\sum_{i=1}^{+\\infin}\\frac{D_i}{(1+R)^i} PV of Dividend Stream=i=1∑+∞​(1+R)iDi​​也被称为 funcdamental value of stock. 在市场完全竞争的情况下，价格 P0=PV of Dividend StreamP_0=\\text{PV of Dividend Stream}P0​=PV of Dividend Stream. 这个模型被称为 Dividend Discount Model. Special Case 1: 恒常分红现金流 当 Di=DjD_i=D_jDi​=Dj​ 时，通过等比数列求和可以简便地计算 P0P_0P0​ P0=D1R P_0=\\frac{D_1}{R} P0​=RD1​​ Special Case 2: 现金流等比增长 也被称为 Gordon’s Growth Model，设分红以每年 ggg 的速度增长，即 Di=(1+g)Di−1D_i=(1+g)D_{i-1}Di​=(1+g)Di−1​，则有 P0=D1R−g P_0=\\frac{D_1}{R-g} P0​=R−gD1​​ 一些指标 Dividend Yield 计算产生的分红 Dividend Yield=D1P0 \\text{Dividend Yield}=\\frac{D_1}{P_0} Dividend Yield=P0​D1​​ Capital Gains Yield 如果在 ttt 时刻卖出 stock，可以计算获得的资本 Capital Gains Yield=Pt−P0P0 \\text{Capital Gains Yield}=\\frac{P_t-P_0}{P_0} Capital Gains Yield=P0​Pt​−P0​​ Common vs. Preferred Common stock 有投票权 Preferred stock 享有优先分红的权利 由于 Preferred stock 的期限是无穷的，我们可以直接按 Perpetual Bond 来看待。如果每年分红 DpD_pDp​，利率 RpR_pRp​，初始股价 P0P_0P0​，根据 DDM 模型，有 P0=DpRp P_0=\\frac{D_p}{R_p} P0​=Rp​Dp​​"},{"title":"MoE 架构","path":"/wiki/llm/Mixture-of-experts.html","content":"MoE 架构 MoE 代码实现：以 MiniMind 为例 Experts 首先定义专家模块，Experts 是 Experts(FeedForward) Code class FeedForward(nn.Module): def __init__(self, config: LMConfig): super().__init__() self.w1 = nn.Linear(config.dim, config.hidden_dim, bias=False) self.w2 = nn.Linear(config.dim, config.hidden_dim, bias=False) self.w3 = nn.Linear(config.hidden_dim, condig.dim, bias=False) self.dropout = nn.Dropout(config.dropout) def forward(self, x): return self.dropout(self.w3(F.silu(self.w1(x)) * self.w2(x))) Router 然后，我们来实现 Router 路由器。Router 接收一个 Token，计算出概率取 Top K 后转发给对应的专家。 Code class MoEGate(nn.Module): def __init__(self, config: LMConfig): super().__init__() self.config = config self.top_k = config.num_experts_per_token self.n_routed_experts = config.n_routed_experts self.scoring_func = config.scoring_func self.alpha = config.aux_loss_alpha self.seq_aux = config.seq_aux self.norm_topk_prob = config.norm_topk_prob self.gating_dim = config.dim self.weight = nn.Parameter( torch.empty((self.n_routed_experts, self.gating_dim)) ) self.reset_parameter() def reset_parameter(self) - None: import torch.nn.init as init init.kaiming_uniform_(self.weight, a=math.sqrt(5)) def forward(self, tokens: torch.Tensor): batch, seq_len, d = tokens.shape tokens = einops.rearrange(tokens, batch seq dim - (batch seq) dim) logits = F.linear(tokens, self.weight, None) if self.scoring_func == softmax: scores = logits.softmax(dim=-1) else: raise NotImplementedError( Unsupported scoring function, ) topk_weight, topk_idx = torch.topk( scores, k=self.top_k, dim=-1, sorted=False, ) if self.top_k 1 and self.norm_topk_prob: denominator = topk_weight.sum(dim=-1, keepdim=True) + 1e-20 topk_weight = topk_weight / denominator if self.train and self.alpha 0.0: scores_for_aux = scores aux_topk = self.top_k topk_idx_for_aux_loss = topk_idx.view(batch, -1) if self.seq_aux: scores_for_seq_aux = scores_for_aux.view(batch, seq_len, -1) ce = torch.zeros( batch, self.n_routed_experts, device=tokens.device, ) ce.scatter_add_( 1, topk_idx_for_aux_loss, torch.ones( batch, seq_len * aux_topk, device=tokens.device ) ).div_(seq_len * aux_topk / self.n_routed_experts) aux_loss = ( (ce * scores_for_seq_aux.mean(dim=-1)) .sum(dim=1) .mean() * self.alpha ) else: mask_ce = F.one_hot( topk_idx_for_aux_loss.view(-1), num_classes=self.n_routed_experts, ) ce = mask_ce.float().mean(0) Pi = scores_for_aux.mean(0) fi = ce * self.n_routed_experts aux_loss = (Pi * fi).sum() * self.alpha else: aux_loss = 0.0 return topk_idx, topk_weight, aux_loss 以下分析约定： Batch size BBB，即一个 batch 包含 BBB 句句子 Sequence Length SSS，即一句句子包含 SSS 个 Token 词嵌入向量维度 HHH 专家数量 EEE 每个 Token 被转发到 Top KKK 个专家 参数含义 top_k 为每一个 Token 选择几个专家进行训练 n_routed_experts 为专家总数 scoring_func 用于计算 Token 和专家之间的评分 aux_loss_alpha 辅助损失的 alpha 参数 seq_aux 控制是否在序列级别上计算辅助损失 norm_topk_prob 是否对概率进行归一化 由于我们对每一个 Token 计算它被发送到某一个专家的概率，在 __init__() 函数里，我们令 Token 的维度为 d=d=d= self.gating_dim，专家数量为 n=n=n= self.n_routed_experts，那么我们希望 Router 输出的矩阵大小就是 Router:RB×S×H↦RB×S×E \\text{Router}:\\R^{B\\times S\\times H}\\mapsto \\R^{B\\times S\\times E} Router:RB×S×H↦RB×S×E因此这里的 self.weight 是 RH×E\\R^{H\\times E}RH×E 大小的矩阵，负责计算一个 Token 的被转发到 Expert 的概率。 前向传播 forward() Tensor 输入是 B×S×HB\\times S\\times HB×S×H，因为我们只关心 Token 发送到哪个专家，所以我们首先把 Tensor 拍成二维 BS×HBS\\times HBS×H，并用 self.weight 计算概率，用 softmax() 归一化。F.linear(x, A, bias=None) 计算 y=xA⊺ y=xA^\\intercal y=xA⊺因此，这里的 score 大小为 BS×EBS\\times EBS×E 接着，我们调用 torch.topk() 选取前 KKK 个专家，返回 score 中对应的权重和下标。此时 topk_weight, topk_idx 大小均为 BS×KBS\\times KBS×K 然后对选择出来的 KKK 个专家的权重再进行一次归一化（除以 denominator）。不过这一步是可选的 接着进入 if self.train and self.alpha 0.0: 判断，目的是为了平衡专家之间的负载。首先，代码确保只在训练模式以及需要平衡负载的时候才会启用。 如果需要计算 sequence level 的 loss，那么 topk_idx 首先被拍平成 (B,SK)(B,SK)(B,SK) 因为要对 sequence level 计算专家负载损失，所以我们先定义每一句句子上专家的负载损失，其大小为 (B,E)(B,E)(B,E). 然后遍历 topk_idx 中的每一个元素，用 scatter_add_() 将 topk_idx 中的每一个元素添加到对应的 sequence 里对应的专家中。 这个流程结束之后，ce (count experts) 保存的就是每一句句子的专家负载。随后，我们对每一句句子都归一化其专家负载：一句句子会产生 SKSKSK 个 counting，总数为 SKSKSK 我们沿 SSS 轴对 scores_for_seq_aux 计算平均值 scores.mean(dim=1) 这就表示每句句子与每个 expert 之间的得分（token 与 experts 得分的平均），其大小变为 (B,E)(B, E)(B,E). 然后再将 ce 与 scores.mean() 对应位置相乘，ce 可以理解为每句句子中 expert 的频率（这个 expert 在这句句子里总是被分配处理 token），scores.mean() 可以理解为每句句子中 expert 对于每个 token 的重要程度（这个 expert 总是被 MoEGate 认为与 token 关联很大），大小变为 (B,E)(B,E)(B,E)，但此时仍然是每句句子与 expert 的关联。 因此再对 EEE 求和取平均 .sum(dim=1).mean()，把 expert 与不同句子之间的频率与关联度整合起来，即对于这些句子 expert 的频率与关联度，也即 expert 的负载，其大小先变为 (E,)(E,)(E,)，再变为 (1,)(1,)(1,)。最后再乘上标量 self.alpha. 这就是我们的 sequence level 的 aux loss. 值得一提的是，这里还额外乘了一个 EEE，推测是为了让梯度不至于太小 Why It Makes Sense 因为我们的训练目标是让 Loss 尽可能的小，对于这个 Aux Loss 而言，如果某一个专家的负载特别大，那么就说明 每一个 Batch 内的所有 Tokens，这个专家对应的 scores 都会比较大 由于 torch.topk 总是都把这个专家选上，因此 ce 计算出来的加权也比较大 所以根据排序不等式，负载越不均衡，计算出来的 aux_loss 也就越大。那么反过来说，如果 aux_loss 越小，说明专家之间的负载越均衡。 如果不关心 sequence level 的 loss，那么我们直接把这一个 batch 的所有 token 拍到一起（总共 B⋅SB\\cdot SB⋅S 个 token，总共被分配 BSKBSKBSK 个专家），我们把 (BSK,1)(BSK, 1)(BSK,1) 的专家重新 encode 为 one-hot vector，即 (BSK,E)(BSK,E)(BSK,E) 那么我们对 BSKBSKBSK 轴求平均，fi 向量大小变为 (1,E)(1,E)(1,E)，就计算出来了某个专家处理的 token 数占所有 token 的比值（即频率）。因为 one-hot vector 不是 000 就是 111. 类似的，我们也对 scores (大小为 (BS,E)(BS,E)(BS,E)) 做 token level 的计算，直接按 BSBSBS 轴取平均即可，Pi 大小变为 (1,E)(1,E)(1,E)，即每个专家在所有 token 上的平均得分（关联度） 同样地，我们直接将 fi 与 Pi 对应位置相乘，求和乘上 self.alpha，这一步的目的和 sequence level 的 aux loss 是一样的。 MoE Feed Forward (MoEFFN) 然后我们来把他们组合到一起：首先，我们为 MoEFFN 定义好门控和专家，以及共享专家（无论如何都要处理 token） class MOEFeedForward(nn.Module): def __init__(self, config: LMConfig): super().__init__() self.config = config self.experts = nn.ModuleList( [ FeedForward(config) for _ in range(config.n_routed_experts) ] ) self.gate = MoEGate(config) if config.n_shared_experts is not None: self.shared_experts = FeedForward(config) 然后编写训练和推理。训练和推理的区别在于 推理模式下，Token 只转发给最优的 Expert。但在训练模式下，Token 会被转发给每一个 Expert Training 我们来考察一下训练时的代码。 这里，x.repeat_interleave() 重复输入数据，目的是让一个 token 可以多次被不同的 expert 处理，提升 expert 的泛化性 然后 y 就是计算 token 经过专家计算后输出的结果，并且将类型转为半精度浮点数 float16，此时的张量形状为 (BS×K,H)(BS\\times K, H)(BS×K,H)，经过 .view(*topk_weight.shape, -1) 之后变为 if self.training: # 训练模式下，重复输入数据 x = x.repeat_interleave(self.config.num_experts_per_tok, dim=0) y = torch.empty_like(x, dtype=torch.float16) for i, expert in enumerate(self.experts): y[flat_topk_idx == i] = expert(x[flat_topk_idx == i]).to( y.dtype ) # 确保类型一致 y = (y.view(*topk_weight.shape, -1) * topk_weight.unsqueeze(-1)).sum(dim=1) y = y.view(*orig_shape) Inferencing 我们来考察前向传播过程。 提取出 x (输入的 Batch of sequence of tokens) 的维数信息之后，先经由 self.gate(x) 计算每一个 token 对应的专家，然后直接拍成 a sequence of tokens (BS,H)(BS,H)(BS,H)，topk_idx 则直接拍成 (BSK,)(BSK,)(BSK,) identity = xorig_shape = x.shapebsz, seq_len, _ = x.shape# 使用门控机制选择专家topk_idx, topk_weight, aux_loss = self.gate(x)x = x.view(-1, x.shape[-1])flat_topk_idx = topk_idx.view(-1) 随后进入 y = self.moe_infer(x, flat_topk_idx, topk_weight.view(-1, 1)).view(*orig_shape) 进行计算。 这里 .argsort() 的逻辑是：因为 flat_expert_indices 的值是专家的编号，通过 argsort()，idxs 把同一个专家要处理的 token 下标聚集到一起。 tokens_per_expert 以前缀和的方式，计算每一个专家处理的 token 下标的范围。 token_idxs 从 idxs 出发计算某一个 idxs[i] 对应的是第 token_idxs[i] 个 token。这是因为每一个 token 都会分给 top KKK 个专家，因此从下标来说，i∗K→(i+1)∗K−1i*K\\to (i+1)*K-1i∗K→(i+1)∗K−1 (idxs 保存的正好都是下标) 对应的都是第 iii 个 token，因此直接整数出除法可以计算出对应第几个 token. @torch.no_grad()def moe_infer(self, x, flat_expert_indices, flat_expert_weights): expert_cache = torch.zeros_like(x) idxs = flat_expert_indices.argsort() tokens_per_expert = flat_expert_indices.bincount().cpu().numpy().cumsum(0) token_idxs = idxs // self.config.num_experts_per_tok 接着，我们枚举每一个专家，拿出它需要处理的所有 tokens (即代码里的 token_idxs[start_idx : end_idx] 以及 x[exp_token_idx]) 我们把这些 token 经过 expert(expert_tokens) 计算、输出，得到 expert_out，乘上（对于这个 token 而言）每一个 expert 的权重。通过 scatter_add_()，expert_cache 包含了每个 token 位置的加权专家输出总和。 for i, end_idx in enumerate(tokens_per_expert): start_idx = 0 if i == 0 else tokens_per_expert[i - 1] if start_idx == end_idx: continue expert = self.experts[i] exp_token_idx = token_idxs[start_idx:end_idx] expert_tokens = x[exp_token_idx] expert_out = expert(expert_tokens).to(expert_cache.dtype) expert_out.mul_(flat_expert_weights[idxs[start_idx:end_idx]]) # 使用 scatter_add_ 进行 sum 操作 expert_cache.scatter_add_( 0, exp_token_idx.view(-1, 1).repeat(1, x.shape[-1]), expert_out )return expert_cache 除此之外，还需要加上共享专家的输出。不过这里的话，如果在推理模式，self.aux_loss 其实没作用 if self.config.n_shared_experts is not None: y = y + self.shared_experts(identity)self.aux_loss = aux_lossreturn y"},{"title":"Attention 中的 KV Cache","path":"/wiki/llm/attn-kv-cache.html","content":"KV Cache KV Cache（键值缓存）是 Transformer 模型推理优化中的核心技术，其核心思想是缓存 Attention 机制中已计算的 Key 和 Value 矩阵，避免重复计算，从而减少计算量并提升推理效率。"},{"title":"Transformer 架构","path":"/wiki/llm/classic-transformer.html","content":"Before Transformer: RNN, Attention 在 RNN 里，我们用一个隐藏变量 hth_{t}ht​ 记录前 ttt 个 Input Token 所代表的 Context。如果要生成第 t+1t+1t+1 个 Output Token 的话，就利用输入的第 t+1t+1t+1 个 Input Token 和代表了前文信息的隐藏状态 hth_{t}ht​ 做 Attention Alignment 计算出一个向量，再转换成 Word. 这样一个 AutoRegressive 模型有两个显著的问题 由于是时序生成（必须一个一个 Token 地生成），无法并行 由于时序生成，如果要保存很久远的信息，隐藏状态 hth_tht​ 的大小就必须非常大，导致了 Computation Memory Overhead Model Arch Transformer 总体是 Encoder-Decoder 架构。Encoder 将 Input 杂谈 其实 Transformer 的本质也是概率统计模型，其生成过程就是给定前 iii 个词的情况下生成第 i+1i+1i+1 个词；训练过程的 Loss Function 是 max⁡∑ilog⁡Pθ(wi∣wi−k,…,wi−1) \\max \\sum_i \\log P_\\theta(w_i|w_{i-k},\\dots,w_{i-1}) maxi∑​logPθ​(wi​∣wi−k​,…,wi−1​)这里的 kkk 其实就是 Context Length 的意思。"},{"title":"Decoder-Only Transformer","path":"/wiki/llm/decoder-only-transformer.html","content":"Decoder-only Transformers Decoder-only 架构通常用于生成任务，代表作包括 GPT，GPT-2 等。 什么是生成任务 简单来说，Decoder-only 解决的生成任务是指：给定前 nnn 个单词 x1,x2,…,xnx_1,x_2,\\dots,x_nx1​,x2​,…,xn​，要求输出第 n+1n+1n+1 个单词。可以看出，这类生成任务的本质是 AutoRegressive 的。 近年来，出现了使用 Diffusion 作为 Language Model 的生成，达到了极快的生成速度。"},{"title":"Multi-Head Attention","path":"/wiki/llm/multi-head-attn.html","content":"Multi-Head Attention Initial 多头注意力就是将 query 的不同部分和 KV 的不同部分分别做 Attention 之后再拼接起来，达到“不同 Head 感受句子的不同信息”的效果。 Multi-Head Attention 的 Head 分的是什么 我们假定有 HHH 个 head，多头注意力做的事是将维度为 DDD 的 word embedding 分成 HHH 个维度为 DH\\frac{D}{H}HD​ 的子 embedding。 考虑输入的一批训练样本的大小为 (B,S,D)(B,S,D)(B,S,D)，那么实际上每一个 Head 计算的 Self-Attention 是 (B,S,DH)(B,S,\\frac{D}{H})(B,S,HD​). 如果硬要直观理解的话……我们可以假想 word embedding 的不同部分蕴含了不同的内在含义。例如，一个 DDD 的 word embedding 的前 D/8D/8D/8 维度编码了“数学”，接下来 D/8D/8D/8 编码了 “情感”……那么，我们 split head 就是想让 Attention 学习到这批样本所有 token 之间、不同领域上的关联。例如 Head 1 学习到数学层面的联系，Head 2 学习到情感层面的联系……"},{"title":"RoPE 旋转位置编码","path":"/wiki/llm/rotary-emb.html","content":"RoPE RoPE 的出发点是：通过绝对位置编码的方式实现相对位置编码 什么意思呢？比如说考虑某个英文词组总是以 A xx yy B 的形式出现，但是出现位置有可能是 1,2,3,4、也可能是 10,11,12,13，RoPE 就可以只通过这些单词的下标计算出代表相对位置的 embedding."},{"title":"Self Attention","path":"/wiki/llm/self-attn.html","content":"Self Attention 所谓的 Self Attention 其实只是 Q=K=VQ=K=VQ=K=V 的一种特例 Self-Attn(X)=Attention(X,X,X) \\text{Self-Attn}(X)=\\text{Attention}(X,X,X) Self-Attn(X)=Attention(X,X,X)直觉理解的话，可以认为是在句子的内部做 Attention，寻找句子内部的联系。"},{"title":"Tokenizer 分词器","path":"/wiki/llm/tokenizer.html","content":"Tokenizer Tokenizer 在 LLM（大型语言模型）的上下文中指的是负责将输入文本分解成称为 tokens 的更小单元的组件。这些 tokens 是模型处理的基本元素（例如单词、子词或字符）。Tokenizer 将原始文本转换为模型可以处理的数字表示，并且在处理之后，还能将 tokens 转换回人类可读的文本。 Hugging Face Tokenizer: tokenizer.json"},{"title":"Tokenizer, BPE 算法","path":"/wiki/llm/tokenizer-bpe.html","content":"Byte-Pair Encoding 算法 Byte-Pair Encoding（BPE）算法是一种常用于分词器（Tokenizer）中的无监督分词方法，其主要思想是将文本中最常见的字符对（或子词对）不断合并，从而构建出一个词汇表。由于进行多轮 （假设 kkk 轮）合并，而每一次合并都会基于统计频率将一对 Token 合并为一个新 Token，因此在 kkk 轮迭代后，BPE 算法可以将长度为 kkk 的单词合并为一个 Token 将输入的文本转化为 UTF-8 Encoding 统计 Byte-Pair 的频率 计算频率最高的 Byte-Pair，合并为一个新的 Token 用新的 Token 替换旧 Byte-Pair 出现的位置 回到第 222 步，重新统计 Byte-Pair (Token-Pair) 频率 直到词汇表大小达到预设值 BPE 算法通过这种逐步合并的方式，不仅能有效地表示常见词汇，还能灵活处理低频词和新词，对于大型语言模型的分词和词表构建有很大的优势。 BPE 代码实现"},{"title":"Attention 机制","path":"/wiki/llm/vanilla-attn.html","content":"Attention 机制 Attention 机制的直观理解就是：给定字典 D={K,V}D=\\{K,V\\}D={K,V}，和一个 Token QQQ。Attention 基于一个朴素的理解，例如英语里，如果两个单词长得差不多，那么语义应该也差不多（也就是词性变换）。如果可以量化出相似度，那么我们就可以一定程度上可以表示出这个单词的意思 对于 Token 而言，其都是长度为 ddd 的词向量，不同的相似度计算方式会产生不同的 Attention 计算公式。一般而言，可以写成下面这种形式 Attention(Q,K,V)=score(Q,K)⋅V \\text{Attention}(Q,K,V)=\\text{score}(Q,K)\\cdot V Attention(Q,K,V)=score(Q,K)⋅V这里，如果字典的大小为 mmm，查询 nnn 个词，每个词的 Embedding 维度为 ddd，代表“意义”的 Value 的维度为 dvd_vdv​，则这三个矩阵的大小分别为 Q∈Rn×dK∈Rm×dV∈Rm×dv Q\\in \\R^{n\\times d}\\\\ K\\in \\R^{m\\times d}\\\\ V\\in \\R^{m\\times d_v} Q∈Rn×dK∈Rm×dV∈Rm×dv​例如经典的 Scaled Dot Product Attention，其 score function 就是 softmax(QKTd)\\text{softmax}(\\frac{QK^T}{\\sqrt d})softmax(d​QKT​) Attention(Q,K,V)=softmax(QK⊺d)⋅V \\text{Attention}(Q,K,V)=\\text{softmax}\\Big( \\frac{QK^\\intercal}{\\sqrt{d}} \\Big)\\cdot V Attention(Q,K,V)=softmax(d​QK⊺​)⋅V"},{"title":"Comparative Statics","path":"/wiki/microecon/comparative-statics.html","content":"Change of Demand Curve 令 xxx 表示商品，那么其 Demand Curve 可以表示为 Qxd=a+bPxd+… Q^d_x=a+bP^d_x+\\dots Qxd​=a+bPxd​+… Increase in Demand 直线向右上移动，可以是向上平移，也可以是向右平移 Movement 影响因素：Income Normal Good Income↑ ⟹ Qxd↑\\text{Income}\\uparrow \\implies Q^d_x\\uparrowIncome↑⟹Qxd​↑ Inferior Good Income↑ ⟹ Qxd↓\\text{Income}\\uparrow \\implies Q^d_x\\downarrowIncome↑⟹Qxd​↓ 影响因素：Population 影响因素：Price of Substitutes Psubstitute↑ ⟹ Qxd↑ P_{\\text{substitute}}\\uparrow \\implies Q^d_x\\uparrow Psubstitute​↑⟹Qxd​↑当其他平替的价格上涨，消费者自然而然会转向价格更低的 xxx 影响因素：Price of Complement Pcomplement↑ ⟹ Qxd↓ P_{\\text{complement}}\\uparrow \\implies Q^d_x\\downarrow Pcomplement​↑⟹Qxd​↓ 影响因素：Expectation The expectation of a higher (lower) price for a good in the future increases (decreases) current demand for the good. 影响因素：Tastes Supply Movement of Supply Curve Increase in Supply Technology Entry implies more sellers in the market increasing supply. Exit implies fewer sellers in the market decreasing supply. Sellers will supply less of a good if the price of an alternate good using the same inputs rises (and vice versa). (-)"},{"title":"Cost Benefit Analysis","path":"/wiki/microecon/cost-benefit.html","content":"Rational Decision 对每一件事进行衡量，其付出为 C(x)C(x)C(x)，获得为 B(x)B(x)B(x)，那么定义 Economic Surplus ES(x)ES(x)ES(x) 为 ES(x)=B(x)−C(x) \\boxed{ES(x)=B(x)-C(x)} ES(x)=B(x)−C(x)​Cost Benefit Principle 当且仅当 ES(x)≥0ES(x)\\ge 0ES(x)≥0 时，才会做 xxx，此时收益大于付出；否则不做。 Cost/Benefit 只包含会影响被决策的 Cost 和 Benefit Sunk Cost Marginal(Additional) Cost/Benefit Only if Marginal Benefit≥Marginal Cost \\text{Marginal Benefit}\\ge\\text{Marginal Cost} Marginal Benefit≥Marginal Cost Allocation of Resources 优先分配给 Marginal Benefit 多的 Opportunity Cost 所有不选的选项里，Economic Surplus(不选的选项的 Cost = Benefit，没有这部分的开销了) 最大的那个"},{"title":"Elasticity 弹性","path":"/wiki/microecon/elasticity.html","content":"弹性 量化某个变量随着另一个变量的变化而变化的程度 弹性大：因变量对自变量的变化很敏感 弹性小：因变量对自变量的变化不怎么敏感 Price Elasticity of Demand 量化 PED=percentage change in Quantity demandedpercentage change in Price=%ΔQd%ΔP PED=\\frac{\\textbf{percentage}\\text{ change in Quantity demanded}} {\\textbf{percentage}\\text{ change in Price}}=\\boxed{\\frac{\\%\\Delta Q^d}{\\%\\Delta P}} PED=percentage change in Pricepercentage change in Quantity demanded​=%ΔP%ΔQd​​ 两点 PED 计算公式 我们用中点代为计算 Percentage Change Percentage=New−Old(New+Old)/2 \\text{Percentage}=\\frac{\\text{New}-\\text{Old}}{(\\text{New+Old})/2} Percentage=(New+Old)/2New−Old​那么 PEDPEDPED 的计算公式可以改写成 PED=Qnewd−QolddPnew−Pold×Pnew+PoldQnewd+Qoldd \\boxed{ PED=\\frac{Q^d_{new}-Q^d_{old}}{P_{new}-P_{old}}\\times \\frac{P_{new}+P_{old}}{Q^d_{new}+Q^d_{old}} } PED=Pnew​−Pold​Qnewd​−Qoldd​​×Qnewd​+Qoldd​Pnew​+Pold​​​当某个点 oldoldold 已经被固定了的时候，考虑其差值 ΔQ→0\\Delta Q\\to 0ΔQ→0，就有 PED=ΔQdΔP×2Pold+ΔP2Qoldd+ΔQd→ΔQdΔP×PoldQoldd→PQd×1slope \\begin{aligned} PED=\\frac{\\Delta Q^d}{\\Delta P}\\times \\frac{2P_{old}+\\Delta P}{2Q^d_{old}+\\Delta Q^d}\\\\ \\to \\frac{\\Delta Q^d}{\\Delta P}\\times\\frac{P_{old}}{Q^d_{old}}\\\\ \\to \\boxed{\\frac{P}{Q^d}\\times \\frac{1}{\\text{slope}}} \\end{aligned} PED​=ΔPΔQd​×2Qoldd​+ΔQd2Pold​+ΔP​→ΔPΔQd​×Qoldd​Pold​​→QdP​×slope1​​​ Observation Price Elasticity 随着点在 Quantity of Demand 曲线上的移动而变化；并且在中点处为 −1-1−1，往上 −1\\lt -1−1，往下 −1\\gt -1−1 如果两条 QdQ^dQd 曲线有交点，那么更加平缓的那条直线在这个点上的弹性更大。 Elasticity 与 Revenue 收入基本公式 Revenue=Quantity×Price \\text{Revenue}=\\text{Quantity}\\times\\text{Price} Revenue=Quantity×Price因此考虑 Elasticity 的话，Revenue 是关于 Price 的二次函数，并且在 PED=−1PED=-1PED=−1 的时候，取到最大值 弹性需求（∣η∣1∣\\eta∣1∣η∣1）：降价增加总收益（需求量增幅 价格降幅）。 非弹性需求（∣η∣1∣\\eta∣1∣η∣1）：降价减少总收益（需求量增幅 价格降幅）。 单位弹性（∣η∣=1∣\\eta∣=1∣η∣=1）：总收益最大。 也可以在 QdQ^dQd 直线上直观地进行比较：找到点变化前后对应的矩形变化面积。更一般的，如果点在中点上方，则总收益一定增加；在下方则总收益减少。 Constant Elasticity 如果一条曲线在每一个点的 PPP Elasticity of QQQ 都相等为 −k-k−k，那么其曲线可以表示为 f(P,Q):PkQ=C f(P,Q):\\boxed{P^{\\textcolor{red}{k}}Q=C} f(P,Q):PkQ=C​ 证明（不考） 考虑 Q-P 曲线 fff 在这一个点的 Elasticity，用点斜式即为 Elasticity=−k=PQ×dQdP \\text{Elasticity}=-k=\\frac{P}{Q}\\times\\frac{dQ}{dP} Elasticity=−k=QP​×dPdQ​把 xdxx\\mathop{dx}xdx 放到一起： −kPdP=1QdQ -\\frac{k}{P}\\mathop{dP}=\\frac{1}{Q}\\mathop{dQ} −Pk​dP=Q1​dQ两边积分 −kln⁡P+CP=ln⁡Q+CQln⁡Q+kln⁡P=cPkQ=C \\begin{aligned} -k\\ln{P}+C_P=\\ln{Q}+C_Q\\\\ \\ln Q+k\\ln P=c\\\\ P^kQ=C \\end{aligned} −klnP+CP​lnQ+klnPPkQ​=lnQ+CQ​=c=C​ 左右取对数，曲线方程也可以写作 ln⁡Q=−kln⁡P+c \\boxed{ \\ln Q=\\textcolor{red}{-k} \\ln P+c } lnQ=−klnP+c​ 影响 Price Elasticity of Demand 的因素 Availability of Substitutes Time Horizon 产品有效期 Category of product (specific or broad) Necessities vs. Luxuries Purchase Size Substitutes Fewer substitutes makes it harder for consumers to adjust QQQ when PPP changes… so demand is more inelastic. Many substitutes? Switching brands when prices change is easy, so demand is more elastic. Time Horizon Category 另外两种 Elasticity Cross-Elasticity Exy=%ΔQd of X%ΔP of Y=PyQxd×ΔQxΔPy \\begin{aligned} E_{xy}=\\frac{\\%\\Delta Q^d \\text{ of X}}{\\%\\Delta P \\text{ of Y}}\\\\ =\\boxed{\\frac{P_y}{Q^d_x}\\times\\frac{\\Delta Q_x}{\\Delta P_y}} \\end{aligned} Exy​​=%ΔP of Y%ΔQd of X​=Qxd​Py​​×ΔPy​ΔQx​​​​Exy0E_{xy}0Exy​0 说明是 Substitute ；反之，说明是 complement Income Elasticity EI=%ΔQd%ΔIncome=IQx×ΔQxΔI \\begin{aligned} E_I=\\frac{\\%\\Delta Q^d}{\\%\\Delta \\text{Income}}\\\\ =\\boxed{\\frac{I}{Q_x}\\times\\frac{\\Delta Q_x}{\\Delta I}} \\end{aligned} EI​​=%ΔIncome%ΔQd​=Qx​I​×ΔIΔQx​​​​ EI1E_I\\gt 1EI​1 说明是 Luxury EI0E_I\\gt 0EI​0 说明是 Normal Goods EI0E_I\\lt 0EI​0 为 Inferior Goods Price Elasticity of Supply 类似的，也有中点公式和点斜公式 性质 PES0PES\\gt 0PES0 若截距 0\\gt 00，那么随着 QsQ^sQs 增加，PESPESPES 降低，但永远 1\\gt 11 若过原点，则 PES≡1PES\\equiv 1PES≡1 影响因素 Change in Per-Unit Costs with Increased Production Time Horizon Share of Market for Inputs Geographic Scope Elasticity and Quick Predictions 把基准点放在 Equilibrium Point，记 ηs\\eta_sηs​ 为 Price Elasticity of Supply，ηd\\eta_dηd​ 为 Price Elasticity of Demand，则有 % change in Price from a shift in Demand ΔQd=% change in Demand ΔQdηs+∣ηd∣% change in Price from a shift in Supply ΔQs=−% change in Supply ΔQsηs+∣ηd∣ \\begin{array}{rll} \\text{\\% change in \\textbf{Price} from a shift in \\textbf{Demand} }\\Delta Q^d\\\\ =\\frac{\\text{\\% change in \\textbf{Demand} }\\Delta Q^d}{\\eta_s+|\\eta_d|}\\\\ \\text{\\% change in \\textbf{Price} from a shift in \\textbf{Supply} }\\Delta Q^s \\\\ =\\textcolor{red}{-}\\frac{\\text{\\% change in \\textbf{Supply} }\\Delta Q^s}{\\eta_s+|\\eta_d|} \\end{array} % change in Price from a shift in Demand ΔQd=ηs​+∣ηd​∣% change in Demand ΔQd​% change in Price from a shift in Supply ΔQs=−ηs​+∣ηd​∣% change in Supply ΔQs​​ 例题 2024 Summer Suppose there is only an initial shift of demand or supply (but not both), and we observe that the equilibrium price of computers increases by 2.1%2.1\\%2.1%, and the equilibrium quantity increases by 8.1%8.1\\%8.1%, we conclude that: A) The price elasticity of demand is elastic. B) The price elasticity of demand is inelastic. C) The price elasticity of supply is elastic. D) The price elasticity of supply is inelastic. 解答 Price 和 Quantity 都上涨了，因此这一定是 Demand 增加引起的 (Demand Curve right shift)。 上涨的幅度由 Supply Curve 的斜率决定，这里 %ΔP=2.1%,%ΔQ=8.1%\\% \\Delta P=2.1\\%,\\% \\Delta Q=8.1\\%%ΔP=2.1%,%ΔQ=8.1%，所以 price elasitcity of supply 等于 Es=%ΔQ%ΔP1 E_s=\\frac{\\% \\Delta Q}{\\% \\Delta P}\\gt 1 Es​=%ΔP%ΔQ​1由此，price elasticity of supply 是 elastic 的。"},{"title":"externalities","path":"/wiki/microecon/externalities.html","content":"Market Failure total surplus (both of the consumer and producer) is maximized in free markets. The market equilibrium price and quantity are socially optimal… (1) when all relevant production costs are incurred by sellers (2) when all relevant consumption benefits accrue to buyers. Sometimes costs or benefits that result from an activity accrue to people not directly involved in the activity Ex ternal cost = a cost paid by people other than the consumer or the producer trading in the market Social cost = the cost to everyone o Social cost = private cost + external cost Deadw eight Loss is the welfare loss because of quantity traded deviating from social optimal level"},{"title":"竞争下的 Cost 与 Profit Maximization","path":"/wiki/microecon/cost-maxprofit-under-competition.html","content":"大前提 在完全竞争的市场下，任何一家企业都无法操控市场价格，只能根据市场价格调整自身的产量。即市场价格决定每一家企业的定价。 逻辑 由于企业无法操控市场价格，如果企业的定价高于市场价格，那么消费者必然转向其替代品；如果企业定价低于市场价格 企业运行的驱动动力：利益 企业必然追求利益。当产量为 QQQ 时，利润 Profit π(Q)\\pi(Q)π(Q) 定义为 π(Q)=TR(Q)−TC(Q) \\boxed{\\pi(Q)=TR(Q)-TC(Q)} π(Q)=TR(Q)−TC(Q)​这里的 Total Cost TC(Q)TC(Q)TC(Q) 包含 explicit cost 和 implicit cost. Economic Profit 与 Accounting Profit 这两个概念会在分析长期行为时提到，简而言之 Economic Profit 需要包含 Implicit Cost Accounting Profit 则不需要包含 后文提到的 Profit 若无特殊说明都是指 Economic Profit. 利益最大化 根据 Cost-Benefit Analysis，利润最大化的时候对应的产量 Q∗Q^\\astQ∗ 必然有 MR(Q∗)=MC(Q∗) MR(Q^\\ast)=MC(Q^\\ast) MR(Q∗)=MC(Q∗)而且，此处的 MRMRMR 恒等于市场价格，即 MR(Q∗)=PMR(Q^\\ast)=PMR(Q∗)=P。因此，在完全竞争的市场下，总是有 P=MC(Q∗) \\boxed{P=MC(Q^\\ast)} P=MC(Q∗)​ 企业的成本 分为两种： 固定成本 (Fixed Cost)：短期内无法改变 Quantity，例如生产机器、办公楼等等 可变成本 (Variable Cost)：短期内可以改变 QUantity，例如劳动力、生产原料等等 在后面分析企业行为的时候也会用到这两个概念。简单来说，如果考察企业的短期行为，由于固定成本可以看作是已经产生费用，因此应当看作 Sunk Cost，不应参与短期行为决策；但对于长期行为而言，也应将固定成本考虑进去。 企业的市场行为 既然要赚取利益，那么企业是否继续参与市场必然与 Profit 有关。当 π(Q∗)0\\pi(Q^\\ast)\\lt 0π(Q∗)0 时，企业的利润小于零，企业会选择退出市场；否则就有利可图，会继续参与市场。 也可以理解为 π(Q=Q∗)\\pi(Q=Q^\\ast)π(Q=Q∗) 与 π(Q=0)\\pi(Q=0)π(Q=0) 之间进行比较 短期行为 从短期来看，企业的 Fixed Cost 不应计入决策过程，企业是否退出市场取决于利润 π(Q∗)≥π(0)TR(Q∗)−TC(Q∗)≥TR(0)−TC(0)PQ∗−TVC(Q∗)−TFC≥0−TVC(0)−TFCPQ∗≥TVC(Q∗) \\begin{aligned} \\pi(Q^\\ast)\\ge \\pi(0)\\\\ TR(Q^\\ast)-TC(Q^\\ast)\\ge TR(0)-TC(0)\\\\ PQ^\\ast-TVC(Q^\\ast)-TFC\\ge 0-TVC(0)-TFC\\\\ PQ^\\ast\\ge TVC(Q^\\ast)\\\\ \\end{aligned} π(Q∗)TR(Q∗)−TC(Q∗)PQ∗−TVC(Q∗)−TFCPQ∗​≥π(0)≥TR(0)−TC(0)≥0−TVC(0)−TFC≥TVC(Q∗)​所以有 P≥AVC(Q∗) \\boxed{P\\ge AVC(Q^\\ast)} P≥AVC(Q∗)​因此从短期来看，企业是否会退出市场，取决于市场价格（会影响收入）和自身生产的平均可变成本 (Average Variable Cost, AVC)。此时的利润为 π(Q∗)=(P−AC)×Q∗ \\boxed{\\pi(Q^\\ast)=\\Big( P-\\textcolor{red}{AC} \\Big)\\times Q^\\ast} π(Q∗)=(P−AC)×Q∗​ 注意！ 计算利润时要注意包含 Fixed Cost。只有在做决策时才不计算 FC. 曲线的性质 MC 曲线总是和 AVC 曲线交于 AVC 曲线的最低点。 证明 略。 进一步的，我们可以推断，企业短期内的生产曲线 Supply Curve 由 MC Curve 和 Shutdown Decision 共同决定。 Supply Curve 长期行为 对于长期而言，Fixed Cost 此时也应该算入（例如办公楼续约费可以视为支出）。类似的，应有 P≥AC(Q∗) \\boxed{P\\ge AC(Q^\\ast)} P≥AC(Q∗)​当且仅当市场价格高于平均成本（含固定成本），企业才会考虑进入市场（不然无法收回固定成本）。 合并来看，Supply Curve 差不多长这样： Aggregate Supply Curve 例题 2020 Spring Final 题目 There are many identical firms (having the same production costs and producing the same product) in a competitive market. Their product is assumed to be perfectly divisible. When one firm produces qqq units, its marginal cost is MC(q)=qMC(q) = qMC(q)=qand the corresponding total variable cost is TVC(q)=0.5q2TVC(q) = 0.5q^2TVC(q)=0.5q2The demand curve in the market is Q=9000−90PQ = 9000 - 90PQ=9000−90PMoreover, assume that the industry is constant cost. The market is currently in a long-run equilibrium, and the equilibrium price is $45\\$45$45 per unit. Using the information, we conclude that there are [ Answer36 ] firms in the market. Using this information, we conclude that the fixed cost of an individual firm is [ Answer37 ] dollars. Using this information, we conclude that the short-run supply curve of this industry is of the form Q=A+B×PQ = A + B \\times PQ=A+B×Pwhere AAA is equal to [ Answer38A ], and BBB is equal to [ Answer38B ] Suppose now the market demand has become Q=15300−153PQ = 15300 - 153PQ=15300−153PUsing the information, we can calculate that in the long run, an individual firm will produce [ Answer39 ] units. 解答 Question Bank Q1 Determine whether the following statements about a perfectly competitive market are TRUE OR FALSE. Statement 1: The demand curve facing the market is horizontal. Statement 2: Entry of new firms will drive the accounting profits of the existing firms to zero in the long run. 【解答】False, False 【解说】对于 Statement 1，完全竞争市场的 Demand Curve 应该是 Downward Sloping 的。陈述错误。 对于 Statement 2，长期来看，完全竞争市场下，企业的 Economic profit 会趋于 000，但是 Accounting profit 相比 Economic profit 无须考虑 implicit cost，因此即使 economic profit 为 000，accounting profit 依旧可能 0\\gt 00。因此陈述错误。 Q2 Determine whether the following statements are TRUE OR FALSE. Statement 1: Competitive firms can still earn positive accounting profits in the long run. Statement 2: A higher total cost to a firm must imply a lower level of output. 【解答】True, False 对 Statement 1 的解说见 Q1 statement 2 对于 statement 2，因为 Total cost=Variable Cost+Fixed Cost \\text{Total cost}=\\text{Variable Cost}+\\text{Fixed Cost} Total cost=Variable Cost+Fixed Cost如果 Fixed cost 增加，那么短期内企业仍然会维持产量。因此陈述错误。 Q3 Suppose the government reduces a commercial registration fee for all firms in a competitive industry. Evaluate whether the following statements are TRUE or FALSE. Statement 1: A typical firm of the industry will raise its output in the short run. Statement 2: A typical firm of the industry will see an increase in producer surplus in the short run. 题目减少的是 fixed cost，对于 short run 没有影响。 生产者剩余=总收益−可变成本 \\text{生产者剩余}=\\text{总收益}-\\text{可变成本} 生产者剩余=总收益−可变成本 Q4 The government invested $10 million in an infrastructure project two years ago. The amount of money was spent on wages and material costs, which cannot be recovered. This year, the government realizes that she needs to invest another $4 million in the project because of construction delays, while the $11 million expected revenue remains unchanged and can only be generated upon the completion of the project. The government should ________ the additional budget because ________. Select one: a. approve; the project can generate positive revenue. b. approve; marginal benefit of the extra payment is greater than its marginal cost. c. disapprove; the cost is higher than expected d. disapprove; the government will suffer from a $3 million loss. 【解答】B 【解说】A 为什么错误呢？分析应该基于边际成本与收益。 Q5 There are 100100100 firms in a perfectly competitive decreasing cost industry at the long-run equilibrium. A typical firm faces the following cost curves (qqq is firm quantity, nnn is number of firms): Average Variable Cost ($): AVC=q+50AVC=q+50AVC=q+50 Marginal Cost ($): MC=2q+50MC=2q+50MC=2q+50 Fixed Cost ($): FC=810000/nFC=810000/nFC=810000/n What are the market price and market quantity? Select one: a. $230\\$230$230, 900090009000 units b. $15.5\\$15.5$15.5, 810081008100 units c. $155\\$155$155, 818181 units d. $230\\$230$230, 909090 units 长期平衡的话，考虑 TC=TVC+TFCTC=TVC+TFCTC=TVC+TFC，AC=AVC+AFCAC=AVC+AFCAC=AVC+AFC。这里，单个企业的 Total Fixed Cost 为 8.1×105100=8100\\frac{8.1\\times 10^5}{100}=81001008.1×105​=8100，因此平均固定成本为 AFC=8100qAFC=\\frac{8100}{q}AFC=q8100​，因此平均总成本为 AC=AVC+AFC=q+50+8100q AC=AVC+AFC=q+50+\\frac{8100}{q} AC=AVC+AFC=q+50+q8100​考虑市场价格，对于单个企业有 MC=ACMC=ACMC=AC，因此 q=90,p=230q=90,p=230q=90,p=230。 这里要求市场上总的产量，因此 Q=nq=9000Q=nq=9000Q=nq=9000 units. Q6 (2020 Spring Final Exam Q31-34) The market of fortune cookies is perfectly competitive. John’s Fortune Cookies is one of the many perfectly competitive firms. Assume that the only variable input required for the production is workers. The following table shows the relationship between the number of workers hired and the total output (packs of fortune cookies produced). # of workers Total output (packs) 1 98 2 183 3 264 4 330 5 391 6 441 7 482 8 517 9 536 10 552 John pays a fixed cost of $380 per day, and to each employee a wage of $54 per day. The price of fortune cookies is $1.14 per pack. Given such information, we can calculate the marginal product due to the 3-rd worker is [Answer1]. Given such information, in the short run, John should hire [Answer2] workers. Given such information, in the short run, John should [Answer3] packs of fortune cookies. Consequently, in the short run, John will make a profit of [Answer4] dollars. Suppose the fixed cost has become $570 per day. In the short run, John should hire [Answer5] workers. 【解答】 决定产量的时候不需要考虑 fixed cost，但是计算利润的时候还是要计算固定成本的。 Q7 (2020 Spring Final Exam Q36-39) There are many identical firms (having the same production costs and producing the same product) in a competitive market. Their product is assumed to be perfectly divisible. When one firm produces qqq units, its marginal cost is MC(q)=qMC(q) = qMC(q)=qand the corresponding total variable cost is TVC(q)=0.5q2TVC(q) = 0.5q^2TVC(q)=0.5q2The demand curve in the market is Q=9180−90PQ = 9180 - 90PQ=9180−90PMoreover, assume that the industry is constant cost. The market is currently in a long-run equilibrium, and the equilibrium price is $45 per unit. Using the information, we conclude that there are [Answer1] firms in the market. Using this information, we conclude that the fixed cost of an individual firm is [Answer2] dollars. Using this information, we conclude that the short-run supply curve of this industry is of the form Q=A+B×PQ = A + B \\times PQ=A+B×P AAA is equal to [Answer3]. BBB is equal to [Answer4]. Suppose now the market demand has become Q=15300−150PQ = 15300 - 150PQ=15300−150P Using the information, we can calculate that in the long run, an individual firm will produce [Answer5] units. 【解答】 对于单个企业而言，其 supply curve 就是 MC curve，也就是单个企业的 P−QP-QP−Q 曲线为 q=0+1Pq=0+1Pq=0+1P，但是这里题目要的是社会总产量 Q=nqQ=nqQ=nq，因此 Q=0+114PQ=0+114PQ=0+114P Q8 In a perfectly competitive constant cost industry, all firms are identical. A typical firm possesses the cost curves: TC=q2+80q+100TC=q^2+80q+100TC=q2+80q+100 MC=2q+80MC=2q+80MC=2q+80 (q is firm quantity). The market demand is P=1100−QP=1100-QP=1100−Q (Q is market quantity). The industry is initially at the long-run equilibrium. (a) A typical firm will shut-down and produce zero quantity in the short run if the price is lower than [Answer1] dollars. (Hint: P_shutdown = min AVC) A typical firm will exit from the industry in the long run if the price is lower than [Answer2] dollars. (Hint: P_exit = min AC, where MC=AC). (b) At initial long-run equilibrium, the price is [Answer3] dollars. (Hint: What is the relationship between long-run equilibrium price and firm exit price?) At initial long-run equilibrium, each firm produces [Answer4] units. © At initial long-run equilibrium, there are [Answer5] firms in the market. (Hint: number of firms = market quantity / firm quantity.) (d) Because of change in environmental regulation that affects production cost, the marginal cost is reduced by 17 dollars but the fixed cost is increased by 300 dollars permanently. The post-regulation short-run supply curve of this industry is: P=A+B×QP = A + B \\times QP=A+B×Qwhere A is equal to [Answer6]. (Hint: What will be the new MC curve?) Continue above, B is equal to [Answer7]. (e) At the post-regulation short-run equilibrium, the price is [Answer8] dollars. At the post-regulation short-run equilibrium, each hotel produces [Answer9] units. At the post-regulation short-run equilibrium, each firm earns a profit of [Answer10] dollars. (Hint: What will be the new TC curve?) (f) With free entry and exit of firms, at the post-regulation long-run equilibrium, the price will be [Answer11] dollars. At the post-regulation long-run equilibrium, there will be [Answer12] firms in the market. (h) Suppose the government wants to induce the market to generate a post-regulation long-run equilibrium quantity the same as the pre-regulation long-run equilibrium quantity. The government should impose per-unit subsidy of [Answer13] dollars. 【解答】 分析 MCMCMC 的表达式，发现当 shutdown 即 q=0q=0q=0 时，对应的价格为 808080，也就是说当价格低于 808080 企业就会选择不生产。因此短期 shutdown price 为 808080. exit price 的话只需要列出方程即可，即 AVC=MCAVC=MCAVC=MCq2+80q+100q=2q+80 \\frac{q^2+80q+100}{q}=2q+80 qq2+80q+100​=2q+80解得 q=10q=10q=10，所以 exit price 为 2q+80=1002q+80=1002q+80=100. 长期平衡价格等于企业 exit price 上面刚刚解出来的 q=10q=10q=10 代入 Demand curve 可知，市场总产量为 Q=1000Q=1000Q=1000，因此，总共有 n=Qq=100n=\\frac{Q}{q}=100n=qQ​=100 家企业 (7.) Marginal Cost 降低 171717 而 fixed cost 增加 300300300，于是，MCMCMC 和 TCTCTC 变成了MC=2q+63TC=q2+63q+400 MC=2q+63\\\\ TC=q^2+63q+400 MC=2q+63TC=q2+63q+400从 P=MC=2q+63P=MC=2q+63P=MC=2q+63 和 q=Qnq=\\frac{Q}{n}q=nQ​，可知 P=0.02Q+63P=0.02Q+63P=0.02Q+63，所以 A=63A=63A=63 B=0.02B=0.02B=0.02 联立 P=0.02Q+63P=0.02Q+63P=0.02Q+63 和 P=1100−QP=1100-QP=1100−Q，可知 Q=1017.67,P=83.33Q=1017.67,P=83.33Q=1017.67,P=83.33 由于 Q=1017.67Q=1017.67Q=1017.67，由于市场刚刚变化，因此此时还不会有企业退出，所以 q=Q/n=10.17q=Q/n=10.17q=Q/n=10.17 把 q=10.17q=10.17q=10.17 代入，Profit=Pq−TC=−296.67\\text{Profit}=Pq-TC=-296.67Profit=Pq−TC=−296.67 h. 最后可以分析出来原来的长期市场价格为 100100100 而当前为 103103103，在 Demand Curve 上我们可以发现，要想让 Q′QQ′ 恢复到 QQQ 的水平，长期均衡的价格必须是 100100100，但是企业现在的 ACACAC 最低点是 103103103，需要降到 100100100. 因此需要补贴 103−100=3103-100=3103−100=3 块钱。"},{"title":"Monopoly 垄断","path":"/wiki/microecon/monopoly.html","content":"垄断定义 拥有定价权 价格不受 Demand Quantity 影响 Profit Maximizing Rule 依然遵循利益最大化原则，对于垄断企业来说，只需要考虑在 Demand Curve 上找到 Marginal Revenue =0=0=0 的那个点即可。 Marginal Revenue 对于离散的 Quantity，有 MR(Q)=TR(Q)−TR(Q−1) MR(Q)=TR(Q)-TR(Q-1) MR(Q)=TR(Q)−TR(Q−1)对于连续的 Quantity，有 P(Q)=a−bQ ⟹ MR(Q)=a−2bQ P(Q)=a-bQ\\implies MR(Q)=a-2bQ P(Q)=a−bQ⟹MR(Q)=a−2bQ 证明 由于是连续性变量，考虑极小值 ΔQ\\Delta QΔQ 的 Marginal Revenue，则有 MR(Q)=lim⁡ΔQ→0(a−b(Q+ΔQ))(Q+ΔQ)−(a−bQ)QΔQ=a−2bQ \\begin{aligned} MR(Q)=\\lim_{\\Delta Q\\to 0}\\frac{\\Big(a-b(Q+\\Delta Q)\\Big)(Q+\\Delta Q)-(a-bQ)Q}{\\Delta Q}\\\\ =a-2bQ \\end{aligned} MR(Q)​=ΔQ→0lim​ΔQ(a−b(Q+ΔQ))(Q+ΔQ)−(a−bQ)Q​=a−2bQ​ Select Price 选定 Quantity 之后，根据 Demand Curve 计算 Price。 Price Elasticity of Demand 与 Monopoly Markup 完全竞争的市场里，无法有溢价，即必须满足 P=MCP=MCP=MC。但垄断市场里可以有溢价： P=ϵ1+ϵMCMarkup=P−MCMC=−11+ϵ P=\\frac{\\epsilon}{1+\\epsilon}MC\\\\ Markup=\\frac{P-MC}{MC}=\\frac{-1}{1+\\epsilon} P=1+ϵϵ​MCMarkup=MCP−MC​=1+ϵ−1​The More Inelastic the Demand Curve the More the Monopolist Raises Price Above Marginal Cost Welfare Analysis Producer Surplus FC=0 Monopoly Profit FC>0 政府干预 垄断企业相比其他企业，由于生产规模更大，其平均生产成本也更低，此时一定会将新入行的企业（其平均生产成本更高）挤出市场。 若政府设置价格上限…… 如果设置在 MCMCMC，垄断企业会退出市场，因为 ACMCACMCACMC。所以如果要让垄断企业留在行业内，最低的上限必须设置为 ACACAC. the price that corresponding to the same quantity Q∗Q^\\astQ∗ depends on the demand. 例题 Q1 A monopolist possesses the cost curves: TC=Q2+80Q+90000TC = Q^2 + 80Q + 90000TC=Q2+80Q+90000, MC=2Q+80MC = 2Q + 80MC=2Q+80. The market demand is P=1100−QP = 1100 - QP=1100−Q. (a) To maximize profit, the monopolist charges [Answer1]. (b) Continue above, the deadweight loss is [Answer2]. © If the government imposes a price ceiling at $700. The monopoly will earn a profit of [Answer3]. (Hint: Be careful with where MR(Q)=MC(Q)MR(Q) = MC(Q)MR(Q)=MC(Q) in price ceiling case.) (d) Suppose the government instead imposes a price ceiling to completely eliminate deadweight loss in the short run. The monopolist will earn a profit of [Answer4]. (e) Ignore price ceiling. Suppose the marginal cost of production is increased by $20 per unit sold. The monopolist will earn a profit of [Answer5]. (Hint: What are the new TC and MC curves?) (f) Suppose instead only the fixed cost of production is increased by $20000. The monopolist will produce earn a profit of [Answer6]. (Hint: What are the new TC and MC curves?) (g) Suppose instead the government provides a 20 per-unit subsidy to the monopoly. The monopolist will earn a profit of $[Answer7]. (Hint: What are the new TC and MC curves?) (h) Suppose instead the government provides a 20 per-unit subsidy to consumers. The monopolist will earn a profit of $[Answer8]. (i) Suppose instead the government wants to completely eliminate deadweight loss. It can do so by providing per-unit subsidy of [Answer9][Answer9][Answer9] to consumers."},{"title":"Price Ceiling/Floor","path":"/wiki/microecon/price-ceiling-floor.html","content":"Price Ceiling 价格上限在 P−QP-QP−Q 图像上表示为一条水平线 Ceiling Line 黑色实线为坐标轴，纵轴 PPP，横轴为 QQQ 橙色线表示 P=F(Qs)P=F(Q^s)P=F(Qs) 黄色线表示 P=F(Qd)P=F(Q^d)P=F(Qd) 蓝色线表示 Price Ceiling， 注意！ 只有当蓝色低于 Equilibrium 点的时候才需要额外分析，如果价格上限高于市场价，那么对于市场完全没有影响 于是此时我们可以看到，需求量远远大于供给量，于是在供给量固定的情况下，市场上的买家需要争夺这些稀缺的供给……我们来看四种情况 Bribery 第一种解决办法，加价/拍卖。Total Value of bribery 会计入 Surplus 中 Waiting in Line Total Value of Time，会算作损失 例题 2024 Summer Suppose the demand and supply of Cannabis in Neverland community are given as follows: Demand: P=930−589QP = 930 - 589QP=930−589Q Supply: P=180+2.5QP = 180 + 2.5QP=180+2.5Q In which PPP is the price per kg in thousand dollars and QQQ is the quantity in thousand kgs. Note: 1 thousand×(1 thousand)=1 million1 \\text{ thousand} \\times (1 \\text{ thousand}) = 1 \\text{ million}1 thousand×(1 thousand)=1 million 18. The unregulated equilibrium Cannabis price is [ Answer18A ] thousand dollars per kg and the equilibrium quantity is [ Answer18B ] thousand kgs. 19. Suppose the government purchases 101010 thousand kgs of Cannabis back from the market regardless of price. After the government enters the market, on the new market demand curve, when the price is 555555555 thousand dollars per kg, the total quantity demanded is [ Answer19 ] thousand kgs. 20. Suppose the government wants to use a buyback program to reduce the quantity of Cannabis traded in the community to zero. The government will need to buy at least [ Answer20A ] thousand kgs from the market and spend at least [ Answer20B ] million dollars. 21. Suppose the government wants to use a price floor to reduce the quantity of Cannabis traded in the community to zero. The government will need to implement a price floor of [ Answer21A ] (A. at most; B. at least) [ Answer21B ] thousand dollars per kg. 22. Knowing that the government is determined to reduce the quantity of Cannabis traded in the community to zero through either buyback or price floor, the Cannabis suppliers are actively thinking of lobbying the government for a policy they favor. The Cannabis suppliers as a group are willing to spend up to [ Answer22 ] million dollars to lobby the government to adopt the policy they favor. 解答 这一小问的核心在于，生产商是从这两个政策里选出最利于自己（收益最大化）的政策，也就是贿赂政府选择 buyback 政策。而 buyback 政策下，Producer Surplus 为 0.5×(930−180)×300=1125000.5\\times (930-180)\\times 300=1125000.5×(930−180)×300=112500 million，因此最多可以支付 112500112500112500 来贿赂政府。"},{"title":"Price Discrimination 价格歧视","path":"/wiki/microecon/price-discrimination.html","content":"Single-Price Monopoly Single-Price Monopoly（单一价格垄断）是指垄断企业在同一市场中对所有消费者收取相同价格的行为 仅考虑企业自身的利润，不考虑 Social Surplus. 价格歧视 本质目的还是为了提升利润。 First Degree (Perfect) Price Discrimination PPD: 企业对每位消费者收取不同的价格，等于其保留价格，完全提取消费者剩余（Consumer Surplus），将其转化为企业利润。此时 DWL=0DWL=0DWL=0 Q↑ ⟹ MB↓ ⟹ P↓ Q\\uparrow \\implies MB\\downarrow \\implies P\\downarrow Q↑⟹MB↓⟹P↓ Secodn Degree Price Discrimination (using Hurdles) Discrimination using Hurdles（使用障碍进行价格歧视） 是一种通过设置特定门槛或障碍，将市场分割为不同子市场，并对各子市场实施差异化定价的策略。 并非 Social Efficient，但是比 Single-Price Monopoly 好很多 DWL 分析 DWL Third Degree PD 根据可观察特征（如年龄、地区）划分市场，对不同子市场设定不同价格. 例题"},{"title":"Supply Demand","path":"/wiki/microecon/supply-demand.html","content":"Demand Curve Normal good: When we have more income, we choose to buy more of the good. Inferior good: When we have more income, we choose to buy less of the good. Combination of Demand Curves Qtotald=Q1d+Q2d Q^d_{total}=Q^d_{1}+Q^d_2 Qtotald​=Q1d​+Q2d​ Supply Curve Horizontally: How many suppliers are willing and able to sell at a certain price. Vertically: The minimum price for which suppliers are willing to sell a certain quantity. Combination of Supply Curves Qtotals=Q1s+Q2s Q^s_{total}=Q^s_{1}+Q^s_2 Qtotals​=Q1s​+Q2s​ 计算 Equilibrium: Supply Curve 与 Demand Curve 的交点 Economic Surplus 这个 Surplus 可以这样理解：如果我预期 100100100 元买下，而我实际只花了 606060，那么其实我会觉得我赚了 100−60=40100-60=40100−60=40。 而在 Equilibrium 的情况下，交易价为 Equi Price，在 Demand Curve 上不同预期价（Price，纵坐标）有对应的人数（Quantity，横坐标，实际上应该是 ΔQ\\Delta QΔQ），因此对于这个预期价而言，他们获得的“赚了”感是 P×ΔQP\\times \\Delta QP×ΔQ 因此在下图的公式里，所有的 Surplus 是一个三角形 Total Economic Surplus=Consumer Surplus+Producer Surplus \\text{Total Economic Surplus}=\\text{Consumer Surplus}+\\text{Producer Surplus} Total Economic Surplus=Consumer Surplus+Producer Surplus如果 Economic Surplus 0\\lt 00 那么交易就不会发生 红色部分就是 Total Economic Surplus 分别计算 Consumer 和 Producer 的 Surplus"},{"title":"Tax and Subsidy","path":"/wiki/microecon/tax-subsidy.html","content":"本章最核心的理论是，无论税收或者补贴，假设为 TTT 元，那么当达到新的平衡点时，消费者支付价格与生产者成本价格之间的差值必为 TTT 元 Pd−Ps=T \\boxed{P^d-P^s=T} Pd−Ps=T​Tax Subsidy"},{"title":"Public Goods","path":"/wiki/microecon/public-goods.html","content":"Excludability and Rivalry Excludability: 排他性 Non-excludable goods: Cannot exclude non-payers (e.g., national defense, radio signals). Excludable goods: Can exclude non-payers (e.g., jeans, paid e-books). Rivalry: 竞争性 Rival goods : Use by one person reduces availability for others. Non-rival goods : One person’s use does not diminish availability for others. Excludability Rivalry Type Examples Excludable Rival Private Goods Jeans, hamburgers, gasoline Excludable Non-rival Nonrival Private Wi-Fi, satellite TV Non-excludable Rival Common Resources Timber in public land, bluefin tuna Non-excludable Non-rival Public Goods National defense, lighthouses 四种商品类型 Private Goods 可以直接高效地进入竞争市场 因为 rival，所以 excludable 不导致 inefficiency 因为 excludable，所以有 incentive 去消费和生产 经典微观经济学的假设： 所有生产成本由生产者承担 所有消费收益由消费者享受 Public Goods Under-provision : Free-rider problem leads to insufficient supply. Collective Action : Difficult to negotiate joint purchases, especially with large groups. 需要政府介入 Taxes to buy public goods (e.g., streetlights, highways). Optimal quantity determined where Marginal Social Benefit (MSB) = Marginal Social Cost (MSC) . MSB curve: 分段加和 Non-rival Private Common Resources 私人决策的低效性 个人在做决策的时候，指针方针仅考虑私人的边际收益和私人的边际成本 MB(Qi)≥MC(Qi) MB(Q_i)\\ge MC(Q_i) MB(Qi​)≥MC(Qi​)然而从社会的角度看，社会成本 === 私人成本 +++ 外部成本，导致市场均衡产量 QmktQ_{mkt}Qmkt​ 远大于社会均衡产量 QsocQ_{soc}Qsoc​. 为防止 Tragedy of the Commons 需要政府干预： 核心思想 当前的 quantity 为 QmktQ_{mkt}Qmkt​，其满足 MB(Qmkt)=MC(Qmkt) MB(Q_{mkt})=MC(Q_{mkt}) MB(Qmkt​)=MC(Qmkt​)既然想让它达到 QsocQ_{soc}Qsoc​ 的水平，那么我们可以列出两个式子 {MB(Qsoc)=MC(Qsoc)MC(Qsoc)=MC(Qmkt)+Extra Cost \\begin{cases} MB(Q_{soc})=MC(Q_{soc})\\\\ MC(Q_{soc})=MC(Q_{mkt})+\\text{Extra Cost} \\end{cases} {MB(Qsoc​)=MC(Qsoc​)MC(Qsoc​)=MC(Qmkt​)+Extra Cost​那么我们只需要限制 Extra Cost\\text{Extra Cost}Extra Cost 的范围即可。 通过税收干预 通过 Tradable Permit 干预 例题 2020 Fall Final Q1 Please refer to the background information below to answer the following three questions. Factory X produces 101010 tons of wastewater every day. Each ton of wastewater caused 17.517.517.5 (in thousand dollars) worth of damage to nearby residents. It costs the factory n2n^2n2 (in thousand dollars) to remove pollutants from nnn tons of wastewater. Suppose nnn can only take integer numbers. If pollution is unregulated and negotiation is impossible, Factory X will discharge [ Answer38 ] tons of untreated wastewater to the sea every day. It is socially efficient for Factory X to treat [ Answer39 ] tons of wastewater. Consider levying a tax on wastewater. In order to achieve the socially efficient outcome, the minimum amount of tax should be [ Answer40 ] thousand dollars per ton of wastewater. 【解答】 我们不妨 38. 由于工厂并不对环境污染负责，所以其 cost 仅由废水处理构成 arg min⁡xx2\\argmin_x x^2argminx​x2，所以 x=0x=0x=0，即不处理任何污水 考虑社会环境效益，假设工厂处理 xxx 吨废水，则社会的成本由废水处理和废水污染构成，即 arg min⁡xx2+17.5(10−x)\\argmin_x x^2+17.5(10-x)argminx​x2+17.5(10−x)，因为 x∈Zx\\in \\Zx∈Z 故 x=9x=9x=9 仅考虑工厂的成本，工厂的成本由废水处理和税构成，假设处理 xxx 吨废水其余排放，每吨废水收税 ppp，则成本为 arg min⁡xx2+p(10−x)\\argmin_x x^2+p(10-x)argminx​x2+p(10−x)，现在要求达到社会最大效益，即这个二次函数的最小值在 x=9x=9x=9 取到。所以解得 p≥17p\\ge 17p≥17 Q2 Please refer to the background information below to answer the following three questions. There is a small public beach in Utopia. The residents of Utopia, in total 20 of them, love to go to the beach but prefer not to when it is too crowded. In particular, if n people share the beach together, each individual gets an economic surplus of 10.5 − n dollars. Suppose n can only take integer numbers. If the residents make their decisions individually, then [ ] residents will go to the beach in equilibrium. The socially optimal number of beach occupants is [ ]. If the government charges an entrance fee of $2.62, [ ] residents will go to the beach in equilibrium."},{"title":"Trading 交易与分工","path":"/wiki/microecon/trading.html","content":"Unit Requirement Table 与 Unit Productivity Table Requirement 和 Productivity Table 最重要的区别就是：前者给出生产一个物品需要的资源，后者给出在限定资源的情况下能生产多少物品。 有一个简单的转化： 1Requirement=Productivity \\frac{1}{\\text{Requirement}}=\\text{Productivity} Requirement1​=Productivity Opportunity Cost Opportunity Cost Copp()C_{opp}()Copp​() 描述某个人在生产某件物品的时候，能够生产多少的其他物品；直观理解就是这个人生产这件物品有多 efficient 重要公式 Copp(A)=Time of ATime of B=Productivity of BProductivity of A C_{opp}(A)=\\frac{\\text{Time of }A}{\\text{Time of }B} =\\frac{\\text{Productivity of }B}{\\text{Productivity of }A} Copp​(A)=Time of BTime of A​=Productivity of AProductivity of B​ 这里的 Quantity 是在一段长度确定的时间内的。并且可以注意到 Copp(A)=1Copp(B)C_{opp}(A)=\\frac{1}{C_{opp}(B)}Copp​(A)=Copp​(B)1​ 如果对于两个人 X,YX,YX,Y，如果 Copp,X(A)Copp,Y(A)C_{opp,X}(A)\\lt C_{opp,Y}(A)Copp,X​(A)Copp,Y​(A)，即 XXX 在 AAA 上的 Opportunity Cost 更小，我们称 XXX 在 AAA 上有 Comparative Advantage. Specialization 分工 一个经济体里肯定会有分工，理性经济体里的分工由 Opportunity Cost 的大小来决定：让 Copp(A)C_{opp}(A)Copp​(A) 最小的人来负责这件 AAA （总是让最高效的人来处理这件事） 分工的存在，也可以让经济体达到 1+121+1\\gt 21+12 的效果。 Term of Trade (TOT) TOTTOTTOT 描述交易时的换算比例（例如 1.11.11.1 Tea/Cake 说明 111 个蛋糕能交易 1.11.11.1 包茶） 因为交易的双方都需要从交易中获利（否则根本不会进行交易），此时 Term of Trade 叫需要满足一些条件，使得双方都能获利。这里的获利的意思是，我从你这里买东西比我自己生产这个东西要好（你更加熟练，需要的资源更少）。 一个重要的公式就是，对于交易的双方，TOTAperBTOT_{A\\mathop{per}B}TOTAperB​（表示 1 unit B=TOT unit A\\text{\\(1\\) unit \\(B=TOT\\) unit \\(A\\)}1 unit B=TOT unit A）应该满足 Copp,X(A)≤TOTAperB≤Copp,Y(A) C_{opp,X}(A)\\le TOT_{A\\mathop{per}B}\\le C_{opp,Y}(A) Copp,X​(A)≤TOTAperB​≤Copp,Y​(A) 证明 我们假设经济体只生产 A,BA,BA,B 两件物品，且生产 AAA 的 XXX 与生产 BBB 的 YYY 进行交易。那么我们首先知道，根据分工，有 Copp,X(A)Copp,Y(A)Copp,X(B)Copp,Y(B) C_{opp,X}(A)\\lt C_{opp,Y}(A)\\\\ C_{opp,X}(B)\\gt C_{opp,Y}(B) Copp,X​(A)Copp,Y​(A)Copp,X​(B)Copp,Y​(B)交易双方判断能否获利的准则是： （Requirement）生产相同数量时，相比自己生产，能否获得资源上的节约？ （Quantity）拥有相同数量资源时，相比自己生产，能否获得产品数量上的提升？ 现在假设 TOT 的计算是 111 个单位 BBB 能交易 TOTTOTTOT 单位的 AAA（那么其单位就是 A/BA/BA/B），用资源的节省量推导。 那么，对 XXX 而言，他生产的是 AAA，购买的是 BBB，那么他生产的 111 个单位的 AAA 能换来 1TOT\\frac{1}{TOT}TOT1​ 的 BBB，理论应该节约 RX(B)−1TOTRX(A)≥0 ⟺ TOT≥RX(A)RX(B)=Copp,X(A) \\begin{aligned} R_{X}(B)-\\frac{1}{TOT}R_X(A)\\ge 0\\\\ \\iff TOT\\ge \\frac{R_X(A)}{R_X(B)}=C_{opp,X}(A) \\end{aligned} ⟺​RX​(B)−TOT1​RX​(A)≥0TOT≥RX​(B)RX​(A)​=Copp,X​(A)​同理，对 YYY 而言，他生产的每单位 BBB 能换 TOTTOTTOT 单位的 AAA，理论上，生产 AAA 可以节约 RY(A)−TOT×RY(B)≥0 ⟺ TOT≤RY(A)RY(B)=Copp,Y(A) \\begin{aligned} R_Y(A)-TOT\\times R_Y(B)\\ge 0\\\\ \\iffTOT\\le\\frac{ R_Y(A)}{R_Y(B)}=C_{opp,Y}(A) \\end{aligned} ⟺​RY​(A)−TOT×RY​(B)≥0TOT≤RY​(B)RY​(A)​=Copp,Y​(A)​所以，对于交易的双方，TOTAperBTOT_{A\\mathop{per}B}TOTAperB​（表示 1 unit B=TOT unit A\\text{\\(1\\) unit \\(B=TOT\\) unit \\(A\\)}1 unit B=TOT unit A）应该满足 Copp,X(A)≤TOTAperB≤Copp,Y(A) C_{opp,X}(A)\\le TOT_{A\\mathop{per}B}\\le C_{opp,Y}(A) Copp,X​(A)≤TOTAperB​≤Copp,Y​(A) (PPC) Production Possibility Curve PPC 上的一条直线 我们假设纵轴表示 AAA 的生产，横轴表示 BBB 的生产，那么截距表示全力生产某一样物品的情况下，该物品的产量。 我们来考察这条直线的斜率 kkk，则有 k=−Productivity of AProductivity of B=−Copp(B)=−1Copp(A) \\begin{aligned} k=-\\frac{\\text{Productivity of }A}{\\text{Productivity of }B}\\\\ =-C_{opp}(B)\\\\ =-\\frac{1}{C_{opp}(A)} \\end{aligned} k​=−Productivity of BProductivity of A​=−Copp​(B)=−Copp​(A)1​​我们更关心 ∣k∣|k|∣k∣，这个绝对值的意义更加鲜明：多生产 111 个单位的 BBB 的 Opportunity Cost 为 ∣k∣|k|∣k∣ 的单位的 AAA.，而 ∣k∣=Copp(B)|k|=C_{opp}(B)∣k∣=Copp​(B) 多条直线：分工 Low-Hanging-Fruit Principle 这个原理描述一个经济体内多人合作分工时，若要扩大生产，一定先让 Lowest Opportunity Cost 的人去做（因为最高效） 如果扩大的是 BBB 的生产（横轴），那么从左向右斜率的绝对值越来越大，越来越陡峭；图像呈现向上凸。 如果扩大的是 AAA 的生产（纵轴），那么从下往上直线的斜率的绝对值越来越小，越来越平缓（因为 Copp(A)C_{opp}(A)Copp​(A) 与 Copp(B)C_{opp}(B)Copp​(B) 成反比）；不过图像仍是上凸的。 直线的相交位置：(Bi−1,Ai)(B_{i-1},A_i)(Bi−1​,Ai​) 影响 PPC 的因素 资源增多 科技进步 总结 通常来说，如果交易双方的 Copp()C_{opp}()Copp​() 差距越大，那么双方交易带来的资源节省和产能提升也会越大。 (CPC) Consumption Probalitity Curve Closed Economy: 无开放贸易 在无开放贸易的情况下，一个经济体的 CPC 和 PPC 是重合的。因为除了这几个人没有人需要生产的物品，因此这些人生产出来的东西只能被自己消耗。 有浪费会趋于减产，有不够会趋于增产，最终都会回归到 PPC 上，因此 CPC 与 PPC 重合。 Open Economy and Open Trade 我们可以从几个角度来看 Open Trade 对 Production 和 Consumption 的影响，然后来看一看相关的计算。 以下假设假设贸易市场上 AAA 的价格为 aaa，BBB 的价格为 bbb，假设 TOTTOTTOT 用 AperBA\\mathop{per} BAperB 计算，此时对于贸易市场来说，TOT=TOTAperB=abTOT=TOT_{A\\mathop{per}B}=\\frac{a}{b}TOT=TOTAperB​=ba​ 例子：如何生产使得收益最大化 贸易市场的价格可以用一根斜率确定、截距不定的直线在 PPC 图像（纵轴为 AAA，横轴为 BBB）上表示出来，这条直线的斜率就是 −TOT-TOT−TOT 为了让利益最大化，我们平移这条直线，让他和 PPC 产生交点，对于每一个交点计算收益，取最大值即可。 从交点倒推 TOT 和市场价格 一个很 tricky 的点是，图像上 PPC 的斜率是 −Copp(B)-C_{opp}(B)−Copp​(B)，但市场的直线的斜率是 −TOTAperB-TOT_{A\\mathop{per}B}−TOTAperB​。记得取倒数。 最大化组合消费 通常会问，若消费 nnn 单位的 AAA，那么最多能消费多少 BBB？ 我们把这个过程转化为，X,YX,YX,Y 两人先生产，通过贸易市场换成钱，再用钱在市场上买所需的物品。这里不考虑成“生产后的东西先拿出一部分满足消费”，是因为这两个思路是等价的 计算：在这个市场下，通过交易最多能赚多少钱 通过计算 TOTTOTTOT，判断出每一个应该生产什么（贸易市场的 TOTAperBTOT_{A\\mathbb{per}B}TOTAperB​ 更大，则生产 AAA；否则生产 BBB） 把生产出来的东西卖成钱 先购买需要消费的东西 然后就能计算最多能买多少了"},{"title":"PCA","path":"/wiki/ml/PCA.html","content":"PCA 主成分分析 PCA 是一种无监督的线性降维方法，它的核心思想是通过线性变换将原始的高维数据投影到一个新的低维空间中，使得投影后的数据在新的坐标轴上的方差最大。这样可以保留数据中最主要的特征信息，同时去除噪声和冗余信息 数学原理 既然需要保留最多的方差，那么首先我们要计算出数据集的协方差矩阵 C[i,j]=Cov(xi,xj)C[i,j]=Cov(x_i,x_j)C[i,j]=Cov(xi​,xj​)"},{"title":"RANSAC 线性回归算法","path":"/wiki/ml/RANSAC.html","content":"RANSAC 线性回归算法 用于解决普通线性回归算法里对 outlier 敏感的缺点 随机挑选出 mmm 个点 用这 mmm 个点拟合一个线性模型 对剩下的所有点，计算模型误差，筛选出在 tolerance ϵ\\epsilonϵ 内的点 用新挑选出来的点对模型进行重新拟合（例如最小二乘法） 最后选择性能最好的模型"},{"title":"Bagging","path":"/wiki/ml/bagging.html","content":"Bagging Algorithm 核心思想：对原数据集采样多次（可以有漏，可以有重）分别用于训练"},{"title":"Bisecting K-Means","path":"/wiki/ml/bisecting-k-means.html","content":"Bisecting K-Means"},{"title":"Cluster Analysis","path":"/wiki/ml/clustering.html","content":"Cluster 分类 Cluster Type Description Well-Separated 簇间完全分离，无重叠。 Center-Based 每个簇由中心点（如均值、中位数）定义，数据点靠近所属簇中心。 Contiguity-Based 基于空间邻近性，形成连通区域。 Density-Based 高密度区域形成簇，低密度区域分隔簇（如DBSCAN）。 Objective Function 通过优化目标函数（如最小化误差平方和）划分簇。 Partitional Clustering Hierarchical Clustering 聚合式 (Agglomerative): 自底向上，初始每个点为独立簇，逐步合并最近簇。 分裂式 (Divisive): 自顶向下，初始一个簇，逐步分裂为更小簇。 Agglomerative 使用 Distance/Similarity/Proximity Matrix Space: O(n2)O(n^2)O(n2) Time: O(n3)O(n^3)O(n3), O(n2log⁡n)O(n^2\\log n)O(n2logn) 计算 Proximity Matrix 循环，直到只剩一个 cluster 合并两个最近的 cluster 更新 Proximity Matrix 如何更新 Proximity Matrix? MIN: 簇间距离取最近点距离，易处理非球形簇但易受噪声影响。 MAX: 取最远点距离，抗噪但易分裂大簇. Biased towards globular clusters Group Avg: 取所有点对的平均距离，平衡抗噪与形状适应性。Biased towards globular clusters Distance between Centroids Ward’s Method: 最小化簇内误差平方和 Divisive: 最小生成树 构建 MST 计算点对之间的距离矩阵 生成 Proximity Graph 的 MST 分裂 MST 从 MST 中选出一条边，断开。 形成的两个连通块对应两个不同的 cluster"},{"title":"Evaluating Regression","path":"/wiki/ml/eval-regression.html","content":"SSE R2 R2=1−SSESST R^2=1-\\frac{SSE}{SST} R2=1−SSTSSE​"},{"title":"K-Means","path":"/wiki/ml/k-means.html","content":"K-Means Partitional Clustering 每一个 cluster 与一个 centroid 相联系，每一个点分配到其最近的 centroid KKK 是超参数 算法流程 选定初始的 KKK 个点作为 centroid 循环，直到 KKK 个 centroid 不再发生变化 把所有点分配到这 KKK 个 cluster 重新计算 KKK 个 centroid O(n×K×I×d)O(n×K×I×d)O(n×K×I×d)，其中 nnn 为数据量，KKK 为簇数，III 为迭代次数，ddd 为特征数。 我们用平均距离衡量 K-Means 算法的优劣： SSE=∑i=1K∑x∈Cidist2(x,mi) SSE=\\sum_{i=1}^K \\sum_{x \\in C_i} \\text{dist}^2(x, m_i) SSE=i=1∑K​x∈Ci​∑​dist2(x,mi​) 局限性 对初始中心的选取很敏感 需要预先指定 KKK 可能出现空聚类 针对这些问题，我们可以作出一些改进： 多运行几次算法，增加找到最优解的概率 用 Hierarchical Clustering 优化初始点的选取 K-Means 算出多于 KKK 个 centroid，再从其中选出 KKK 个 后处理 Bisecting K-Means 空聚类的处理 将距离所有簇中心最远的样本点选为空簇的新中心。该点对当前聚类的误差（SSE）贡献最大，重新分配它有助于优化整体聚类效果。 从SSE（误差平方和）最高的非空簇中选择一个点，将其作为空簇的新中心。该簇的误差较大，说明其内部数据分布分散，分裂或调整其中心可能改善聚类质量。 If there are several empty clusters, the above can be repeated several times. 增量法更新 不会产生空簇 前、后处理 前处理： Normalization 去除异常值 后处理： 去除小聚类（可能由异常值组成） 分裂稀疏、分散的聚类 合并close, 紧密的聚类 使用 ISODATA"},{"title":"Particle Filter 粒子滤波","path":"/wiki/ml/particle-filter.html","content":"Particle Filter: Overview 现实世界里，xxx 的维度太大、数量太多，计算的时间复杂度爆炸。我们很难精确计算出 P(X)P(X)P(X) 的 closed form，一个比较经典的方法就是利用蒙特卡罗方法，化连续为离散，用若干个点近似 P(X)P(X)P(X)，这就是粒子滤波的思想。 我们通过对这些点进行追踪，从而得到大致的分布。粒子的平均值代表对 state 的近似，粒子的分布代表对 state distribution 的近似 HMM view of PF PF 对于粒子滤波而言有这么几个东西比较重要： 粒子滤波算法流程 粒子滤波的流程大致可以分为这么几步 获得 observation oto_tot​，得到每一个粒子对真实 state 的近似程度 对粒子进行重采样 (resample)，越近似的粒子比重越大。重采样将近似程度低的粒子替换为近似程度高的粒子 sample：对每一个粒子进行状态转移，即 xt+1=sample(P(Xt+1∣Xt=xt))x_{t+1}=\\text{sample}(P(X_{t+1}|X_t=x_t))xt+1​=sample(P(Xt+1​∣Xt​=xt​))"},{"title":"Plurality Majority Voting","path":"/wiki/ml/plurality-majority.html","content":"Majority Voting 多个模型分别输出预测结果，然后取投票最多的那个标签作为最后的输出。 Voting 用数学语言描述就是 y^=model{Ci(x)},1≤i≤m \\hat y=model\\Big\\{ C_i(x) \\Big\\},1\\le i\\le m y^​=model{Ci​(x)},1≤i≤m其中 CiC_iCi​ 表示训练的第 iii 个 Classifier 多个模型组合带来准确率提升 考虑训练了 2n+12n+12n+1 个分类器，每一个分类器的准确率为 rrr，那么组合后，由于需要超过半数投票，因此正确分类的概率为 ∑k=n+12n+1(kn)rk(1−r)2n+1−k \\sum_{k=n+1}^{2n+1} \\binom{k}{n}r^k(1-r)^{2n+1-k} k=n+1∑2n+1​(nk​)rk(1−r)2n+1−k当 n=5,r=0.7n=5,r=0.7n=5,r=0.7 时，这个值约为 0.92180.92180.9218，可以看到，准确率有很大提升。 Weighted Majority Vote 在此基础上，给每一个模型的预测结果添加权重 y^=arg max⁡i∈A∑j=1mwj[Cj(x)=i] \\hat y=\\argmax_{i\\in A} \\sum_{j=1}^m w_j \\Big[ C_j(\\bold{x})=i \\Big] y^​=i∈Aargmax​j=1∑m​wj​[Cj​(x)=i]其中 AAA 是所有的标签，方括号函数表示如果第 jjj 的分类器对于样本 x\\bold xx 给出的预测结果是 iii 类别的话则为 111，否则为 000. 因此，Weighted Vote 就相当于是枚举标签，然后看每一个模型预测结果的加权平均，取均值最大的那个对应的标签。 Soft Voting 有的模型可以输出概率，所以我们也可以对概率进行加权，最后取最高 y^=arg max⁡i∈A∑j=1mwj⋅Pj(i) \\hat y=\\argmax_{i\\in A}\\sum_{j=1}^m w_j\\cdot P_{j}(i) y^​=i∈Aargmax​j=1∑m​wj​⋅Pj​(i) 代码实现 下面的代码实现了一个 Majority Vote Classifier (vote='classlabel') 和 Soft Vote (vote='probability') from sklearn.base import BaseEstimator, ClassifierMixin, clonefrom sklearn.preprocessing import LabelEncoderfrom sklearn.pipeline import _name_estimatorsimport numpy as npimport operatorclass MajorityVoteClassifier(BaseEstimator, ClassifierMixin): def __init__(self, classifiers, vote=classlabel, weights=None): __init__ 函数接收分类器列表，进行初始化 vote 表示投票方法 self.classifiers = classifiers self.named_classifiers = key: value for key, value in _name_estimators(classifiers) self.vote = vote self.weights = weights def fit(self, X, y): fit() 根据输入的数据 + 标签， 对标签进行 encoding（方便 Soft Vote 获取概率） 然后对 classifier 模型进行训练，并存起来 self.label_enc = LabelEncoder() self.label_enc.fit(y) self.classes = self.label_enc.classes_ self.trained_classifiers = [] for classifier in self.classifiers: trained_clf = clone(classifier).fit( X, self.label_enc.transform(y), ) self.trained_classifiers.append(trained_clf) return self def predict(self, X): probability 部分比较容易理解 classlabel 部分的话，我们首先获取每一个模型的输出结果（`predictions`）， 然后 if self.vote == probability: maj_vote = np.argmax(self.predict_proba(X), axis=1) else: predictions = np.asarray( [ clf.predict(X) for clf in self.trained_classifiers ] ).T maj_vote = np.apply_along_axis( lambda x: np.argmax(np.bincount(x, weights=self.weights)), axis=1, arr=predictions) maj_vote = self.label_enc.inverse_transform(maj_vote) return maj_vote def predict_proba(self, X): probas = np.asarray([clf.predict_proba(X) for clf in self.classifiers_]) avg_proba = np.average(probas, axis=0, weights=self.weights) return avg_proba"},{"title":"Regression","path":"/wiki/ml/regression.html","content":"Linear Regression Polynomial Regression 对每一个 feature xix_ixi​ 都映射到 xi1,xi2,…xidx_i^1,x_i^2,\\dots x_i^dxi1​,xi2​,…xid​，以及可能的交叉项。 Decision Tree (Random Forest) Regression Random Forest: 视为 ensemble of 多个 linear functions Impurity for continuous variables I(t)=MSE(t)=1Nt⋅∑i∈Dt(y(i)−y^t)2 I(t)=MSE(t)=\\frac{1}{N_t}\\cdot \\sum_{i\\in D_t}\\Big( y^{(i)}-\\hat y_t \\Big)^2 I(t)=MSE(t)=Nt​1​⋅i∈Dt​∑​(y(i)−y^​t​)2其中 NtN_tNt​ 是节点 ttt 内的样本数量，DtD_tDt​ 代表这个节点对应的所有样本，y^t\\hat y_ty^​t​ 代表预测样本值（其实是 sample mean），y(i)y^{(i)}y(i) 表示样本真实值 y^t=1Nt∑i∈Dty(i) \\hat y_t=\\frac{1}{N_t}\\sum_{i\\in D_t}y^{(i)} y^​t​=Nt​1​i∈Dt​∑​y(i)使用随机森林时，在构建单棵决策树的时候，predicted target variable is calculated as the average prediction over all decision trees"},{"title":"Regularization","path":"/wiki/ml/regularization.html","content":"Regularization shrink the parameter values L2 正则化: Ridge 在原始的损失函数上加上 L2\\mathcal{L}_2L2​ Penalty JRidge=J(θ)+α⋅∥θ∥22 J_{Ridge}=J(\\theta)+\\alpha\\cdot\\|\\theta\\|_2^2 JRidge​=J(θ)+α⋅∥θ∥22​ L1 正则化: LASSO 加上 L1\\cal L_1L1​ Penalty JLASSO=J(θ)+α⋅∥θ∥ J_{LASSO}=J(\\theta)+\\alpha\\cdot\\|\\theta\\| JLASSO​=J(θ)+α⋅∥θ∥ 有些权重容易变成 000 折中: Elastic Net λ\\lambdaλ 控制比例，α\\alphaα 控制正则程度 JElastic=J(θ)+α⋅[λ∥θ∥2+(1−λ)∥θ∥] J_{Elastic}=J(\\theta)+\\alpha\\cdot\\Bigg[ \\lambda\\|\\theta\\|^2+(1-\\lambda)\\|\\theta\\| \\Bigg] JElastic​=J(θ)+α⋅[λ∥θ∥2+(1−λ)∥θ∥]"},{"title":"Support Vector Machine","path":"/wiki/ml/svm.html","content":"Linear SVM Kernel SVM 通过映射函数 ϕ()\\phi()ϕ()，将低维的特征向量 feature vector xxx 映射到高维空间中 vxv_xvx​，以期望在低维空间不可线性分割的 feature vector 在高维空间可以被线性分割。 但是当映射到高维空间之后，高维向量之间的点乘运算比较耗时，因此利用核函数 Kernel Function K(v1,v2)\\mathcal{K}(v_1,v_2)K(v1​,v2​) 替换点乘运算。例如常见的做法是 K(x(i),x(j))=exp⁡(−γ∥x(i)−x(j)∥2) \\mathcal{K}(x^{(i)},x^{(j)})=\\exp\\Big( -\\gamma\\|x^{(i)}-x^{(j)} \\|^2 \\Big) K(x(i),x(j))=exp(−γ∥x(i)−x(j)∥2)当 γ=12σ2\\gamma=\\frac{1}{2\\sigma^2}γ=2σ21​ 时，就是高斯核函数。"},{"title":"VAE: Variational AutoEncoders","path":"/wiki/multimodal/VAE.html","content":"Representation 图像生成模型的本质是一个概率模型：如果我们知道了真实图像 xxx 的分布规律 p(x)p(x)p(x)，那么我们只需要从这个分布里随便采样 x′∼p(x)x\\sim p(x)x′∼p(x)，那么 x′xx′ 就是我们想要生成的图像。 不过通常，p(x)p(x)p(x) 很难表示和学习。我们考虑通过两个步骤生成图像： 先生成图片的特征，例如想要生成二次元图片，就先指定 tags 例如发色、动作等等 在根据特征，去生成图像 我们用 zzz 表示图像的“特征” (latent variable)，那么这样的过程就是如同下面所示 z⟶guidex \\boxed{z}\\overset{\\text{guide}}{\\longrightarrow} \\boxed{x} z​⟶guide​x​用数学语言描述就是这样一个恒等式 p(x)=∑zp(x∣z)⋅p(z) p(x)=\\sum_z p(x|z)\\cdot p(z) p(x)=z∑​p(x∣z)⋅p(z)VAE 的推理从数学的角度也就变成了 Sample zzz from p(z)p(z)p(z) Sample xxx from p(x∣z)p(x|z)p(x∣z) 当然，由于我们的目的是简化 p(x)p(x)p(x) 的建模，因此我们通常假设 p(z)∼N(0,1)p(x∣z)∼N(μθ(z),Σθ(z)) \\begin{aligned} p(z)\\sim \\mathcal N(0,1)\\\\ p(x|z)\\sim \\mathcal N(\\mu_\\theta(z),\\Sigma_\\theta(z)) \\end{aligned} p(z)p(x∣z)​∼N(0,1)∼N(μθ​(z),Σθ​(z))​其中 μθ(⋅),Σθ(⋅)\\mu_\\theta(\\cdot),\\Sigma_\\theta(\\cdot)μθ​(⋅),Σθ​(⋅) 是神经网络。 这里也不一定非得是正态分布，其他容易计算的分布也可以。简单起见直接用正态分布了 Inference Inferencing Objective Function 给定一个数据集 D={x1,x2,…,xm}\\mathcal D=\\{x^{1}, x^{2}, \\dots, x^{m}\\}D={x1,x2,…,xm}，模型训练目标就是，从数据集 D\\mathcal DD 里训练的图像分布 pθ(x)p_\\theta(x)pθ​(x) 和真实的图像分布 p(x)p(x)p(x) 尽可能接近。衡量两个分布接近程度可以用 KL 散度，即训练目标为最小化 KL 散度： min⁡θDKL(pθ(x)∥p(x)) \\min_\\theta D_{KL}\\Big( p_\\theta(x) \\big\\| p(x) \\Big) θmin​DKL​(pθ​(x)​p(x))最小化 KL 散度等同于最大化 Marginal Log-Likelilhood log⁡pθ(x)\\log p_\\theta(x)logpθ​(x) over D\\mathcal DD max⁡θ∑xi∈Dlog⁡pθ(xi)=max⁡θ∑xi∈Dlog⁡(∑zpθ(xi,z)) \\begin{aligned} \\max_\\theta \\sum_{x^{i} \\in\\mathcal D} \\log p_\\theta(x^{i})\\\\ =\\max_\\theta \\sum_{x^{i} \\in\\mathcal D} \\log \\Big(\\sum_z p_\\theta(x^{i},z)\\Big) \\end{aligned} =​θmax​xi∈D∑​logpθ​(xi)θmax​xi∈D∑​log(z∑​pθ​(xi,z))​然而，zzz 是高维空间的隐变量，∑z\\sum_z∑z​ 需要遍历所有可能的 zzz、计算 pθ(xi,z)p_\\theta(x^{i},z)pθ​(xi,z)、再相加，几乎是不可能做到的，我们只能用各种方法去近似求解 log-likelihood via Monte Carlo 我们随机采样一些 zi∼p(z)z^{i} \\sim p(z)zi∼p(z)，用这些采样的 ziz^{i}zi 计算平均值： log⁡pθ(x)≈log⁡1k∑i=1kp(x∣zi),zi∼p(z) \\log p_\\theta(x)\\approx \\log \\frac{1}{k}\\sum_{i=1}^k p(x|z^{i}), \\quad z^{i}\\sim p(z) logpθ​(x)≈logk1​i=1∑k​p(x∣zi),zi∼p(z)尽管理论上，蒙特卡洛估计方法是 no-bias 的，但是在实战中，用蒙特卡洛计算出来的梯度具有很大的方差。 via Importance Sampling 比起直接 maximize 目标，我们也可以构造出目标的 lower bound 然后通过 maximize 这个 lower bound 从而 maximize 目标。 此处，log⁡pθ(x)\\log p_\\theta(x)logpθ​(x) 的一个下界被称为 ELBO (Evidence Lower Bound) pθ(x)=∑zq(z)q(z)pθ(x,z)=∑zq(z)⋅pθ(x,z)q(z)=Ez∼q(z)[pθ(x,z)q(z)]log⁡pθ(x)=log⁡Ez∼q(z)[pθ(x,z)q(z)]=log⁡∑zq(z)⋅pθ(x,z)q(z)≥∑zq(z)⋅log⁡pθ(x,z)q(z)‾by Jensen’s Inequality=Ez∼q(z)[log⁡pθ(x,z)q(z)]≔ELBO(x;θ)=Lθ(x) \\begin{aligned} p_\\theta(x) =\\sum_z \\frac{q(z)}{q(z)}p_\\theta(x,z)\\\\ =\\sum_z q(z)\\cdot \\frac{p_\\theta(x,z)}{q(z)}\\\\ =\\mathbb E_{z\\sim q(z)}\\Big[\\frac{p_\\theta(x,z)}{q(z)}\\Big]\\\\ \\log p_\\theta(x)=\\log \\mathbb E_{z\\sim q(z)}\\Big[ \\frac{p_\\theta(x,z)}{q(z)} \\Big]\\\\ = \\log \\sum_z q(z)\\cdot \\frac{p_\\theta(x,z)}{q(z)}\\\\ \\ge \\underset{\\scriptsize\\text{by Jensens Inequality}}{\\underline{\\sum_z q(z)\\cdot \\log\\frac{p_\\theta(x,z)}{q(z)}}}\\\\ =\\mathbb E_{z\\sim q(z)}\\Big[ \\log\\frac{p_\\theta(x,z)}{q(z)} \\Big]\\\\ \\coloneqq \\text{ELBO}(x;\\theta)=\\mathcal L_{\\theta}(x) \\end{aligned} pθ​(x)logpθ​(x)​=z∑​q(z)q(z)​pθ​(x,z)=z∑​q(z)⋅q(z)pθ​(x,z)​=Ez∼q(z)​[q(z)pθ​(x,z)​]=logEz∼q(z)​[q(z)pθ​(x,z)​]=logz∑​q(z)⋅q(z)pθ​(x,z)​≥by Jensen’s Inequalityz∑​q(z)⋅logq(z)pθ​(x,z)​​​=Ez∼q(z)​[logq(z)pθ​(x,z)​]:=ELBO(x;θ)=Lθ​(x)​ 从 KL 散度的视角理解 ELBO 而实际上 log⁡pθ(x)=Ez∼q(z)[log⁡pθ(x,z)]+H(q)entropy of q(z)‾ \\log p_\\theta(x)=\\mathbb E_{z\\sim q(z)}\\Big[ \\log p_\\theta(x,z) \\Big] + \\underset{\\overline{\\scriptsize\\text{entropy of }q(z)}}{H(q)} logpθ​(x)=Ez∼q(z)​[logpθ​(x,z)]+entropy of q(z)​H(q)​直觉上理解，我们选取的 q(z)q(z)q(z) 应该同模型从图像出发对特征的预测接近，即 DKL(q(z)∥pθ(z∣x)) D_{KL}\\Big( q(z) \\big\\| p_\\theta(z|x) \\Big) DKL​(q(z)​pθ​(z∣x))越小越好。而 DKL()D_{KL}()DKL​() 具有非负性，移项后便是 ELBO 的形式。一般形式的，也有 log⁡pθ(x)=ELBO+DKL(q(z)∥pθ(z∣x)) \\log p_\\theta(x)=\\text{ELBO}+D_{KL}\\Big( q(z)\\big\\|p_\\theta(z|x) \\Big) logpθ​(x)=ELBO+DKL​(q(z)​pθ​(z∣x)) 然后我们就又可以用 Monte Carlo 方法估计 ELBO 了。 ELBO(x;θ)≈1k∑i=1klog⁡pθ(x,zi)q(zi),zi∼q(z) \\text{ELBO}(x;\\theta)\\approx \\frac{1}{k}\\sum_{i=1}^k \\log\\frac{p_\\theta(x,z^{i})}{q(z^{i})},\\quad z^{i}\\sim q(z) ELBO(x;θ)≈k1​i=1∑k​logq(zi)pθ​(x,zi)​,zi∼q(z) VAE: Decoder 与 Encoder from Decoder to Encoder: Variational Inference 到目前位置，我们实际上只讨论了 Decoder 部分：pθ(x∣z)p_\\theta(x|z)pθ​(x∣z)。为了训练模型，我们肯定还需要 x→zx\\to zx→z 的推理与训练。这就是 VAE 里 Encoder 的作用。 Encoder 负责的就是 pθ(z∣x)p_\\theta(z|x)pθ​(z∣x)，但是 pθ(z∣x)p_\\theta(z|x)pθ​(z∣x) 很难从神经网络模型中推导出来。不过，根据上文对 ELBO 与 KL 散度 DKL(q(z)∥pθ(z∣x))D_{KL}\\Big( q(z)\\big\\| p_\\theta(z|x) \\Big)DKL​(q(z)​pθ​(z∣x)) 的分析，我们其实也可以通过优化 q(z)q(z)q(z) 让其近似 pθ(z∣x)p_\\theta(z|x)pθ​(z∣x) 来达成相同的目的。 所以，我们把 q(z)q(z)q(z) 也用神经网络建模为 qϕ(z)q_\\phi(z)qϕ​(z)，其中 ϕ\\phiϕ 为 Encoder 模型的参数，此时 ELBO 改写为 ELBO=Lθ,ϕ(x)=∑zqϕ(z)log⁡pθ(z,x)+H(qϕ(z)) \\text{ELBO}=\\mathcal L_{\\theta,\\phi}(x)=\\sum_z q_\\phi(z)\\log p_\\theta(z,x)+H(q_\\phi(z)) ELBO=Lθ,ϕ​(x)=z∑​qϕ​(z)logpθ​(z,x)+H(qϕ​(z)) Amortized Inference 注意：这里的 Decoder 与 Encoder 本质上是对分布进行建模，即给定张量，输出一个分布。 如果 Encoder 部分我们为每一个输入的图像都训练一个 Encoder qϕ(z)q_\\phi(z)qϕ​(z)，计算代价无法承受。 因此，我们用神经网络对分布进行拟合，即 gλ:xi↦qϕi(z)g_\\lambda:x^{i} \\mapsto q_{\\phi^{i}}(z)gλ​:xi↦qϕi​(z)，这样就可以避免反复求解 ϕi\\phi^{i}ϕi 了。 而对 Decoder 部分就不用了，因为 pθ(x∣z)p_\\theta(x|z)pθ​(x∣z) 的 zzz 是由 Encoder 完成的，而每一个而 Encoder 总是输出的 qϕ(z)≈pθ(z∣x)q_\\phi(z)\\approx p_\\theta(z|x)qϕ​(z)≈pθ​(z∣x) 总是映射到同一个 random variable space 里. Training VAE 有一个 Encoder 架构，负责将图像 xxx 编码为 latent variable zzz；Decoder 架构则负责从 latent variable zzz 生成出图像 xxx. VAE 上文的 ELBO 则为我们优化 VAE 模型提供了一个良好的目标函数：（其实应该是求解上文的 λ\\lambdaλ） max⁡θ,ϕELBO=max⁡θ∑x∈Dmax⁡ϕEqϕ(z)[log⁡pθ(z,x)qϕ(z)]⇒max⁡θ,λ∑x∈Dmax⁡λEgλ(x)[log⁡pθ(z,x)gλ(x)] \\begin{aligned} \\max_{\\theta,\\phi}\\text{ELBO}=\\max_{\\theta}\\sum_{x\\in\\mathcal D}\\max_{\\phi}\\mathbb E_{q_\\phi(z)}\\Bigg[ \\log\\frac{p_\\theta(z,x)}{q_\\phi(z)} \\Bigg]\\\\ \\Rightarrow\\max_{\\theta,\\lambda}\\sum_{x\\in\\mathcal D}\\max_\\lambda\\mathbb E_{g_\\lambda(x)}\\Bigg[ \\log\\frac{p_\\theta(z,x)}{g_\\lambda(x)} \\Bigg] \\end{aligned} θ,ϕmax​ELBO​=θmax​x∈D∑​ϕmax​Eqϕ​(z)​[logqϕ​(z)pθ​(z,x)​]⇒θ,λmax​x∈D∑​λmax​Egλ​(x)​[loggλ​(x)pθ​(z,x)​]​ Stochastic Variational Inference 用随机梯度下降法进行学习 初始化 θ,ϕ1…m\\theta,\\phi^{1\\dots m}θ,ϕ1…m 随机一个 xi∈Dx^{i} \\in\\mathcal Dxi∈D 先优化 ϕi\\phi^{i}ϕi： ϕi←ϕi+η∇ϕiLθ,ϕ(xi)\\phi^{i}\\gets \\phi^{i}+\\eta abla_{\\phi^{i}}\\mathcal L_{\\theta,\\phi}(x^{i})ϕi←ϕi+η∇ϕi​Lθ,ϕ​(xi) 直到收敛为止 更新 θ\\thetaθ：θ←θ+η∇θLθ,ϕi(xi)\\theta\\gets\\theta+\\eta abla_{\\theta}\\mathcal L_{\\theta,\\phi^{i}}(x^{i})θ←θ+η∇θ​Lθ,ϕi​(xi)。回到 step 2 继续执行。 那么我们如何计算梯度呢？因为很有可能这个式子并不存在 closed form，我们依然采用 Monte Carlo 的方法解决问题，即 Eqϕ(z)[log⁡pθ(z,x)−log⁡qϕ(z)]≈1K∑i=1Klog⁡pθ(zi,x)−log⁡qϕ(zi) \\mathbb E_{q_\\phi(z)}\\Bigg[ \\log p_\\theta(z,x)-\\log q_\\phi(z) \\Bigg]\\approx \\frac{1}{K}\\sum_{i=1}^{K}\\log p_\\theta(z^{i},x)-\\log q_\\phi(z^{i}) Eqϕ​(z)​[logpθ​(z,x)−logqϕ​(z)]≈K1​i=1∑K​logpθ​(zi,x)−logqϕ​(zi)其中 qϕ(z)q_\\phi(z)qϕ​(z) 应该容易采样和计算。由此，ELBO 关于 θ\\thetaθ 的导数即为 ∇θEqϕ(z)[log⁡pθ(z,x)−log⁡qϕ(z)]≈1K∑i=1K∇θlog⁡pθ(zi,x) abla_\\theta \\mathbb E_{q_\\phi(z)}\\Bigg[ \\log p_\\theta(z,x)-\\log q_\\phi(z) \\Bigg]\\approx \\frac{1}{K}\\sum_{i=1}^K abla_\\theta \\log p_\\theta(z^{i},x) ∇θ​Eqϕ​(z)​[logpθ​(z,x)−logqϕ​(z)]≈K1​i=1∑K​∇θ​logpθ​(zi,x)然而 ELBO 关于 ϕi\\phi^iϕi 的导数不那么好算，因为期望本身依赖于这个参数。一般而言，可以使用强化学习的方法进行学习，也可以使用 Reparameterization 的方法。 Reparam 我们把 qϕ(z)∼N(μ,σ2I)q_\\phi(z)\\sim \\mathcal N(\\mu, \\sigma^2 I)qϕ​(z)∼N(μ,σ2I)，即 ϕi=(μ,σ)\\phi^i=(\\mu,\\sigma)ϕi=(μ,σ)，那么从这个正态分布采样就等同于 ϵ∼N(0,1)z=μ+σϵ=gϕ(ϵ) \\epsilon\\sim \\mathcal N(0,1)\\\\ z=\\mu+\\sigma\\epsilon=g_\\phi(\\epsilon) ϵ∼N(0,1)z=μ+σϵ=gϕ​(ϵ)借用这个想法，我们可以改写 ELBO，这里先让 r(z)=log⁡qϕ(z)r(z)=\\log q_\\phi(z)r(z)=logqϕ​(z) 简化计算，稍后再代入 Ez∼qϕ(z)[r(z)]=∑zqϕ(z)r(z)=Eϵ∼N(0,1)[r(gϕ(ϵ))]=∫N(ϵ)r(μ+σϵ)dϵ∇ϕEqϕ(z)[r(z)]=∇ϕEϵ[r(gϕ(ϵ))]=Eϵ[∇ϕr(gϕ(ϵ))]≈1K∑i=1Kr(gϕ(ϵi))‾Monte Carlo Estim \\begin{aligned} \\mathbb E_{z\\sim q_\\phi(z)}[r(z)]=\\sum_z q_\\phi(z)r(z)\\\\ =\\mathbb E_{\\epsilon\\sim\\mathcal N(0,1)}[r(g_\\phi(\\epsilon))]\\\\ =\\int \\mathcal N(\\epsilon) r(\\mu+\\sigma\\epsilon) d\\epsilon\\\\ abla_\\phi \\mathbb E_{q_\\phi(z)}[r(z)]= abla_\\phi \\mathbb E_\\epsilon [r(g_\\phi(\\epsilon))]\\\\ =\\mathbb E_{\\epsilon}[ abla_\\phi r(g_\\phi(\\epsilon))]\\\\ \\approx \\underset{\\text{Monte Carlo Estim}}{\\underline{\\frac{1}{K}\\sum_{i=1}^K r(g_\\phi(\\epsilon^i))}} \\end{aligned} Ez∼qϕ​(z)​[r(z)]∇ϕ​Eqϕ​(z)​[r(z)]​=z∑​qϕ​(z)r(z)=Eϵ∼N(0,1)​[r(gϕ​(ϵ))]=∫N(ϵ)r(μ+σϵ)dϵ=∇ϕ​Eϵ​[r(gϕ​(ϵ))]=Eϵ​[∇ϕ​r(gϕ​(ϵ))]≈Monte Carlo EstimK1​i=1∑K​r(gϕ​(ϵi))​​​"},{"title":"ViT","path":"/wiki/multimodal/ViT.html","content":"372f7a9688aae3bb4ec6e6afab19ca439bb95e6d91164a50dda5c3f9a4f813ff Password is needed."},{"title":"LightRAG","path":"/wiki/rag/LightRAG.html","content":"LightRAG Overview LightRAG 是由 香港大学研究团队 推出的一种轻量级检索增强生成（Retrieval-Augmented Generation, RAG）系统，通过整合 图结构索引 和 双层检索机制，显著提升了大型语言模型（LLM）在信息检索中的准确性与效率 。其核心特点是： 轻量化设计 相较于传统的 GraphRAG，LightRAG 通过简化知识图谱构建流程和减少冗余计算，大幅降低了资源消耗和 API 调用成本，在动态数据环境中更新速度更快、维护更灵活 。 双层检索架构 LightRAG 结合关键词匹配与语义向量检索：第一层快速定位实体及关联关系，第二层通过向量数据库（如 Milvus 或 TiDB Vector）补充相关片段，兼顾效率与精度 。 动态数据支持 系统支持增量更新，能够高效处理实时变化的数据源，适应动态环境下的检索需求 。 成本效益 实验表明，LightRAG 在保证检索质量的同时，能显著降低大模型问答的计算成本，适用于高并发或预算受限的场景 。 LightRAG"},{"title":"基于 Nano GraphRAG 的二次开发","path":"/wiki/rag/build-on-nano-graphrag.html","content":"本地部署 LLM"},{"title":"Dify 中使用 HTTP Request 配合 Flask 进行高级数据处理","path":"/wiki/rag/custom-data-process.html","content":"Flask Server"},{"title":"GraphRAG 解读","path":"/wiki/rag/graph-rag.html","content":"算法流程 GraphRAG WorkFlow Overview NanoGraphRAG 工作流程 Chunk Documents graph LR A(Document) --> B(Text Chunk 1) A --> C(Text Chunk 2) 像普通的 VectorRAG 一样，提取出来的 Text Chunk 可以用于后续 LLM 的知识来源。 NanoGraphRAG 源码解读 Extract Entity and Relationships Graph Indexing Graph Decomposition"},{"title":"NanoGraphRAG项目思路（一）：文档分块","path":"/wiki/rag/nano-graph-rag-p1.html","content":"Phase 1: 文档预处理 (论文 3.1.1) 在 Nano GraphRAG 里，预处理文档的任务在 GraphRAG.ainsert() 中完成。GraphRAG.ainsert() 由 GraphRAG.insert() 调用，并且使用了 asyncio.get_event_loop() 保证执行完毕。 文档去重 ainsert() 首先计算文档的 MD5 哈希值，检查文档是否已经添加过了。如果已经添加过了，那么就不用再插入数据库。 new_docs 首先准备所有待检查的字符串，计算其哈希值。 new_docs = compute_mdhash_id(c.strip(), prefix=doc-): content: c.strip() for c in string_or_strings 然后丢入 self.full_docs 检查是否有重复的字符串并剔除 _add_doc_keys = await self.full_docs.filter_keys(list(new_docs.keys())) 剔除完成后的字符串拼接成 hash: str 形式的字典重新赋值回 new_docs. new_docs = k: v for k, v in new_docs.items() if k in _add_doc_keys 如果没有新文档，直接退出。然后输出一点调试日志 if not len(new_docs): logger.warning(fAll docs are already in the storage) returnlogger.info(f[New Docs] inserting len(new_docs) docs) 文档分块 Text Chunk 否则，准备插入文档。先对文档 get_chunk() 拆分成若干个 text chunks inserting_chunks = get_chunks( new_docs=new_docs, # 要切分的文档 chunk_func=self.chunk_func, # chunk 切分方法，默认按 token 数量 overlap_token_size=self.chunk_overlap_token_size, # chunk 之间重叠的 token 数量，充当上下文的作用 max_token_size=self.chunk_token_size, # 一个 chunk 最多多少 token) 然后 get_chunk() 加载 Tokenizer (这里调用的是 OpenAI tiktoken 的库)，将 docs（纯文本）转化为 Tokens，再调用 chunk_func 进行切块，每一块都标注成 tokens: token 个数, content: token 内容（已经不是文本了）, chunk_order_index: 是第几个 chunk, full_doc_id: 所属文档的哈希值, 标注完成后，再为每一个 text chunk 计算哈希值 chunk-xxxxx，放入 inserting_chunk 并返回 Text Chunk 去重 对 text chunks 也进行去重 _add_chunk_keys = await self.text_chunks.filter_keys( list(inserting_chunks.keys()))inserting_chunks = k: v for k, v in inserting_chunks.items() if k in _add_chunk_keysif not len(inserting_chunks): logger.warning(fAll chunks are already in the storage) returnlogger.info(f[New Chunks] inserting len(inserting_chunks) chunks)if self.enable_naive_rag: logger.info(Insert chunks for naive RAG) await self.chunks_vdb.upsert(inserting_chunks) 和文档去重的逻辑很相似，就是在 KVStorage 里按哈希值查找，去重 更新数据库 这里有另一点比较重要的是，如果需要插入新的 chunk，那么首先需要把 self.community_reports 清空。因为插入新块后，可能这个文档的 community 就会改变 await self.community_reports.drop()"},{"title":"强化学习研究的是什么？","path":"/wiki/rl/what-is-rl.html","content":"强化学习研究的是什么？ 强化学习的研究目标可以概括为一句话：在特定的环境 (Environment) 下，智能体 (Agent) 如何通过和环境的交互，学习一个策略 (Policy)，使其在长期内获得最大的累计奖励。 强化学习的目标 .typst-text { pointer-events: bounding-box; } .tsel span, .tsel { left: 0; position: fixed; text-align: justify; white-space: nowrap; width: 100%; height: 100%; text-align-last: justify; color: transparent; white-space: pre; } .tsel span::-moz-selection, .tsel::-moz-selection { color: transparent; background: #7db9dea0; } .tsel span::selection, .tsel::selection { color: transparent; background: #7db9dea0; } .pseudo-link { fill: transparent; cursor: pointer; pointer-events: all; } svg { fill: none; } .outline_glyph path, path.outline_glyph { fill: var(--glyph_fill); stroke: var(--glyph_stroke); } .outline_glyph path, path.outline_glyph { transition: 0.2s fill stroke; } .hover .typst-text { --glyph_fill: #66bab7; --glyph_stroke: #66bab7; } .typst-jump-ripple, .typst-debug-react-ripple { width: 0; height: 0; background-color: transparent; position: absolute; border-radius: 50%; } .typst-jump-ripple { border: 1px solid #66bab7; } .typst-debug-react-ripple { border: 1px solid #cb1b45; } @keyframes typst-jump-ripple-effect { to { width: 10vw; height: 10vw; opacity: 0.01; margin: -5vw; } } @keyframes typst-debug-react-ripple-effect { to { width: 3vw; height: 3vw; opacity: 0.01; margin: -1.5vw; } } •State 𝑠∈𝑆, 表示 agent 在环境中所有可能的状态•Action 𝑎∈𝐴, 表示 agent 在环境中所有可以进行的动作 因此，从环境的视角来看，agent 实际上不断地在产生 State, Action, State, Action, … 的数据：agent 每一次行动都会导致自己的 state 发生变化。 (s0,a0,s1,a1,s2,a2,… ) (s_0,a_0,s_1,a_1,s_2,a_2,\\dots) (s0​,a0​,s1​,a1​,s2​,a2​,…)agent 通过和环境的交互学习如何根据环境和状态决定自己下一步的动作，也就是 policy. 我们可以把 policy 看成是一个函数：接收当前 state 作为参数，输出 action 表示当前 state 下应该怎么行动 Policyπ:S↦A \\text{Policy}\\quad \\pi: S \\mapsto A Policyπ:S↦A那么我们怎么让 agent 学习 action 呢？如果我们希望 agent 按照我们预想的那样，在特定的 state 下学习到应该走出特定的步骤，我们该怎么诱导 agent 呢？就是利用 Reward 机制，诱导 agent 向着 Reward 更大的方向行动，就好像我们玩游戏的时候也是朝着让自己更加“强大”的方向去打怪升级。 于是我们就需要给 agent 的每一次行动进行“打分”，告诉 agent 你这一步棋走的好不好。我们可以把 Reward 也看成一个函数，给定 sss 当前的状态、aaa 采取的行动、s′ss′ 行动完后的状态，来判断这个行动是不是 OK. R(s′∣s,a)∈R R(s\\vert s,a) \\in \\R R(s′∣s,a)∈R于是考虑上 reward 的话，agent 的动作 sequence 就变成了 (s0,a0,r0,s1,a1,r1,s2,a2,r2,… ) (s_0,a_0,r_0,s_1,a_1,r_1,s_2,a_2,r_2,\\dots) (s0​,a0​,r0​,s1​,a1​,r1​,s2​,a2​,r2​,…) 传统强化学习算法: Deterministic Approach 传统强化学习算法简而言之就是 现代强化学习: Vision + Language + Action"},{"title":"基础","path":"/wiki/rustbook/basics.html","content":"流程控制"},{"title":"泛型、模板","path":"/wiki/rustbook/generic.html","content":"泛型（对标 C++ 模板） 函数、方法、结构体、枚举都可以使用泛型。 Type Annotation 明确指出泛型的类型需要满足什么条件。 函数泛型/函数模板 fn funcT(a: T) template typename Tvoid function(T a) 方法泛型/方法模板 可以包含其他的类型 implT PointT fn funcU(self) - T // 等价于 ...... template typename Tclass Point template typename U T func() const 泛型、模板参数 对应 C++ 中 template int N 这样的模板参数。 fn funcT, const N: usize(arr: [T; N]) template typename T, size_t Nvoid func(std::arrayT, N arr) 针对 const 泛型做检查 这个在 C++ 里应该需要使用 require 做检查，我还没有研究过。Rust 里使用 Assert: IsTrue 泛型限制即可。 fn somethingT(val: T)where Assert core::mem::size_of::T() 768 : IsTrue, // ^ 这里是一个 const 表达式，换成其它的 const 表达式也可以 // const fn 对应 C++ 的 constexpr，在编译期求值。"},{"title":"深入特征","path":"/wiki/rustbook/more-traits.html","content":"关联类型 pub trait Iterator type Item; fn next(mut self) - OptionSelf::Item; why not Generics? 使用泛型：trait ContainerA, B fn contains(self, a: A, b: B) - bool;fn differenceA, B, C(container: C) - i32 where C : ContainerA, B ... 使用关联类型trait Container type A; type B; fn contains(self, a: Self::A, b: Self::B) - bool;fn differenceC: Container(container: C) 特征和类型都有同名方法 优先调用类型上的方法 显示通过特征调用方法 // for example ...Trait.method(object); 用完全限定语法，让类型使用某个特征的方法（也可适用于 2） // like thisType as Trait::function(receiver_if_method, other_arguments...); 特征定义中的特征约束 trait X: Y 如果你想要实现 X 特征，首先你需要实现 Y 特征。 外部类型上实现外部特征"},{"title":"所有权","path":"/wiki/rustbook/ownership.html","content":"所有权"},{"title":"特征、特征对象","path":"/wiki/rustbook/traits.html","content":"Traits 特征定义了一组可以被共享的行为，只要实现了特征，你就能使用这组行为。 Trait 实现：孤儿规则 如果你想要为类型 A 实现特征 T，那么 A 或者 T 至少有一个是在当前作用域中定义的！ 使用特征作为函数参数 意义：所有实现了 Trait 这个特征的类型 fn func(item: impl Trait) 本质是泛型的语法糖： fn funcT: Trait(item: T) derive 派生 特征作为返回值 返回一个对象，这个对象实现了 Summary 特征 fn func(...) - impl Summary 问题：最终 impl Summary 只能对应一个类型，如果想做到 if .. return A else return B 是不行的 在 C++ 里，我们可以用继承的方式，返回父类指针。在 Rust 里应该怎么做呢？ 在 Rust 里，我们使用 Boxdyn Trait 或者 dyn Trait，两者的区别在于：前者是通过 Box::new() 在堆上创建的新变量，后者是对已有的变量的引用。 特征对象的动态分发 当使用特征对象时，Rust 必须使用动态分发。编译器无法知晓所有可能用于特征对象代码的类型，所以它也不知道应该调用哪个类型的哪个方法实现。为此，Rust 在运行时使用特征对象中的指针来知晓需要调用哪个方法。动态分发也阻止编译器有选择的内联方法代码，这会相应的禁用一些优化。 trait object 虽然特征对象没有固定大小，但它的引用类型的大小是固定的，它由两个指针组成（ptr 和 vptr），因此占用两个指针大小 一个指针 ptr 指向实现了特征 Draw 的具体类型的实例，也就是当作特征 Draw 来用的类型的实例，比如类型 Button 的实例、类型 SelectBox 的实例 另一个指针 vptr 指向一个虚表 vtable，vtable 中保存了类型 Button 或类型 SelectBox 的实例对于可以调用的实现于特征 Draw 的方法。当调用方法时，直接从 vtable 中找到方法并调用。之所以要使用一个 vtable 来保存各实例的方法，是因为实现了特征 Draw 的类型有多种，这些类型拥有的方法各不相同，当将这些类型的实例都当作特征 Draw 来使用时(此时，它们全都看作是特征 Draw 类型的实例)，有必要区分这些实例各自有哪些方法可调用 但是虚表里只会保存 Draw 特征的方法 struct A impl A fn foo(self) println!(A::foo); struct B impl B fn foo(self) println!(B::foo); trait Bar fn bar(self);impl Bar for A fn bar(self) println!(A::bar); impl Bar for B fn bar(self) println!(B::bar); fn main() let mut v = Vec::Boxdyn Bar::new(); v.push(Box::new(A)); v.push(Box::new(B)); for item in v.iter() item.bar(); // item.foo(); // This line will cause a compile-time error 特征对象的限制 必须满足下列所有条件： 返回类型不能是 Self 如果特征方法返回了具体的 Self 类型，但是特征对象忘记了其真正的类型（特征对象只知道这个类型实现了某个 Trait），那这个 Self 就非常尴尬，因为没人知道它是谁了。 没有泛型参数 对于泛型类型参数来说，当使用特征时其会放入具体的类型参数：此具体类型变成了实现该特征的类型的一部分。而当使用特征对象时其具体类型被抹去了，故而无从得知放入泛型参数类型到底是什么。 针对第一点的解释 考虑这么一段代码 trait Trait fn foo(self) - Self;fn call_foo(x: Boxdyn Trait) let y = x.foo(); // What type is y? // ... 我们只能推断出 y 的类型是某个实现了 Trait 特征的类型， 针对第二点的解释 trait Trait fn fooT(self, on: T); // more methodsimpl Trait for String fn fooT(self, on: T) // implementation 1 impl Trait for u8 fn fooT(self, on: T) // implementation 2 // 8 more implementations 考虑这样的调用 fn call_foo(thing: Boxdyn Trait) thing.foo(true); // this could be any one of the 8 types above thing.foo(1); thing.foo(hello); Rust 针对泛型的处理又是单态化，这意味着这样一结合，Rust 代码会出现 303030 种实现，全都是泛型的单态化展开。"},{"title":"Isaac Lab(Sim) 简介","path":"/wiki/simulation/isaac-lab-brief.html","content":"Assets Isaac Sim Has more built-in scenes and robots available Classic: Cartpole, Humanoid, Ant Fixed-Arm and Hands: UR10, Franka, Allegro, Shadow Hand Quadrupeds: Anybotics Anymal-B, Anymal-C, Anymal-D, Unitree A1, Unitree Go1, Unitree Go2, Boston Dynamics Spot Humanoids: Unitree H1, Unitree G1 Quadcopter: Crazyflie Procedure Isaac Lab: Manager Method: More specified control Direct Method: Similar to Maniskill. Example of Direct Method: def _get_rewards(self) - torch.Tensor: total_reward = compute_rewards( self.cfg.rew_scale_alive, self.cfg.rew_scale_terminated, self.cfg.rew_scale_pole_pos, self.cfg.rew_scale_cart_vel, self.cfg.rew_scale_pole_vel, self.joint_pos[:, self._pole_dof_idx[0]], self.joint_vel[:, self._pole_dof_idx[0]], self.joint_pos[:, self._cart_dof_idx[0]], self.joint_vel[:, self._cart_dof_idx[0]], self.reset_terminated, ) return total_reward@torch.jit.scriptdef compute_rewards( rew_scale_alive: float, rew_scale_terminated: float, rew_scale_pole_pos: float, rew_scale_cart_vel: float, rew_scale_pole_vel: float, pole_pos: torch.Tensor, pole_vel: torch.Tensor, cart_pos: torch.Tensor, cart_vel: torch.Tensor, reset_terminated: torch.Tensor,): rew_alive = rew_scale_alive * (1.0 - reset_terminated.float()) rew_termination = rew_scale_terminated * reset_terminated.float() rew_pole_pos = rew_scale_pole_pos * torch.sum(torch.square(pole_pos).unsqueeze(dim=1), dim=-1) rew_cart_vel = rew_scale_cart_vel * torch.sum(torch.abs(cart_vel).unsqueeze(dim=1), dim=-1) rew_pole_vel = rew_scale_pole_vel * torch.sum(torch.abs(pole_vel).unsqueeze(dim=1), dim=-1) total_reward = rew_alive + rew_termination + rew_pole_pos + rew_cart_vel + rew_pole_vel return total_reward Tasks"},{"title":"ManiSkill 物理仿真：编写 Tasks for RL","path":"/wiki/simulation/maniskill-testcase.html","content":"Task Components 较为繁琐的说法 Setting up the Task Class Loading (Robots, Assets, Sensors, etc.) (run once) Episode initialization / Randomization (run every env.reset) Success/Failure Condition (run every env.step) Extra Observations (run every env.step) (Optional) Dense Reward Function (run every env.step) (Optional) Setting up cameras/sensors for observations and rendering/recording (run once) 最简工作流示例 env init env.step 负责根据 Action，然后在物理仿真，模拟无理式解的变化，并计算 Reward。 env.step 简单来说，一个类包含这些元素： @register_env() 方便外部调用 class CustomEnv(BaseEnv) 使用继承，快速开发新 Testcase （成员变量）SUPPORTED_ROBOTS = [] 定义该 Testcase 里使用的 Robot （成员变量）agent: Union[...] Robot，也即 Agent Environment Class 首先，我们定义一个类继承 BaseEnv，这个类是我们初始化 Environment 的入口。同时需要调用 mani_skill.utils.registeration.register_env() 函数进行“注册”（主要是定义名称和限定最大迭代步数） @register_env(CustomEnv-v1, max_episode_steps=200)class CustomEnv(BaseEnv): 然后我们在这个环境里定义我们需要的 Agent 定义物体 位置与朝向 建议在 _load_scene() 的时候就设置一次位置与朝向，然后在 _initialize_episode() 中"},{"title":"llama.cpp 常用 API","path":"/wiki/usefulAPIs/llama-cpp.html","content":"Preliminary: 启动一个 llama.cpp server llama-server 的 API"},{"title":"django 表单","path":"/wiki/web_fullstack/django-forms.html","content":"django.forms.Form 类 在 Form 里定义需要填写的栏目，这样就可以直接在 template 里渲染了"},{"title":"vllm 服务器 API 与示例","path":"/wiki/usefulAPIs/vllm-server.html","content":"vllm 部署 embedding 模型 vllm 部署 Vision Language Model, LLM 选用的是 Qwen/Qwen2.5-VL-3B-Instruct vllm 部署命令： $"},{"title":"Django 模板","path":"/wiki/web_fullstack/django-template.html","content":"Django 模板 Django 模板的作用是，可以根据数据动态地展示网页。例如，可以根据用户的权限，选择向用户展示 dashboard 或者登录界面。 与 views.py 交互"}]